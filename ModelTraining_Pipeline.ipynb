{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyOJS4gHNvraPbDqTVYnVcCe"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Model Training & Evaluation Pipeline"
      ],
      "metadata": {
        "id": "COF7WWOtCQRP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Details: [Model Training Specifications](https://docs.google.com/document/d/1UiDi8nyTcfMeMNIAz3KntlVZBlYrpoMAURuDccTt-wk/edit?usp=sharing)\n",
        "\n",
        "Model Evaluation: Identify best parameters for each model"
      ],
      "metadata": {
        "id": "kNbJ7WYUXWks"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "qK_KRJw0rpA9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0c9bb39c-06aa-458b-c362-4ed7bcdacc30"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "# Basic Libraries\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sb\n",
        "import matplotlib.pyplot as plt\n",
        "from datetime import datetime\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Data Source\n",
        "\n",
        "df = pd.read_csv(\"/content/drive/MyDrive/Senior Project/Datasets/cleaned_gee_data.csv\")\n",
        "df = df.drop(columns = ['Unnamed: 0'], axis=1)\n",
        "df.head()"
      ],
      "metadata": {
        "id": "BTKpuPDqvTli",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "outputId": "68f18206-6b85-431d-b6f6-0f0d419c5a33"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   LATITUDE  LONGITUDE  ACQ_DATE  ACQ_TIME  OPEN_TIME  CLOSE_TIME  BRIGHTNESS  \\\n",
              "0 -5.466232  -0.176027 -1.866392  0.634294   0.506405    0.526945   -2.231078   \n",
              "1 -5.466232  -0.176027 -1.866392  0.634294   0.506405    0.526945   -2.231078   \n",
              "2 -5.466232  -0.176027 -1.866392  0.634294   0.506405    0.526945   -2.231078   \n",
              "3 -5.466232  -0.176027 -1.866392  0.634294   0.506405    0.526945   -2.231078   \n",
              "4 -5.433352  -0.197441 -1.723773  0.634294   2.286080    1.793843   -1.141613   \n",
              "\n",
              "   FIRE_OCCURRED  CO_MOL/M2  SO2_MOL/M2  NO2_MOL/M2  O3_MOL/M2  LOCATION  \\\n",
              "0              0  -0.024223   -0.474440   -1.152277  -0.511001 -1.159086   \n",
              "1              0   0.113599   -0.474440   -1.152277  -0.511001 -1.159086   \n",
              "2              0  -0.024223   -0.474440   -1.361255  -0.511001 -1.159086   \n",
              "3              0   0.113599   -0.474440   -1.361255  -0.511001 -1.159086   \n",
              "4              0  -0.967684    0.339667   -1.251770   0.426114 -1.159086   \n",
              "\n",
              "   INSTRUMENT  DRY_SEASON  \n",
              "0           0           1  \n",
              "1           0           1  \n",
              "2           0           1  \n",
              "3           0           1  \n",
              "4           0           1  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-81f43fef-4944-49e8-8275-70e33b6c5dbf\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>LATITUDE</th>\n",
              "      <th>LONGITUDE</th>\n",
              "      <th>ACQ_DATE</th>\n",
              "      <th>ACQ_TIME</th>\n",
              "      <th>OPEN_TIME</th>\n",
              "      <th>CLOSE_TIME</th>\n",
              "      <th>BRIGHTNESS</th>\n",
              "      <th>FIRE_OCCURRED</th>\n",
              "      <th>CO_MOL/M2</th>\n",
              "      <th>SO2_MOL/M2</th>\n",
              "      <th>NO2_MOL/M2</th>\n",
              "      <th>O3_MOL/M2</th>\n",
              "      <th>LOCATION</th>\n",
              "      <th>INSTRUMENT</th>\n",
              "      <th>DRY_SEASON</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>-5.466232</td>\n",
              "      <td>-0.176027</td>\n",
              "      <td>-1.866392</td>\n",
              "      <td>0.634294</td>\n",
              "      <td>0.506405</td>\n",
              "      <td>0.526945</td>\n",
              "      <td>-2.231078</td>\n",
              "      <td>0</td>\n",
              "      <td>-0.024223</td>\n",
              "      <td>-0.474440</td>\n",
              "      <td>-1.152277</td>\n",
              "      <td>-0.511001</td>\n",
              "      <td>-1.159086</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>-5.466232</td>\n",
              "      <td>-0.176027</td>\n",
              "      <td>-1.866392</td>\n",
              "      <td>0.634294</td>\n",
              "      <td>0.506405</td>\n",
              "      <td>0.526945</td>\n",
              "      <td>-2.231078</td>\n",
              "      <td>0</td>\n",
              "      <td>0.113599</td>\n",
              "      <td>-0.474440</td>\n",
              "      <td>-1.152277</td>\n",
              "      <td>-0.511001</td>\n",
              "      <td>-1.159086</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>-5.466232</td>\n",
              "      <td>-0.176027</td>\n",
              "      <td>-1.866392</td>\n",
              "      <td>0.634294</td>\n",
              "      <td>0.506405</td>\n",
              "      <td>0.526945</td>\n",
              "      <td>-2.231078</td>\n",
              "      <td>0</td>\n",
              "      <td>-0.024223</td>\n",
              "      <td>-0.474440</td>\n",
              "      <td>-1.361255</td>\n",
              "      <td>-0.511001</td>\n",
              "      <td>-1.159086</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>-5.466232</td>\n",
              "      <td>-0.176027</td>\n",
              "      <td>-1.866392</td>\n",
              "      <td>0.634294</td>\n",
              "      <td>0.506405</td>\n",
              "      <td>0.526945</td>\n",
              "      <td>-2.231078</td>\n",
              "      <td>0</td>\n",
              "      <td>0.113599</td>\n",
              "      <td>-0.474440</td>\n",
              "      <td>-1.361255</td>\n",
              "      <td>-0.511001</td>\n",
              "      <td>-1.159086</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>-5.433352</td>\n",
              "      <td>-0.197441</td>\n",
              "      <td>-1.723773</td>\n",
              "      <td>0.634294</td>\n",
              "      <td>2.286080</td>\n",
              "      <td>1.793843</td>\n",
              "      <td>-1.141613</td>\n",
              "      <td>0</td>\n",
              "      <td>-0.967684</td>\n",
              "      <td>0.339667</td>\n",
              "      <td>-1.251770</td>\n",
              "      <td>0.426114</td>\n",
              "      <td>-1.159086</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-81f43fef-4944-49e8-8275-70e33b6c5dbf')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-81f43fef-4944-49e8-8275-70e33b6c5dbf button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-81f43fef-4944-49e8-8275-70e33b6c5dbf');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vigF6PJAfy9R",
        "outputId": "bda643ff-20ce-40a9-b956-e7156e341e59"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 171893 entries, 0 to 171892\n",
            "Data columns (total 15 columns):\n",
            " #   Column         Non-Null Count   Dtype  \n",
            "---  ------         --------------   -----  \n",
            " 0   LATITUDE       171893 non-null  float64\n",
            " 1   LONGITUDE      171893 non-null  float64\n",
            " 2   ACQ_DATE       171893 non-null  float64\n",
            " 3   ACQ_TIME       171893 non-null  float64\n",
            " 4   OPEN_TIME      171893 non-null  float64\n",
            " 5   CLOSE_TIME     171893 non-null  float64\n",
            " 6   BRIGHTNESS     171893 non-null  float64\n",
            " 7   FIRE_OCCURRED  171893 non-null  int64  \n",
            " 8   CO_MOL/M2      171893 non-null  float64\n",
            " 9   SO2_MOL/M2     171893 non-null  float64\n",
            " 10  NO2_MOL/M2     171893 non-null  float64\n",
            " 11  O3_MOL/M2      171893 non-null  float64\n",
            " 12  LOCATION       171893 non-null  float64\n",
            " 13  INSTRUMENT     171893 non-null  int64  \n",
            " 14  DRY_SEASON     171893 non-null  int64  \n",
            "dtypes: float64(12), int64(3)\n",
            "memory usage: 19.7 MB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "display(df['FIRE_OCCURRED'].value_counts())"
      ],
      "metadata": {
        "id": "2z3siI-MvbQs",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "outputId": "d7ec4676-6a77-421e-865a-8ee0d4d6d6e0"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "0    170544\n",
              "1      1349\n",
              "Name: FIRE_OCCURRED, dtype: int64"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "0.78% of FIRE_OCCURRED = 1"
      ],
      "metadata": {
        "id": "bmVgX-C_pJrz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X = df.drop('FIRE_OCCURRED', axis=1)\n",
        "y = df['FIRE_OCCURRED']"
      ],
      "metadata": {
        "id": "GEBLWi5ooiTO"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Training, Validation, Testing Split\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# 80:10:10\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.10, random_state=10, shuffle=True)\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=1/9, random_state=10, shuffle=True)\n",
        "\n",
        "Original = [X_train, X_val, X_test, y_train, y_val, y_test] # For reference"
      ],
      "metadata": {
        "id": "96m0rNH7vhDg"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if len(X_train)==len(y_train) and len(X_test) == len(y_test) and len(X_val) == len(y_val):\n",
        "  print(\"X and y data length matching\")\n",
        "else:\n",
        "  print(\"Error in data preparation pipeline\")\n",
        "print()\n",
        "print(\"No. of training data = %d\" % len(X_train))\n",
        "print(\"No. of validation data = %d\" % len(X_val))\n",
        "print(\"No. of testing data = %d\" % len(X_test))"
      ],
      "metadata": {
        "id": "oihO76nhvifX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "49e0456d-f56b-4c34-ba4c-a4a294cdb4bf"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X and y data length matching\n",
            "\n",
            "No. of training data = 137513\n",
            "No. of validation data = 17190\n",
            "No. of testing data = 17190\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "display(y_test.value_counts())"
      ],
      "metadata": {
        "id": "1ZcyP7nRvlYp",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "outputId": "2f2a2e51-b5bf-4527-bcb9-41d6c35e0c28"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "0    17059\n",
              "1      131\n",
              "Name: FIRE_OCCURRED, dtype: int64"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# SMOTE\n",
        "\n",
        "from collections import Counter\n",
        "from imblearn.over_sampling import SMOTE \n",
        "\n",
        "print('Original dataset shape %s' % Counter(y_train))\n",
        "sm = SMOTE(random_state=10)\n",
        "X_train, y_train = sm.fit_resample(X_train, y_train)\n",
        "print('Resampled dataset shape %s' % Counter(y_train))"
      ],
      "metadata": {
        "id": "T8MI03z-vmdA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b8d99e7b-52f9-4b8d-b98a-b66f2eba7e02"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original dataset shape Counter({0: 136417, 1: 1096})\n",
            "Resampled dataset shape Counter({0: 136417, 1: 136417})\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_train.head()"
      ],
      "metadata": {
        "id": "8BHENYosoccE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_train.tail()"
      ],
      "metadata": {
        "id": "LQklXxstodv8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Shuffle Data since SMOTE appended many 1s at the end\n",
        "# Required for some algorithms such as ANN\n",
        "\n",
        "from sklearn.utils import shuffle\n",
        "\n",
        "X_train, y_train = shuffle(X_train, y_train, random_state = 10)"
      ],
      "metadata": {
        "id": "Ts3u8k7ZoTmA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluation Metrics\n",
        "\n",
        "from sklearn.metrics import confusion_matrix, recall_score, f1_score, roc_auc_score, accuracy_score\n",
        "\n",
        "def evaluation_metrics(y_true, y_pred):\n",
        "  cfm = confusion_matrix(y_true, y_pred).ravel()\n",
        "  acc = accuracy_score(y_true, y_pred)\n",
        "  recs = recall_score(y_true, y_pred, average='binary')\n",
        "  f1s = f1_score(y_true, y_pred, average='binary')\n",
        "  rocs = roc_auc_score(y_true, y_pred, average='macro')\n",
        "  return [cfm, acc, recs, f1s, rocs]"
      ],
      "metadata": {
        "id": "5pMqZtYUvo3T"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Confusion matrix format : [ tn , fp , fn , tp ]"
      ],
      "metadata": {
        "id": "bDAw6kBSvqrd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Store Model Parameters and Eval\n",
        "\n",
        "models = pd.DataFrame(columns = ['model_name', 'model', 'parameters'])\n",
        "models_eval = pd.DataFrame(columns = ['model_name', 'confusion_matrix', 'accuracy', 'recall', 'f1_score', 'roc_auc_score'])"
      ],
      "metadata": {
        "id": "2m4kHhLmvnxj"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Import ML Algorithms\n",
        "\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "import xgboost\n",
        "from xgboost import XGBClassifier\n",
        "import lightgbm\n",
        "from lightgbm import LGBMClassifier\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from sklearn.ensemble import VotingClassifier\n",
        "\n",
        "# RandomizedSearchCV\n",
        "\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "\n",
        "# Save Model\n",
        "\n",
        "import pickle"
      ],
      "metadata": {
        "id": "fFvGo3IYwC3h"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Logistic Regression\n",
        "\n",
        "- Library: Scikit-learn"
      ],
      "metadata": {
        "id": "ez3z3utYt1Y4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Training\n",
        "\n",
        "name = 'log_clf'\n",
        "\n",
        "train = pd.DataFrame(columns = ['penalty', 'warm_start', 'solver', 'max_iter', 'dual', 'n_jobs','random_state'])\n",
        "train = train.append({'penalty' : 'none', 'warm_start': False, 'solver': 'newton-cg',  'max_iter': 247,  'dual': False, 'n_jobs': -1, 'random_state': 10}, ignore_index=True)\n",
        "train = train.append({'penalty' : 'l2', 'warm_start': False, 'solver': 'newton-cg',  'max_iter': 100,  'dual': False, 'n_jobs': -1, 'random_state': 10}, ignore_index=True)\n",
        "\n",
        "{'warm_start': False,\n",
        " 'solver': 'newton-cg',\n",
        " 'penalty': 'none',\n",
        " 'max_iter': 247,\n",
        " 'dual': False,\n",
        " 'C': 0}\n",
        "\n",
        "train = train.reset_index()\n",
        "for index, row in train.iterrows():\n",
        "    model_name = name + str(index)\n",
        "    log_clf = LogisticRegression(penalty = row['penalty'], n_jobs = int(row['n_jobs']), random_state = int(row['random_state']))\n",
        "    log_clf.fit(X_train, y_train)\n",
        "   \n",
        "    y_true = y_val\n",
        "    y_pred = log_clf.predict(X_val)\n",
        "    evaluation_results = evaluation_metrics(y_true, y_pred)\n",
        "\n",
        "    models = models.append({'model_name': model_name, \n",
        "                            'model': log_clf, \n",
        "                            'parameters': log_clf.get_params()}, \n",
        "                           ignore_index=True)\n",
        "   \n",
        "    models_eval = models_eval.append({'model_name': model_name, \n",
        "                                      'confusion_matrix' : evaluation_results[0], \n",
        "                                      'accuracy': evaluation_results[1], \n",
        "                                      'recall' : evaluation_results[2], \n",
        "                                      'f1_score': evaluation_results[3], \n",
        "                                      'roc_auc_score': evaluation_results[4]}, \n",
        "                                     ignore_index=True)"
      ],
      "metadata": {
        "id": "fiXiFiYsZSB6"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# RandomizedSearchCV\n",
        "\n",
        "random_grid = {\n",
        "                \"penalty\": ['l1', 'l2', 'elasticnet', 'none'],\n",
        "                \"dual\": [True, False],\n",
        "                \"max_iter\" : [int(x) for x in np.linspace(100, 500, num = 20)],\n",
        "                \"warm_start\" : [True, False],\n",
        "                \"solver\" : ['lbfgs', 'newton-cg', 'liblinear'],\n",
        "                \"C\" : [int(x) for x in np.linspace(0, 1, num = 50)]\n",
        "              }\n",
        "\n",
        "log_random = RandomizedSearchCV(estimator = log_clf, \n",
        "                                param_distributions = random_grid, \n",
        "                                n_iter = 50, \n",
        "                                cv = 3, \n",
        "                                verbose=2, \n",
        "                                scoring='recall',\n",
        "                                random_state=10)\n",
        "\n",
        "log_random.fit(X_train, y_train)\n",
        "log_random.best_params_"
      ],
      "metadata": {
        "id": "09I9B42LX8mb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "de50fc5d-284f-4f64-b1e1-3905c20b5d22"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 3 folds for each of 50 candidates, totalling 150 fits\n",
            "[CV] END C=0, dual=True, max_iter=436, penalty=l2, solver=newton-cg, warm_start=False; total time=   0.0s\n",
            "[CV] END C=0, dual=True, max_iter=436, penalty=l2, solver=newton-cg, warm_start=False; total time=   0.0s\n",
            "[CV] END C=0, dual=True, max_iter=436, penalty=l2, solver=newton-cg, warm_start=False; total time=   0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_logistic.py:1523: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 2.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_logistic.py:1523: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 2.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV] END C=0, dual=False, max_iter=289, penalty=l1, solver=liblinear, warm_start=False; total time=   0.1s\n",
            "[CV] END C=0, dual=False, max_iter=289, penalty=l1, solver=liblinear, warm_start=False; total time=   0.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_logistic.py:1523: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 2.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV] END C=0, dual=False, max_iter=289, penalty=l1, solver=liblinear, warm_start=False; total time=   0.1s\n",
            "[CV] END C=0, dual=True, max_iter=436, penalty=elasticnet, solver=newton-cg, warm_start=False; total time=   0.0s\n",
            "[CV] END C=0, dual=True, max_iter=436, penalty=elasticnet, solver=newton-cg, warm_start=False; total time=   0.0s\n",
            "[CV] END C=0, dual=True, max_iter=436, penalty=elasticnet, solver=newton-cg, warm_start=False; total time=   0.0s\n",
            "[CV] END C=0, dual=True, max_iter=247, penalty=l2, solver=newton-cg, warm_start=False; total time=   0.0s\n",
            "[CV] END C=0, dual=True, max_iter=247, penalty=l2, solver=newton-cg, warm_start=False; total time=   0.0s\n",
            "[CV] END C=0, dual=True, max_iter=247, penalty=l2, solver=newton-cg, warm_start=False; total time=   0.0s\n",
            "[CV] END C=0, dual=False, max_iter=289, penalty=l1, solver=newton-cg, warm_start=False; total time=   0.0s\n",
            "[CV] END C=0, dual=False, max_iter=289, penalty=l1, solver=newton-cg, warm_start=False; total time=   0.0s\n",
            "[CV] END C=0, dual=False, max_iter=289, penalty=l1, solver=newton-cg, warm_start=False; total time=   0.0s\n",
            "[CV] END C=0, dual=False, max_iter=310, penalty=elasticnet, solver=lbfgs, warm_start=True; total time=   0.1s\n",
            "[CV] END C=0, dual=False, max_iter=310, penalty=elasticnet, solver=lbfgs, warm_start=True; total time=   0.1s\n",
            "[CV] END C=0, dual=False, max_iter=310, penalty=elasticnet, solver=lbfgs, warm_start=True; total time=   0.0s\n",
            "[CV] END C=0, dual=False, max_iter=205, penalty=l1, solver=lbfgs, warm_start=False; total time=   0.1s\n",
            "[CV] END C=0, dual=False, max_iter=205, penalty=l1, solver=lbfgs, warm_start=False; total time=   0.0s\n",
            "[CV] END C=0, dual=False, max_iter=205, penalty=l1, solver=lbfgs, warm_start=False; total time=   0.0s\n",
            "[CV] END C=0, dual=True, max_iter=226, penalty=elasticnet, solver=lbfgs, warm_start=False; total time=   0.0s\n",
            "[CV] END C=0, dual=True, max_iter=226, penalty=elasticnet, solver=lbfgs, warm_start=False; total time=   0.0s\n",
            "[CV] END C=0, dual=True, max_iter=226, penalty=elasticnet, solver=lbfgs, warm_start=False; total time=   0.0s\n",
            "[CV] END C=0, dual=False, max_iter=226, penalty=l1, solver=lbfgs, warm_start=True; total time=   0.0s\n",
            "[CV] END C=0, dual=False, max_iter=226, penalty=l1, solver=lbfgs, warm_start=True; total time=   0.0s\n",
            "[CV] END C=0, dual=False, max_iter=226, penalty=l1, solver=lbfgs, warm_start=True; total time=   0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV] END C=0, dual=False, max_iter=247, penalty=none, solver=newton-cg, warm_start=False; total time=  10.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV] END C=0, dual=False, max_iter=247, penalty=none, solver=newton-cg, warm_start=False; total time=   7.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV] END C=0, dual=False, max_iter=247, penalty=none, solver=newton-cg, warm_start=False; total time=   8.4s\n",
            "[CV] END C=0, dual=False, max_iter=436, penalty=elasticnet, solver=liblinear, warm_start=False; total time=   0.0s\n",
            "[CV] END C=0, dual=False, max_iter=436, penalty=elasticnet, solver=liblinear, warm_start=False; total time=   0.0s\n",
            "[CV] END C=0, dual=False, max_iter=436, penalty=elasticnet, solver=liblinear, warm_start=False; total time=   0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV] END C=0, dual=False, max_iter=331, penalty=none, solver=lbfgs, warm_start=True; total time=   2.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV] END C=0, dual=False, max_iter=331, penalty=none, solver=lbfgs, warm_start=True; total time=   2.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV] END C=0, dual=False, max_iter=331, penalty=none, solver=lbfgs, warm_start=True; total time=   2.6s\n",
            "[CV] END C=0, dual=False, max_iter=184, penalty=l2, solver=newton-cg, warm_start=True; total time=   0.1s\n",
            "[CV] END C=0, dual=False, max_iter=184, penalty=l2, solver=newton-cg, warm_start=True; total time=   0.9s\n",
            "[CV] END C=0, dual=False, max_iter=184, penalty=l2, solver=newton-cg, warm_start=True; total time=   0.9s\n",
            "[CV] END C=0, dual=False, max_iter=247, penalty=l1, solver=lbfgs, warm_start=False; total time=   0.0s\n",
            "[CV] END C=0, dual=False, max_iter=247, penalty=l1, solver=lbfgs, warm_start=False; total time=   0.0s\n",
            "[CV] END C=0, dual=False, max_iter=247, penalty=l1, solver=lbfgs, warm_start=False; total time=   0.0s\n",
            "[CV] END C=0, dual=False, max_iter=100, penalty=l2, solver=liblinear, warm_start=True; total time=   0.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_logistic.py:1523: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 2.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_logistic.py:1523: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 2.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_logistic.py:1523: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 2.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV] END C=0, dual=False, max_iter=100, penalty=l2, solver=liblinear, warm_start=True; total time=   0.1s\n",
            "[CV] END C=0, dual=False, max_iter=100, penalty=l2, solver=liblinear, warm_start=True; total time=   0.1s\n",
            "[CV] END C=0, dual=False, max_iter=436, penalty=l2, solver=newton-cg, warm_start=True; total time=   0.9s\n",
            "[CV] END C=0, dual=False, max_iter=436, penalty=l2, solver=newton-cg, warm_start=True; total time=   0.9s\n",
            "[CV] END C=0, dual=False, max_iter=436, penalty=l2, solver=newton-cg, warm_start=True; total time=   0.9s\n",
            "[CV] END C=0, dual=True, max_iter=247, penalty=elasticnet, solver=newton-cg, warm_start=True; total time=   0.0s\n",
            "[CV] END C=0, dual=True, max_iter=247, penalty=elasticnet, solver=newton-cg, warm_start=True; total time=   0.0s\n",
            "[CV] END C=0, dual=True, max_iter=247, penalty=elasticnet, solver=newton-cg, warm_start=True; total time=   0.0s\n",
            "[CV] END C=1, dual=True, max_iter=478, penalty=l1, solver=newton-cg, warm_start=False; total time=   0.0s\n",
            "[CV] END C=1, dual=True, max_iter=478, penalty=l1, solver=newton-cg, warm_start=False; total time=   0.0s\n",
            "[CV] END C=1, dual=True, max_iter=478, penalty=l1, solver=newton-cg, warm_start=False; total time=   0.0s\n",
            "[CV] END C=0, dual=True, max_iter=100, penalty=elasticnet, solver=liblinear, warm_start=True; total time=   0.0s\n",
            "[CV] END C=0, dual=True, max_iter=100, penalty=elasticnet, solver=liblinear, warm_start=True; total time=   0.0s\n",
            "[CV] END C=0, dual=True, max_iter=100, penalty=elasticnet, solver=liblinear, warm_start=True; total time=   0.0s\n",
            "[CV] END C=0, dual=True, max_iter=247, penalty=elasticnet, solver=newton-cg, warm_start=True; total time=   0.0s\n",
            "[CV] END C=0, dual=True, max_iter=247, penalty=elasticnet, solver=newton-cg, warm_start=True; total time=   0.0s\n",
            "[CV] END C=0, dual=True, max_iter=247, penalty=elasticnet, solver=newton-cg, warm_start=True; total time=   0.0s\n",
            "[CV] END C=0, dual=False, max_iter=247, penalty=elasticnet, solver=liblinear, warm_start=True; total time=   0.0s\n",
            "[CV] END C=0, dual=False, max_iter=247, penalty=elasticnet, solver=liblinear, warm_start=True; total time=   0.0s\n",
            "[CV] END C=0, dual=False, max_iter=247, penalty=elasticnet, solver=liblinear, warm_start=True; total time=   0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV] END C=0, dual=False, max_iter=163, penalty=none, solver=lbfgs, warm_start=True; total time=   2.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV] END C=0, dual=False, max_iter=163, penalty=none, solver=lbfgs, warm_start=True; total time=   2.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV] END C=0, dual=False, max_iter=163, penalty=none, solver=lbfgs, warm_start=True; total time=   2.7s\n",
            "[CV] END C=0, dual=False, max_iter=289, penalty=l2, solver=lbfgs, warm_start=True; total time=   0.1s\n",
            "[CV] END C=0, dual=False, max_iter=289, penalty=l2, solver=lbfgs, warm_start=True; total time=   0.9s\n",
            "[CV] END C=0, dual=False, max_iter=289, penalty=l2, solver=lbfgs, warm_start=True; total time=   0.9s\n",
            "[CV] END C=0, dual=False, max_iter=205, penalty=l2, solver=newton-cg, warm_start=False; total time=   0.9s\n",
            "[CV] END C=0, dual=False, max_iter=205, penalty=l2, solver=newton-cg, warm_start=False; total time=   0.9s\n",
            "[CV] END C=0, dual=False, max_iter=205, penalty=l2, solver=newton-cg, warm_start=False; total time=   0.9s\n",
            "[CV] END C=0, dual=True, max_iter=457, penalty=elasticnet, solver=lbfgs, warm_start=True; total time=   0.0s\n",
            "[CV] END C=0, dual=True, max_iter=457, penalty=elasticnet, solver=lbfgs, warm_start=True; total time=   0.0s\n",
            "[CV] END C=0, dual=True, max_iter=457, penalty=elasticnet, solver=lbfgs, warm_start=True; total time=   0.0s\n",
            "[CV] END C=0, dual=False, max_iter=184, penalty=elasticnet, solver=newton-cg, warm_start=True; total time=   0.0s\n",
            "[CV] END C=0, dual=False, max_iter=184, penalty=elasticnet, solver=newton-cg, warm_start=True; total time=   0.0s\n",
            "[CV] END C=0, dual=False, max_iter=184, penalty=elasticnet, solver=newton-cg, warm_start=True; total time=   0.0s\n",
            "[CV] END C=0, dual=False, max_iter=163, penalty=l2, solver=newton-cg, warm_start=False; total time=   0.9s\n",
            "[CV] END C=0, dual=False, max_iter=163, penalty=l2, solver=newton-cg, warm_start=False; total time=   0.9s\n",
            "[CV] END C=0, dual=False, max_iter=163, penalty=l2, solver=newton-cg, warm_start=False; total time=   0.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV] END C=0, dual=False, max_iter=268, penalty=none, solver=lbfgs, warm_start=False; total time=   2.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV] END C=0, dual=False, max_iter=268, penalty=none, solver=lbfgs, warm_start=False; total time=   2.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV] END C=0, dual=False, max_iter=268, penalty=none, solver=lbfgs, warm_start=False; total time=   2.6s\n",
            "[CV] END C=0, dual=False, max_iter=331, penalty=elasticnet, solver=newton-cg, warm_start=True; total time=   0.0s\n",
            "[CV] END C=0, dual=False, max_iter=331, penalty=elasticnet, solver=newton-cg, warm_start=True; total time=   0.0s\n",
            "[CV] END C=0, dual=False, max_iter=331, penalty=elasticnet, solver=newton-cg, warm_start=True; total time=   0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV] END C=0, dual=False, max_iter=457, penalty=none, solver=newton-cg, warm_start=False; total time=  10.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV] END C=0, dual=False, max_iter=457, penalty=none, solver=newton-cg, warm_start=False; total time=   8.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV] END C=0, dual=False, max_iter=457, penalty=none, solver=newton-cg, warm_start=False; total time=   7.9s\n",
            "[CV] END C=0, dual=True, max_iter=478, penalty=none, solver=newton-cg, warm_start=False; total time=   0.0s\n",
            "[CV] END C=0, dual=True, max_iter=478, penalty=none, solver=newton-cg, warm_start=False; total time=   0.0s\n",
            "[CV] END C=0, dual=True, max_iter=478, penalty=none, solver=newton-cg, warm_start=False; total time=   0.0s\n",
            "[CV] END C=0, dual=False, max_iter=352, penalty=elasticnet, solver=lbfgs, warm_start=False; total time=   0.0s\n",
            "[CV] END C=0, dual=False, max_iter=352, penalty=elasticnet, solver=lbfgs, warm_start=False; total time=   0.0s\n",
            "[CV] END C=0, dual=False, max_iter=352, penalty=elasticnet, solver=lbfgs, warm_start=False; total time=   0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_logistic.py:1523: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 2.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_logistic.py:1523: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 2.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_logistic.py:1523: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 2.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV] END C=0, dual=True, max_iter=247, penalty=l2, solver=liblinear, warm_start=False; total time=   0.1s\n",
            "[CV] END C=0, dual=True, max_iter=247, penalty=l2, solver=liblinear, warm_start=False; total time=   0.1s\n",
            "[CV] END C=0, dual=True, max_iter=247, penalty=l2, solver=liblinear, warm_start=False; total time=   0.1s\n",
            "[CV] END C=0, dual=True, max_iter=500, penalty=elasticnet, solver=liblinear, warm_start=False; total time=   0.0s\n",
            "[CV] END C=0, dual=True, max_iter=500, penalty=elasticnet, solver=liblinear, warm_start=False; total time=   0.0s\n",
            "[CV] END C=0, dual=True, max_iter=500, penalty=elasticnet, solver=liblinear, warm_start=False; total time=   0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV] END C=0, dual=False, max_iter=289, penalty=none, solver=newton-cg, warm_start=False; total time=   9.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV] END C=0, dual=False, max_iter=289, penalty=none, solver=newton-cg, warm_start=False; total time=   8.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV] END C=0, dual=False, max_iter=289, penalty=none, solver=newton-cg, warm_start=False; total time=   8.3s\n",
            "[CV] END C=0, dual=True, max_iter=289, penalty=l1, solver=liblinear, warm_start=True; total time=   0.1s\n",
            "[CV] END C=0, dual=True, max_iter=289, penalty=l1, solver=liblinear, warm_start=True; total time=   0.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_logistic.py:1523: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 2.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_logistic.py:1523: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 2.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_logistic.py:1523: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 2.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV] END C=0, dual=True, max_iter=289, penalty=l1, solver=liblinear, warm_start=True; total time=   0.1s\n",
            "[CV] END C=0, dual=True, max_iter=436, penalty=none, solver=liblinear, warm_start=True; total time=   0.0s\n",
            "[CV] END C=0, dual=True, max_iter=436, penalty=none, solver=liblinear, warm_start=True; total time=   0.0s\n",
            "[CV] END C=0, dual=True, max_iter=436, penalty=none, solver=liblinear, warm_start=True; total time=   0.0s\n",
            "[CV] END C=0, dual=False, max_iter=205, penalty=l1, solver=lbfgs, warm_start=False; total time=   0.0s\n",
            "[CV] END C=0, dual=False, max_iter=205, penalty=l1, solver=lbfgs, warm_start=False; total time=   0.0s\n",
            "[CV] END C=0, dual=False, max_iter=205, penalty=l1, solver=lbfgs, warm_start=False; total time=   0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV] END C=0, dual=False, max_iter=457, penalty=none, solver=newton-cg, warm_start=True; total time=   9.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV] END C=0, dual=False, max_iter=457, penalty=none, solver=newton-cg, warm_start=True; total time=  11.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV] END C=0, dual=False, max_iter=457, penalty=none, solver=newton-cg, warm_start=True; total time=   8.7s\n",
            "[CV] END C=0, dual=False, max_iter=457, penalty=l2, solver=newton-cg, warm_start=False; total time=   0.1s\n",
            "[CV] END C=0, dual=False, max_iter=457, penalty=l2, solver=newton-cg, warm_start=False; total time=   0.9s\n",
            "[CV] END C=0, dual=False, max_iter=457, penalty=l2, solver=newton-cg, warm_start=False; total time=   0.9s\n",
            "[CV] END C=0, dual=False, max_iter=394, penalty=l2, solver=newton-cg, warm_start=False; total time=   0.9s\n",
            "[CV] END C=0, dual=False, max_iter=394, penalty=l2, solver=newton-cg, warm_start=False; total time=   0.9s\n",
            "[CV] END C=0, dual=False, max_iter=394, penalty=l2, solver=newton-cg, warm_start=False; total time=   0.9s\n",
            "[CV] END C=0, dual=False, max_iter=436, penalty=l1, solver=liblinear, warm_start=True; total time=   0.1s\n",
            "[CV] END C=0, dual=False, max_iter=436, penalty=l1, solver=liblinear, warm_start=True; total time=   0.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_logistic.py:1523: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 2.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_logistic.py:1523: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 2.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_logistic.py:1523: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 2.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV] END C=0, dual=False, max_iter=436, penalty=l1, solver=liblinear, warm_start=True; total time=   0.1s\n",
            "[CV] END C=0, dual=True, max_iter=394, penalty=l1, solver=newton-cg, warm_start=True; total time=   0.0s\n",
            "[CV] END C=0, dual=True, max_iter=394, penalty=l1, solver=newton-cg, warm_start=True; total time=   0.0s\n",
            "[CV] END C=0, dual=True, max_iter=394, penalty=l1, solver=newton-cg, warm_start=True; total time=   0.0s\n",
            "[CV] END C=0, dual=False, max_iter=205, penalty=l1, solver=liblinear, warm_start=False; total time=   0.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_logistic.py:1523: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 2.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_logistic.py:1523: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 2.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_logistic.py:1523: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 2.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV] END C=0, dual=False, max_iter=205, penalty=l1, solver=liblinear, warm_start=False; total time=   0.1s\n",
            "[CV] END C=0, dual=False, max_iter=205, penalty=l1, solver=liblinear, warm_start=False; total time=   0.1s\n",
            "[CV] END C=0, dual=True, max_iter=100, penalty=elasticnet, solver=lbfgs, warm_start=False; total time=   0.0s\n",
            "[CV] END C=0, dual=True, max_iter=100, penalty=elasticnet, solver=lbfgs, warm_start=False; total time=   0.0s\n",
            "[CV] END C=0, dual=True, max_iter=100, penalty=elasticnet, solver=lbfgs, warm_start=False; total time=   0.0s\n",
            "[CV] END C=0, dual=True, max_iter=394, penalty=l2, solver=lbfgs, warm_start=False; total time=   0.0s\n",
            "[CV] END C=0, dual=True, max_iter=394, penalty=l2, solver=lbfgs, warm_start=False; total time=   0.0s\n",
            "[CV] END C=0, dual=True, max_iter=394, penalty=l2, solver=lbfgs, warm_start=False; total time=   0.0s\n",
            "[CV] END C=0, dual=False, max_iter=415, penalty=none, solver=liblinear, warm_start=True; total time=   0.0s\n",
            "[CV] END C=0, dual=False, max_iter=415, penalty=none, solver=liblinear, warm_start=True; total time=   0.0s\n",
            "[CV] END C=0, dual=False, max_iter=415, penalty=none, solver=liblinear, warm_start=True; total time=   0.0s\n",
            "[CV] END C=0, dual=False, max_iter=163, penalty=elasticnet, solver=liblinear, warm_start=True; total time=   0.0s\n",
            "[CV] END C=0, dual=False, max_iter=163, penalty=elasticnet, solver=liblinear, warm_start=True; total time=   0.0s\n",
            "[CV] END C=0, dual=False, max_iter=163, penalty=elasticnet, solver=liblinear, warm_start=True; total time=   0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV] END C=0, dual=False, max_iter=289, penalty=none, solver=lbfgs, warm_start=False; total time=   2.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV] END C=0, dual=False, max_iter=289, penalty=none, solver=lbfgs, warm_start=False; total time=   2.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV] END C=0, dual=False, max_iter=289, penalty=none, solver=lbfgs, warm_start=False; total time=   2.7s\n",
            "[CV] END C=0, dual=False, max_iter=142, penalty=elasticnet, solver=lbfgs, warm_start=True; total time=   0.0s\n",
            "[CV] END C=0, dual=False, max_iter=142, penalty=elasticnet, solver=lbfgs, warm_start=True; total time=   0.0s\n",
            "[CV] END C=0, dual=False, max_iter=142, penalty=elasticnet, solver=lbfgs, warm_start=True; total time=   0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/model_selection/_validation.py:372: FitFailedWarning: \n",
            "126 fits failed out of a total of 150.\n",
            "The score on these train-test partitions for these parameters will be set to nan.\n",
            "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
            "\n",
            "Below are more details about the failures:\n",
            "--------------------------------------------------------------------------------\n",
            "9 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_logistic.py\", line 1461, in fit\n",
            "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_logistic.py\", line 452, in _check_solver\n",
            "    raise ValueError(\n",
            "ValueError: Solver newton-cg supports only dual=False, got dual=True\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "15 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_logistic.py\", line 1528, in fit\n",
            "    self.coef_, self.intercept_, n_iter_ = _fit_liblinear(\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/sklearn/svm/_base.py\", line 1186, in _fit_liblinear\n",
            "    raw_coef_, n_iter_ = liblinear.train_wrap(\n",
            "  File \"sklearn/svm/_liblinear.pyx\", line 52, in sklearn.svm._liblinear.train_wrap\n",
            "ValueError: b'C <= 0'\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "15 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_logistic.py\", line 1461, in fit\n",
            "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_logistic.py\", line 447, in _check_solver\n",
            "    raise ValueError(\n",
            "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "9 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_logistic.py\", line 1461, in fit\n",
            "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_logistic.py\", line 447, in _check_solver\n",
            "    raise ValueError(\n",
            "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got l1 penalty.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "18 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_logistic.py\", line 1461, in fit\n",
            "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_logistic.py\", line 447, in _check_solver\n",
            "    raise ValueError(\n",
            "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "12 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_logistic.py\", line 1461, in fit\n",
            "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_logistic.py\", line 447, in _check_solver\n",
            "    raise ValueError(\n",
            "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "15 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_logistic.py\", line 1461, in fit\n",
            "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_logistic.py\", line 457, in _check_solver\n",
            "    raise ValueError(\n",
            "ValueError: Only 'saga' solver supports elasticnet penalty, got solver=liblinear.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "18 fits failed with the following error:\n",
            "joblib.externals.loky.process_executor._RemoteTraceback: \n",
            "\"\"\"\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/joblib/externals/loky/process_executor.py\", line 428, in _process_worker\n",
            "    r = call_item()\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/joblib/externals/loky/process_executor.py\", line 275, in __call__\n",
            "    return self.fn(*self.args, **self.kwargs)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/joblib/_parallel_backends.py\", line 620, in __call__\n",
            "    return self.func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/joblib/parallel.py\", line 288, in __call__\n",
            "    return [func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/joblib/parallel.py\", line 288, in <listcomp>\n",
            "    return [func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/sklearn/utils/fixes.py\", line 216, in __call__\n",
            "    return self.function(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_logistic.py\", line 822, in _logistic_regression_path\n",
            "    args = (X, target, 1.0 / C, sample_weight)\n",
            "ZeroDivisionError: float division by zero\n",
            "\"\"\"\n",
            "\n",
            "The above exception was the direct cause of the following exception:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_logistic.py\", line 1589, in fit\n",
            "    fold_coefs_ = Parallel(\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/joblib/parallel.py\", line 1098, in __call__\n",
            "    self.retrieve()\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/joblib/parallel.py\", line 975, in retrieve\n",
            "    self._output.extend(job.get(timeout=self.timeout))\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/joblib/_parallel_backends.py\", line 567, in wrap_future_result\n",
            "    return future.result(timeout=timeout)\n",
            "  File \"/usr/lib/python3.8/concurrent/futures/_base.py\", line 444, in result\n",
            "    return self.__get_result()\n",
            "  File \"/usr/lib/python3.8/concurrent/futures/_base.py\", line 389, in __get_result\n",
            "    raise self._exception\n",
            "ZeroDivisionError: float division by zero\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "3 fits failed with the following error:\n",
            "joblib.externals.loky.process_executor._RemoteTraceback: \n",
            "\"\"\"\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/joblib/externals/loky/process_executor.py\", line 428, in _process_worker\n",
            "    r = call_item()\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/joblib/externals/loky/process_executor.py\", line 275, in __call__\n",
            "    return self.fn(*self.args, **self.kwargs)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/joblib/_parallel_backends.py\", line 620, in __call__\n",
            "    return self.func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/joblib/parallel.py\", line 288, in __call__\n",
            "    return [func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/joblib/parallel.py\", line 288, in <listcomp>\n",
            "    return [func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/sklearn/utils/fixes.py\", line 216, in __call__\n",
            "    return self.function(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_logistic.py\", line 811, in _logistic_regression_path\n",
            "    args=(X, target, 1.0 / C, sample_weight),\n",
            "ZeroDivisionError: float division by zero\n",
            "\"\"\"\n",
            "\n",
            "The above exception was the direct cause of the following exception:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_logistic.py\", line 1589, in fit\n",
            "    fold_coefs_ = Parallel(\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/joblib/parallel.py\", line 1098, in __call__\n",
            "    self.retrieve()\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/joblib/parallel.py\", line 975, in retrieve\n",
            "    self._output.extend(job.get(timeout=self.timeout))\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/joblib/_parallel_backends.py\", line 567, in wrap_future_result\n",
            "    return future.result(timeout=timeout)\n",
            "  File \"/usr/lib/python3.8/concurrent/futures/_base.py\", line 444, in result\n",
            "    return self.__get_result()\n",
            "  File \"/usr/lib/python3.8/concurrent/futures/_base.py\", line 389, in __get_result\n",
            "    raise self._exception\n",
            "ZeroDivisionError: float division by zero\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "3 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_logistic.py\", line 1528, in fit\n",
            "    self.coef_, self.intercept_, n_iter_ = _fit_liblinear(\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/sklearn/svm/_base.py\", line 1185, in _fit_liblinear\n",
            "    solver_type = _get_liblinear_solver_type(multi_class, penalty, loss, dual)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/sklearn/svm/_base.py\", line 1024, in _get_liblinear_solver_type\n",
            "    raise ValueError(\n",
            "ValueError: Unsupported set of arguments: The combination of penalty='l1' and loss='logistic_regression' are not supported when dual=True, Parameters: penalty='l1', loss='logistic_regression', dual=True\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "6 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_logistic.py\", line 1461, in fit\n",
            "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_logistic.py\", line 464, in _check_solver\n",
            "    raise ValueError(\"penalty='none' is not supported for the liblinear solver\")\n",
            "ValueError: penalty='none' is not supported for the liblinear solver\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "3 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_logistic.py\", line 1461, in fit\n",
            "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_logistic.py\", line 452, in _check_solver\n",
            "    raise ValueError(\n",
            "ValueError: Solver lbfgs supports only dual=False, got dual=True\n",
            "\n",
            "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/model_selection/_search.py:969: UserWarning: One or more of the test scores are non-finite: [       nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan 0.83852086        nan 0.83852086\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan 0.83852086        nan        nan\n",
            "        nan        nan        nan 0.83852086        nan 0.83852086\n",
            "        nan        nan        nan        nan 0.83852086        nan\n",
            "        nan        nan 0.83852086        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            " 0.83852086        nan]\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'warm_start': False,\n",
              " 'solver': 'newton-cg',\n",
              " 'penalty': 'none',\n",
              " 'max_iter': 247,\n",
              " 'dual': False,\n",
              " 'C': 0}"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "display(models_eval)"
      ],
      "metadata": {
        "id": "w5hD6F2kX9ih",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 112
        },
        "outputId": "e9f713fd-8f5d-4eda-b8dc-fd284453ed21"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  model_name       confusion_matrix  accuracy    recall  f1_score  \\\n",
              "0   log_clf0  [14440, 2628, 28, 94]  0.845492  0.770492  0.066104   \n",
              "1   log_clf1  [14441, 2627, 28, 94]  0.845550  0.770492  0.066127   \n",
              "\n",
              "   roc_auc_score  \n",
              "0       0.808260  \n",
              "1       0.808289  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-462a8e4c-6840-4097-af7e-d3fb9b8c87db\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>model_name</th>\n",
              "      <th>confusion_matrix</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>recall</th>\n",
              "      <th>f1_score</th>\n",
              "      <th>roc_auc_score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>log_clf0</td>\n",
              "      <td>[14440, 2628, 28, 94]</td>\n",
              "      <td>0.845492</td>\n",
              "      <td>0.770492</td>\n",
              "      <td>0.066104</td>\n",
              "      <td>0.808260</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>log_clf1</td>\n",
              "      <td>[14441, 2627, 28, 94]</td>\n",
              "      <td>0.845550</td>\n",
              "      <td>0.770492</td>\n",
              "      <td>0.066127</td>\n",
              "      <td>0.808289</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-462a8e4c-6840-4097-af7e-d3fb9b8c87db')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-462a8e4c-6840-4097-af7e-d3fb9b8c87db button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-462a8e4c-6840-4097-af7e-d3fb9b8c87db');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "log_random.best_params_"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GQf2Kg82OkuJ",
        "outputId": "3811788a-c1d4-4001-fc05-fafb1657bc7c"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'warm_start': False,\n",
              " 'solver': 'newton-cg',\n",
              " 'penalty': 'none',\n",
              " 'max_iter': 247,\n",
              " 'dual': False,\n",
              " 'C': 0}"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Support Vector Machine (SVM)\n",
        "\n",
        "- Library: Scikit-learn"
      ],
      "metadata": {
        "id": "oBBQ_iust1eb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_SVM = Original[0]\n",
        "X_val_SVM = Original[1]\n",
        "y_train_SVM = Original[3]\n",
        "y_val_SVM = Original[4]"
      ],
      "metadata": {
        "id": "tsq0c55qZSVE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "display(y_train_SVM.value_counts())"
      ],
      "metadata": {
        "id": "OlCn_HS1dItl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Undersampling\n",
        "\n",
        "from imblearn.under_sampling import RandomUnderSampler\n",
        "\n",
        "rus = RandomUnderSampler(random_state=10)\n",
        "X_train_SVM, y_train_SVM = rus.fit_resample(X_train_SVM, y_train_SVM)"
      ],
      "metadata": {
        "id": "wPwHlXKMdiO9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "display(y_train_SVM.value_counts())"
      ],
      "metadata": {
        "id": "9by4YC8tdj47"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Training\n",
        "\n",
        "name = 'svc_clf'\n",
        "\n",
        "train = pd.DataFrame(columns = ['kernel', 'random_state'])\n",
        "train = train.append({'kernel' : 'rbf', 'random_state': 10}, ignore_index=True)\n",
        "train = train.append({'kernel' : 'sigmoid', 'random_state': 10}, ignore_index=True)\n",
        "train = train.append({'kernel' : 'linear', 'random_state': 10}, ignore_index=True)\n",
        "\n",
        "train = train.reset_index()\n",
        "for index, row in train.iterrows():\n",
        "    model_name = name + str(index)\n",
        "    print(\"Currently at :\" , model_name)\n",
        "    svc_clf = SVC(kernel=row[\"kernel\"], random_state = int(row[\"random_state\"]))\n",
        "    svc_clf.fit(X_train_SVM, y_train_SVM)\n",
        "    \n",
        "    y_true = y_val_SVM\n",
        "    y_pred = svc_clf.predict(X_val_SVM)\n",
        "    evaluation_results = evaluation_metrics(y_true, y_pred)\n",
        "\n",
        "    models = models.append({'model_name': model_name, \n",
        "                            'model': svc_clf, \n",
        "                            'parameters': svc_clf.get_params()}, \n",
        "                           ignore_index=True)\n",
        "    \n",
        "    models_eval = models_eval.append({'model_name': model_name, \n",
        "                                      'confusion_matrix' : evaluation_results[0], \n",
        "                                      'accuracy': evaluation_results[1], \n",
        "                                      'recall' : evaluation_results[2], \n",
        "                                      'f1_score': evaluation_results[3], \n",
        "                                      'roc_auc_score': evaluation_results[4]}, \n",
        "                                     ignore_index=True)"
      ],
      "metadata": {
        "id": "XsSKT8gmdoVT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# RandomizedSearchCV\n",
        "\n",
        "random_grid = {\n",
        "              \"kernel\": ['linear', 'poly', 'rbf', 'sigmoid'],\n",
        "              \"C\": np.arange(2, 10, 2),\n",
        "              \"gamma\": np.arange(0.1, 1, 0.2)\n",
        "             }\n",
        "\n",
        "svc_random = RandomizedSearchCV(estimator = svc_clf, \n",
        "                                param_distributions = random_grid, \n",
        "                                n_iter = 50, \n",
        "                                cv = 3, \n",
        "                                verbose=2, \n",
        "                                scoring='recall',\n",
        "                                random_state=10)\n",
        "\n",
        "svc_random.fit(X_train, y_train)\n",
        "svc_random.best_params_"
      ],
      "metadata": {
        "id": "7ZlA9AUldq5L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "display(models_eval)"
      ],
      "metadata": {
        "id": "ouPtk_gtdt0I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Naive Bayes\n",
        "\n",
        "- Library: Scikit-learn\n",
        "- Shuffling does not affect the model building. No random_state.\n",
        "- RandomizedSearchCV is not appropriate since there is only 1 parameter and the value is close to 0. Choose from models_eval."
      ],
      "metadata": {
        "id": "Tzx0wl2ht1R1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Training\n",
        "\n",
        "name = 'bayes_clf'\n",
        "\n",
        "train = pd.DataFrame(columns = ['var_smoothing'])\n",
        "train = train.append({'var_smoothing': 1e-10}, ignore_index=True)\n",
        "train = train.append({'var_smoothing': 1e-20}, ignore_index=True)\n",
        "train = train.append({'var_smoothing': 0}, ignore_index=True)\n",
        "\n",
        "train = train.reset_index()\n",
        "for index, row in train.iterrows():\n",
        "    model_name = name + str(index)\n",
        "    bayes_clf = GaussianNB(var_smoothing = row['var_smoothing'])\n",
        "    bayes_clf.fit(X_train, y_train)\n",
        "    \n",
        "    y_true = y_val\n",
        "    y_pred = bayes_clf.predict(X_val)\n",
        "    evaluation_results = evaluation_metrics(y_true, y_pred)\n",
        "\n",
        "    models = models.append({'model_name': model_name, \n",
        "                            'model': bayes_clf, \n",
        "                            'parameters': bayes_clf.get_params()}, \n",
        "                           ignore_index=True)\n",
        "    \n",
        "    models_eval = models_eval.append({'model_name': model_name, \n",
        "                                      'confusion_matrix' : evaluation_results[0], \n",
        "                                      'accuracy': evaluation_results[1], \n",
        "                                      'recall' : evaluation_results[2], \n",
        "                                      'f1_score': evaluation_results[3], \n",
        "                                      'roc_auc_score': evaluation_results[4]}, \n",
        "                                     ignore_index=True)"
      ],
      "metadata": {
        "id": "tAmU3wsqZSwf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c434235e-8e77-490b-dc2b-3544803b6848"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/naive_bayes.py:489: RuntimeWarning: divide by zero encountered in log\n",
            "  n_ij = -0.5 * np.sum(np.log(2.0 * np.pi * self.var_[i, :]))\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/naive_bayes.py:490: RuntimeWarning: divide by zero encountered in true_divide\n",
            "  n_ij -= 0.5 * np.sum(((X - self.theta_[i, :]) ** 2) / (self.var_[i, :]), 1)\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/naive_bayes.py:490: RuntimeWarning: invalid value encountered in true_divide\n",
            "  n_ij -= 0.5 * np.sum(((X - self.theta_[i, :]) ** 2) / (self.var_[i, :]), 1)\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/naive_bayes.py:490: RuntimeWarning: invalid value encountered in subtract\n",
            "  n_ij -= 0.5 * np.sum(((X - self.theta_[i, :]) ** 2) / (self.var_[i, :]), 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "display(models_eval)"
      ],
      "metadata": {
        "id": "n7Ad5Gr5eH_U",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "outputId": "569a7c48-3183-4d37-aa0d-10a54a760be8"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "   model_name       confusion_matrix  accuracy    recall  f1_score  \\\n",
              "0    log_clf0  [14440, 2628, 28, 94]  0.845492  0.770492  0.066104   \n",
              "1    log_clf1  [14441, 2627, 28, 94]  0.845550  0.770492  0.066127   \n",
              "2  bayes_clf0  [1326, 15742, 0, 122]  0.084235  1.000000  0.015263   \n",
              "3  bayes_clf1   [592, 16476, 0, 122]  0.041536  1.000000  0.014593   \n",
              "4  bayes_clf2     [0, 17068, 0, 122]  0.007097  1.000000  0.014094   \n",
              "\n",
              "   roc_auc_score  \n",
              "0       0.808260  \n",
              "1       0.808289  \n",
              "2       0.538845  \n",
              "3       0.517342  \n",
              "4       0.500000  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-b722c60b-201d-4403-b4be-41b72965a69a\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>model_name</th>\n",
              "      <th>confusion_matrix</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>recall</th>\n",
              "      <th>f1_score</th>\n",
              "      <th>roc_auc_score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>log_clf0</td>\n",
              "      <td>[14440, 2628, 28, 94]</td>\n",
              "      <td>0.845492</td>\n",
              "      <td>0.770492</td>\n",
              "      <td>0.066104</td>\n",
              "      <td>0.808260</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>log_clf1</td>\n",
              "      <td>[14441, 2627, 28, 94]</td>\n",
              "      <td>0.845550</td>\n",
              "      <td>0.770492</td>\n",
              "      <td>0.066127</td>\n",
              "      <td>0.808289</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>bayes_clf0</td>\n",
              "      <td>[1326, 15742, 0, 122]</td>\n",
              "      <td>0.084235</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.015263</td>\n",
              "      <td>0.538845</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>bayes_clf1</td>\n",
              "      <td>[592, 16476, 0, 122]</td>\n",
              "      <td>0.041536</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.014593</td>\n",
              "      <td>0.517342</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>bayes_clf2</td>\n",
              "      <td>[0, 17068, 0, 122]</td>\n",
              "      <td>0.007097</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.014094</td>\n",
              "      <td>0.500000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b722c60b-201d-4403-b4be-41b72965a69a')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-b722c60b-201d-4403-b4be-41b72965a69a button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-b722c60b-201d-4403-b4be-41b72965a69a');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## K-Nearest Neighbor\n",
        "\n",
        "- Library: Scikit-learn\n",
        "- Shuffling does not affect the model building. No random_state."
      ],
      "metadata": {
        "id": "M_gEyKKnt00q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Training\n",
        "\n",
        "name = 'neigh_clf'\n",
        "\n",
        "train = pd.DataFrame(columns = ['n_neighbors', 'algorithm', 'n_jobs'])\n",
        "train = train.append({'n_neighbors': 5, 'algorithm':'auto', 'n_jobs':-1}, ignore_index=True)\n",
        "train = train.append({'n_neighbors': 1, 'algorithm':'auto', 'n_jobs':-1}, ignore_index=True)\n",
        "train = train.append({'n_neighbors': 20, 'algorithm':'kd_tree', 'n_jobs':-1}, ignore_index=True)\n",
        "\n",
        "train = train.reset_index()\n",
        "for index, row in train.iterrows():\n",
        "    model_name = name + str(index)\n",
        "    neigh_clf = KNeighborsClassifier(n_neighbors=int(row['n_neighbors']), algorithm = row['algorithm'], n_jobs = int(row['n_jobs']))\n",
        "    neigh_clf.fit(X_train, y_train)\n",
        "    \n",
        "    y_true = y_val\n",
        "    y_pred = neigh_clf.predict(X_val)\n",
        "    evaluation_results = evaluation_metrics(y_true, y_pred)\n",
        "\n",
        "    models = models.append({'model_name': model_name, \n",
        "                            'model': neigh_clf, \n",
        "                            'parameters': neigh_clf.get_params()}, \n",
        "                           ignore_index=True)\n",
        "    \n",
        "    models_eval = models_eval.append({'model_name': model_name, \n",
        "                                      'confusion_matrix' : evaluation_results[0], \n",
        "                                      'accuracy': evaluation_results[1], \n",
        "                                      'recall' : evaluation_results[2], \n",
        "                                      'f1_score': evaluation_results[3], \n",
        "                                      'roc_auc_score': evaluation_results[4]}, \n",
        "                                     ignore_index=True)"
      ],
      "metadata": {
        "id": "Vw5TiOkaZTHW"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# RandomizedSearchCV\n",
        "\n",
        "random_grid = {\n",
        "                \"n_neighbors\": [int(x) for x in np.linspace(1, 20, num = 20)],\n",
        "                \"algorithm\": ['auto', 'kd_tree','ball_tree']\n",
        "              }\n",
        "\n",
        "neigh_random = RandomizedSearchCV(estimator = neigh_clf, \n",
        "                                  param_distributions = random_grid, \n",
        "                                  n_iter = 50, \n",
        "                                  cv = 3, \n",
        "                                  verbose=2, \n",
        "                                  scoring='recall',\n",
        "                                  random_state=10)\n",
        "\n",
        "neigh_random.fit(X_train, y_train)\n",
        "neigh_random.best_params_"
      ],
      "metadata": {
        "id": "SlJiuLzfen_x",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "be1ed423-446e-4707-dfb6-e97fa3bd8a2b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 3 folds for each of 50 candidates, totalling 150 fits\n",
            "[CV] END ..................algorithm=kd_tree, n_neighbors=12; total time= 1.4min\n",
            "[CV] END ..................algorithm=kd_tree, n_neighbors=12; total time=  51.5s\n",
            "[CV] END ..................algorithm=kd_tree, n_neighbors=12; total time=  48.8s\n",
            "[CV] END ......................algorithm=auto, n_neighbors=4; total time=  26.0s\n",
            "[CV] END ......................algorithm=auto, n_neighbors=4; total time=  25.5s\n",
            "[CV] END ......................algorithm=auto, n_neighbors=4; total time=  26.7s\n",
            "[CV] END ..................algorithm=kd_tree, n_neighbors=19; total time= 1.0min\n",
            "[CV] END ..................algorithm=kd_tree, n_neighbors=19; total time=  57.6s\n",
            "[CV] END ..................algorithm=kd_tree, n_neighbors=19; total time=  58.6s\n",
            "[CV] END ...................algorithm=kd_tree, n_neighbors=8; total time=  36.3s\n",
            "[CV] END ...................algorithm=kd_tree, n_neighbors=8; total time=  39.0s\n",
            "[CV] END ...................algorithm=kd_tree, n_neighbors=8; total time=  37.1s\n",
            "[CV] END ...................algorithm=kd_tree, n_neighbors=2; total time=  18.1s\n",
            "[CV] END ...................algorithm=kd_tree, n_neighbors=2; total time=  21.1s\n",
            "[CV] END ...................algorithm=kd_tree, n_neighbors=2; total time=  18.0s\n",
            "[CV] END .....................algorithm=auto, n_neighbors=18; total time=  56.2s\n",
            "[CV] END .....................algorithm=auto, n_neighbors=18; total time=  58.9s\n",
            "[CV] END .....................algorithm=auto, n_neighbors=18; total time=  57.7s\n",
            "[CV] END .................algorithm=ball_tree, n_neighbors=7; total time= 8.4min\n",
            "[CV] END .................algorithm=ball_tree, n_neighbors=7; total time= 8.6min\n",
            "[CV] END .................algorithm=ball_tree, n_neighbors=7; total time= 8.5min\n",
            "[CV] END ......................algorithm=auto, n_neighbors=3; total time=  24.9s\n",
            "[CV] END ......................algorithm=auto, n_neighbors=3; total time=  23.7s\n",
            "[CV] END ......................algorithm=auto, n_neighbors=3; total time=  24.0s\n",
            "[CV] END ...................algorithm=kd_tree, n_neighbors=4; total time=  27.3s\n",
            "[CV] END ...................algorithm=kd_tree, n_neighbors=4; total time=  27.2s\n",
            "[CV] END ...................algorithm=kd_tree, n_neighbors=4; total time=  27.0s\n",
            "[CV] END ...................algorithm=kd_tree, n_neighbors=7; total time=  38.2s\n",
            "[CV] END ...................algorithm=kd_tree, n_neighbors=7; total time=  36.9s\n",
            "[CV] END ...................algorithm=kd_tree, n_neighbors=7; total time=  37.9s\n",
            "[CV] END ..................algorithm=kd_tree, n_neighbors=16; total time=  55.2s\n",
            "[CV] END ..................algorithm=kd_tree, n_neighbors=16; total time=  57.3s\n",
            "[CV] END ..................algorithm=kd_tree, n_neighbors=16; total time=  56.3s\n",
            "[CV] END ..................algorithm=kd_tree, n_neighbors=20; total time= 1.0min\n",
            "[CV] END ..................algorithm=kd_tree, n_neighbors=20; total time= 1.0min\n",
            "[CV] END ..................algorithm=kd_tree, n_neighbors=20; total time= 1.1min\n",
            "[CV] END ...................algorithm=kd_tree, n_neighbors=1; total time=  13.1s\n",
            "[CV] END ...................algorithm=kd_tree, n_neighbors=1; total time=  12.9s\n",
            "[CV] END ...................algorithm=kd_tree, n_neighbors=1; total time=  13.3s\n",
            "[CV] END ..................algorithm=kd_tree, n_neighbors=18; total time=  58.7s\n",
            "[CV] END ..................algorithm=kd_tree, n_neighbors=18; total time= 1.0min\n",
            "[CV] END ..................algorithm=kd_tree, n_neighbors=18; total time=  57.9s\n",
            "[CV] END ......................algorithm=auto, n_neighbors=8; total time=  38.1s\n",
            "[CV] END ......................algorithm=auto, n_neighbors=8; total time=  38.2s\n",
            "[CV] END ......................algorithm=auto, n_neighbors=8; total time=  38.5s\n",
            "[CV] END ......................algorithm=auto, n_neighbors=7; total time=  39.7s\n",
            "[CV] END ......................algorithm=auto, n_neighbors=7; total time=  36.0s\n",
            "[CV] END ......................algorithm=auto, n_neighbors=7; total time=  42.7s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "display(models_eval)"
      ],
      "metadata": {
        "id": "EvI_e6r-exRk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "neigh_random.best_params_"
      ],
      "metadata": {
        "id": "2G3z6f8vP21Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Decision Tree\n",
        "\n",
        "- Library: Scikit-learn"
      ],
      "metadata": {
        "id": "brtgIH7pt1jO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Training\n",
        "\n",
        "name = 'tree_clf'\n",
        "\n",
        "train = pd.DataFrame(columns = ['criterion', 'splitter', 'min_samples_leaf', 'max_features', 'max_depth', 'n_jobs', 'random_state'])\n",
        "train = train.append({'criterion' : 'gini', 'splitter': 'best', 'min_samples_leaf': 1, 'max_features': 9, 'max_depth': None, 'random_state': 10}, ignore_index=True)\n",
        "train = train.append({'criterion' : 'entropy', 'splitter': 'best', 'min_samples_leaf': 1, 'max_features': 9, 'max_depth': None, 'random_state': 10}, ignore_index=True)\n",
        "train = train.append({'criterion' : 'gini', 'splitter': 'random', 'min_samples_leaf': 1, 'max_features': \"auto\", 'max_depth': None, 'random_state': 10}, ignore_index=True)\n",
        "train = train.append({'criterion' : 'entropy', 'splitter': 'random', 'min_samples_leaf': 1, 'max_features': \"auto\", 'max_depth': None, 'random_state': 10}, ignore_index=True)\n",
        "\n",
        "train = train.reset_index()\n",
        "for index, row in train.iterrows():\n",
        "    model_name = name + str(index)\n",
        "    tree_clf = DecisionTreeClassifier(criterion = row['criterion'], splitter = row['splitter'], max_depth = None, random_state = row['random_state'])\n",
        "    tree_clf.fit(X_train, y_train)\n",
        "    \n",
        "    y_true = y_val\n",
        "    y_pred = tree_clf.predict(X_val)\n",
        "    evaluation_results = evaluation_metrics(y_true, y_pred)\n",
        "\n",
        "    models = models.append({'model_name': model_name, \n",
        "                            'model': tree_clf, \n",
        "                            'parameters': tree_clf.get_params()}, \n",
        "                           ignore_index=True)\n",
        "    \n",
        "    models_eval = models_eval.append({'model_name': model_name, \n",
        "                                      'confusion_matrix' : evaluation_results[0], \n",
        "                                      'accuracy': evaluation_results[1], \n",
        "                                      'recall' : evaluation_results[2], \n",
        "                                      'f1_score': evaluation_results[3], \n",
        "                                      'roc_auc_score': evaluation_results[4]}, \n",
        "                                     ignore_index=True)"
      ],
      "metadata": {
        "id": "le5Xgsd8ZUHB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# RandomizedSearchCV\n",
        "\n",
        "max_depth = list([int(x) for x in np.linspace(2, 6, num = 5)])\n",
        "max_depth.append(None)\n",
        "\n",
        "random_grid = {\n",
        "              \"max_depth\": max_depth,\n",
        "              \"max_features\": [int(x) for x in np.linspace(1, len(df.columns), num = len(df.columns))],\n",
        "              \"min_samples_leaf\": [int(x) for x in np.linspace(1, len(df.columns), num = len(df.columns))],\n",
        "              \"criterion\": [\"gini\", \"entropy\", \"log_loss\"],\n",
        "              \"splitter\": [\"random\", \"best\"]\n",
        "              }\n",
        "\n",
        "tree_random = RandomizedSearchCV(estimator = tree_clf, \n",
        "                                 param_distributions = random_grid, \n",
        "                                 n_iter = 100, \n",
        "                                 cv = 3, \n",
        "                                 verbose=2, \n",
        "                                 scoring='recall',\n",
        "                                 random_state=10)\n",
        "\n",
        "tree_random.fit(X_train, y_train)\n",
        "tree_random.best_params_"
      ],
      "metadata": {
        "id": "8lLlrOw_fGlc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 831
        },
        "outputId": "c9f65516-f66a-43b0-e051-c4e7582bf446"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 3 folds for each of 50 candidates, totalling 150 fits\n",
            "[CV] END criterion=gini, max_depth=5, max_features=11, min_samples_leaf=8, splitter=best; total time=   0.6s\n",
            "[CV] END criterion=gini, max_depth=5, max_features=11, min_samples_leaf=8, splitter=best; total time=   0.6s\n",
            "[CV] END criterion=gini, max_depth=5, max_features=11, min_samples_leaf=8, splitter=best; total time=   0.6s\n",
            "[CV] END criterion=log_loss, max_depth=3, max_features=9, min_samples_leaf=11, splitter=best; total time=   0.0s\n",
            "[CV] END criterion=log_loss, max_depth=3, max_features=9, min_samples_leaf=11, splitter=best; total time=   0.0s\n",
            "[CV] END criterion=log_loss, max_depth=3, max_features=9, min_samples_leaf=11, splitter=best; total time=   0.0s\n",
            "[CV] END criterion=gini, max_depth=5, max_features=13, min_samples_leaf=10, splitter=random; total time=   0.0s\n",
            "[CV] END criterion=gini, max_depth=5, max_features=13, min_samples_leaf=10, splitter=random; total time=   0.0s\n",
            "[CV] END criterion=gini, max_depth=5, max_features=13, min_samples_leaf=10, splitter=random; total time=   0.0s\n",
            "[CV] END criterion=entropy, max_depth=6, max_features=3, min_samples_leaf=5, splitter=best; total time=   0.3s\n",
            "[CV] END criterion=entropy, max_depth=6, max_features=3, min_samples_leaf=5, splitter=best; total time=   0.3s\n",
            "[CV] END criterion=entropy, max_depth=6, max_features=3, min_samples_leaf=5, splitter=best; total time=   0.3s\n",
            "[CV] END criterion=gini, max_depth=5, max_features=7, min_samples_leaf=6, splitter=random; total time=   0.1s\n",
            "[CV] END criterion=gini, max_depth=5, max_features=7, min_samples_leaf=6, splitter=random; total time=   0.1s\n",
            "[CV] END criterion=gini, max_depth=5, max_features=7, min_samples_leaf=6, splitter=random; total time=   0.1s\n",
            "[CV] END criterion=gini, max_depth=None, max_features=13, min_samples_leaf=4, splitter=best; total time=   0.0s\n",
            "[CV] END criterion=gini, max_depth=None, max_features=13, min_samples_leaf=4, splitter=best; total time=   0.0s\n",
            "[CV] END criterion=gini, max_depth=None, max_features=13, min_samples_leaf=4, splitter=best; total time=   0.0s\n",
            "[CV] END criterion=log_loss, max_depth=4, max_features=4, min_samples_leaf=10, splitter=best; total time=   0.0s\n",
            "[CV] END criterion=log_loss, max_depth=4, max_features=4, min_samples_leaf=10, splitter=best; total time=   0.0s\n",
            "[CV] END criterion=log_loss, max_depth=4, max_features=4, min_samples_leaf=10, splitter=best; total time=   0.0s\n",
            "[CV] END criterion=gini, max_depth=6, max_features=7, min_samples_leaf=7, splitter=random; total time=   0.1s\n",
            "[CV] END criterion=gini, max_depth=6, max_features=7, min_samples_leaf=7, splitter=random; total time=   0.1s\n",
            "[CV] END criterion=gini, max_depth=6, max_features=7, min_samples_leaf=7, splitter=random; total time=   0.1s\n",
            "[CV] END criterion=gini, max_depth=None, max_features=10, min_samples_leaf=13, splitter=best; total time=   1.1s\n",
            "[CV] END criterion=gini, max_depth=None, max_features=10, min_samples_leaf=13, splitter=best; total time=   1.1s\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-102-a3d5fadb8339>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     19\u001b[0m                                  random_state=10)\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m \u001b[0mtree_random\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m \u001b[0mtree_random\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_params_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    889\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    890\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 891\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    892\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    893\u001b[0m             \u001b[0;31m# multimetric is determined here because in the case of a callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36m_run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1764\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1765\u001b[0m         \u001b[0;34m\"\"\"Search n_iter candidates from param_distributions\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1766\u001b[0;31m         evaluate_candidates(\n\u001b[0m\u001b[1;32m   1767\u001b[0m             ParameterSampler(\n\u001b[1;32m   1768\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparam_distributions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_iter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mevaluate_candidates\u001b[0;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[1;32m    836\u001b[0m                     )\n\u001b[1;32m    837\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 838\u001b[0;31m                 out = parallel(\n\u001b[0m\u001b[1;32m    839\u001b[0m                     delayed(_fit_and_score)(\n\u001b[1;32m    840\u001b[0m                         \u001b[0mclone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbase_estimator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1086\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1087\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1088\u001b[0;31m             \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1089\u001b[0m                 \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1090\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    899\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    900\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 901\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    902\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    903\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    817\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    818\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 819\u001b[0;31m             \u001b[0mjob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    820\u001b[0m             \u001b[0;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    821\u001b[0m             \u001b[0;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    206\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    207\u001b[0m         \u001b[0;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 208\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    209\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    595\u001b[0m         \u001b[0;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    596\u001b[0m         \u001b[0;31m# arguments in memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 597\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    598\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    599\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    286\u001b[0m         \u001b[0;31m# change the default number of processes to -1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    287\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 288\u001b[0;31m             return [func(*args, **kwargs)\n\u001b[0m\u001b[1;32m    289\u001b[0m                     for func, args, kwargs in self.items]\n\u001b[1;32m    290\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    286\u001b[0m         \u001b[0;31m# change the default number of processes to -1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    287\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 288\u001b[0;31m             return [func(*args, **kwargs)\n\u001b[0m\u001b[1;32m    289\u001b[0m                     for func, args, kwargs in self.items]\n\u001b[1;32m    290\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/sklearn/utils/fixes.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    214\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mconfig_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 216\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    217\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36m_fit_and_score\u001b[0;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, split_progress, candidate_progress, error_score)\u001b[0m\n\u001b[1;32m    678\u001b[0m             \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    679\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 680\u001b[0;31m             \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    681\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    682\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/sklearn/tree/_classes.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[1;32m    935\u001b[0m         \"\"\"\n\u001b[1;32m    936\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 937\u001b[0;31m         super().fit(\n\u001b[0m\u001b[1;32m    938\u001b[0m             \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    939\u001b[0m             \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/sklearn/tree/_classes.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[1;32m    418\u001b[0m             )\n\u001b[1;32m    419\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 420\u001b[0;31m         \u001b[0mbuilder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtree_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    421\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    422\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_outputs_\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mis_classifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "display(models_eval)"
      ],
      "metadata": {
        "id": "aW_Ztq6rfEiS",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 520
        },
        "outputId": "7b6262f6-d952-40f3-a727-7c7a2887397b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "   model_name      confusion_matrix  accuracy    recall  f1_score  \\\n",
              "0    rnd_clf0   [15249, 4, 10, 177]  0.999093  0.946524  0.961957   \n",
              "1    rnd_clf1    [15248, 5, 9, 178]  0.999093  0.951872  0.962162   \n",
              "2    rnd_clf2    [15248, 5, 9, 178]  0.999093  0.951872  0.962162   \n",
              "3   tree_clf0   [15234, 19, 9, 178]  0.998187  0.951872  0.927083   \n",
              "4   tree_clf1   [15228, 25, 6, 181]  0.997992  0.967914  0.921120   \n",
              "5   tree_clf2   [15230, 23, 9, 178]  0.997927  0.951872  0.917526   \n",
              "6   tree_clf3  [15227, 26, 10, 177]  0.997668  0.946524  0.907692   \n",
              "7   tree_clf0  [15227, 26, 10, 177]  0.997668  0.946524  0.907692   \n",
              "8   tree_clf1   [15228, 25, 6, 181]  0.997992  0.967914  0.921120   \n",
              "9   tree_clf2   [15230, 23, 9, 178]  0.997927  0.951872  0.917526   \n",
              "10  tree_clf3  [15227, 26, 10, 177]  0.997668  0.946524  0.907692   \n",
              "11  tree_clf0   [15234, 19, 9, 178]  0.998187  0.951872  0.927083   \n",
              "12  tree_clf1   [15228, 25, 6, 181]  0.997992  0.967914  0.921120   \n",
              "13  tree_clf2   [15230, 23, 9, 178]  0.997927  0.951872  0.917526   \n",
              "14  tree_clf3  [15227, 26, 10, 177]  0.997668  0.946524  0.907692   \n",
              "\n",
              "    roc_auc_score  \n",
              "0        0.973131  \n",
              "1        0.975772  \n",
              "2        0.975772  \n",
              "3        0.975313  \n",
              "4        0.983138  \n",
              "5        0.975182  \n",
              "6        0.972410  \n",
              "7        0.972410  \n",
              "8        0.983138  \n",
              "9        0.975182  \n",
              "10       0.972410  \n",
              "11       0.975313  \n",
              "12       0.983138  \n",
              "13       0.975182  \n",
              "14       0.972410  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-10784ce4-2f8f-4f3e-9e8b-bc3766b57d7c\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>model_name</th>\n",
              "      <th>confusion_matrix</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>recall</th>\n",
              "      <th>f1_score</th>\n",
              "      <th>roc_auc_score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>rnd_clf0</td>\n",
              "      <td>[15249, 4, 10, 177]</td>\n",
              "      <td>0.999093</td>\n",
              "      <td>0.946524</td>\n",
              "      <td>0.961957</td>\n",
              "      <td>0.973131</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>rnd_clf1</td>\n",
              "      <td>[15248, 5, 9, 178]</td>\n",
              "      <td>0.999093</td>\n",
              "      <td>0.951872</td>\n",
              "      <td>0.962162</td>\n",
              "      <td>0.975772</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>rnd_clf2</td>\n",
              "      <td>[15248, 5, 9, 178]</td>\n",
              "      <td>0.999093</td>\n",
              "      <td>0.951872</td>\n",
              "      <td>0.962162</td>\n",
              "      <td>0.975772</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>tree_clf0</td>\n",
              "      <td>[15234, 19, 9, 178]</td>\n",
              "      <td>0.998187</td>\n",
              "      <td>0.951872</td>\n",
              "      <td>0.927083</td>\n",
              "      <td>0.975313</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>tree_clf1</td>\n",
              "      <td>[15228, 25, 6, 181]</td>\n",
              "      <td>0.997992</td>\n",
              "      <td>0.967914</td>\n",
              "      <td>0.921120</td>\n",
              "      <td>0.983138</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>tree_clf2</td>\n",
              "      <td>[15230, 23, 9, 178]</td>\n",
              "      <td>0.997927</td>\n",
              "      <td>0.951872</td>\n",
              "      <td>0.917526</td>\n",
              "      <td>0.975182</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>tree_clf3</td>\n",
              "      <td>[15227, 26, 10, 177]</td>\n",
              "      <td>0.997668</td>\n",
              "      <td>0.946524</td>\n",
              "      <td>0.907692</td>\n",
              "      <td>0.972410</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>tree_clf0</td>\n",
              "      <td>[15227, 26, 10, 177]</td>\n",
              "      <td>0.997668</td>\n",
              "      <td>0.946524</td>\n",
              "      <td>0.907692</td>\n",
              "      <td>0.972410</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>tree_clf1</td>\n",
              "      <td>[15228, 25, 6, 181]</td>\n",
              "      <td>0.997992</td>\n",
              "      <td>0.967914</td>\n",
              "      <td>0.921120</td>\n",
              "      <td>0.983138</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>tree_clf2</td>\n",
              "      <td>[15230, 23, 9, 178]</td>\n",
              "      <td>0.997927</td>\n",
              "      <td>0.951872</td>\n",
              "      <td>0.917526</td>\n",
              "      <td>0.975182</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>tree_clf3</td>\n",
              "      <td>[15227, 26, 10, 177]</td>\n",
              "      <td>0.997668</td>\n",
              "      <td>0.946524</td>\n",
              "      <td>0.907692</td>\n",
              "      <td>0.972410</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>tree_clf0</td>\n",
              "      <td>[15234, 19, 9, 178]</td>\n",
              "      <td>0.998187</td>\n",
              "      <td>0.951872</td>\n",
              "      <td>0.927083</td>\n",
              "      <td>0.975313</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>tree_clf1</td>\n",
              "      <td>[15228, 25, 6, 181]</td>\n",
              "      <td>0.997992</td>\n",
              "      <td>0.967914</td>\n",
              "      <td>0.921120</td>\n",
              "      <td>0.983138</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>tree_clf2</td>\n",
              "      <td>[15230, 23, 9, 178]</td>\n",
              "      <td>0.997927</td>\n",
              "      <td>0.951872</td>\n",
              "      <td>0.917526</td>\n",
              "      <td>0.975182</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>tree_clf3</td>\n",
              "      <td>[15227, 26, 10, 177]</td>\n",
              "      <td>0.997668</td>\n",
              "      <td>0.946524</td>\n",
              "      <td>0.907692</td>\n",
              "      <td>0.972410</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-10784ce4-2f8f-4f3e-9e8b-bc3766b57d7c')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-10784ce4-2f8f-4f3e-9e8b-bc3766b57d7c button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-10784ce4-2f8f-4f3e-9e8b-bc3766b57d7c');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Random Forest Classifier\n",
        "\n",
        "- Library: Scikit-learn"
      ],
      "metadata": {
        "id": "e5dbRikwt1ov"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Training\n",
        "\n",
        "name = 'rnd_clf'\n",
        "\n",
        "train = pd.DataFrame(columns = ['n_estimators', 'min_samples_split', 'min_samples_leaf', 'max_features','max_depth', 'n_jobs', 'random_state'])\n",
        "train = train.append({'n_estimators' : 100, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'auto', 'max_depth' : None, 'n_jobs': -1, 'random_state': 10}, ignore_index=True)\n",
        "train = train.append({'n_estimators' : 300, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_features': 'auto', 'max_depth' : 31, 'n_jobs': -1, 'random_state': 10}, ignore_index=True)\n",
        "train = train.append({'n_estimators' : 300, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_features': 'auto', 'max_depth' : None, 'n_jobs': -1, 'random_state': 10}, ignore_index=True)\n",
        "\n",
        "train = train.reset_index()\n",
        "for index, row in train.iterrows():\n",
        "    model_name = name + str(index)\n",
        "    rnd_clf = RandomForestClassifier(n_estimators = int(row['n_estimators']), max_depth = None, \n",
        "                                    n_jobs = int(row['n_jobs']), random_state = int(row['random_state']))\n",
        "    rnd_clf.fit(X_train, y_train)\n",
        "    \n",
        "    y_true = y_val\n",
        "    y_pred = rnd_clf.predict(X_val)\n",
        "    evaluation_results = evaluation_metrics(y_true, y_pred)\n",
        "\n",
        "    models = models.append({'model_name': model_name, \n",
        "                            'model': rnd_clf, \n",
        "                            'parameters': rnd_clf.get_params()}, \n",
        "                           ignore_index=True)\n",
        "    \n",
        "    models_eval = models_eval.append({'model_name': model_name, \n",
        "                                      'confusion_matrix' : evaluation_results[0], \n",
        "                                      'accuracy': evaluation_results[1], \n",
        "                                      'recall' : evaluation_results[2], \n",
        "                                      'f1_score': evaluation_results[3], \n",
        "                                      'roc_auc_score': evaluation_results[4]}, \n",
        "                                     ignore_index=True)"
      ],
      "metadata": {
        "id": "_n_M-g9kZTyK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# RandomizedSearchCV\n",
        "\n",
        "# Number of trees in random forest\n",
        "n_estimators = [int(x) for x in np.linspace(start = 300, stop = 500, num = 20)]\n",
        "# Number of features to consider at every split\n",
        "max_features = [int(x) for x in np.linspace(1, len(df.columns), num = len(df.columns))]\n",
        "# Maximum number of levels in tree\n",
        "max_depth = [int(x) for x in np.linspace(15, 35, num = 7)]\n",
        "max_depth.append(None)\n",
        "# Minimum number of samples required to split a node\n",
        "min_samples_split = [2, 3, 4, 5, 6]\n",
        "# Minimum number of samples required at each leaf node\n",
        "min_samples_leaf = [1, 2, 4]\n",
        "\n",
        "# Create the random grid\n",
        "random_grid = {\n",
        "               'n_estimators': n_estimators,\n",
        "               'max_features': max_features,\n",
        "               'max_depth': max_depth,\n",
        "               'min_samples_split': min_samples_split,\n",
        "               'min_samples_leaf': min_samples_leaf,\n",
        "              }\n",
        "\n",
        "rnd_random = RandomizedSearchCV(estimator = rnd_clf, \n",
        "                                param_distributions = random_grid, \n",
        "                                n_iter = 100, \n",
        "                                cv = 3, \n",
        "                                verbose=2, \n",
        "                                scoring='recall',\n",
        "                                random_state=10)\n",
        "\n",
        "rnd_random.fit(X_train, y_train)\n",
        "rnd_random.best_params_"
      ],
      "metadata": {
        "id": "WskTBZDQe43o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "display(models_eval)"
      ],
      "metadata": {
        "id": "jo4WWeMIe3G6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        },
        "outputId": "fdd79b73-c8ec-449c-e74a-44d9445df1b0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  model_name     confusion_matrix  accuracy    recall  f1_score  roc_auc_score\n",
              "0   rnd_clf0  [15249, 4, 10, 177]  0.999093  0.946524  0.961957       0.973131\n",
              "1   rnd_clf1   [15248, 5, 9, 178]  0.999093  0.951872  0.962162       0.975772\n",
              "2   rnd_clf2   [15248, 5, 9, 178]  0.999093  0.951872  0.962162       0.975772"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-00443d69-a7a1-4d35-af39-eb6d859c3b63\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>model_name</th>\n",
              "      <th>confusion_matrix</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>recall</th>\n",
              "      <th>f1_score</th>\n",
              "      <th>roc_auc_score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>rnd_clf0</td>\n",
              "      <td>[15249, 4, 10, 177]</td>\n",
              "      <td>0.999093</td>\n",
              "      <td>0.946524</td>\n",
              "      <td>0.961957</td>\n",
              "      <td>0.973131</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>rnd_clf1</td>\n",
              "      <td>[15248, 5, 9, 178]</td>\n",
              "      <td>0.999093</td>\n",
              "      <td>0.951872</td>\n",
              "      <td>0.962162</td>\n",
              "      <td>0.975772</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>rnd_clf2</td>\n",
              "      <td>[15248, 5, 9, 178]</td>\n",
              "      <td>0.999093</td>\n",
              "      <td>0.951872</td>\n",
              "      <td>0.962162</td>\n",
              "      <td>0.975772</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-00443d69-a7a1-4d35-af39-eb6d859c3b63')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-00443d69-a7a1-4d35-af39-eb6d859c3b63 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-00443d69-a7a1-4d35-af39-eb6d859c3b63');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Gradient Boosting Classifier\n",
        "\n",
        "- Library: Scikit-learn"
      ],
      "metadata": {
        "id": "-0VzXIIcuTah"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Training\n",
        "\n",
        "name = 'gboost_clf'\n",
        "\n",
        "train = pd.DataFrame(columns = ['n_estimators', 'learning_rate', 'max_depth', 'random_state'])\n",
        "train = train.append({'n_estimators': 100, 'learning_rate':0.1, 'max_depth':3, 'random_state':10}, ignore_index=True)\n",
        "train = train.append({'n_estimators': 500, 'learning_rate':0.5, 'max_depth':1, 'random_state':10}, ignore_index=True)\n",
        "train = train.append({'n_estimators': 50, 'learning_rate':0.01, 'max_depth':10, 'random_state':10}, ignore_index=True)\n",
        "\n",
        "train = train.reset_index()\n",
        "for index, row in train.iterrows():\n",
        "    model_name = name + str(index)\n",
        "    gboost_clf = GradientBoostingClassifier(n_estimators=int(row['n_estimators']), learning_rate=row['learning_rate'],\n",
        "                                            max_depth=int(row['max_depth']), random_state=int(row['random_state']))\n",
        "    gboost_clf.fit(X_train, y_train)\n",
        "   \n",
        "    y_true = y_val\n",
        "    y_pred = gboost_clf.predict(X_val)\n",
        "    evaluation_results = evaluation_metrics(y_true, y_pred)\n",
        "\n",
        "    models = models.append({'model_name': model_name, \n",
        "                            'model': gboost_clf, \n",
        "                            'parameters': gboost_clf.get_params()}, \n",
        "                           ignore_index=True)\n",
        "   \n",
        "    models_eval = models_eval.append({'model_name': model_name, \n",
        "                                      'confusion_matrix' : evaluation_results[0], \n",
        "                                      'accuracy': evaluation_results[1], \n",
        "                                      'recall' : evaluation_results[2], \n",
        "                                      'f1_score': evaluation_results[3], \n",
        "                                      'roc_auc_score': evaluation_results[4]}, \n",
        "                                     ignore_index=True)"
      ],
      "metadata": {
        "id": "xRoZe1r0ZUd-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# RandomizedSearchCV\n",
        "\n",
        "random_grid = {\n",
        "              \"n_estimators\": [100, 500, 750, 1000, 2000],\n",
        "              \"learning_rate\": [0.01, 0.05, 0.10, 0.15, 0.20, 0.25, 0.30, 0.50],\n",
        "              \"max_depth\": [1, 3, 5, 8, 10, 15]\n",
        "              }\n",
        "\n",
        "gboost_random = RandomizedSearchCV(estimator = gboost_clf, \n",
        "                                 param_distributions = random_grid, \n",
        "                                 n_iter = 50, \n",
        "                                 cv = 3, \n",
        "                                 verbose=2, \n",
        "                                 scoring='recall',\n",
        "                                 random_state=10)\n",
        "\n",
        "gboost_random.fit(X_train, y_train)\n",
        "gboost_random.best_params_"
      ],
      "metadata": {
        "id": "1FhLDX1nN6bT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "display(models_eval)"
      ],
      "metadata": {
        "id": "GiUCLVzoq4qa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## XGBoost\n",
        "\n",
        "- Library: xgboost"
      ],
      "metadata": {
        "id": "J3M3ob9buTHm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Training\n",
        "\n",
        "name = 'xgboost_clf'\n",
        "\n",
        "train = pd.DataFrame(columns = ['n_estimators', 'learning_rate', 'max_depth', 'random_state'])\n",
        "train = train.append({'n_estimators': 1000, 'learning_rate':0.0001, 'max_depth':3, 'random_state':10}, ignore_index=True)\n",
        "train = train.append({'n_estimators': 500, 'learning_rate':0.5, 'max_depth':1, 'random_state':10}, ignore_index=True)\n",
        "train = train.append({'n_estimators': 750, 'learning_rate':0.01, 'max_depth':10, 'random_state':10}, ignore_index=True)\n",
        "\n",
        "train = train.reset_index()\n",
        "for index, row in train.iterrows():\n",
        "    model_name = name + str(index)\n",
        "    xgboost_clf = XGBClassifier(n_estimators=int(row['n_estimators']), learning_rate=row['learning_rate'],\n",
        "                                max_depth=int(row['max_depth']), random_state=int(row['random_state']))\n",
        "    xgboost_clf.fit(X_train, y_train)\n",
        "    \n",
        "    y_true = y_val\n",
        "    y_pred = xgboost_clf.predict(X_val)\n",
        "    evaluation_results = evaluation_metrics(y_true, y_pred)\n",
        "\n",
        "    models = models.append({'model_name': model_name, \n",
        "                            'model': xgboost_clf, \n",
        "                            'parameters': xgboost_clf.get_params()}, \n",
        "                           ignore_index=True)\n",
        "    \n",
        "    models_eval = models_eval.append({'model_name': model_name, \n",
        "                                      'confusion_matrix' : evaluation_results[0], \n",
        "                                      'accuracy': evaluation_results[1], \n",
        "                                      'recall' : evaluation_results[2], \n",
        "                                      'f1_score': evaluation_results[3], \n",
        "                                      'roc_auc_score': evaluation_results[4]}, \n",
        "                                     ignore_index=True)"
      ],
      "metadata": {
        "id": "evYZbB-MZVmF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# RandomizedSearchCV\n",
        "\n",
        "random_grid = {\n",
        "              \"n_estimators\": [100, 500, 750, 1000, 2000],\n",
        "              \"learning_rate\": [0.01, 0.05, 0.10, 0.15, 0.20, 0.25, 0.30, 0.50],\n",
        "              \"max_depth\": [1, 3, 5, 8, 10, 15],\n",
        "              \"min_child_weight\" : [1, 3, 5, 7]\n",
        "              }\n",
        "\n",
        "xgboost_random = RandomizedSearchCV(estimator = xgboost_clf, \n",
        "                                 param_distributions = random_grid, \n",
        "                                 n_iter = 50, \n",
        "                                 cv = 3, \n",
        "                                 verbose=2, \n",
        "                                 scoring='recall',\n",
        "                                 random_state=10)\n",
        "\n",
        "xgboost_random.fit(X_train, y_train)\n",
        "xgboost_random.best_params_"
      ],
      "metadata": {
        "id": "DJEXkDKKPtx_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "display(models_eval)"
      ],
      "metadata": {
        "id": "PSc4LKMTq3qd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "xgboost_random.best_params_"
      ],
      "metadata": {
        "id": "Z1hMgf8SnLmG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## LightGBM\n",
        "\n",
        "- Library: lightbgm"
      ],
      "metadata": {
        "id": "p3iAdzksueOk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Training\n",
        "\n",
        "name = 'lightgbm_clf'\n",
        "\n",
        "train = pd.DataFrame(columns = ['n_estimators', 'learning_rate', 'max_depth', 'random_state'])\n",
        "train = train.append({'n_estimators': 1000, 'learning_rate':0.1, 'max_depth':3, 'random_state':10}, ignore_index=True)\n",
        "train = train.append({'n_estimators': 500, 'learning_rate':0.5, 'max_depth':1, 'random_state':10}, ignore_index=True)\n",
        "train = train.append({'n_estimators': 750, 'learning_rate':0.01, 'max_depth':10, 'random_state':10}, ignore_index=True)\n",
        "\n",
        "train = train.reset_index()\n",
        "for index, row in train.iterrows():\n",
        "    model_name = name + str(index)\n",
        "    lightgbm_clf = LGBMClassifier(n_estimators=int(row['n_estimators']), learning_rate=row['learning_rate'],\n",
        "                                max_depth=int(row['max_depth']), random_state=int(row['random_state']))\n",
        "    lightgbm_clf.fit(X_train, y_train)\n",
        "    \n",
        "    y_true = y_val\n",
        "    y_pred = lightgbm_clf.predict(X_val)\n",
        "    evaluation_results = evaluation_metrics(y_true, y_pred)   \n",
        "\n",
        "    models = models.append({'model_name': model_name, \n",
        "                            'model': lightgbm_clf, \n",
        "                            'parameters': lightgbm_clf.get_params()}, \n",
        "                           ignore_index=True)\n",
        "    \n",
        "    models_eval = models_eval.append({'model_name': model_name, \n",
        "                                      'confusion_matrix' : evaluation_results[0], \n",
        "                                      'accuracy': evaluation_results[1], \n",
        "                                      'recall' : evaluation_results[2], \n",
        "                                      'f1_score': evaluation_results[3], \n",
        "                                      'roc_auc_score': evaluation_results[4]}, \n",
        "                                     ignore_index=True)"
      ],
      "metadata": {
        "id": "sh_I5t-TZVaP"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# RandomizedSearchCV\n",
        "\n",
        "random_grid = {\n",
        "              \"n_estimators\": [100, 500, 750, 1000, 2000],\n",
        "              \"learning_rate\": [0.01, 0.05, 0.10, 0.15, 0.20, 0.25, 0.30, 0.50],\n",
        "              \"max_depth\": [1, 3, 5, 8, 10, 15, 20],\n",
        "              \"num_leaves\": [10, 31, 50, 100, 200, 500],\n",
        "              \"min_data_in_leaf\": [10, 20, 25, 50, 100]\n",
        "              }\n",
        "\n",
        "lightgbm_random = RandomizedSearchCV(estimator = lightgbm_clf, \n",
        "                                 param_distributions = random_grid, \n",
        "                                 n_iter = 150, \n",
        "                                 cv = 3, \n",
        "                                 verbose=2, \n",
        "                                 scoring='recall',\n",
        "                                 random_state=10)\n",
        "\n",
        "lightgbm_random.fit(X_train, y_train)\n",
        "lightgbm_random.best_params_"
      ],
      "metadata": {
        "id": "-P5Jw0-sQ6Vn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fce6c8bf-8aae-4e17-da02-f762bcf8cd5d"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 3 folds for each of 150 candidates, totalling 450 fits\n",
            "[CV] END learning_rate=0.5, max_depth=1, min_data_in_leaf=10, n_estimators=2000, num_leaves=500; total time=  23.9s\n",
            "[CV] END learning_rate=0.5, max_depth=1, min_data_in_leaf=10, n_estimators=2000, num_leaves=500; total time=  25.2s\n",
            "[CV] END learning_rate=0.5, max_depth=1, min_data_in_leaf=10, n_estimators=2000, num_leaves=500; total time=  23.0s\n",
            "[CV] END learning_rate=0.3, max_depth=20, min_data_in_leaf=10, n_estimators=2000, num_leaves=50; total time=  51.9s\n",
            "[CV] END learning_rate=0.3, max_depth=20, min_data_in_leaf=10, n_estimators=2000, num_leaves=50; total time=  58.6s\n",
            "[CV] END learning_rate=0.3, max_depth=20, min_data_in_leaf=10, n_estimators=2000, num_leaves=50; total time=  58.0s\n",
            "[CV] END learning_rate=0.15, max_depth=15, min_data_in_leaf=10, n_estimators=100, num_leaves=50; total time=   3.8s\n",
            "[CV] END learning_rate=0.15, max_depth=15, min_data_in_leaf=10, n_estimators=100, num_leaves=50; total time=   3.8s\n",
            "[CV] END learning_rate=0.15, max_depth=15, min_data_in_leaf=10, n_estimators=100, num_leaves=50; total time=   3.8s\n",
            "[CV] END learning_rate=0.25, max_depth=1, min_data_in_leaf=50, n_estimators=2000, num_leaves=200; total time=  26.5s\n",
            "[CV] END learning_rate=0.25, max_depth=1, min_data_in_leaf=50, n_estimators=2000, num_leaves=200; total time=  23.2s\n",
            "[CV] END learning_rate=0.25, max_depth=1, min_data_in_leaf=50, n_estimators=2000, num_leaves=200; total time=  24.0s\n",
            "[CV] END learning_rate=0.5, max_depth=1, min_data_in_leaf=100, n_estimators=500, num_leaves=10; total time=   6.1s\n",
            "[CV] END learning_rate=0.5, max_depth=1, min_data_in_leaf=100, n_estimators=500, num_leaves=10; total time=   6.1s\n",
            "[CV] END learning_rate=0.5, max_depth=1, min_data_in_leaf=100, n_estimators=500, num_leaves=10; total time=   6.1s\n",
            "[CV] END learning_rate=0.1, max_depth=8, min_data_in_leaf=100, n_estimators=2000, num_leaves=50; total time= 1.0min\n",
            "[CV] END learning_rate=0.1, max_depth=8, min_data_in_leaf=100, n_estimators=2000, num_leaves=50; total time= 1.0min\n",
            "[CV] END learning_rate=0.1, max_depth=8, min_data_in_leaf=100, n_estimators=2000, num_leaves=50; total time= 1.0min\n",
            "[CV] END learning_rate=0.25, max_depth=5, min_data_in_leaf=20, n_estimators=100, num_leaves=50; total time=   2.8s\n",
            "[CV] END learning_rate=0.25, max_depth=5, min_data_in_leaf=20, n_estimators=100, num_leaves=50; total time=   2.8s\n",
            "[CV] END learning_rate=0.25, max_depth=5, min_data_in_leaf=20, n_estimators=100, num_leaves=50; total time=   2.9s\n",
            "[CV] END learning_rate=0.2, max_depth=10, min_data_in_leaf=100, n_estimators=100, num_leaves=500; total time=   5.5s\n",
            "[CV] END learning_rate=0.2, max_depth=10, min_data_in_leaf=100, n_estimators=100, num_leaves=500; total time=   5.3s\n",
            "[CV] END learning_rate=0.2, max_depth=10, min_data_in_leaf=100, n_estimators=100, num_leaves=500; total time=   5.3s\n",
            "[CV] END learning_rate=0.05, max_depth=5, min_data_in_leaf=20, n_estimators=1000, num_leaves=10; total time=  22.6s\n",
            "[CV] END learning_rate=0.05, max_depth=5, min_data_in_leaf=20, n_estimators=1000, num_leaves=10; total time=  19.4s\n",
            "[CV] END learning_rate=0.05, max_depth=5, min_data_in_leaf=20, n_estimators=1000, num_leaves=10; total time=  19.3s\n",
            "[CV] END learning_rate=0.2, max_depth=10, min_data_in_leaf=50, n_estimators=2000, num_leaves=31; total time=  52.4s\n",
            "[CV] END learning_rate=0.2, max_depth=10, min_data_in_leaf=50, n_estimators=2000, num_leaves=31; total time=  55.7s\n",
            "[CV] END learning_rate=0.2, max_depth=10, min_data_in_leaf=50, n_estimators=2000, num_leaves=31; total time=  53.6s\n",
            "[CV] END learning_rate=0.1, max_depth=8, min_data_in_leaf=100, n_estimators=100, num_leaves=100; total time=   4.0s\n",
            "[CV] END learning_rate=0.1, max_depth=8, min_data_in_leaf=100, n_estimators=100, num_leaves=100; total time=   4.0s\n",
            "[CV] END learning_rate=0.1, max_depth=8, min_data_in_leaf=100, n_estimators=100, num_leaves=100; total time=   4.0s\n",
            "[CV] END learning_rate=0.15, max_depth=8, min_data_in_leaf=20, n_estimators=750, num_leaves=500; total time=  27.3s\n",
            "[CV] END learning_rate=0.15, max_depth=8, min_data_in_leaf=20, n_estimators=750, num_leaves=500; total time=  27.7s\n",
            "[CV] END learning_rate=0.15, max_depth=8, min_data_in_leaf=20, n_estimators=750, num_leaves=500; total time=  30.2s\n",
            "[CV] END learning_rate=0.05, max_depth=1, min_data_in_leaf=100, n_estimators=750, num_leaves=50; total time=   9.0s\n",
            "[CV] END learning_rate=0.05, max_depth=1, min_data_in_leaf=100, n_estimators=750, num_leaves=50; total time=   9.1s\n",
            "[CV] END learning_rate=0.05, max_depth=1, min_data_in_leaf=100, n_estimators=750, num_leaves=50; total time=   9.1s\n",
            "[CV] END learning_rate=0.25, max_depth=8, min_data_in_leaf=20, n_estimators=100, num_leaves=200; total time=   4.5s\n",
            "[CV] END learning_rate=0.25, max_depth=8, min_data_in_leaf=20, n_estimators=100, num_leaves=200; total time=   4.4s\n",
            "[CV] END learning_rate=0.25, max_depth=8, min_data_in_leaf=20, n_estimators=100, num_leaves=200; total time=   4.4s\n",
            "[CV] END learning_rate=0.05, max_depth=5, min_data_in_leaf=50, n_estimators=2000, num_leaves=500; total time=  50.0s\n",
            "[CV] END learning_rate=0.05, max_depth=5, min_data_in_leaf=50, n_estimators=2000, num_leaves=500; total time=  52.7s\n",
            "[CV] END learning_rate=0.05, max_depth=5, min_data_in_leaf=50, n_estimators=2000, num_leaves=500; total time=  49.9s\n",
            "[CV] END learning_rate=0.15, max_depth=15, min_data_in_leaf=100, n_estimators=1000, num_leaves=31; total time=  26.4s\n",
            "[CV] END learning_rate=0.15, max_depth=15, min_data_in_leaf=100, n_estimators=1000, num_leaves=31; total time=  36.5s\n",
            "[CV] END learning_rate=0.15, max_depth=15, min_data_in_leaf=100, n_estimators=1000, num_leaves=31; total time=  36.3s\n",
            "[CV] END learning_rate=0.3, max_depth=20, min_data_in_leaf=50, n_estimators=1000, num_leaves=10; total time=  17.1s\n",
            "[CV] END learning_rate=0.3, max_depth=20, min_data_in_leaf=50, n_estimators=1000, num_leaves=10; total time=  18.3s\n",
            "[CV] END learning_rate=0.3, max_depth=20, min_data_in_leaf=50, n_estimators=1000, num_leaves=10; total time=  18.4s\n",
            "[CV] END learning_rate=0.25, max_depth=20, min_data_in_leaf=50, n_estimators=100, num_leaves=10; total time=   2.5s\n",
            "[CV] END learning_rate=0.25, max_depth=20, min_data_in_leaf=50, n_estimators=100, num_leaves=10; total time=   2.5s\n",
            "[CV] END learning_rate=0.25, max_depth=20, min_data_in_leaf=50, n_estimators=100, num_leaves=10; total time=   2.5s\n",
            "[CV] END learning_rate=0.05, max_depth=3, min_data_in_leaf=50, n_estimators=500, num_leaves=500; total time=   9.8s\n",
            "[CV] END learning_rate=0.05, max_depth=3, min_data_in_leaf=50, n_estimators=500, num_leaves=500; total time=  10.8s\n",
            "[CV] END learning_rate=0.05, max_depth=3, min_data_in_leaf=50, n_estimators=500, num_leaves=500; total time=  18.4s\n",
            "[CV] END learning_rate=0.01, max_depth=8, min_data_in_leaf=50, n_estimators=750, num_leaves=200; total time=  57.9s\n",
            "[CV] END learning_rate=0.01, max_depth=8, min_data_in_leaf=50, n_estimators=750, num_leaves=200; total time=  43.1s\n",
            "[CV] END learning_rate=0.01, max_depth=8, min_data_in_leaf=50, n_estimators=750, num_leaves=200; total time=  41.3s\n",
            "[CV] END learning_rate=0.1, max_depth=20, min_data_in_leaf=10, n_estimators=500, num_leaves=200; total time=  48.1s\n",
            "[CV] END learning_rate=0.1, max_depth=20, min_data_in_leaf=10, n_estimators=500, num_leaves=200; total time=  24.6s\n",
            "[CV] END learning_rate=0.1, max_depth=20, min_data_in_leaf=10, n_estimators=500, num_leaves=200; total time=  25.8s\n",
            "[CV] END learning_rate=0.1, max_depth=20, min_data_in_leaf=10, n_estimators=1000, num_leaves=500; total time= 1.0min\n",
            "[CV] END learning_rate=0.1, max_depth=20, min_data_in_leaf=10, n_estimators=1000, num_leaves=500; total time=  48.9s\n",
            "[CV] END learning_rate=0.1, max_depth=20, min_data_in_leaf=10, n_estimators=1000, num_leaves=500; total time=  42.8s\n",
            "[CV] END learning_rate=0.3, max_depth=1, min_data_in_leaf=20, n_estimators=750, num_leaves=31; total time=  11.2s\n",
            "[CV] END learning_rate=0.3, max_depth=1, min_data_in_leaf=20, n_estimators=750, num_leaves=31; total time=   9.0s\n",
            "[CV] END learning_rate=0.3, max_depth=1, min_data_in_leaf=20, n_estimators=750, num_leaves=31; total time=   9.0s\n",
            "[CV] END learning_rate=0.05, max_depth=3, min_data_in_leaf=25, n_estimators=750, num_leaves=10; total time=  13.5s\n",
            "[CV] END learning_rate=0.05, max_depth=3, min_data_in_leaf=25, n_estimators=750, num_leaves=10; total time=  13.3s\n",
            "[CV] END learning_rate=0.05, max_depth=3, min_data_in_leaf=25, n_estimators=750, num_leaves=10; total time=  13.4s\n",
            "[CV] END learning_rate=0.5, max_depth=3, min_data_in_leaf=25, n_estimators=2000, num_leaves=500; total time=  38.9s\n",
            "[CV] END learning_rate=0.5, max_depth=3, min_data_in_leaf=25, n_estimators=2000, num_leaves=500; total time=  38.6s\n",
            "[CV] END learning_rate=0.5, max_depth=3, min_data_in_leaf=25, n_estimators=2000, num_leaves=500; total time=  22.2s\n",
            "[CV] END learning_rate=0.05, max_depth=15, min_data_in_leaf=50, n_estimators=100, num_leaves=31; total time=   3.4s\n",
            "[CV] END learning_rate=0.05, max_depth=15, min_data_in_leaf=50, n_estimators=100, num_leaves=31; total time=   3.4s\n",
            "[CV] END learning_rate=0.05, max_depth=15, min_data_in_leaf=50, n_estimators=100, num_leaves=31; total time=   3.4s\n",
            "[CV] END learning_rate=0.3, max_depth=8, min_data_in_leaf=100, n_estimators=1000, num_leaves=500; total time=  29.9s\n",
            "[CV] END learning_rate=0.3, max_depth=8, min_data_in_leaf=100, n_estimators=1000, num_leaves=500; total time=  30.0s\n",
            "[CV] END learning_rate=0.3, max_depth=8, min_data_in_leaf=100, n_estimators=1000, num_leaves=500; total time=  33.2s\n",
            "[CV] END learning_rate=0.2, max_depth=8, min_data_in_leaf=50, n_estimators=100, num_leaves=100; total time=   4.1s\n",
            "[CV] END learning_rate=0.2, max_depth=8, min_data_in_leaf=50, n_estimators=100, num_leaves=100; total time=   4.0s\n",
            "[CV] END learning_rate=0.2, max_depth=8, min_data_in_leaf=50, n_estimators=100, num_leaves=100; total time=   4.1s\n",
            "[CV] END learning_rate=0.5, max_depth=8, min_data_in_leaf=20, n_estimators=500, num_leaves=31; total time=  10.3s\n",
            "[CV] END learning_rate=0.5, max_depth=8, min_data_in_leaf=20, n_estimators=500, num_leaves=31; total time=  10.3s\n",
            "[CV] END learning_rate=0.5, max_depth=8, min_data_in_leaf=20, n_estimators=500, num_leaves=31; total time=  10.8s\n",
            "[CV] END learning_rate=0.01, max_depth=3, min_data_in_leaf=20, n_estimators=750, num_leaves=31; total time=  13.8s\n",
            "[CV] END learning_rate=0.01, max_depth=3, min_data_in_leaf=20, n_estimators=750, num_leaves=31; total time=  13.9s\n",
            "[CV] END learning_rate=0.01, max_depth=3, min_data_in_leaf=20, n_estimators=750, num_leaves=31; total time=  13.7s\n",
            "[CV] END learning_rate=0.1, max_depth=5, min_data_in_leaf=25, n_estimators=100, num_leaves=10; total time=   2.5s\n",
            "[CV] END learning_rate=0.1, max_depth=5, min_data_in_leaf=25, n_estimators=100, num_leaves=10; total time=   2.5s\n",
            "[CV] END learning_rate=0.1, max_depth=5, min_data_in_leaf=25, n_estimators=100, num_leaves=10; total time=   2.5s\n",
            "[CV] END learning_rate=0.3, max_depth=5, min_data_in_leaf=50, n_estimators=1000, num_leaves=10; total time=  17.1s\n",
            "[CV] END learning_rate=0.3, max_depth=5, min_data_in_leaf=50, n_estimators=1000, num_leaves=10; total time=  20.1s\n",
            "[CV] END learning_rate=0.3, max_depth=5, min_data_in_leaf=50, n_estimators=1000, num_leaves=10; total time=  19.4s\n",
            "[CV] END learning_rate=0.2, max_depth=8, min_data_in_leaf=50, n_estimators=1000, num_leaves=200; total time=  32.0s\n",
            "[CV] END learning_rate=0.2, max_depth=8, min_data_in_leaf=50, n_estimators=1000, num_leaves=200; total time=  32.0s\n",
            "[CV] END learning_rate=0.2, max_depth=8, min_data_in_leaf=50, n_estimators=1000, num_leaves=200; total time=  32.0s\n",
            "[CV] END learning_rate=0.2, max_depth=1, min_data_in_leaf=25, n_estimators=100, num_leaves=500; total time=   1.6s\n",
            "[CV] END learning_rate=0.2, max_depth=1, min_data_in_leaf=25, n_estimators=100, num_leaves=500; total time=   1.6s\n",
            "[CV] END learning_rate=0.2, max_depth=1, min_data_in_leaf=25, n_estimators=100, num_leaves=500; total time=   1.6s\n",
            "[CV] END learning_rate=0.15, max_depth=1, min_data_in_leaf=20, n_estimators=1000, num_leaves=50; total time=  11.7s\n",
            "[CV] END learning_rate=0.15, max_depth=1, min_data_in_leaf=20, n_estimators=1000, num_leaves=50; total time=  11.6s\n",
            "[CV] END learning_rate=0.15, max_depth=1, min_data_in_leaf=20, n_estimators=1000, num_leaves=50; total time=  14.5s\n",
            "[CV] END learning_rate=0.2, max_depth=10, min_data_in_leaf=100, n_estimators=750, num_leaves=100; total time=  25.6s\n",
            "[CV] END learning_rate=0.2, max_depth=10, min_data_in_leaf=100, n_estimators=750, num_leaves=100; total time=  26.4s\n",
            "[CV] END learning_rate=0.2, max_depth=10, min_data_in_leaf=100, n_estimators=750, num_leaves=100; total time=  26.5s\n",
            "[CV] END learning_rate=0.2, max_depth=15, min_data_in_leaf=50, n_estimators=2000, num_leaves=500; total time= 1.0min\n",
            "[CV] END learning_rate=0.2, max_depth=15, min_data_in_leaf=50, n_estimators=2000, num_leaves=500; total time= 1.1min\n",
            "[CV] END learning_rate=0.2, max_depth=15, min_data_in_leaf=50, n_estimators=2000, num_leaves=500; total time= 1.1min\n",
            "[CV] END learning_rate=0.15, max_depth=15, min_data_in_leaf=10, n_estimators=500, num_leaves=100; total time=  23.4s\n",
            "[CV] END learning_rate=0.15, max_depth=15, min_data_in_leaf=10, n_estimators=500, num_leaves=100; total time=  20.6s\n",
            "[CV] END learning_rate=0.15, max_depth=15, min_data_in_leaf=10, n_estimators=500, num_leaves=100; total time=  20.7s\n",
            "[CV] END learning_rate=0.25, max_depth=10, min_data_in_leaf=10, n_estimators=500, num_leaves=50; total time=  16.2s\n",
            "[CV] END learning_rate=0.25, max_depth=10, min_data_in_leaf=10, n_estimators=500, num_leaves=50; total time=  16.2s\n",
            "[CV] END learning_rate=0.25, max_depth=10, min_data_in_leaf=10, n_estimators=500, num_leaves=50; total time=  16.2s\n",
            "[CV] END learning_rate=0.2, max_depth=20, min_data_in_leaf=25, n_estimators=100, num_leaves=10; total time=   2.5s\n",
            "[CV] END learning_rate=0.2, max_depth=20, min_data_in_leaf=25, n_estimators=100, num_leaves=10; total time=   2.5s\n",
            "[CV] END learning_rate=0.2, max_depth=20, min_data_in_leaf=25, n_estimators=100, num_leaves=10; total time=   2.5s\n",
            "[CV] END learning_rate=0.2, max_depth=8, min_data_in_leaf=100, n_estimators=750, num_leaves=200; total time=  25.4s\n",
            "[CV] END learning_rate=0.2, max_depth=8, min_data_in_leaf=100, n_estimators=750, num_leaves=200; total time=  28.5s\n",
            "[CV] END learning_rate=0.2, max_depth=8, min_data_in_leaf=100, n_estimators=750, num_leaves=200; total time=  25.5s\n",
            "[CV] END learning_rate=0.01, max_depth=5, min_data_in_leaf=50, n_estimators=1000, num_leaves=500; total time=  25.5s\n",
            "[CV] END learning_rate=0.01, max_depth=5, min_data_in_leaf=50, n_estimators=1000, num_leaves=500; total time=  25.9s\n",
            "[CV] END learning_rate=0.01, max_depth=5, min_data_in_leaf=50, n_estimators=1000, num_leaves=500; total time=  25.5s\n",
            "[CV] END learning_rate=0.05, max_depth=5, min_data_in_leaf=10, n_estimators=2000, num_leaves=100; total time=  52.9s\n",
            "[CV] END learning_rate=0.05, max_depth=5, min_data_in_leaf=10, n_estimators=2000, num_leaves=100; total time=  50.6s\n",
            "[CV] END learning_rate=0.05, max_depth=5, min_data_in_leaf=10, n_estimators=2000, num_leaves=100; total time=  51.1s\n",
            "[CV] END learning_rate=0.05, max_depth=15, min_data_in_leaf=100, n_estimators=100, num_leaves=500; total time=   7.8s\n",
            "[CV] END learning_rate=0.05, max_depth=15, min_data_in_leaf=100, n_estimators=100, num_leaves=500; total time=   7.9s\n",
            "[CV] END learning_rate=0.05, max_depth=15, min_data_in_leaf=100, n_estimators=100, num_leaves=500; total time=   7.9s\n",
            "[CV] END learning_rate=0.3, max_depth=3, min_data_in_leaf=25, n_estimators=500, num_leaves=31; total time=  11.7s\n",
            "[CV] END learning_rate=0.3, max_depth=3, min_data_in_leaf=25, n_estimators=500, num_leaves=31; total time=   9.0s\n",
            "[CV] END learning_rate=0.3, max_depth=3, min_data_in_leaf=25, n_estimators=500, num_leaves=31; total time=   9.1s\n",
            "[CV] END learning_rate=0.1, max_depth=10, min_data_in_leaf=20, n_estimators=2000, num_leaves=31; total time=  54.7s\n",
            "[CV] END learning_rate=0.1, max_depth=10, min_data_in_leaf=20, n_estimators=2000, num_leaves=31; total time=  53.7s\n",
            "[CV] END learning_rate=0.1, max_depth=10, min_data_in_leaf=20, n_estimators=2000, num_leaves=31; total time=  56.8s\n",
            "[CV] END learning_rate=0.15, max_depth=3, min_data_in_leaf=25, n_estimators=1000, num_leaves=100; total time=  17.2s\n",
            "[CV] END learning_rate=0.15, max_depth=3, min_data_in_leaf=25, n_estimators=1000, num_leaves=100; total time=  17.1s\n",
            "[CV] END learning_rate=0.15, max_depth=3, min_data_in_leaf=25, n_estimators=1000, num_leaves=100; total time=  17.3s\n",
            "[CV] END learning_rate=0.2, max_depth=20, min_data_in_leaf=50, n_estimators=500, num_leaves=200; total time=  18.9s\n",
            "[CV] END learning_rate=0.2, max_depth=20, min_data_in_leaf=50, n_estimators=500, num_leaves=200; total time=  19.9s\n",
            "[CV] END learning_rate=0.2, max_depth=20, min_data_in_leaf=50, n_estimators=500, num_leaves=200; total time=  23.0s\n",
            "[CV] END learning_rate=0.05, max_depth=15, min_data_in_leaf=100, n_estimators=500, num_leaves=50; total time=  16.7s\n",
            "[CV] END learning_rate=0.05, max_depth=15, min_data_in_leaf=100, n_estimators=500, num_leaves=50; total time=  16.8s\n",
            "[CV] END learning_rate=0.05, max_depth=15, min_data_in_leaf=100, n_estimators=500, num_leaves=50; total time=  16.6s\n",
            "[CV] END learning_rate=0.25, max_depth=8, min_data_in_leaf=25, n_estimators=2000, num_leaves=10; total time=  33.6s\n",
            "[CV] END learning_rate=0.25, max_depth=8, min_data_in_leaf=25, n_estimators=2000, num_leaves=10; total time=  36.0s\n",
            "[CV] END learning_rate=0.25, max_depth=8, min_data_in_leaf=25, n_estimators=2000, num_leaves=10; total time=  38.9s\n",
            "[CV] END learning_rate=0.05, max_depth=1, min_data_in_leaf=10, n_estimators=500, num_leaves=500; total time=   6.1s\n",
            "[CV] END learning_rate=0.05, max_depth=1, min_data_in_leaf=10, n_estimators=500, num_leaves=500; total time=   6.1s\n",
            "[CV] END learning_rate=0.05, max_depth=1, min_data_in_leaf=10, n_estimators=500, num_leaves=500; total time=   6.2s\n",
            "[CV] END learning_rate=0.05, max_depth=20, min_data_in_leaf=10, n_estimators=2000, num_leaves=200; total time= 1.3min\n",
            "[CV] END learning_rate=0.05, max_depth=20, min_data_in_leaf=10, n_estimators=2000, num_leaves=200; total time= 1.4min\n",
            "[CV] END learning_rate=0.05, max_depth=20, min_data_in_leaf=10, n_estimators=2000, num_leaves=200; total time= 1.3min\n",
            "[CV] END learning_rate=0.1, max_depth=15, min_data_in_leaf=25, n_estimators=100, num_leaves=50; total time=   3.8s\n",
            "[CV] END learning_rate=0.1, max_depth=15, min_data_in_leaf=25, n_estimators=100, num_leaves=50; total time=   3.8s\n",
            "[CV] END learning_rate=0.1, max_depth=15, min_data_in_leaf=25, n_estimators=100, num_leaves=50; total time=   3.8s\n",
            "[CV] END learning_rate=0.5, max_depth=5, min_data_in_leaf=50, n_estimators=1000, num_leaves=50; total time=  15.5s\n",
            "[CV] END learning_rate=0.5, max_depth=5, min_data_in_leaf=50, n_estimators=1000, num_leaves=50; total time=  23.1s\n",
            "[CV] END learning_rate=0.5, max_depth=5, min_data_in_leaf=50, n_estimators=1000, num_leaves=50; total time=  22.9s\n",
            "[CV] END learning_rate=0.2, max_depth=15, min_data_in_leaf=100, n_estimators=750, num_leaves=100; total time=  25.8s\n",
            "[CV] END learning_rate=0.2, max_depth=15, min_data_in_leaf=100, n_estimators=750, num_leaves=100; total time=  26.8s\n",
            "[CV] END learning_rate=0.2, max_depth=15, min_data_in_leaf=100, n_estimators=750, num_leaves=100; total time=  26.6s\n",
            "[CV] END learning_rate=0.05, max_depth=20, min_data_in_leaf=100, n_estimators=2000, num_leaves=200; total time= 1.4min\n",
            "[CV] END learning_rate=0.05, max_depth=20, min_data_in_leaf=100, n_estimators=2000, num_leaves=200; total time= 1.4min\n",
            "[CV] END learning_rate=0.05, max_depth=20, min_data_in_leaf=100, n_estimators=2000, num_leaves=200; total time= 1.4min\n",
            "[CV] END learning_rate=0.2, max_depth=15, min_data_in_leaf=100, n_estimators=2000, num_leaves=100; total time=  56.1s\n",
            "[CV] END learning_rate=0.2, max_depth=15, min_data_in_leaf=100, n_estimators=2000, num_leaves=100; total time= 1.1min\n",
            "[CV] END learning_rate=0.2, max_depth=15, min_data_in_leaf=100, n_estimators=2000, num_leaves=100; total time= 1.0min\n",
            "[CV] END learning_rate=0.3, max_depth=20, min_data_in_leaf=10, n_estimators=500, num_leaves=50; total time=  15.9s\n",
            "[CV] END learning_rate=0.3, max_depth=20, min_data_in_leaf=10, n_estimators=500, num_leaves=50; total time=  19.2s\n",
            "[CV] END learning_rate=0.3, max_depth=20, min_data_in_leaf=10, n_estimators=500, num_leaves=50; total time=  16.4s\n",
            "[CV] END learning_rate=0.01, max_depth=5, min_data_in_leaf=50, n_estimators=100, num_leaves=50; total time=   2.8s\n",
            "[CV] END learning_rate=0.01, max_depth=5, min_data_in_leaf=50, n_estimators=100, num_leaves=50; total time=   2.8s\n",
            "[CV] END learning_rate=0.01, max_depth=5, min_data_in_leaf=50, n_estimators=100, num_leaves=50; total time=   2.9s\n",
            "[CV] END learning_rate=0.05, max_depth=3, min_data_in_leaf=100, n_estimators=1000, num_leaves=10; total time=  17.8s\n",
            "[CV] END learning_rate=0.05, max_depth=3, min_data_in_leaf=100, n_estimators=1000, num_leaves=10; total time=  17.6s\n",
            "[CV] END learning_rate=0.05, max_depth=3, min_data_in_leaf=100, n_estimators=1000, num_leaves=10; total time=  17.6s\n",
            "[CV] END learning_rate=0.5, max_depth=20, min_data_in_leaf=50, n_estimators=500, num_leaves=200; total time=  15.3s\n",
            "[CV] END learning_rate=0.5, max_depth=20, min_data_in_leaf=50, n_estimators=500, num_leaves=200; total time=  16.1s\n",
            "[CV] END learning_rate=0.5, max_depth=20, min_data_in_leaf=50, n_estimators=500, num_leaves=200; total time=   8.1s\n",
            "[CV] END learning_rate=0.5, max_depth=10, min_data_in_leaf=20, n_estimators=750, num_leaves=500; total time=  21.4s\n",
            "[CV] END learning_rate=0.5, max_depth=10, min_data_in_leaf=20, n_estimators=750, num_leaves=500; total time=  25.3s\n",
            "[CV] END learning_rate=0.5, max_depth=10, min_data_in_leaf=20, n_estimators=750, num_leaves=500; total time=  22.8s\n",
            "[CV] END learning_rate=0.25, max_depth=1, min_data_in_leaf=20, n_estimators=750, num_leaves=100; total time=   9.0s\n",
            "[CV] END learning_rate=0.25, max_depth=1, min_data_in_leaf=20, n_estimators=750, num_leaves=100; total time=   8.9s\n",
            "[CV] END learning_rate=0.25, max_depth=1, min_data_in_leaf=20, n_estimators=750, num_leaves=100; total time=   9.0s\n",
            "[CV] END learning_rate=0.2, max_depth=3, min_data_in_leaf=25, n_estimators=750, num_leaves=500; total time=  13.1s\n",
            "[CV] END learning_rate=0.2, max_depth=3, min_data_in_leaf=25, n_estimators=750, num_leaves=500; total time=  14.3s\n",
            "[CV] END learning_rate=0.2, max_depth=3, min_data_in_leaf=25, n_estimators=750, num_leaves=500; total time=  14.4s\n",
            "[CV] END learning_rate=0.3, max_depth=5, min_data_in_leaf=10, n_estimators=750, num_leaves=10; total time=  13.6s\n",
            "[CV] END learning_rate=0.3, max_depth=5, min_data_in_leaf=10, n_estimators=750, num_leaves=10; total time=  13.8s\n",
            "[CV] END learning_rate=0.3, max_depth=5, min_data_in_leaf=10, n_estimators=750, num_leaves=10; total time=  16.1s\n",
            "[CV] END learning_rate=0.3, max_depth=5, min_data_in_leaf=25, n_estimators=2000, num_leaves=200; total time=  45.9s\n",
            "[CV] END learning_rate=0.3, max_depth=5, min_data_in_leaf=25, n_estimators=2000, num_leaves=200; total time=  46.3s\n",
            "[CV] END learning_rate=0.3, max_depth=5, min_data_in_leaf=25, n_estimators=2000, num_leaves=200; total time=  45.9s\n",
            "[CV] END learning_rate=0.05, max_depth=1, min_data_in_leaf=100, n_estimators=100, num_leaves=100; total time=   1.6s\n",
            "[CV] END learning_rate=0.05, max_depth=1, min_data_in_leaf=100, n_estimators=100, num_leaves=100; total time=   1.6s\n",
            "[CV] END learning_rate=0.05, max_depth=1, min_data_in_leaf=100, n_estimators=100, num_leaves=100; total time=   1.7s\n",
            "[CV] END learning_rate=0.05, max_depth=10, min_data_in_leaf=100, n_estimators=500, num_leaves=31; total time=  16.7s\n",
            "[CV] END learning_rate=0.05, max_depth=10, min_data_in_leaf=100, n_estimators=500, num_leaves=31; total time=  14.3s\n",
            "[CV] END learning_rate=0.05, max_depth=10, min_data_in_leaf=100, n_estimators=500, num_leaves=31; total time=  14.1s\n",
            "[CV] END learning_rate=0.5, max_depth=10, min_data_in_leaf=10, n_estimators=2000, num_leaves=500; total time=  49.0s\n",
            "[CV] END learning_rate=0.5, max_depth=10, min_data_in_leaf=10, n_estimators=2000, num_leaves=500; total time=  51.9s\n",
            "[CV] END learning_rate=0.5, max_depth=10, min_data_in_leaf=10, n_estimators=2000, num_leaves=500; total time=  24.8s\n",
            "[CV] END learning_rate=0.2, max_depth=5, min_data_in_leaf=50, n_estimators=100, num_leaves=500; total time=   2.8s\n",
            "[CV] END learning_rate=0.2, max_depth=5, min_data_in_leaf=50, n_estimators=100, num_leaves=500; total time=   2.8s\n",
            "[CV] END learning_rate=0.2, max_depth=5, min_data_in_leaf=50, n_estimators=100, num_leaves=500; total time=   2.8s\n",
            "[CV] END learning_rate=0.5, max_depth=8, min_data_in_leaf=50, n_estimators=500, num_leaves=100; total time=  14.4s\n",
            "[CV] END learning_rate=0.5, max_depth=8, min_data_in_leaf=50, n_estimators=500, num_leaves=100; total time=  14.5s\n",
            "[CV] END learning_rate=0.5, max_depth=8, min_data_in_leaf=50, n_estimators=500, num_leaves=100; total time=  14.5s\n",
            "[CV] END learning_rate=0.01, max_depth=1, min_data_in_leaf=100, n_estimators=1000, num_leaves=31; total time=  11.6s\n",
            "[CV] END learning_rate=0.01, max_depth=1, min_data_in_leaf=100, n_estimators=1000, num_leaves=31; total time=  11.7s\n",
            "[CV] END learning_rate=0.01, max_depth=1, min_data_in_leaf=100, n_estimators=1000, num_leaves=31; total time=  11.7s\n",
            "[CV] END learning_rate=0.05, max_depth=1, min_data_in_leaf=20, n_estimators=100, num_leaves=10; total time=   1.6s\n",
            "[CV] END learning_rate=0.05, max_depth=1, min_data_in_leaf=20, n_estimators=100, num_leaves=10; total time=   1.6s\n",
            "[CV] END learning_rate=0.05, max_depth=1, min_data_in_leaf=20, n_estimators=100, num_leaves=10; total time=   1.6s\n",
            "[CV] END learning_rate=0.3, max_depth=20, min_data_in_leaf=50, n_estimators=500, num_leaves=50; total time=  22.7s\n",
            "[CV] END learning_rate=0.3, max_depth=20, min_data_in_leaf=50, n_estimators=500, num_leaves=50; total time=  19.5s\n",
            "[CV] END learning_rate=0.3, max_depth=20, min_data_in_leaf=50, n_estimators=500, num_leaves=50; total time=  16.1s\n",
            "[CV] END learning_rate=0.3, max_depth=20, min_data_in_leaf=50, n_estimators=1000, num_leaves=200; total time=  29.4s\n",
            "[CV] END learning_rate=0.3, max_depth=20, min_data_in_leaf=50, n_estimators=1000, num_leaves=200; total time=  31.2s\n",
            "[CV] END learning_rate=0.3, max_depth=20, min_data_in_leaf=50, n_estimators=1000, num_leaves=200; total time=  31.8s\n",
            "[CV] END learning_rate=0.25, max_depth=10, min_data_in_leaf=25, n_estimators=100, num_leaves=500; total time=   5.8s\n",
            "[CV] END learning_rate=0.25, max_depth=10, min_data_in_leaf=25, n_estimators=100, num_leaves=500; total time=   5.8s\n",
            "[CV] END learning_rate=0.25, max_depth=10, min_data_in_leaf=25, n_estimators=100, num_leaves=500; total time=   5.8s\n",
            "[CV] END learning_rate=0.15, max_depth=15, min_data_in_leaf=50, n_estimators=2000, num_leaves=50; total time= 1.0min\n",
            "[CV] END learning_rate=0.15, max_depth=15, min_data_in_leaf=50, n_estimators=2000, num_leaves=50; total time=  59.4s\n",
            "[CV] END learning_rate=0.15, max_depth=15, min_data_in_leaf=50, n_estimators=2000, num_leaves=50; total time= 1.0min\n",
            "[CV] END learning_rate=0.15, max_depth=10, min_data_in_leaf=25, n_estimators=750, num_leaves=10; total time=  13.8s\n",
            "[CV] END learning_rate=0.15, max_depth=10, min_data_in_leaf=25, n_estimators=750, num_leaves=10; total time=  13.8s\n",
            "[CV] END learning_rate=0.15, max_depth=10, min_data_in_leaf=25, n_estimators=750, num_leaves=10; total time=  14.0s\n",
            "[CV] END learning_rate=0.25, max_depth=8, min_data_in_leaf=50, n_estimators=1000, num_leaves=100; total time=  29.5s\n",
            "[CV] END learning_rate=0.25, max_depth=8, min_data_in_leaf=50, n_estimators=1000, num_leaves=100; total time=  29.5s\n",
            "[CV] END learning_rate=0.25, max_depth=8, min_data_in_leaf=50, n_estimators=1000, num_leaves=100; total time=  29.7s\n",
            "[CV] END learning_rate=0.25, max_depth=5, min_data_in_leaf=50, n_estimators=100, num_leaves=200; total time=   5.6s\n",
            "[CV] END learning_rate=0.25, max_depth=5, min_data_in_leaf=50, n_estimators=100, num_leaves=200; total time=   2.8s\n",
            "[CV] END learning_rate=0.25, max_depth=5, min_data_in_leaf=50, n_estimators=100, num_leaves=200; total time=   2.8s\n",
            "[CV] END learning_rate=0.01, max_depth=1, min_data_in_leaf=25, n_estimators=1000, num_leaves=100; total time=  11.7s\n",
            "[CV] END learning_rate=0.01, max_depth=1, min_data_in_leaf=25, n_estimators=1000, num_leaves=100; total time=  11.6s\n",
            "[CV] END learning_rate=0.01, max_depth=1, min_data_in_leaf=25, n_estimators=1000, num_leaves=100; total time=  11.6s\n",
            "[CV] END learning_rate=0.01, max_depth=20, min_data_in_leaf=25, n_estimators=2000, num_leaves=10; total time=  41.3s\n",
            "[CV] END learning_rate=0.01, max_depth=20, min_data_in_leaf=25, n_estimators=2000, num_leaves=10; total time=  41.4s\n",
            "[CV] END learning_rate=0.01, max_depth=20, min_data_in_leaf=25, n_estimators=2000, num_leaves=10; total time=  44.2s\n",
            "[CV] END learning_rate=0.01, max_depth=10, min_data_in_leaf=10, n_estimators=100, num_leaves=500; total time=   5.7s\n",
            "[CV] END learning_rate=0.01, max_depth=10, min_data_in_leaf=10, n_estimators=100, num_leaves=500; total time=   5.8s\n",
            "[CV] END learning_rate=0.01, max_depth=10, min_data_in_leaf=10, n_estimators=100, num_leaves=500; total time=   5.9s\n",
            "[CV] END learning_rate=0.3, max_depth=8, min_data_in_leaf=25, n_estimators=500, num_leaves=31; total time=  12.5s\n",
            "[CV] END learning_rate=0.3, max_depth=8, min_data_in_leaf=25, n_estimators=500, num_leaves=31; total time=  13.0s\n",
            "[CV] END learning_rate=0.3, max_depth=8, min_data_in_leaf=25, n_estimators=500, num_leaves=31; total time=  13.1s\n",
            "[CV] END learning_rate=0.01, max_depth=10, min_data_in_leaf=25, n_estimators=1000, num_leaves=100; total time=  40.4s\n",
            "[CV] END learning_rate=0.01, max_depth=10, min_data_in_leaf=25, n_estimators=1000, num_leaves=100; total time=  42.4s\n",
            "[CV] END learning_rate=0.01, max_depth=10, min_data_in_leaf=25, n_estimators=1000, num_leaves=100; total time=  40.7s\n",
            "[CV] END learning_rate=0.2, max_depth=10, min_data_in_leaf=50, n_estimators=1000, num_leaves=50; total time=  30.5s\n",
            "[CV] END learning_rate=0.2, max_depth=10, min_data_in_leaf=50, n_estimators=1000, num_leaves=50; total time=  30.6s\n",
            "[CV] END learning_rate=0.2, max_depth=10, min_data_in_leaf=50, n_estimators=1000, num_leaves=50; total time=  30.6s\n",
            "[CV] END learning_rate=0.01, max_depth=1, min_data_in_leaf=50, n_estimators=2000, num_leaves=50; total time=  25.7s\n",
            "[CV] END learning_rate=0.01, max_depth=1, min_data_in_leaf=50, n_estimators=2000, num_leaves=50; total time=  22.9s\n",
            "[CV] END learning_rate=0.01, max_depth=1, min_data_in_leaf=50, n_estimators=2000, num_leaves=50; total time=  23.4s\n",
            "[CV] END learning_rate=0.05, max_depth=8, min_data_in_leaf=100, n_estimators=500, num_leaves=50; total time=  16.2s\n",
            "[CV] END learning_rate=0.05, max_depth=8, min_data_in_leaf=100, n_estimators=500, num_leaves=50; total time=  15.9s\n",
            "[CV] END learning_rate=0.05, max_depth=8, min_data_in_leaf=100, n_estimators=500, num_leaves=50; total time=  16.0s\n",
            "[CV] END learning_rate=0.5, max_depth=15, min_data_in_leaf=100, n_estimators=100, num_leaves=50; total time=   3.6s\n",
            "[CV] END learning_rate=0.5, max_depth=15, min_data_in_leaf=100, n_estimators=100, num_leaves=50; total time=   3.4s\n",
            "[CV] END learning_rate=0.5, max_depth=15, min_data_in_leaf=100, n_estimators=100, num_leaves=50; total time=   3.5s\n",
            "[CV] END learning_rate=0.05, max_depth=5, min_data_in_leaf=20, n_estimators=2000, num_leaves=500; total time=  52.1s\n",
            "[CV] END learning_rate=0.05, max_depth=5, min_data_in_leaf=20, n_estimators=2000, num_leaves=500; total time=  49.7s\n",
            "[CV] END learning_rate=0.05, max_depth=5, min_data_in_leaf=20, n_estimators=2000, num_leaves=500; total time=  49.3s\n",
            "[CV] END learning_rate=0.05, max_depth=10, min_data_in_leaf=10, n_estimators=500, num_leaves=500; total time=  32.1s\n",
            "[CV] END learning_rate=0.05, max_depth=10, min_data_in_leaf=10, n_estimators=500, num_leaves=500; total time=  31.3s\n",
            "[CV] END learning_rate=0.05, max_depth=10, min_data_in_leaf=10, n_estimators=500, num_leaves=500; total time=  30.9s\n",
            "[CV] END learning_rate=0.25, max_depth=15, min_data_in_leaf=20, n_estimators=750, num_leaves=500; total time=  25.3s\n",
            "[CV] END learning_rate=0.25, max_depth=15, min_data_in_leaf=20, n_estimators=750, num_leaves=500; total time=  26.6s\n",
            "[CV] END learning_rate=0.25, max_depth=15, min_data_in_leaf=20, n_estimators=750, num_leaves=500; total time=  26.7s\n",
            "[CV] END learning_rate=0.01, max_depth=20, min_data_in_leaf=25, n_estimators=750, num_leaves=10; total time=  19.1s\n",
            "[CV] END learning_rate=0.01, max_depth=20, min_data_in_leaf=25, n_estimators=750, num_leaves=10; total time=  16.6s\n",
            "[CV] END learning_rate=0.01, max_depth=20, min_data_in_leaf=25, n_estimators=750, num_leaves=10; total time=  16.5s\n",
            "[CV] END learning_rate=0.15, max_depth=20, min_data_in_leaf=20, n_estimators=750, num_leaves=200; total time=  27.4s\n",
            "[CV] END learning_rate=0.15, max_depth=20, min_data_in_leaf=20, n_estimators=750, num_leaves=200; total time=  28.8s\n",
            "[CV] END learning_rate=0.15, max_depth=20, min_data_in_leaf=20, n_estimators=750, num_leaves=200; total time=  29.0s\n",
            "[CV] END learning_rate=0.05, max_depth=20, min_data_in_leaf=50, n_estimators=1000, num_leaves=500; total time= 1.7min\n",
            "[CV] END learning_rate=0.05, max_depth=20, min_data_in_leaf=50, n_estimators=1000, num_leaves=500; total time= 1.4min\n",
            "[CV] END learning_rate=0.05, max_depth=20, min_data_in_leaf=50, n_estimators=1000, num_leaves=500; total time= 1.0min\n",
            "[CV] END learning_rate=0.2, max_depth=3, min_data_in_leaf=10, n_estimators=1000, num_leaves=10; total time=  17.2s\n",
            "[CV] END learning_rate=0.2, max_depth=3, min_data_in_leaf=10, n_estimators=1000, num_leaves=10; total time=  19.7s\n",
            "[CV] END learning_rate=0.2, max_depth=3, min_data_in_leaf=10, n_estimators=1000, num_leaves=10; total time=  17.2s\n",
            "[CV] END learning_rate=0.25, max_depth=3, min_data_in_leaf=20, n_estimators=750, num_leaves=31; total time=  12.8s\n",
            "[CV] END learning_rate=0.25, max_depth=3, min_data_in_leaf=20, n_estimators=750, num_leaves=31; total time=  13.0s\n",
            "[CV] END learning_rate=0.25, max_depth=3, min_data_in_leaf=20, n_estimators=750, num_leaves=31; total time=  16.9s\n",
            "[CV] END learning_rate=0.2, max_depth=15, min_data_in_leaf=100, n_estimators=1000, num_leaves=500; total time=  35.2s\n",
            "[CV] END learning_rate=0.2, max_depth=15, min_data_in_leaf=100, n_estimators=1000, num_leaves=500; total time=  36.8s\n",
            "[CV] END learning_rate=0.2, max_depth=15, min_data_in_leaf=100, n_estimators=1000, num_leaves=500; total time=  37.9s\n",
            "[CV] END learning_rate=0.1, max_depth=3, min_data_in_leaf=100, n_estimators=500, num_leaves=50; total time=   8.8s\n",
            "[CV] END learning_rate=0.1, max_depth=3, min_data_in_leaf=100, n_estimators=500, num_leaves=50; total time=   8.7s\n",
            "[CV] END learning_rate=0.1, max_depth=3, min_data_in_leaf=100, n_estimators=500, num_leaves=50; total time=   8.8s\n",
            "[CV] END learning_rate=0.2, max_depth=8, min_data_in_leaf=100, n_estimators=1000, num_leaves=200; total time=  34.0s\n",
            "[CV] END learning_rate=0.2, max_depth=8, min_data_in_leaf=100, n_estimators=1000, num_leaves=200; total time=  31.6s\n",
            "[CV] END learning_rate=0.2, max_depth=8, min_data_in_leaf=100, n_estimators=1000, num_leaves=200; total time=  31.5s\n",
            "[CV] END learning_rate=0.3, max_depth=3, min_data_in_leaf=100, n_estimators=500, num_leaves=200; total time=   8.8s\n",
            "[CV] END learning_rate=0.3, max_depth=3, min_data_in_leaf=100, n_estimators=500, num_leaves=200; total time=   8.8s\n",
            "[CV] END learning_rate=0.3, max_depth=3, min_data_in_leaf=100, n_estimators=500, num_leaves=200; total time=   8.9s\n",
            "[CV] END learning_rate=0.15, max_depth=1, min_data_in_leaf=10, n_estimators=1000, num_leaves=10; total time=  11.6s\n",
            "[CV] END learning_rate=0.15, max_depth=1, min_data_in_leaf=10, n_estimators=1000, num_leaves=10; total time=  11.6s\n",
            "[CV] END learning_rate=0.15, max_depth=1, min_data_in_leaf=10, n_estimators=1000, num_leaves=10; total time=  14.4s\n",
            "[CV] END learning_rate=0.3, max_depth=20, min_data_in_leaf=50, n_estimators=100, num_leaves=50; total time=   3.6s\n",
            "[CV] END learning_rate=0.3, max_depth=20, min_data_in_leaf=50, n_estimators=100, num_leaves=50; total time=   3.6s\n",
            "[CV] END learning_rate=0.3, max_depth=20, min_data_in_leaf=50, n_estimators=100, num_leaves=50; total time=   3.7s\n",
            "[CV] END learning_rate=0.25, max_depth=15, min_data_in_leaf=20, n_estimators=750, num_leaves=100; total time=  24.0s\n",
            "[CV] END learning_rate=0.25, max_depth=15, min_data_in_leaf=20, n_estimators=750, num_leaves=100; total time=  25.1s\n",
            "[CV] END learning_rate=0.25, max_depth=15, min_data_in_leaf=20, n_estimators=750, num_leaves=100; total time=  25.2s\n",
            "[CV] END learning_rate=0.2, max_depth=10, min_data_in_leaf=25, n_estimators=1000, num_leaves=100; total time=  31.4s\n",
            "[CV] END learning_rate=0.2, max_depth=10, min_data_in_leaf=25, n_estimators=1000, num_leaves=100; total time=  34.2s\n",
            "[CV] END learning_rate=0.2, max_depth=10, min_data_in_leaf=25, n_estimators=1000, num_leaves=100; total time=  32.2s\n",
            "[CV] END learning_rate=0.5, max_depth=10, min_data_in_leaf=10, n_estimators=1000, num_leaves=200; total time=  12.5s\n",
            "[CV] END learning_rate=0.5, max_depth=10, min_data_in_leaf=10, n_estimators=1000, num_leaves=200; total time=  30.6s\n",
            "[CV] END learning_rate=0.5, max_depth=10, min_data_in_leaf=10, n_estimators=1000, num_leaves=200; total time=  18.3s\n",
            "[CV] END learning_rate=0.15, max_depth=3, min_data_in_leaf=10, n_estimators=750, num_leaves=500; total time=  13.0s\n",
            "[CV] END learning_rate=0.15, max_depth=3, min_data_in_leaf=10, n_estimators=750, num_leaves=500; total time=  14.9s\n",
            "[CV] END learning_rate=0.15, max_depth=3, min_data_in_leaf=10, n_estimators=750, num_leaves=500; total time=  13.4s\n",
            "[CV] END learning_rate=0.05, max_depth=5, min_data_in_leaf=10, n_estimators=500, num_leaves=500; total time=  12.2s\n",
            "[CV] END learning_rate=0.05, max_depth=5, min_data_in_leaf=10, n_estimators=500, num_leaves=500; total time=  28.1s\n",
            "[CV] END learning_rate=0.05, max_depth=5, min_data_in_leaf=10, n_estimators=500, num_leaves=500; total time=  12.0s\n",
            "[CV] END learning_rate=0.01, max_depth=1, min_data_in_leaf=25, n_estimators=500, num_leaves=10; total time=   6.1s\n",
            "[CV] END learning_rate=0.01, max_depth=1, min_data_in_leaf=25, n_estimators=500, num_leaves=10; total time=   6.2s\n",
            "[CV] END learning_rate=0.01, max_depth=1, min_data_in_leaf=25, n_estimators=500, num_leaves=10; total time=   6.1s\n",
            "[CV] END learning_rate=0.01, max_depth=15, min_data_in_leaf=100, n_estimators=1000, num_leaves=200; total time=  53.5s\n",
            "[CV] END learning_rate=0.01, max_depth=15, min_data_in_leaf=100, n_estimators=1000, num_leaves=200; total time=  56.0s\n",
            "[CV] END learning_rate=0.01, max_depth=15, min_data_in_leaf=100, n_estimators=1000, num_leaves=200; total time=  54.2s\n",
            "[CV] END learning_rate=0.1, max_depth=1, min_data_in_leaf=25, n_estimators=2000, num_leaves=10; total time=  22.8s\n",
            "[CV] END learning_rate=0.1, max_depth=1, min_data_in_leaf=25, n_estimators=2000, num_leaves=10; total time=  22.7s\n",
            "[CV] END learning_rate=0.1, max_depth=1, min_data_in_leaf=25, n_estimators=2000, num_leaves=10; total time=  22.8s\n",
            "[CV] END learning_rate=0.5, max_depth=8, min_data_in_leaf=100, n_estimators=500, num_leaves=10; total time=   8.5s\n",
            "[CV] END learning_rate=0.5, max_depth=8, min_data_in_leaf=100, n_estimators=500, num_leaves=10; total time=   8.3s\n",
            "[CV] END learning_rate=0.5, max_depth=8, min_data_in_leaf=100, n_estimators=500, num_leaves=10; total time=  11.4s\n",
            "[CV] END learning_rate=0.25, max_depth=15, min_data_in_leaf=25, n_estimators=1000, num_leaves=10; total time=  17.9s\n",
            "[CV] END learning_rate=0.25, max_depth=15, min_data_in_leaf=25, n_estimators=1000, num_leaves=10; total time=  16.4s\n",
            "[CV] END learning_rate=0.25, max_depth=15, min_data_in_leaf=25, n_estimators=1000, num_leaves=10; total time=  17.8s\n",
            "[CV] END learning_rate=0.15, max_depth=3, min_data_in_leaf=100, n_estimators=2000, num_leaves=100; total time=  34.4s\n",
            "[CV] END learning_rate=0.15, max_depth=3, min_data_in_leaf=100, n_estimators=2000, num_leaves=100; total time=  34.6s\n",
            "[CV] END learning_rate=0.15, max_depth=3, min_data_in_leaf=100, n_estimators=2000, num_leaves=100; total time=  37.2s\n",
            "[CV] END learning_rate=0.01, max_depth=10, min_data_in_leaf=50, n_estimators=750, num_leaves=500; total time=  42.4s\n",
            "[CV] END learning_rate=0.01, max_depth=10, min_data_in_leaf=50, n_estimators=750, num_leaves=500; total time=  42.5s\n",
            "[CV] END learning_rate=0.01, max_depth=10, min_data_in_leaf=50, n_estimators=750, num_leaves=500; total time=  43.1s\n",
            "[CV] END learning_rate=0.15, max_depth=10, min_data_in_leaf=25, n_estimators=100, num_leaves=200; total time=   5.1s\n",
            "[CV] END learning_rate=0.15, max_depth=10, min_data_in_leaf=25, n_estimators=100, num_leaves=200; total time=   5.1s\n",
            "[CV] END learning_rate=0.15, max_depth=10, min_data_in_leaf=25, n_estimators=100, num_leaves=200; total time=   7.9s\n",
            "[CV] END learning_rate=0.05, max_depth=15, min_data_in_leaf=50, n_estimators=100, num_leaves=200; total time=   6.4s\n",
            "[CV] END learning_rate=0.05, max_depth=15, min_data_in_leaf=50, n_estimators=100, num_leaves=200; total time=   6.7s\n",
            "[CV] END learning_rate=0.05, max_depth=15, min_data_in_leaf=50, n_estimators=100, num_leaves=200; total time=   5.2s\n",
            "[CV] END learning_rate=0.05, max_depth=5, min_data_in_leaf=25, n_estimators=2000, num_leaves=100; total time=  48.7s\n",
            "[CV] END learning_rate=0.05, max_depth=5, min_data_in_leaf=25, n_estimators=2000, num_leaves=100; total time=  49.3s\n",
            "[CV] END learning_rate=0.05, max_depth=5, min_data_in_leaf=25, n_estimators=2000, num_leaves=100; total time=  52.1s\n",
            "[CV] END learning_rate=0.1, max_depth=8, min_data_in_leaf=25, n_estimators=2000, num_leaves=50; total time=  59.2s\n",
            "[CV] END learning_rate=0.1, max_depth=8, min_data_in_leaf=25, n_estimators=2000, num_leaves=50; total time=  58.6s\n",
            "[CV] END learning_rate=0.1, max_depth=8, min_data_in_leaf=25, n_estimators=2000, num_leaves=50; total time= 1.0min\n",
            "[CV] END learning_rate=0.15, max_depth=3, min_data_in_leaf=10, n_estimators=100, num_leaves=200; total time=   2.2s\n",
            "[CV] END learning_rate=0.15, max_depth=3, min_data_in_leaf=10, n_estimators=100, num_leaves=200; total time=   2.2s\n",
            "[CV] END learning_rate=0.15, max_depth=3, min_data_in_leaf=10, n_estimators=100, num_leaves=200; total time=   2.2s\n",
            "[CV] END learning_rate=0.2, max_depth=20, min_data_in_leaf=100, n_estimators=500, num_leaves=100; total time=  19.0s\n",
            "[CV] END learning_rate=0.2, max_depth=20, min_data_in_leaf=100, n_estimators=500, num_leaves=100; total time=  19.3s\n",
            "[CV] END learning_rate=0.2, max_depth=20, min_data_in_leaf=100, n_estimators=500, num_leaves=100; total time=  19.3s\n",
            "[CV] END learning_rate=0.2, max_depth=20, min_data_in_leaf=20, n_estimators=1000, num_leaves=500; total time=  32.0s\n",
            "[CV] END learning_rate=0.2, max_depth=20, min_data_in_leaf=20, n_estimators=1000, num_leaves=500; total time=  37.3s\n",
            "[CV] END learning_rate=0.2, max_depth=20, min_data_in_leaf=20, n_estimators=1000, num_leaves=500; total time=  35.3s\n",
            "[CV] END learning_rate=0.2, max_depth=15, min_data_in_leaf=10, n_estimators=500, num_leaves=500; total time=  19.6s\n",
            "[CV] END learning_rate=0.2, max_depth=15, min_data_in_leaf=10, n_estimators=500, num_leaves=500; total time=  20.2s\n",
            "[CV] END learning_rate=0.2, max_depth=15, min_data_in_leaf=10, n_estimators=500, num_leaves=500; total time=  20.3s\n",
            "[CV] END learning_rate=0.3, max_depth=15, min_data_in_leaf=25, n_estimators=500, num_leaves=100; total time=  16.8s\n",
            "[CV] END learning_rate=0.3, max_depth=15, min_data_in_leaf=25, n_estimators=500, num_leaves=100; total time=  17.4s\n",
            "[CV] END learning_rate=0.3, max_depth=15, min_data_in_leaf=25, n_estimators=500, num_leaves=100; total time=  20.3s\n",
            "[CV] END learning_rate=0.05, max_depth=10, min_data_in_leaf=25, n_estimators=750, num_leaves=31; total time=  20.5s\n",
            "[CV] END learning_rate=0.05, max_depth=10, min_data_in_leaf=25, n_estimators=750, num_leaves=31; total time=  20.4s\n",
            "[CV] END learning_rate=0.05, max_depth=10, min_data_in_leaf=25, n_estimators=750, num_leaves=31; total time=  20.3s\n",
            "[CV] END learning_rate=0.1, max_depth=15, min_data_in_leaf=50, n_estimators=750, num_leaves=500; total time=  35.5s\n",
            "[CV] END learning_rate=0.1, max_depth=15, min_data_in_leaf=50, n_estimators=750, num_leaves=500; total time=  36.7s\n",
            "[CV] END learning_rate=0.1, max_depth=15, min_data_in_leaf=50, n_estimators=750, num_leaves=500; total time=  39.6s\n",
            "[CV] END learning_rate=0.3, max_depth=5, min_data_in_leaf=20, n_estimators=100, num_leaves=10; total time=   2.4s\n",
            "[CV] END learning_rate=0.3, max_depth=5, min_data_in_leaf=20, n_estimators=100, num_leaves=10; total time=   2.4s\n",
            "[CV] END learning_rate=0.3, max_depth=5, min_data_in_leaf=20, n_estimators=100, num_leaves=10; total time=   2.4s\n",
            "[CV] END learning_rate=0.2, max_depth=8, min_data_in_leaf=10, n_estimators=2000, num_leaves=31; total time=  51.3s\n",
            "[CV] END learning_rate=0.2, max_depth=8, min_data_in_leaf=10, n_estimators=2000, num_leaves=31; total time=  51.3s\n",
            "[CV] END learning_rate=0.2, max_depth=8, min_data_in_leaf=10, n_estimators=2000, num_leaves=31; total time=  54.5s\n",
            "[CV] END learning_rate=0.15, max_depth=5, min_data_in_leaf=50, n_estimators=2000, num_leaves=100; total time=  47.6s\n",
            "[CV] END learning_rate=0.15, max_depth=5, min_data_in_leaf=50, n_estimators=2000, num_leaves=100; total time=  47.7s\n",
            "[CV] END learning_rate=0.15, max_depth=5, min_data_in_leaf=50, n_estimators=2000, num_leaves=100; total time=  50.8s\n",
            "[CV] END learning_rate=0.05, max_depth=20, min_data_in_leaf=20, n_estimators=500, num_leaves=200; total time=  28.6s\n",
            "[CV] END learning_rate=0.05, max_depth=20, min_data_in_leaf=20, n_estimators=500, num_leaves=200; total time=  28.7s\n",
            "[CV] END learning_rate=0.05, max_depth=20, min_data_in_leaf=20, n_estimators=500, num_leaves=200; total time=  29.1s\n",
            "[CV] END learning_rate=0.05, max_depth=3, min_data_in_leaf=20, n_estimators=750, num_leaves=200; total time=  13.0s\n",
            "[CV] END learning_rate=0.05, max_depth=3, min_data_in_leaf=20, n_estimators=750, num_leaves=200; total time=  13.0s\n",
            "[CV] END learning_rate=0.05, max_depth=3, min_data_in_leaf=20, n_estimators=750, num_leaves=200; total time=  15.6s\n",
            "[CV] END learning_rate=0.5, max_depth=5, min_data_in_leaf=20, n_estimators=2000, num_leaves=31; total time=  22.0s\n",
            "[CV] END learning_rate=0.5, max_depth=5, min_data_in_leaf=20, n_estimators=2000, num_leaves=31; total time=  21.7s\n",
            "[CV] END learning_rate=0.5, max_depth=5, min_data_in_leaf=20, n_estimators=2000, num_leaves=31; total time=  22.0s\n",
            "[CV] END learning_rate=0.2, max_depth=20, min_data_in_leaf=25, n_estimators=500, num_leaves=500; total time=  19.3s\n",
            "[CV] END learning_rate=0.2, max_depth=20, min_data_in_leaf=25, n_estimators=500, num_leaves=500; total time=  20.8s\n",
            "[CV] END learning_rate=0.2, max_depth=20, min_data_in_leaf=25, n_estimators=500, num_leaves=500; total time=  20.5s\n",
            "[CV] END learning_rate=0.3, max_depth=15, min_data_in_leaf=25, n_estimators=100, num_leaves=100; total time=   4.6s\n",
            "[CV] END learning_rate=0.3, max_depth=15, min_data_in_leaf=25, n_estimators=100, num_leaves=100; total time=   4.5s\n",
            "[CV] END learning_rate=0.3, max_depth=15, min_data_in_leaf=25, n_estimators=100, num_leaves=100; total time=   4.6s\n",
            "[CV] END learning_rate=0.2, max_depth=1, min_data_in_leaf=25, n_estimators=100, num_leaves=31; total time=   1.6s\n",
            "[CV] END learning_rate=0.2, max_depth=1, min_data_in_leaf=25, n_estimators=100, num_leaves=31; total time=   1.6s\n",
            "[CV] END learning_rate=0.2, max_depth=1, min_data_in_leaf=25, n_estimators=100, num_leaves=31; total time=   1.6s\n",
            "[CV] END learning_rate=0.15, max_depth=3, min_data_in_leaf=100, n_estimators=750, num_leaves=50; total time=  15.6s\n",
            "[CV] END learning_rate=0.15, max_depth=3, min_data_in_leaf=100, n_estimators=750, num_leaves=50; total time=  12.8s\n",
            "[CV] END learning_rate=0.15, max_depth=3, min_data_in_leaf=100, n_estimators=750, num_leaves=50; total time=  12.8s\n",
            "[CV] END learning_rate=0.15, max_depth=20, min_data_in_leaf=20, n_estimators=100, num_leaves=10; total time=   2.5s\n",
            "[CV] END learning_rate=0.15, max_depth=20, min_data_in_leaf=20, n_estimators=100, num_leaves=10; total time=   2.5s\n",
            "[CV] END learning_rate=0.15, max_depth=20, min_data_in_leaf=20, n_estimators=100, num_leaves=10; total time=   2.5s\n",
            "[CV] END learning_rate=0.1, max_depth=5, min_data_in_leaf=10, n_estimators=500, num_leaves=200; total time=  11.9s\n",
            "[CV] END learning_rate=0.1, max_depth=5, min_data_in_leaf=10, n_estimators=500, num_leaves=200; total time=  11.9s\n",
            "[CV] END learning_rate=0.1, max_depth=5, min_data_in_leaf=10, n_estimators=500, num_leaves=200; total time=  12.0s\n",
            "[CV] END learning_rate=0.5, max_depth=20, min_data_in_leaf=100, n_estimators=2000, num_leaves=10; total time=  25.2s\n",
            "[CV] END learning_rate=0.5, max_depth=20, min_data_in_leaf=100, n_estimators=2000, num_leaves=10; total time=  26.0s\n",
            "[CV] END learning_rate=0.5, max_depth=20, min_data_in_leaf=100, n_estimators=2000, num_leaves=10; total time=  24.6s\n",
            "[CV] END learning_rate=0.5, max_depth=8, min_data_in_leaf=50, n_estimators=100, num_leaves=50; total time=   6.3s\n",
            "[CV] END learning_rate=0.5, max_depth=8, min_data_in_leaf=50, n_estimators=100, num_leaves=50; total time=   3.5s\n",
            "[CV] END learning_rate=0.5, max_depth=8, min_data_in_leaf=50, n_estimators=100, num_leaves=50; total time=   3.5s\n",
            "[CV] END learning_rate=0.1, max_depth=10, min_data_in_leaf=20, n_estimators=750, num_leaves=100; total time=  29.0s\n",
            "[CV] END learning_rate=0.1, max_depth=10, min_data_in_leaf=20, n_estimators=750, num_leaves=100; total time=  28.9s\n",
            "[CV] END learning_rate=0.1, max_depth=10, min_data_in_leaf=20, n_estimators=750, num_leaves=100; total time=  29.2s\n",
            "[CV] END learning_rate=0.3, max_depth=3, min_data_in_leaf=50, n_estimators=1000, num_leaves=10; total time=  17.1s\n",
            "[CV] END learning_rate=0.3, max_depth=3, min_data_in_leaf=50, n_estimators=1000, num_leaves=10; total time=  17.2s\n",
            "[CV] END learning_rate=0.3, max_depth=3, min_data_in_leaf=50, n_estimators=1000, num_leaves=10; total time=  16.6s\n",
            "[CV] END learning_rate=0.1, max_depth=5, min_data_in_leaf=25, n_estimators=2000, num_leaves=10; total time=  39.2s\n",
            "[CV] END learning_rate=0.1, max_depth=5, min_data_in_leaf=25, n_estimators=2000, num_leaves=10; total time=  36.2s\n",
            "[CV] END learning_rate=0.1, max_depth=5, min_data_in_leaf=25, n_estimators=2000, num_leaves=10; total time=  36.3s\n",
            "[CV] END learning_rate=0.3, max_depth=3, min_data_in_leaf=100, n_estimators=100, num_leaves=10; total time=   2.2s\n",
            "[CV] END learning_rate=0.3, max_depth=3, min_data_in_leaf=100, n_estimators=100, num_leaves=10; total time=   2.1s\n",
            "[CV] END learning_rate=0.3, max_depth=3, min_data_in_leaf=100, n_estimators=100, num_leaves=10; total time=   2.1s\n",
            "[CV] END learning_rate=0.05, max_depth=20, min_data_in_leaf=25, n_estimators=500, num_leaves=50; total time=  16.4s\n",
            "[CV] END learning_rate=0.05, max_depth=20, min_data_in_leaf=25, n_estimators=500, num_leaves=50; total time=  16.5s\n",
            "[CV] END learning_rate=0.05, max_depth=20, min_data_in_leaf=25, n_estimators=500, num_leaves=50; total time=  19.2s\n",
            "[CV] END learning_rate=0.05, max_depth=15, min_data_in_leaf=50, n_estimators=2000, num_leaves=31; total time=  51.3s\n",
            "[CV] END learning_rate=0.05, max_depth=15, min_data_in_leaf=50, n_estimators=2000, num_leaves=31; total time=  51.7s\n",
            "[CV] END learning_rate=0.05, max_depth=15, min_data_in_leaf=50, n_estimators=2000, num_leaves=31; total time=  54.7s\n",
            "[CV] END learning_rate=0.2, max_depth=8, min_data_in_leaf=10, n_estimators=500, num_leaves=10; total time=   9.4s\n",
            "[CV] END learning_rate=0.2, max_depth=8, min_data_in_leaf=10, n_estimators=500, num_leaves=10; total time=   9.6s\n",
            "[CV] END learning_rate=0.2, max_depth=8, min_data_in_leaf=10, n_estimators=500, num_leaves=10; total time=   9.4s\n",
            "[CV] END learning_rate=0.3, max_depth=3, min_data_in_leaf=25, n_estimators=2000, num_leaves=10; total time=  35.1s\n",
            "[CV] END learning_rate=0.3, max_depth=3, min_data_in_leaf=25, n_estimators=2000, num_leaves=10; total time=  45.0s\n",
            "[CV] END learning_rate=0.3, max_depth=3, min_data_in_leaf=25, n_estimators=2000, num_leaves=10; total time=  27.6s\n",
            "[CV] END learning_rate=0.5, max_depth=8, min_data_in_leaf=10, n_estimators=500, num_leaves=200; total time=  14.5s\n",
            "[CV] END learning_rate=0.5, max_depth=8, min_data_in_leaf=10, n_estimators=500, num_leaves=200; total time=  12.1s\n",
            "[CV] END learning_rate=0.5, max_depth=8, min_data_in_leaf=10, n_estimators=500, num_leaves=200; total time=   8.9s\n",
            "[CV] END learning_rate=0.15, max_depth=1, min_data_in_leaf=10, n_estimators=100, num_leaves=500; total time=   1.6s\n",
            "[CV] END learning_rate=0.15, max_depth=1, min_data_in_leaf=10, n_estimators=100, num_leaves=500; total time=   1.6s\n",
            "[CV] END learning_rate=0.15, max_depth=1, min_data_in_leaf=10, n_estimators=100, num_leaves=500; total time=   1.6s\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'num_leaves': 500,\n",
              " 'n_estimators': 100,\n",
              " 'min_data_in_leaf': 100,\n",
              " 'max_depth': 10,\n",
              " 'learning_rate': 0.2}"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "display(models_eval)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "id": "HXwRGqZRmoDv",
        "outputId": "580343a5-ab92-4a7d-b947-6f5cf56b2bfa"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "      model_name       confusion_matrix  accuracy    recall  f1_score  \\\n",
              "0       log_clf0  [14440, 2628, 28, 94]  0.845492  0.770492  0.066104   \n",
              "1       log_clf1  [14441, 2627, 28, 94]  0.845550  0.770492  0.066127   \n",
              "2     bayes_clf0  [1326, 15742, 0, 122]  0.084235  1.000000  0.015263   \n",
              "3     bayes_clf1   [592, 16476, 0, 122]  0.041536  1.000000  0.014593   \n",
              "4     bayes_clf2     [0, 17068, 0, 122]  0.007097  1.000000  0.014094   \n",
              "5  lightgbm_clf0    [16971, 97, 5, 117]  0.994066  0.959016  0.696429   \n",
              "6  lightgbm_clf1   [16458, 610, 4, 118]  0.964282  0.967213  0.277647   \n",
              "7  lightgbm_clf2   [16878, 190, 3, 119]  0.988773  0.975410  0.552204   \n",
              "\n",
              "   roc_auc_score  \n",
              "0       0.808260  \n",
              "1       0.808289  \n",
              "2       0.538845  \n",
              "3       0.517342  \n",
              "4       0.500000  \n",
              "5       0.976667  \n",
              "6       0.965737  \n",
              "7       0.982139  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-16922944-b13f-4fa6-9f46-90e0386dadd3\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>model_name</th>\n",
              "      <th>confusion_matrix</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>recall</th>\n",
              "      <th>f1_score</th>\n",
              "      <th>roc_auc_score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>log_clf0</td>\n",
              "      <td>[14440, 2628, 28, 94]</td>\n",
              "      <td>0.845492</td>\n",
              "      <td>0.770492</td>\n",
              "      <td>0.066104</td>\n",
              "      <td>0.808260</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>log_clf1</td>\n",
              "      <td>[14441, 2627, 28, 94]</td>\n",
              "      <td>0.845550</td>\n",
              "      <td>0.770492</td>\n",
              "      <td>0.066127</td>\n",
              "      <td>0.808289</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>bayes_clf0</td>\n",
              "      <td>[1326, 15742, 0, 122]</td>\n",
              "      <td>0.084235</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.015263</td>\n",
              "      <td>0.538845</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>bayes_clf1</td>\n",
              "      <td>[592, 16476, 0, 122]</td>\n",
              "      <td>0.041536</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.014593</td>\n",
              "      <td>0.517342</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>bayes_clf2</td>\n",
              "      <td>[0, 17068, 0, 122]</td>\n",
              "      <td>0.007097</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.014094</td>\n",
              "      <td>0.500000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>lightgbm_clf0</td>\n",
              "      <td>[16971, 97, 5, 117]</td>\n",
              "      <td>0.994066</td>\n",
              "      <td>0.959016</td>\n",
              "      <td>0.696429</td>\n",
              "      <td>0.976667</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>lightgbm_clf1</td>\n",
              "      <td>[16458, 610, 4, 118]</td>\n",
              "      <td>0.964282</td>\n",
              "      <td>0.967213</td>\n",
              "      <td>0.277647</td>\n",
              "      <td>0.965737</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>lightgbm_clf2</td>\n",
              "      <td>[16878, 190, 3, 119]</td>\n",
              "      <td>0.988773</td>\n",
              "      <td>0.975410</td>\n",
              "      <td>0.552204</td>\n",
              "      <td>0.982139</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-16922944-b13f-4fa6-9f46-90e0386dadd3')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-16922944-b13f-4fa6-9f46-90e0386dadd3 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-16922944-b13f-4fa6-9f46-90e0386dadd3');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lightgbm_random.best_params_"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gosX6phBODjz",
        "outputId": "baf566dc-21d7-426d-a89a-52526b2f3528"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'num_leaves': 500,\n",
              " 'n_estimators': 100,\n",
              " 'min_data_in_leaf': 100,\n",
              " 'max_depth': 10,\n",
              " 'learning_rate': 0.2}"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Artificial Neural Network\n",
        "\n",
        "- Library: Keras, Tensorflow"
      ],
      "metadata": {
        "id": "QpthCMRHuhWe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tf.random.set_seed(10)\n",
        "\n",
        "print(tf.__version__)\n",
        "print(keras.__version__)"
      ],
      "metadata": {
        "id": "fJ6kS48GZVH3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Experiment 1: Base Model"
      ],
      "metadata": {
        "id": "vivojhGnfeEz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train.info()"
      ],
      "metadata": {
        "id": "XO7_fl_pfaEP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ann_clf = keras.models.Sequential([\n",
        "    keras.layers.Dense(15, input_shape=(X_train.shape[1],), activation='relu'), # No bias term\n",
        "    keras.layers.Dense(10, activation='relu'), \n",
        "    keras.layers.Dense(10, activation='relu'), \n",
        "    keras.layers.Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "ann_clf.summary()"
      ],
      "metadata": {
        "id": "OVpParvzfhtl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ann_clf.layers"
      ],
      "metadata": {
        "id": "eLJhQfiHfi14"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ann_clf.compile(optimizer = 'adam', \n",
        "                loss ='binary_crossentropy',\n",
        "                metrics=[tf.keras.metrics.Accuracy(), tf.keras.metrics.Recall()])\n",
        "\n",
        "record = ann_clf.fit(\n",
        "            X_train, \n",
        "            y_train, \n",
        "            validation_data = (X_val, y_val), \n",
        "            batch_size = 10, \n",
        "            epochs = 50)"
      ],
      "metadata": {
        "id": "bK1SXteMfln5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "keras.utils.plot_model(ann_clf, show_shapes=True, rankdir=\"LR\")"
      ],
      "metadata": {
        "id": "ChuhGr3Ufmgq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "_, train_acc = ann_clf.evaluate(X_train, y_train, verbose=0)\n",
        "_, val_acc = ann_clf.evaluate(X_val, y_val, verbose=0)\n",
        "_, test_acc = ann_clf.evaluate(X_test, y_test, verbose=0)\n",
        "print('Train: %.3f, Validation: %.3f, Test: %.3f' % (train_acc, val_acc, test_acc))"
      ],
      "metadata": {
        "id": "rsSZTcIlfnQa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(record.history['accuracy'], label='Training')\n",
        "plt.plot(record.history['val_accuracy'], label='Validation')\n",
        "plt.legend()\n",
        "plt.xlabel('Epochs', fontsize=16)\n",
        "plt.ylabel('Accuracy', fontsize=16)\n",
        "plt.title('Accuracy Curves', fontsize=16)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Jvmnf03BfoDj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# plot training history\n",
        "plt.plot(record.history['loss'], label='Training')\n",
        "plt.plot(record.history['val_loss'], label='Validation')\n",
        "plt.legend()\n",
        "plt.xlabel('Epochs', fontsize=14)\n",
        "plt.ylabel('Loss', fontsize=14)\n",
        "plt.title('Loss Curves', fontsize=16)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Bk9KBNCCfpw5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Experiment 2: Different Batch Sizes"
      ],
      "metadata": {
        "id": "hy1WHdJSfrl1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Fit a model and plot learning curve\n",
        "def fit_model_1(X_train, y_train, X_test, y_test, n_batch):\n",
        "  # Define Model\n",
        "  ann_clf = keras.models.Sequential([\n",
        "      keras.layers.Dense(6, input_shape=(X_train.shape[1],), activation='sigmoid'),\n",
        "      keras.layers.Dense(6, activation='sigmoid'),\n",
        "      keras.layers.Dense(6, activation='sigmoid'), \n",
        "      # keras.layers.Dropout(0.2),\n",
        "      keras.layers.Dense(1, activation = 'sigmoid')\n",
        "  ])\n",
        "\n",
        "  # Compile Model\n",
        "  ann_clf.compile(optimizer = 'adam',\n",
        "                metrics=['accuracy'],\n",
        "                loss = 'binary_crossentropy')\n",
        "  \n",
        "  # Fit Model\n",
        "  history = ann_clf.fit(X_train,\n",
        "                      y_train,\n",
        "                      validation_data=(X_test, y_test),\n",
        "                      epochs=100,\n",
        "                      verbose=0,\n",
        "                      batch_size=n_batch)\n",
        "\n",
        "  # Plot Learning Curves\n",
        "  plt.plot(history.history['accuracy'], label='train') \n",
        "  plt.plot(history.history['val_accuracy'], label='test') \n",
        "  plt.title('batch='+str(n_batch)) \n",
        "  plt.legend()"
      ],
      "metadata": {
        "id": "EbpRvs_nfsV4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create learning curves for different batch sizes\n",
        "# batch_sizes = [4, 6, 10, 16, 32, 64, 128, 260]\n",
        "batch_sizes = [10, 15, 20, 25, 30]\n",
        "\n",
        "plt.figure(figsize=(10,15))\n",
        "for i in range(len(batch_sizes)):\n",
        "\n",
        "  # Determine the Plot Number\n",
        "  plot_no = 420 + (i+1)\n",
        "  plt.subplot(plot_no)\n",
        "\n",
        "  # Fit model and plot learning curves for a batch size\n",
        "  fit_model_1(X_train, y_train, X_test, y_test, batch_sizes[i])\n",
        "\n",
        "# Show learning curves\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "govzlyT3fwI0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Experiment 3: Different EPOCHs"
      ],
      "metadata": {
        "id": "jDdPwZjcfxsF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Fit a model and plot learning curve\n",
        "def fit_model_2(trainX, trainy, validX, validy, n_epoch):\n",
        "  # Define Model\n",
        "  ann_clf = keras.models.Sequential([\n",
        "      keras.layers.Dense(6, input_shape=(X_train.shape[1],), activation='sigmoid'),\n",
        "      keras.layers.Dense(6, activation='sigmoid'),\n",
        "      keras.layers.Dense(6, activation='sigmoid'), \n",
        "      # keras.layers.Dropout(0.2),\n",
        "      keras.layers.Dense(1, activation = 'sigmoid')\n",
        "  ])\n",
        "\n",
        "  # Compile Model\n",
        "  ann_clf.compile(optimizer = 'adam',\n",
        "                metrics=['accuracy'],\n",
        "                loss = 'binary_crossentropy')\n",
        "    \n",
        "  # fit model\n",
        "  history = ann_clf.fit(X_train,\n",
        "                      y_train,\n",
        "                      validation_data=(X_test, y_test),\n",
        "                      epochs=n_epoch,\n",
        "                      verbose=0,\n",
        "                      batch_size=6)\n",
        "    \n",
        "  # plot learning curves\n",
        "  plt.plot(history.history['accuracy'], label='train')\n",
        "  plt.plot(history.history['val_accuracy'], label='test')\n",
        "  plt.title('epoch='+str(n_epoch))\n",
        "  plt.legend()"
      ],
      "metadata": {
        "id": "gjSGc9u6fxTv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create learning curves for different batch sizes\n",
        "# epochs = [20, 50, 100, 120, 150, 200, 300, 400]\n",
        "epochs = [50, 60, 70, 80, 90, 100]\n",
        "\n",
        "plt.figure(figsize=(10,15))\n",
        "for i in range(len(batch_sizes)):\n",
        "\n",
        "  # Determine the Plot Number\n",
        "  plot_no = 420 + (i+1)\n",
        "  plt.subplot(plot_no)\n",
        "\n",
        "  # Fit model and plot learning curves for a batch size\n",
        "  fit_model_2(X_train, y_train, X_test, y_test, epochs[i])\n",
        "\n",
        "# Show learning curves\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "SP2zm_ySfznt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Experiment 4: Early Stopping"
      ],
      "metadata": {
        "id": "3_QvFWOmf0JZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.callbacks import EarlyStopping\n",
        "from keras.callbacks import ModelCheckpoint"
      ],
      "metadata": {
        "id": "3AUOp_Qwf2_U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def init_model():\n",
        "  # Define Model\n",
        "  ann_clf = keras.models.Sequential([\n",
        "      keras.layers.Dense(6, input_shape=(X_train.shape[1],), activation='sigmoid'),\n",
        "      keras.layers.Dense(6, activation='sigmoid'),\n",
        "      keras.layers.Dense(6, activation='sigmoid'), \n",
        "      keras.layers.Dropout(0.2),\n",
        "      keras.layers.Dense(1, activation = 'sigmoid')\n",
        "  ])\n",
        "\n",
        "  # Compile Model\n",
        "  ann_clf.compile(optimizer = 'adam',\n",
        "                metrics=['accuracy'],\n",
        "                loss = 'binary_crossentropy')\n",
        "  return ann_clf\n",
        "\n",
        "# init model\n",
        "ann_clf = init_model()\n",
        "# simple early stopping\n",
        "es = EarlyStopping(monitor='val_loss',\n",
        "                   mode='min',\n",
        "                   verbose=1,\n",
        "                   patience=150)\n",
        "mc = ModelCheckpoint('best_model.h5',\n",
        "                     monitor='val_accuracy',\n",
        "                     mode='max',\n",
        "                     verbose=1,\n",
        "                     save_best_only=True)\n",
        "history = ann_clf.fit(X_train,\n",
        "                    y_train,\n",
        "                    validation_data=(X_test, y_test),\n",
        "                    epochs=50,\n",
        "                    verbose=0,\n",
        "                    batch_size=25,\n",
        "                    callbacks=[es, mc])"
      ],
      "metadata": {
        "id": "8uidzovhf4S6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# plot training history\n",
        "plt.plot(history.history['loss'], label='Training')\n",
        "plt.plot(history.history['val_loss'], label='Validation')\n",
        "plt.legend()\n",
        "plt.xlabel('Epochs', fontsize=14)\n",
        "plt.ylabel('Loss', fontsize=14)\n",
        "plt.title('Loss Curves', fontsize=16)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "JAVLJDzLf6Ce"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=[8,5])\n",
        "plt.plot(history.history['accuracy'], label='Training')\n",
        "plt.plot(history.history['val_accuracy'], label='Validation')\n",
        "plt.legend()\n",
        "plt.xlabel('Epochs', fontsize=16)\n",
        "plt.ylabel('Accuracy', fontsize=16)\n",
        "plt.title('Accuracy Curves', fontsize=16)\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "sPPqcZCyf6zy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Voting Classifier\n",
        "\n",
        "- Library: Scikit-learn, Keras, Tensorflow\n",
        "- Shuffling does not affect the model building. No random_state.\n",
        "- No need for RandomizedSearchCV since there is only 1 important parameter: voting"
      ],
      "metadata": {
        "id": "4rBdGe3Gukv6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "display(models_eval)"
      ],
      "metadata": {
        "id": "YCHV8rR-ZU5c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Re-Train Top 3 Models Using Their Parameters Specifically\n",
        "\n",
        "model_1 = LGBMClassifier(n_estimators=1000, learning_rate=0.1, max_depth=3, random_state=10)\n",
        "model_2 = GradientBoostingClassifier(n_estimators=500, learning_rate=0.5, max_depth=1, random_state=10)\n",
        "model_3 = RandomForestClassifier(n_estimators=1000, max_depth = None, n_jobs =-1, random_state=10)\n",
        "\n",
        "name = 'ensem_clf'\n",
        "\n",
        "train = pd.DataFrame(columns = ['voting', 'n_jobs'])\n",
        "train = train.append({'voting': 'hard', 'n_jobs': -1}, ignore_index=True)\n",
        "train = train.append({'voting': 'soft', 'n_jobs': -1}, ignore_index=True)\n",
        "train = train.reset_index()\n",
        "\n",
        "for index, row in train.iterrows():\n",
        "    model_name = name + str(index)\n",
        "    ens_clf = VotingClassifier(estimators=[('m1', model_1), ('m2', model_2), ('m3', model_3)],\n",
        "                               voting = row['voting'],\n",
        "                               n_jobs = int(row['n_jobs']))\n",
        "    ens_clf.fit(X_train, y_train)\n",
        "    y_true = y_val\n",
        "    y_pred = ens_clf.predict(X_val)\n",
        "    evaluation_results = evaluation_metrics(y_true, y_pred)\n",
        "\n",
        "    models = models.append({'model_name': model_name, \n",
        "                            'model': ens_clf, \n",
        "                            'parameters': ens_clf.get_params()}, \n",
        "                           ignore_index=True)\n",
        "    \n",
        "    models_eval = models_eval.append({'model_name': model_name, \n",
        "                                      'confusion_matrix' : evaluation_results[0], \n",
        "                                      'accuracy': evaluation_results[1], \n",
        "                                      'recall' : evaluation_results[2], \n",
        "                                      'f1_score': evaluation_results[3], \n",
        "                                      'roc_auc_score': evaluation_results[4]}, \n",
        "                                     ignore_index=True)"
      ],
      "metadata": {
        "id": "YIe8XVe4gBMX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Discussion"
      ],
      "metadata": {
        "id": "VSpOrrm2gNXL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "display(models)"
      ],
      "metadata": {
        "id": "EZfBQi4KgLrV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "display(models_eval)"
      ],
      "metadata": {
        "id": "2LY9af70gM_6"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}