{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyMk8moV1NtP34LHscWZ9DD0"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Model Training & Evaluation Pipeline"
      ],
      "metadata": {
        "id": "COF7WWOtCQRP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Details: [Model Training Specifications](https://docs.google.com/document/d/1UiDi8nyTcfMeMNIAz3KntlVZBlYrpoMAURuDccTt-wk/edit?usp=sharing)\n",
        "\n",
        "Model Evaluation: Identify best parameters for each model"
      ],
      "metadata": {
        "id": "kNbJ7WYUXWks"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qK_KRJw0rpA9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b3422de3-b2fd-4f51-b314-a10d5a524d13"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "# Basic Libraries\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sb\n",
        "import matplotlib.pyplot as plt\n",
        "from datetime import datetime\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Data Source\n",
        "\n",
        "df = pd.read_csv(\"/content/drive/MyDrive/Senior Project/Datasets/cleaned_gee_data.csv\")\n",
        "df = df.drop(columns = ['Unnamed: 0'], axis=1)\n",
        "df.head()"
      ],
      "metadata": {
        "id": "BTKpuPDqvTli",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 270
        },
        "outputId": "2083b382-d755-4825-d815-23f4e9264ea3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   LATITUDE  LONGITUDE  ACQ_DATE  ACQ_TIME  OPEN_TIME  CLOSE_TIME  BRIGHTNESS  \\\n",
              "0 -5.466232  -0.176027 -1.866392  0.634294   0.506405    0.526945   -2.231078   \n",
              "1 -5.466232  -0.176027 -1.866392  0.634294   0.506405    0.526945   -2.231078   \n",
              "2 -5.466232  -0.176027 -1.866392  0.634294   0.506405    0.526945   -2.231078   \n",
              "3 -5.466232  -0.176027 -1.866392  0.634294   0.506405    0.526945   -2.231078   \n",
              "4 -5.433352  -0.197441 -1.723773  0.634294   2.286080    1.793843   -1.141613   \n",
              "\n",
              "   FIRE_OCCURRED  CO_MOL/M2  SO2_MOL/M2  NO2_MOL/M2  O3_MOL/M2  LOCATION  \\\n",
              "0              0  -0.024223   -0.474440   -1.152277  -0.511001 -1.159086   \n",
              "1              0   0.113599   -0.474440   -1.152277  -0.511001 -1.159086   \n",
              "2              0  -0.024223   -0.474440   -1.361255  -0.511001 -1.159086   \n",
              "3              0   0.113599   -0.474440   -1.361255  -0.511001 -1.159086   \n",
              "4              0  -0.967684    0.339667   -1.251770   0.426114 -1.159086   \n",
              "\n",
              "   INSTRUMENT  DRY_SEASON  \n",
              "0           0           1  \n",
              "1           0           1  \n",
              "2           0           1  \n",
              "3           0           1  \n",
              "4           0           1  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-d2ffe572-e0ba-40b4-b6f2-1d67532a4f56\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>LATITUDE</th>\n",
              "      <th>LONGITUDE</th>\n",
              "      <th>ACQ_DATE</th>\n",
              "      <th>ACQ_TIME</th>\n",
              "      <th>OPEN_TIME</th>\n",
              "      <th>CLOSE_TIME</th>\n",
              "      <th>BRIGHTNESS</th>\n",
              "      <th>FIRE_OCCURRED</th>\n",
              "      <th>CO_MOL/M2</th>\n",
              "      <th>SO2_MOL/M2</th>\n",
              "      <th>NO2_MOL/M2</th>\n",
              "      <th>O3_MOL/M2</th>\n",
              "      <th>LOCATION</th>\n",
              "      <th>INSTRUMENT</th>\n",
              "      <th>DRY_SEASON</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>-5.466232</td>\n",
              "      <td>-0.176027</td>\n",
              "      <td>-1.866392</td>\n",
              "      <td>0.634294</td>\n",
              "      <td>0.506405</td>\n",
              "      <td>0.526945</td>\n",
              "      <td>-2.231078</td>\n",
              "      <td>0</td>\n",
              "      <td>-0.024223</td>\n",
              "      <td>-0.474440</td>\n",
              "      <td>-1.152277</td>\n",
              "      <td>-0.511001</td>\n",
              "      <td>-1.159086</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>-5.466232</td>\n",
              "      <td>-0.176027</td>\n",
              "      <td>-1.866392</td>\n",
              "      <td>0.634294</td>\n",
              "      <td>0.506405</td>\n",
              "      <td>0.526945</td>\n",
              "      <td>-2.231078</td>\n",
              "      <td>0</td>\n",
              "      <td>0.113599</td>\n",
              "      <td>-0.474440</td>\n",
              "      <td>-1.152277</td>\n",
              "      <td>-0.511001</td>\n",
              "      <td>-1.159086</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>-5.466232</td>\n",
              "      <td>-0.176027</td>\n",
              "      <td>-1.866392</td>\n",
              "      <td>0.634294</td>\n",
              "      <td>0.506405</td>\n",
              "      <td>0.526945</td>\n",
              "      <td>-2.231078</td>\n",
              "      <td>0</td>\n",
              "      <td>-0.024223</td>\n",
              "      <td>-0.474440</td>\n",
              "      <td>-1.361255</td>\n",
              "      <td>-0.511001</td>\n",
              "      <td>-1.159086</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>-5.466232</td>\n",
              "      <td>-0.176027</td>\n",
              "      <td>-1.866392</td>\n",
              "      <td>0.634294</td>\n",
              "      <td>0.506405</td>\n",
              "      <td>0.526945</td>\n",
              "      <td>-2.231078</td>\n",
              "      <td>0</td>\n",
              "      <td>0.113599</td>\n",
              "      <td>-0.474440</td>\n",
              "      <td>-1.361255</td>\n",
              "      <td>-0.511001</td>\n",
              "      <td>-1.159086</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>-5.433352</td>\n",
              "      <td>-0.197441</td>\n",
              "      <td>-1.723773</td>\n",
              "      <td>0.634294</td>\n",
              "      <td>2.286080</td>\n",
              "      <td>1.793843</td>\n",
              "      <td>-1.141613</td>\n",
              "      <td>0</td>\n",
              "      <td>-0.967684</td>\n",
              "      <td>0.339667</td>\n",
              "      <td>-1.251770</td>\n",
              "      <td>0.426114</td>\n",
              "      <td>-1.159086</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d2ffe572-e0ba-40b4-b6f2-1d67532a4f56')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-d2ffe572-e0ba-40b4-b6f2-1d67532a4f56 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-d2ffe572-e0ba-40b4-b6f2-1d67532a4f56');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vigF6PJAfy9R",
        "outputId": "09b51f64-73f2-47f7-9ef9-7296c3d3f8b1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 171893 entries, 0 to 171892\n",
            "Data columns (total 15 columns):\n",
            " #   Column         Non-Null Count   Dtype  \n",
            "---  ------         --------------   -----  \n",
            " 0   LATITUDE       171893 non-null  float64\n",
            " 1   LONGITUDE      171893 non-null  float64\n",
            " 2   ACQ_DATE       171893 non-null  float64\n",
            " 3   ACQ_TIME       171893 non-null  float64\n",
            " 4   OPEN_TIME      171893 non-null  float64\n",
            " 5   CLOSE_TIME     171893 non-null  float64\n",
            " 6   BRIGHTNESS     171893 non-null  float64\n",
            " 7   FIRE_OCCURRED  171893 non-null  int64  \n",
            " 8   CO_MOL/M2      171893 non-null  float64\n",
            " 9   SO2_MOL/M2     171893 non-null  float64\n",
            " 10  NO2_MOL/M2     171893 non-null  float64\n",
            " 11  O3_MOL/M2      171893 non-null  float64\n",
            " 12  LOCATION       171893 non-null  float64\n",
            " 13  INSTRUMENT     171893 non-null  int64  \n",
            " 14  DRY_SEASON     171893 non-null  int64  \n",
            "dtypes: float64(12), int64(3)\n",
            "memory usage: 19.7 MB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "display(df['FIRE_OCCURRED'].value_counts())"
      ],
      "metadata": {
        "id": "2z3siI-MvbQs",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "outputId": "09509686-3ece-4bfb-a119-01dd79acad54"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "0    170544\n",
              "1      1349\n",
              "Name: FIRE_OCCURRED, dtype: int64"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "0.785% of FIRE_OCCURRED = 1"
      ],
      "metadata": {
        "id": "bmVgX-C_pJrz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X = df.drop('FIRE_OCCURRED', axis=1)\n",
        "y = df['FIRE_OCCURRED']"
      ],
      "metadata": {
        "id": "GEBLWi5ooiTO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Training, Validation, Testing Split\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# 80:10:10\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.10, random_state=10, shuffle=True)\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=1/9, random_state=10, shuffle=True)\n",
        "\n",
        "Original = [X_train, X_val, X_test, y_train, y_val, y_test] # For reference"
      ],
      "metadata": {
        "id": "96m0rNH7vhDg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if len(X_train)==len(y_train) and len(X_test) == len(y_test) and len(X_val) == len(y_val):\n",
        "  print(\"X and y data length matching\")\n",
        "else:\n",
        "  print(\"Error in data preparation pipeline\")\n",
        "print()\n",
        "print(\"No. of training data = %d\" % len(X_train))\n",
        "print(\"No. of validation data = %d\" % len(X_val))\n",
        "print(\"No. of testing data = %d\" % len(X_test))"
      ],
      "metadata": {
        "id": "oihO76nhvifX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4cec8573-827c-4453-d0ee-e20a973dacea"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X and y data length matching\n",
            "\n",
            "No. of training data = 137513\n",
            "No. of validation data = 17190\n",
            "No. of testing data = 17190\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "display(y_test.value_counts())"
      ],
      "metadata": {
        "id": "1ZcyP7nRvlYp",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "outputId": "6d26392c-29d0-4ea9-ed5d-660b01af7733"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "0    17059\n",
              "1      131\n",
              "Name: FIRE_OCCURRED, dtype: int64"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# SMOTE\n",
        "\n",
        "from collections import Counter\n",
        "from imblearn.over_sampling import SMOTE \n",
        "\n",
        "print('Original dataset shape %s' % Counter(y_train))\n",
        "sm = SMOTE(random_state=10)\n",
        "X_train, y_train = sm.fit_resample(X_train, y_train)\n",
        "print('Resampled dataset shape %s' % Counter(y_train))"
      ],
      "metadata": {
        "id": "T8MI03z-vmdA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a7c61e4e-cd7a-42c4-c5af-662c571d559b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original dataset shape Counter({0: 136417, 1: 1096})\n",
            "Resampled dataset shape Counter({0: 136417, 1: 136417})\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Shuffle Data since SMOTE appended many 1s at the end\n",
        "# Required for some algorithms such as ANN\n",
        "\n",
        "from sklearn.utils import shuffle\n",
        "\n",
        "X_train, y_train = shuffle(X_train, y_train, random_state = 10)"
      ],
      "metadata": {
        "id": "Ts3u8k7ZoTmA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluation Metrics\n",
        "\n",
        "from sklearn.metrics import confusion_matrix, recall_score, f1_score, roc_auc_score, accuracy_score\n",
        "\n",
        "def evaluation_metrics(y_true, y_pred):\n",
        "  cfm = confusion_matrix(y_true, y_pred).ravel()\n",
        "  acc = accuracy_score(y_true, y_pred)\n",
        "  recs = recall_score(y_true, y_pred, average='binary')\n",
        "  f1s = f1_score(y_true, y_pred, average='binary')\n",
        "  rocs = roc_auc_score(y_true, y_pred, average='macro')\n",
        "  return [cfm, acc, recs, f1s, rocs]"
      ],
      "metadata": {
        "id": "5pMqZtYUvo3T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Confusion matrix format : [ tn , fp , fn , tp ]"
      ],
      "metadata": {
        "id": "bDAw6kBSvqrd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Store Model Parameters and Eval\n",
        "\n",
        "models = pd.DataFrame(columns = ['model_name', 'model', 'parameters'])\n",
        "models_eval = pd.DataFrame(columns = ['model_name', 'confusion_matrix', 'accuracy', 'recall', 'f1_score', 'roc_auc_score'])"
      ],
      "metadata": {
        "id": "2m4kHhLmvnxj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Import ML Algorithms\n",
        "\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "import xgboost\n",
        "from xgboost import XGBClassifier\n",
        "import lightgbm\n",
        "from lightgbm import LGBMClassifier\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from sklearn.ensemble import VotingClassifier\n",
        "\n",
        "# RandomizedSearchCV\n",
        "\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "\n",
        "# Save Model\n",
        "\n",
        "import pickle"
      ],
      "metadata": {
        "id": "fFvGo3IYwC3h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Logistic Regression\n",
        "\n",
        "- Library: Scikit-learn"
      ],
      "metadata": {
        "id": "ez3z3utYt1Y4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Training\n",
        "\n",
        "name = 'log_clf'\n",
        "\n",
        "train = pd.DataFrame(columns = ['penalty', 'warm_start', 'solver', 'max_iter', 'dual', 'n_jobs','random_state'])\n",
        "train = train.append({'penalty' : 'none', 'warm_start': False, 'solver': 'newton-cg',  'max_iter': 247,  'dual': False, 'n_jobs': -1, 'random_state': 10}, ignore_index=True)\n",
        "train = train.append({'penalty' : 'l2', 'warm_start': False, 'solver': 'newton-cg',  'max_iter': 100,  'dual': False, 'n_jobs': -1, 'random_state': 10}, ignore_index=True)\n",
        "\n",
        "train = train.reset_index()\n",
        "for index, row in train.iterrows():\n",
        "    model_name = name + str(index)\n",
        "    log_clf = LogisticRegression(penalty = row['penalty'], n_jobs = int(row['n_jobs']), random_state = int(row['random_state']))\n",
        "    log_clf.fit(X_train, y_train)\n",
        "   \n",
        "    y_true = y_val\n",
        "    y_pred = log_clf.predict(X_val)\n",
        "    evaluation_results = evaluation_metrics(y_true, y_pred)\n",
        "\n",
        "    models = models.append({'model_name': model_name, \n",
        "                            'model': log_clf, \n",
        "                            'parameters': log_clf.get_params()}, \n",
        "                            ignore_index=True)\n",
        "   \n",
        "    models_eval = models_eval.append({'model_name': model_name, \n",
        "                                      'confusion_matrix' : evaluation_results[0], \n",
        "                                      'accuracy': evaluation_results[1], \n",
        "                                      'recall' : evaluation_results[2], \n",
        "                                      'f1_score': evaluation_results[3], \n",
        "                                      'roc_auc_score': evaluation_results[4]}, \n",
        "                                      ignore_index=True)"
      ],
      "metadata": {
        "id": "fiXiFiYsZSB6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "display(models_eval)"
      ],
      "metadata": {
        "id": "w5hD6F2kX9ih",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 112
        },
        "outputId": "3071acc9-477a-4a60-d1ce-868380e118eb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  model_name       confusion_matrix  accuracy    recall  f1_score  \\\n",
              "0   log_clf0  [14440, 2628, 28, 94]  0.845492  0.770492  0.066104   \n",
              "1   log_clf1  [14441, 2627, 28, 94]  0.845550  0.770492  0.066127   \n",
              "\n",
              "   roc_auc_score  \n",
              "0       0.808260  \n",
              "1       0.808289  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-00eb2ece-1785-424f-b348-910d9d1eb40a\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>model_name</th>\n",
              "      <th>confusion_matrix</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>recall</th>\n",
              "      <th>f1_score</th>\n",
              "      <th>roc_auc_score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>log_clf0</td>\n",
              "      <td>[14440, 2628, 28, 94]</td>\n",
              "      <td>0.845492</td>\n",
              "      <td>0.770492</td>\n",
              "      <td>0.066104</td>\n",
              "      <td>0.808260</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>log_clf1</td>\n",
              "      <td>[14441, 2627, 28, 94]</td>\n",
              "      <td>0.845550</td>\n",
              "      <td>0.770492</td>\n",
              "      <td>0.066127</td>\n",
              "      <td>0.808289</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-00eb2ece-1785-424f-b348-910d9d1eb40a')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-00eb2ece-1785-424f-b348-910d9d1eb40a button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-00eb2ece-1785-424f-b348-910d9d1eb40a');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# RandomizedSearchCV\n",
        "\n",
        "random_grid = {\n",
        "                \"penalty\": ['l1', 'l2', 'elasticnet', 'none'],\n",
        "                \"dual\": [True, False],\n",
        "                \"max_iter\" : [int(x) for x in np.linspace(100, 500, num = 20)],\n",
        "                \"warm_start\" : [True, False],\n",
        "                \"solver\" : ['lbfgs', 'newton-cg', 'liblinear'],\n",
        "                \"C\" : [int(x) for x in np.linspace(0, 1, num = 50)]\n",
        "              }\n",
        "\n",
        "log_random = RandomizedSearchCV(estimator = log_clf, \n",
        "                                param_distributions = random_grid, \n",
        "                                n_iter = 70, \n",
        "                                cv = 3, \n",
        "                                verbose=2, \n",
        "                                scoring='recall',\n",
        "                                random_state=10)\n",
        "\n",
        "log_random.fit(X_train, y_train)\n",
        "log_random.best_params_"
      ],
      "metadata": {
        "id": "09I9B42LX8mb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "870869db-4cbc-4b06-9229-cdea9c8f0e96"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 3 folds for each of 50 candidates, totalling 150 fits\n",
            "[CV] END C=0, dual=True, max_iter=436, penalty=l2, solver=newton-cg, warm_start=False; total time=   0.0s\n",
            "[CV] END C=0, dual=True, max_iter=436, penalty=l2, solver=newton-cg, warm_start=False; total time=   0.0s\n",
            "[CV] END C=0, dual=True, max_iter=436, penalty=l2, solver=newton-cg, warm_start=False; total time=   0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_logistic.py:1523: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 2.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_logistic.py:1523: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 2.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_logistic.py:1523: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 2.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV] END C=0, dual=False, max_iter=289, penalty=l1, solver=liblinear, warm_start=False; total time=   0.1s\n",
            "[CV] END C=0, dual=False, max_iter=289, penalty=l1, solver=liblinear, warm_start=False; total time=   0.1s\n",
            "[CV] END C=0, dual=False, max_iter=289, penalty=l1, solver=liblinear, warm_start=False; total time=   0.1s\n",
            "[CV] END C=0, dual=True, max_iter=436, penalty=elasticnet, solver=newton-cg, warm_start=False; total time=   0.0s\n",
            "[CV] END C=0, dual=True, max_iter=436, penalty=elasticnet, solver=newton-cg, warm_start=False; total time=   0.0s\n",
            "[CV] END C=0, dual=True, max_iter=436, penalty=elasticnet, solver=newton-cg, warm_start=False; total time=   0.0s\n",
            "[CV] END C=0, dual=True, max_iter=247, penalty=l2, solver=newton-cg, warm_start=False; total time=   0.0s\n",
            "[CV] END C=0, dual=True, max_iter=247, penalty=l2, solver=newton-cg, warm_start=False; total time=   0.0s\n",
            "[CV] END C=0, dual=True, max_iter=247, penalty=l2, solver=newton-cg, warm_start=False; total time=   0.0s\n",
            "[CV] END C=0, dual=False, max_iter=289, penalty=l1, solver=newton-cg, warm_start=False; total time=   0.0s\n",
            "[CV] END C=0, dual=False, max_iter=289, penalty=l1, solver=newton-cg, warm_start=False; total time=   0.0s\n",
            "[CV] END C=0, dual=False, max_iter=289, penalty=l1, solver=newton-cg, warm_start=False; total time=   0.0s\n",
            "[CV] END C=0, dual=False, max_iter=310, penalty=elasticnet, solver=lbfgs, warm_start=True; total time=   0.0s\n",
            "[CV] END C=0, dual=False, max_iter=310, penalty=elasticnet, solver=lbfgs, warm_start=True; total time=   0.0s\n",
            "[CV] END C=0, dual=False, max_iter=310, penalty=elasticnet, solver=lbfgs, warm_start=True; total time=   0.0s\n",
            "[CV] END C=0, dual=False, max_iter=205, penalty=l1, solver=lbfgs, warm_start=False; total time=   0.0s\n",
            "[CV] END C=0, dual=False, max_iter=205, penalty=l1, solver=lbfgs, warm_start=False; total time=   0.0s\n",
            "[CV] END C=0, dual=False, max_iter=205, penalty=l1, solver=lbfgs, warm_start=False; total time=   0.0s\n",
            "[CV] END C=0, dual=True, max_iter=226, penalty=elasticnet, solver=lbfgs, warm_start=False; total time=   0.0s\n",
            "[CV] END C=0, dual=True, max_iter=226, penalty=elasticnet, solver=lbfgs, warm_start=False; total time=   0.0s\n",
            "[CV] END C=0, dual=True, max_iter=226, penalty=elasticnet, solver=lbfgs, warm_start=False; total time=   0.0s\n",
            "[CV] END C=0, dual=False, max_iter=226, penalty=l1, solver=lbfgs, warm_start=True; total time=   0.0s\n",
            "[CV] END C=0, dual=False, max_iter=226, penalty=l1, solver=lbfgs, warm_start=True; total time=   0.0s\n",
            "[CV] END C=0, dual=False, max_iter=226, penalty=l1, solver=lbfgs, warm_start=True; total time=   0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV] END C=0, dual=False, max_iter=247, penalty=none, solver=newton-cg, warm_start=False; total time=   5.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV] END C=0, dual=False, max_iter=247, penalty=none, solver=newton-cg, warm_start=False; total time=   5.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV] END C=0, dual=False, max_iter=247, penalty=none, solver=newton-cg, warm_start=False; total time=   5.1s\n",
            "[CV] END C=0, dual=False, max_iter=436, penalty=elasticnet, solver=liblinear, warm_start=False; total time=   0.0s\n",
            "[CV] END C=0, dual=False, max_iter=436, penalty=elasticnet, solver=liblinear, warm_start=False; total time=   0.0s\n",
            "[CV] END C=0, dual=False, max_iter=436, penalty=elasticnet, solver=liblinear, warm_start=False; total time=   0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV] END C=0, dual=False, max_iter=331, penalty=none, solver=lbfgs, warm_start=True; total time=   2.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV] END C=0, dual=False, max_iter=331, penalty=none, solver=lbfgs, warm_start=True; total time=   2.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV] END C=0, dual=False, max_iter=331, penalty=none, solver=lbfgs, warm_start=True; total time=   2.2s\n",
            "[CV] END C=0, dual=False, max_iter=184, penalty=l2, solver=newton-cg, warm_start=True; total time=   0.1s\n",
            "[CV] END C=0, dual=False, max_iter=184, penalty=l2, solver=newton-cg, warm_start=True; total time=   0.7s\n",
            "[CV] END C=0, dual=False, max_iter=184, penalty=l2, solver=newton-cg, warm_start=True; total time=   0.8s\n",
            "[CV] END C=0, dual=False, max_iter=247, penalty=l1, solver=lbfgs, warm_start=False; total time=   0.0s\n",
            "[CV] END C=0, dual=False, max_iter=247, penalty=l1, solver=lbfgs, warm_start=False; total time=   0.0s\n",
            "[CV] END C=0, dual=False, max_iter=247, penalty=l1, solver=lbfgs, warm_start=False; total time=   0.0s\n",
            "[CV] END C=0, dual=False, max_iter=100, penalty=l2, solver=liblinear, warm_start=True; total time=   0.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_logistic.py:1523: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 2.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_logistic.py:1523: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 2.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_logistic.py:1523: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 2.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV] END C=0, dual=False, max_iter=100, penalty=l2, solver=liblinear, warm_start=True; total time=   0.1s\n",
            "[CV] END C=0, dual=False, max_iter=100, penalty=l2, solver=liblinear, warm_start=True; total time=   0.1s\n",
            "[CV] END C=0, dual=False, max_iter=436, penalty=l2, solver=newton-cg, warm_start=True; total time=   0.7s\n",
            "[CV] END C=0, dual=False, max_iter=436, penalty=l2, solver=newton-cg, warm_start=True; total time=   0.7s\n",
            "[CV] END C=0, dual=False, max_iter=436, penalty=l2, solver=newton-cg, warm_start=True; total time=   0.7s\n",
            "[CV] END C=0, dual=True, max_iter=247, penalty=elasticnet, solver=newton-cg, warm_start=True; total time=   0.0s\n",
            "[CV] END C=0, dual=True, max_iter=247, penalty=elasticnet, solver=newton-cg, warm_start=True; total time=   0.0s\n",
            "[CV] END C=0, dual=True, max_iter=247, penalty=elasticnet, solver=newton-cg, warm_start=True; total time=   0.0s\n",
            "[CV] END C=1, dual=True, max_iter=478, penalty=l1, solver=newton-cg, warm_start=False; total time=   0.0s\n",
            "[CV] END C=1, dual=True, max_iter=478, penalty=l1, solver=newton-cg, warm_start=False; total time=   0.0s\n",
            "[CV] END C=1, dual=True, max_iter=478, penalty=l1, solver=newton-cg, warm_start=False; total time=   0.0s\n",
            "[CV] END C=0, dual=True, max_iter=100, penalty=elasticnet, solver=liblinear, warm_start=True; total time=   0.0s\n",
            "[CV] END C=0, dual=True, max_iter=100, penalty=elasticnet, solver=liblinear, warm_start=True; total time=   0.0s\n",
            "[CV] END C=0, dual=True, max_iter=100, penalty=elasticnet, solver=liblinear, warm_start=True; total time=   0.0s\n",
            "[CV] END C=0, dual=True, max_iter=247, penalty=elasticnet, solver=newton-cg, warm_start=True; total time=   0.0s\n",
            "[CV] END C=0, dual=True, max_iter=247, penalty=elasticnet, solver=newton-cg, warm_start=True; total time=   0.0s\n",
            "[CV] END C=0, dual=True, max_iter=247, penalty=elasticnet, solver=newton-cg, warm_start=True; total time=   0.0s\n",
            "[CV] END C=0, dual=False, max_iter=247, penalty=elasticnet, solver=liblinear, warm_start=True; total time=   0.0s\n",
            "[CV] END C=0, dual=False, max_iter=247, penalty=elasticnet, solver=liblinear, warm_start=True; total time=   0.0s\n",
            "[CV] END C=0, dual=False, max_iter=247, penalty=elasticnet, solver=liblinear, warm_start=True; total time=   0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV] END C=0, dual=False, max_iter=163, penalty=none, solver=lbfgs, warm_start=True; total time=   2.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV] END C=0, dual=False, max_iter=163, penalty=none, solver=lbfgs, warm_start=True; total time=   1.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV] END C=0, dual=False, max_iter=163, penalty=none, solver=lbfgs, warm_start=True; total time=   2.2s\n",
            "[CV] END C=0, dual=False, max_iter=289, penalty=l2, solver=lbfgs, warm_start=True; total time=   0.1s\n",
            "[CV] END C=0, dual=False, max_iter=289, penalty=l2, solver=lbfgs, warm_start=True; total time=   0.8s\n",
            "[CV] END C=0, dual=False, max_iter=289, penalty=l2, solver=lbfgs, warm_start=True; total time=   0.8s\n",
            "[CV] END C=0, dual=False, max_iter=205, penalty=l2, solver=newton-cg, warm_start=False; total time=   0.8s\n",
            "[CV] END C=0, dual=False, max_iter=205, penalty=l2, solver=newton-cg, warm_start=False; total time=   0.7s\n",
            "[CV] END C=0, dual=False, max_iter=205, penalty=l2, solver=newton-cg, warm_start=False; total time=   0.7s\n",
            "[CV] END C=0, dual=True, max_iter=457, penalty=elasticnet, solver=lbfgs, warm_start=True; total time=   0.0s\n",
            "[CV] END C=0, dual=True, max_iter=457, penalty=elasticnet, solver=lbfgs, warm_start=True; total time=   0.0s\n",
            "[CV] END C=0, dual=True, max_iter=457, penalty=elasticnet, solver=lbfgs, warm_start=True; total time=   0.0s\n",
            "[CV] END C=0, dual=False, max_iter=184, penalty=elasticnet, solver=newton-cg, warm_start=True; total time=   0.0s\n",
            "[CV] END C=0, dual=False, max_iter=184, penalty=elasticnet, solver=newton-cg, warm_start=True; total time=   0.0s\n",
            "[CV] END C=0, dual=False, max_iter=184, penalty=elasticnet, solver=newton-cg, warm_start=True; total time=   0.0s\n",
            "[CV] END C=0, dual=False, max_iter=163, penalty=l2, solver=newton-cg, warm_start=False; total time=   0.8s\n",
            "[CV] END C=0, dual=False, max_iter=163, penalty=l2, solver=newton-cg, warm_start=False; total time=   0.8s\n",
            "[CV] END C=0, dual=False, max_iter=163, penalty=l2, solver=newton-cg, warm_start=False; total time=   0.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV] END C=0, dual=False, max_iter=268, penalty=none, solver=lbfgs, warm_start=False; total time=   2.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV] END C=0, dual=False, max_iter=268, penalty=none, solver=lbfgs, warm_start=False; total time=   1.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV] END C=0, dual=False, max_iter=268, penalty=none, solver=lbfgs, warm_start=False; total time=   2.2s\n",
            "[CV] END C=0, dual=False, max_iter=331, penalty=elasticnet, solver=newton-cg, warm_start=True; total time=   0.0s\n",
            "[CV] END C=0, dual=False, max_iter=331, penalty=elasticnet, solver=newton-cg, warm_start=True; total time=   0.0s\n",
            "[CV] END C=0, dual=False, max_iter=331, penalty=elasticnet, solver=newton-cg, warm_start=True; total time=   0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV] END C=0, dual=False, max_iter=457, penalty=none, solver=newton-cg, warm_start=False; total time=   5.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV] END C=0, dual=False, max_iter=457, penalty=none, solver=newton-cg, warm_start=False; total time=   5.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV] END C=0, dual=False, max_iter=457, penalty=none, solver=newton-cg, warm_start=False; total time=   5.2s\n",
            "[CV] END C=0, dual=True, max_iter=478, penalty=none, solver=newton-cg, warm_start=False; total time=   0.0s\n",
            "[CV] END C=0, dual=True, max_iter=478, penalty=none, solver=newton-cg, warm_start=False; total time=   0.0s\n",
            "[CV] END C=0, dual=True, max_iter=478, penalty=none, solver=newton-cg, warm_start=False; total time=   0.0s\n",
            "[CV] END C=0, dual=False, max_iter=352, penalty=elasticnet, solver=lbfgs, warm_start=False; total time=   0.0s\n",
            "[CV] END C=0, dual=False, max_iter=352, penalty=elasticnet, solver=lbfgs, warm_start=False; total time=   0.0s\n",
            "[CV] END C=0, dual=False, max_iter=352, penalty=elasticnet, solver=lbfgs, warm_start=False; total time=   0.0s\n",
            "[CV] END C=0, dual=True, max_iter=247, penalty=l2, solver=liblinear, warm_start=False; total time=   0.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_logistic.py:1523: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 2.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_logistic.py:1523: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 2.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_logistic.py:1523: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 2.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV] END C=0, dual=True, max_iter=247, penalty=l2, solver=liblinear, warm_start=False; total time=   0.1s\n",
            "[CV] END C=0, dual=True, max_iter=247, penalty=l2, solver=liblinear, warm_start=False; total time=   0.1s\n",
            "[CV] END C=0, dual=True, max_iter=500, penalty=elasticnet, solver=liblinear, warm_start=False; total time=   0.0s\n",
            "[CV] END C=0, dual=True, max_iter=500, penalty=elasticnet, solver=liblinear, warm_start=False; total time=   0.0s\n",
            "[CV] END C=0, dual=True, max_iter=500, penalty=elasticnet, solver=liblinear, warm_start=False; total time=   0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV] END C=0, dual=False, max_iter=289, penalty=none, solver=newton-cg, warm_start=False; total time=   5.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV] END C=0, dual=False, max_iter=289, penalty=none, solver=newton-cg, warm_start=False; total time=   5.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV] END C=0, dual=False, max_iter=289, penalty=none, solver=newton-cg, warm_start=False; total time=   5.1s\n",
            "[CV] END C=0, dual=True, max_iter=289, penalty=l1, solver=liblinear, warm_start=True; total time=   0.1s\n",
            "[CV] END C=0, dual=True, max_iter=289, penalty=l1, solver=liblinear, warm_start=True; total time=   0.1s\n",
            "[CV] END C=0, dual=True, max_iter=289, penalty=l1, solver=liblinear, warm_start=True; total time=   0.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_logistic.py:1523: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 2.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_logistic.py:1523: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 2.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_logistic.py:1523: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 2.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV] END C=0, dual=True, max_iter=436, penalty=none, solver=liblinear, warm_start=True; total time=   0.0s\n",
            "[CV] END C=0, dual=True, max_iter=436, penalty=none, solver=liblinear, warm_start=True; total time=   0.0s\n",
            "[CV] END C=0, dual=True, max_iter=436, penalty=none, solver=liblinear, warm_start=True; total time=   0.0s\n",
            "[CV] END C=0, dual=False, max_iter=205, penalty=l1, solver=lbfgs, warm_start=False; total time=   0.0s\n",
            "[CV] END C=0, dual=False, max_iter=205, penalty=l1, solver=lbfgs, warm_start=False; total time=   0.0s\n",
            "[CV] END C=0, dual=False, max_iter=205, penalty=l1, solver=lbfgs, warm_start=False; total time=   0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV] END C=0, dual=False, max_iter=457, penalty=none, solver=newton-cg, warm_start=True; total time=   5.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV] END C=0, dual=False, max_iter=457, penalty=none, solver=newton-cg, warm_start=True; total time=   5.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV] END C=0, dual=False, max_iter=457, penalty=none, solver=newton-cg, warm_start=True; total time=   5.2s\n",
            "[CV] END C=0, dual=False, max_iter=457, penalty=l2, solver=newton-cg, warm_start=False; total time=   0.1s\n",
            "[CV] END C=0, dual=False, max_iter=457, penalty=l2, solver=newton-cg, warm_start=False; total time=   0.8s\n",
            "[CV] END C=0, dual=False, max_iter=457, penalty=l2, solver=newton-cg, warm_start=False; total time=   0.8s\n",
            "[CV] END C=0, dual=False, max_iter=394, penalty=l2, solver=newton-cg, warm_start=False; total time=   0.8s\n",
            "[CV] END C=0, dual=False, max_iter=394, penalty=l2, solver=newton-cg, warm_start=False; total time=   0.8s\n",
            "[CV] END C=0, dual=False, max_iter=394, penalty=l2, solver=newton-cg, warm_start=False; total time=   0.8s\n",
            "[CV] END C=0, dual=False, max_iter=436, penalty=l1, solver=liblinear, warm_start=True; total time=   0.1s\n",
            "[CV] END C=0, dual=False, max_iter=436, penalty=l1, solver=liblinear, warm_start=True; total time=   0.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_logistic.py:1523: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 2.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_logistic.py:1523: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 2.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_logistic.py:1523: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 2.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV] END C=0, dual=False, max_iter=436, penalty=l1, solver=liblinear, warm_start=True; total time=   0.1s\n",
            "[CV] END C=0, dual=True, max_iter=394, penalty=l1, solver=newton-cg, warm_start=True; total time=   0.0s\n",
            "[CV] END C=0, dual=True, max_iter=394, penalty=l1, solver=newton-cg, warm_start=True; total time=   0.0s\n",
            "[CV] END C=0, dual=True, max_iter=394, penalty=l1, solver=newton-cg, warm_start=True; total time=   0.0s\n",
            "[CV] END C=0, dual=False, max_iter=205, penalty=l1, solver=liblinear, warm_start=False; total time=   0.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_logistic.py:1523: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 2.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_logistic.py:1523: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 2.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_logistic.py:1523: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 2.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV] END C=0, dual=False, max_iter=205, penalty=l1, solver=liblinear, warm_start=False; total time=   0.1s\n",
            "[CV] END C=0, dual=False, max_iter=205, penalty=l1, solver=liblinear, warm_start=False; total time=   0.1s\n",
            "[CV] END C=0, dual=True, max_iter=100, penalty=elasticnet, solver=lbfgs, warm_start=False; total time=   0.0s\n",
            "[CV] END C=0, dual=True, max_iter=100, penalty=elasticnet, solver=lbfgs, warm_start=False; total time=   0.0s\n",
            "[CV] END C=0, dual=True, max_iter=100, penalty=elasticnet, solver=lbfgs, warm_start=False; total time=   0.0s\n",
            "[CV] END C=0, dual=True, max_iter=394, penalty=l2, solver=lbfgs, warm_start=False; total time=   0.0s\n",
            "[CV] END C=0, dual=True, max_iter=394, penalty=l2, solver=lbfgs, warm_start=False; total time=   0.0s\n",
            "[CV] END C=0, dual=True, max_iter=394, penalty=l2, solver=lbfgs, warm_start=False; total time=   0.0s\n",
            "[CV] END C=0, dual=False, max_iter=415, penalty=none, solver=liblinear, warm_start=True; total time=   0.0s\n",
            "[CV] END C=0, dual=False, max_iter=415, penalty=none, solver=liblinear, warm_start=True; total time=   0.0s\n",
            "[CV] END C=0, dual=False, max_iter=415, penalty=none, solver=liblinear, warm_start=True; total time=   0.0s\n",
            "[CV] END C=0, dual=False, max_iter=163, penalty=elasticnet, solver=liblinear, warm_start=True; total time=   0.0s\n",
            "[CV] END C=0, dual=False, max_iter=163, penalty=elasticnet, solver=liblinear, warm_start=True; total time=   0.0s\n",
            "[CV] END C=0, dual=False, max_iter=163, penalty=elasticnet, solver=liblinear, warm_start=True; total time=   0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV] END C=0, dual=False, max_iter=289, penalty=none, solver=lbfgs, warm_start=False; total time=   2.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV] END C=0, dual=False, max_iter=289, penalty=none, solver=lbfgs, warm_start=False; total time=   1.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV] END C=0, dual=False, max_iter=289, penalty=none, solver=lbfgs, warm_start=False; total time=   2.2s\n",
            "[CV] END C=0, dual=False, max_iter=142, penalty=elasticnet, solver=lbfgs, warm_start=True; total time=   0.0s\n",
            "[CV] END C=0, dual=False, max_iter=142, penalty=elasticnet, solver=lbfgs, warm_start=True; total time=   0.0s\n",
            "[CV] END C=0, dual=False, max_iter=142, penalty=elasticnet, solver=lbfgs, warm_start=True; total time=   0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/model_selection/_validation.py:372: FitFailedWarning: \n",
            "126 fits failed out of a total of 150.\n",
            "The score on these train-test partitions for these parameters will be set to nan.\n",
            "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
            "\n",
            "Below are more details about the failures:\n",
            "--------------------------------------------------------------------------------\n",
            "9 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_logistic.py\", line 1461, in fit\n",
            "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_logistic.py\", line 452, in _check_solver\n",
            "    raise ValueError(\n",
            "ValueError: Solver newton-cg supports only dual=False, got dual=True\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "15 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_logistic.py\", line 1528, in fit\n",
            "    self.coef_, self.intercept_, n_iter_ = _fit_liblinear(\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/sklearn/svm/_base.py\", line 1186, in _fit_liblinear\n",
            "    raw_coef_, n_iter_ = liblinear.train_wrap(\n",
            "  File \"sklearn/svm/_liblinear.pyx\", line 52, in sklearn.svm._liblinear.train_wrap\n",
            "ValueError: b'C <= 0'\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "15 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_logistic.py\", line 1461, in fit\n",
            "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_logistic.py\", line 447, in _check_solver\n",
            "    raise ValueError(\n",
            "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "9 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_logistic.py\", line 1461, in fit\n",
            "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_logistic.py\", line 447, in _check_solver\n",
            "    raise ValueError(\n",
            "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got l1 penalty.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "18 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_logistic.py\", line 1461, in fit\n",
            "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_logistic.py\", line 447, in _check_solver\n",
            "    raise ValueError(\n",
            "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "12 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_logistic.py\", line 1461, in fit\n",
            "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_logistic.py\", line 447, in _check_solver\n",
            "    raise ValueError(\n",
            "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "15 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_logistic.py\", line 1461, in fit\n",
            "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_logistic.py\", line 457, in _check_solver\n",
            "    raise ValueError(\n",
            "ValueError: Only 'saga' solver supports elasticnet penalty, got solver=liblinear.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "18 fits failed with the following error:\n",
            "joblib.externals.loky.process_executor._RemoteTraceback: \n",
            "\"\"\"\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/joblib/externals/loky/process_executor.py\", line 428, in _process_worker\n",
            "    r = call_item()\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/joblib/externals/loky/process_executor.py\", line 275, in __call__\n",
            "    return self.fn(*self.args, **self.kwargs)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/joblib/_parallel_backends.py\", line 620, in __call__\n",
            "    return self.func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/joblib/parallel.py\", line 288, in __call__\n",
            "    return [func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/joblib/parallel.py\", line 288, in <listcomp>\n",
            "    return [func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/sklearn/utils/fixes.py\", line 216, in __call__\n",
            "    return self.function(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_logistic.py\", line 822, in _logistic_regression_path\n",
            "    args = (X, target, 1.0 / C, sample_weight)\n",
            "ZeroDivisionError: float division by zero\n",
            "\"\"\"\n",
            "\n",
            "The above exception was the direct cause of the following exception:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_logistic.py\", line 1589, in fit\n",
            "    fold_coefs_ = Parallel(\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/joblib/parallel.py\", line 1098, in __call__\n",
            "    self.retrieve()\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/joblib/parallel.py\", line 975, in retrieve\n",
            "    self._output.extend(job.get(timeout=self.timeout))\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/joblib/_parallel_backends.py\", line 567, in wrap_future_result\n",
            "    return future.result(timeout=timeout)\n",
            "  File \"/usr/lib/python3.8/concurrent/futures/_base.py\", line 444, in result\n",
            "    return self.__get_result()\n",
            "  File \"/usr/lib/python3.8/concurrent/futures/_base.py\", line 389, in __get_result\n",
            "    raise self._exception\n",
            "ZeroDivisionError: float division by zero\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "3 fits failed with the following error:\n",
            "joblib.externals.loky.process_executor._RemoteTraceback: \n",
            "\"\"\"\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/joblib/externals/loky/process_executor.py\", line 428, in _process_worker\n",
            "    r = call_item()\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/joblib/externals/loky/process_executor.py\", line 275, in __call__\n",
            "    return self.fn(*self.args, **self.kwargs)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/joblib/_parallel_backends.py\", line 620, in __call__\n",
            "    return self.func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/joblib/parallel.py\", line 288, in __call__\n",
            "    return [func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/joblib/parallel.py\", line 288, in <listcomp>\n",
            "    return [func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/sklearn/utils/fixes.py\", line 216, in __call__\n",
            "    return self.function(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_logistic.py\", line 811, in _logistic_regression_path\n",
            "    args=(X, target, 1.0 / C, sample_weight),\n",
            "ZeroDivisionError: float division by zero\n",
            "\"\"\"\n",
            "\n",
            "The above exception was the direct cause of the following exception:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_logistic.py\", line 1589, in fit\n",
            "    fold_coefs_ = Parallel(\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/joblib/parallel.py\", line 1098, in __call__\n",
            "    self.retrieve()\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/joblib/parallel.py\", line 975, in retrieve\n",
            "    self._output.extend(job.get(timeout=self.timeout))\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/joblib/_parallel_backends.py\", line 567, in wrap_future_result\n",
            "    return future.result(timeout=timeout)\n",
            "  File \"/usr/lib/python3.8/concurrent/futures/_base.py\", line 444, in result\n",
            "    return self.__get_result()\n",
            "  File \"/usr/lib/python3.8/concurrent/futures/_base.py\", line 389, in __get_result\n",
            "    raise self._exception\n",
            "ZeroDivisionError: float division by zero\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "3 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_logistic.py\", line 1528, in fit\n",
            "    self.coef_, self.intercept_, n_iter_ = _fit_liblinear(\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/sklearn/svm/_base.py\", line 1185, in _fit_liblinear\n",
            "    solver_type = _get_liblinear_solver_type(multi_class, penalty, loss, dual)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/sklearn/svm/_base.py\", line 1024, in _get_liblinear_solver_type\n",
            "    raise ValueError(\n",
            "ValueError: Unsupported set of arguments: The combination of penalty='l1' and loss='logistic_regression' are not supported when dual=True, Parameters: penalty='l1', loss='logistic_regression', dual=True\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "6 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_logistic.py\", line 1461, in fit\n",
            "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_logistic.py\", line 464, in _check_solver\n",
            "    raise ValueError(\"penalty='none' is not supported for the liblinear solver\")\n",
            "ValueError: penalty='none' is not supported for the liblinear solver\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "3 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_logistic.py\", line 1461, in fit\n",
            "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_logistic.py\", line 452, in _check_solver\n",
            "    raise ValueError(\n",
            "ValueError: Solver lbfgs supports only dual=False, got dual=True\n",
            "\n",
            "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/model_selection/_search.py:969: UserWarning: One or more of the test scores are non-finite: [       nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan 0.83288007        nan 0.83287274\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan 0.83287274        nan        nan\n",
            "        nan        nan        nan 0.83287274        nan 0.83288007\n",
            "        nan        nan        nan        nan 0.83288007        nan\n",
            "        nan        nan 0.83288007        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            " 0.83287274        nan]\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'warm_start': False,\n",
              " 'solver': 'newton-cg',\n",
              " 'penalty': 'none',\n",
              " 'max_iter': 247,\n",
              " 'dual': False,\n",
              " 'C': 0}"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "log_random.best_params_"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GQf2Kg82OkuJ",
        "outputId": "cce82259-9120-4fad-9850-8f55aa2f328e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'warm_start': False,\n",
              " 'solver': 'newton-cg',\n",
              " 'penalty': 'none',\n",
              " 'max_iter': 247,\n",
              " 'dual': False,\n",
              " 'C': 0}"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "log_random.best_score_"
      ],
      "metadata": {
        "id": "rSyim973PLda"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Support Vector Machine (SVM)\n",
        "\n",
        "- Library: Scikit-learn"
      ],
      "metadata": {
        "id": "oBBQ_iust1eb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Approach 1: Undersampling to lower number of training samples and reduce learning time"
      ],
      "metadata": {
        "id": "-DJDztBnUV6b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_SVM = Original[0]\n",
        "X_val_SVM = Original[1]\n",
        "y_train_SVM = Original[3]\n",
        "y_val_SVM = Original[4]"
      ],
      "metadata": {
        "id": "tsq0c55qZSVE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "display(y_train_SVM.value_counts())"
      ],
      "metadata": {
        "id": "OlCn_HS1dItl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Undersampling & Shuffle\n",
        "\n",
        "from imblearn.under_sampling import RandomUnderSampler\n",
        "\n",
        "rus = RandomUnderSampler(random_state=10)\n",
        "X_train_SVM, y_train_SVM = rus.fit_resample(X_train_SVM, y_train_SVM)\n",
        "X_train_SVM, y_train_SVM = shuffle(X_train_SVM, y_train_SVM, random_state = 10)"
      ],
      "metadata": {
        "id": "wPwHlXKMdiO9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "display(y_train_SVM.value_counts())"
      ],
      "metadata": {
        "id": "9by4YC8tdj47"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Training\n",
        "\n",
        "name = 'svc_clf'\n",
        "\n",
        "train = pd.DataFrame(columns = ['kernel', 'random_state'])\n",
        "train = train.append({'kernel' : 'rbf', 'random_state': 10}, ignore_index=True)\n",
        "train = train.append({'kernel' : 'poly', 'random_state': 10}, ignore_index=True)\n",
        "train = train.append({'kernel' : 'sigmoid', 'random_state': 10}, ignore_index=True)\n",
        "\n",
        "train = train.reset_index()\n",
        "for index, row in train.iterrows():\n",
        "    model_name = name + str(index)\n",
        "    print(\"Currently at :\" , model_name)\n",
        "    svc_clf = SVC(kernel=row[\"kernel\"], random_state = int(row[\"random_state\"]))\n",
        "    svc_clf.fit(X_train_SVM, y_train_SVM)\n",
        "    \n",
        "    y_true = y_val_SVM\n",
        "    y_pred = svc_clf.predict(X_val_SVM)\n",
        "    evaluation_results = evaluation_metrics(y_true, y_pred)\n",
        "\n",
        "    models = models.append({'model_name': model_name, \n",
        "                            'model': svc_clf, \n",
        "                            'parameters': svc_clf.get_params()}, \n",
        "                            ignore_index=True)\n",
        "    \n",
        "    models_eval = models_eval.append({'model_name': model_name, \n",
        "                                      'confusion_matrix' : evaluation_results[0], \n",
        "                                      'accuracy': evaluation_results[1], \n",
        "                                      'recall' : evaluation_results[2], \n",
        "                                      'f1_score': evaluation_results[3], \n",
        "                                      'roc_auc_score': evaluation_results[4]}, \n",
        "                                      ignore_index=True)"
      ],
      "metadata": {
        "id": "XsSKT8gmdoVT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "display(models_eval)"
      ],
      "metadata": {
        "id": "Wb-YSYc9VwpI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The best kernel is rbf"
      ],
      "metadata": {
        "id": "qrWtVscoHjwp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Approach 2: Class-weighted SVM with original amount of data (before SMOTE)"
      ],
      "metadata": {
        "id": "dMGtSxvfUekT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_SVM = Original[0]\n",
        "X_val_SVM = Original[1]\n",
        "y_train_SVM = Original[3]\n",
        "y_val_SVM = Original[4]"
      ],
      "metadata": {
        "id": "ySImEnhqGWbH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Shuffle\n",
        "\n",
        "X_train_SVM, y_train_SVM = shuffle(X_train_SVM, y_train_SVM, random_state = 10)"
      ],
      "metadata": {
        "id": "ugeOje0B-dZ1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "display(y_train_SVM.value_counts())"
      ],
      "metadata": {
        "id": "A88D9hpjGYf-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Training\n",
        "\n",
        "name = 'svc_clf'\n",
        "\n",
        "train = pd.DataFrame(columns = ['kernel', 'random_state'])\n",
        "train = train.append({'kernel' : 'rbf', 'C': 1, 'random_state': 10}, ignore_index=True)\n",
        "train = train.append({'kernel' : 'rbf', 'C': 2, 'random_state': 10}, ignore_index=True)\n",
        "train = train.append({'kernel' : 'rbf', 'C': 0.5, 'random_state': 10}, ignore_index=True)\n",
        "\n",
        "train = train.reset_index()\n",
        "for index, row in train.iterrows():\n",
        "    model_name = name + str(index)\n",
        "    print(\"Currently at :\" , model_name)\n",
        "    svc_clf = SVC(kernel=row[\"kernel\"], class_weight='balanced', 'C' = int(row[\"C\"]), random_state = int(row[\"random_state\"]))\n",
        "    svc_clf.fit(X_train_SVM, y_train_SVM)\n",
        "    \n",
        "    y_true = y_val_SVM\n",
        "    y_pred = svc_clf.predict(X_val_SVM)\n",
        "    evaluation_results = evaluation_metrics(y_true, y_pred)\n",
        "\n",
        "    models = models.append({'model_name': model_name, \n",
        "                            'model': svc_clf, \n",
        "                            'parameters': svc_clf.get_params()}, \n",
        "                            ignore_index=True)\n",
        "    \n",
        "    models_eval = models_eval.append({'model_name': model_name, \n",
        "                                      'confusion_matrix' : evaluation_results[0], \n",
        "                                      'accuracy': evaluation_results[1], \n",
        "                                      'recall' : evaluation_results[2], \n",
        "                                      'f1_score': evaluation_results[3], \n",
        "                                      'roc_auc_score': evaluation_results[4]}, \n",
        "                                      ignore_index=True)"
      ],
      "metadata": {
        "id": "QGpzJBu7VRov"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Best Params: \n",
        "\n",
        "{\n",
        "\n",
        "'kernel': 'rbf',\n",
        "\n",
        "'C' : '1',\n",
        "\n",
        "'class_weight'='balanced'\n",
        "\n",
        "}"
      ],
      "metadata": {
        "id": "v35KdCcEGL7J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "display(models)"
      ],
      "metadata": {
        "id": "7arKkPPaGDO2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "display(models_eval)"
      ],
      "metadata": {
        "id": "ouPtk_gtdt0I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Naive Bayes\n",
        "\n",
        "- Library: Scikit-learn"
      ],
      "metadata": {
        "id": "Tzx0wl2ht1R1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Training\n",
        "\n",
        "name = 'bayes_clf'\n",
        "\n",
        "train = pd.DataFrame(columns = ['var_smoothing'])\n",
        "train = train.append({'var_smoothing': 1e-0}, ignore_index=True)\n",
        "train = train.append({'var_smoothing': 1e-1}, ignore_index=True)\n",
        "train = train.append({'var_smoothing': 1e-3}, ignore_index=True)\n",
        "train = train.append({'var_smoothing': 1e-5}, ignore_index=True)\n",
        "train = train.append({'var_smoothing': 1e-9}, ignore_index=True)\n",
        "train = train.append({'var_smoothing': 1e-10}, ignore_index=True)\n",
        "train = train.append({'var_smoothing': 1e-20}, ignore_index=True)\n",
        "\n",
        "train = train.reset_index()\n",
        "for index, row in train.iterrows():\n",
        "    model_name = name + str(index)\n",
        "    bayes_clf = GaussianNB(var_smoothing = row['var_smoothing'])\n",
        "    bayes_clf.fit(X_train, y_train)\n",
        "    \n",
        "    y_true = y_val\n",
        "    y_pred = bayes_clf.predict(X_val)\n",
        "    evaluation_results = evaluation_metrics(y_true, y_pred)\n",
        "\n",
        "    models = models.append({'model_name': model_name, \n",
        "                            'model': bayes_clf, \n",
        "                            'parameters': bayes_clf.get_params()}, \n",
        "                            ignore_index=True)\n",
        "    \n",
        "    models_eval = models_eval.append({'model_name': model_name, \n",
        "                                      'confusion_matrix' : evaluation_results[0], \n",
        "                                      'accuracy': evaluation_results[1], \n",
        "                                      'recall' : evaluation_results[2], \n",
        "                                      'f1_score': evaluation_results[3], \n",
        "                                      'roc_auc_score': evaluation_results[4]}, \n",
        "                                      ignore_index=True)"
      ],
      "metadata": {
        "id": "tAmU3wsqZSwf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "display(models_eval)"
      ],
      "metadata": {
        "id": "n7Ad5Gr5eH_U",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 175
        },
        "outputId": "8d419116-e025-444a-c5fd-04ff5cd268e6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "   model_name        confusion_matrix  accuracy    recall  f1_score  \\\n",
              "0  bayes_clf0    [16538, 530, 42, 80]  0.966725  0.655738  0.218579   \n",
              "1  bayes_clf1   [14850, 2218, 26, 96]  0.869459  0.786885  0.078818   \n",
              "2  bayes_clf2  [13712, 3356, 13, 109]  0.804014  0.893443  0.060775   \n",
              "3  bayes_clf3   [10485, 6583, 1, 121]  0.616987  0.991803  0.035453   \n",
              "\n",
              "   roc_auc_score  \n",
              "0       0.812343  \n",
              "1       0.828467  \n",
              "2       0.848409  \n",
              "3       0.803055  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-a9d4b17b-a683-4a8a-82c1-46e0c7ea1b61\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>model_name</th>\n",
              "      <th>confusion_matrix</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>recall</th>\n",
              "      <th>f1_score</th>\n",
              "      <th>roc_auc_score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>bayes_clf0</td>\n",
              "      <td>[16538, 530, 42, 80]</td>\n",
              "      <td>0.966725</td>\n",
              "      <td>0.655738</td>\n",
              "      <td>0.218579</td>\n",
              "      <td>0.812343</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>bayes_clf1</td>\n",
              "      <td>[14850, 2218, 26, 96]</td>\n",
              "      <td>0.869459</td>\n",
              "      <td>0.786885</td>\n",
              "      <td>0.078818</td>\n",
              "      <td>0.828467</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>bayes_clf2</td>\n",
              "      <td>[13712, 3356, 13, 109]</td>\n",
              "      <td>0.804014</td>\n",
              "      <td>0.893443</td>\n",
              "      <td>0.060775</td>\n",
              "      <td>0.848409</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>bayes_clf3</td>\n",
              "      <td>[10485, 6583, 1, 121]</td>\n",
              "      <td>0.616987</td>\n",
              "      <td>0.991803</td>\n",
              "      <td>0.035453</td>\n",
              "      <td>0.803055</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a9d4b17b-a683-4a8a-82c1-46e0c7ea1b61')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-a9d4b17b-a683-4a8a-82c1-46e0c7ea1b61 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-a9d4b17b-a683-4a8a-82c1-46e0c7ea1b61');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Best Params: \n",
        "\n",
        "{\n",
        "\n",
        "'var_smoothing': '1e-10'\n",
        "\n",
        "}"
      ],
      "metadata": {
        "id": "xbdXqp_Rq353"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## K-Nearest Neighbor\n",
        "\n",
        "- Library: Scikit-learn\n",
        "- Shuffling does not affect the model building. No random_state."
      ],
      "metadata": {
        "id": "M_gEyKKnt00q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Training\n",
        "\n",
        "name = 'neigh_clf'\n",
        "\n",
        "train = pd.DataFrame(columns = ['n_neighbors', 'algorithm', 'n_jobs'])\n",
        "train = train.append({'n_neighbors': 5, 'algorithm':'auto', 'n_jobs':-1}, ignore_index=True)\n",
        "train = train.append({'n_neighbors': 1, 'algorithm':'auto', 'n_jobs':-1}, ignore_index=True)\n",
        "train = train.append({'n_neighbors': 20, 'algorithm':'kd_tree', 'n_jobs':-1}, ignore_index=True)\n",
        "\n",
        "train = train.reset_index()\n",
        "for index, row in train.iterrows():\n",
        "    model_name = name + str(index)\n",
        "    neigh_clf = KNeighborsClassifier(n_neighbors=int(row['n_neighbors']), algorithm = row['algorithm'], n_jobs = int(row['n_jobs']))\n",
        "    neigh_clf.fit(X_train, y_train)\n",
        "    \n",
        "    y_true = y_val\n",
        "    y_pred = neigh_clf.predict(X_val)\n",
        "    evaluation_results = evaluation_metrics(y_true, y_pred)\n",
        "\n",
        "    models = models.append({'model_name': model_name, \n",
        "                            'model': neigh_clf, \n",
        "                            'parameters': neigh_clf.get_params()}, \n",
        "                            ignore_index=True)\n",
        "    \n",
        "    models_eval = models_eval.append({'model_name': model_name, \n",
        "                                      'confusion_matrix' : evaluation_results[0], \n",
        "                                      'accuracy': evaluation_results[1], \n",
        "                                      'recall' : evaluation_results[2], \n",
        "                                      'f1_score': evaluation_results[3], \n",
        "                                      'roc_auc_score': evaluation_results[4]}, \n",
        "                                      ignore_index=True)"
      ],
      "metadata": {
        "id": "Vw5TiOkaZTHW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "display(models_eval)"
      ],
      "metadata": {
        "id": "EvI_e6r-exRk",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "outputId": "bc387626-84e5-4528-b070-d6d0b2752308"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "   model_name       confusion_matrix  accuracy    recall  f1_score  \\\n",
              "0    log_clf0  [14440, 2628, 28, 94]  0.845492  0.770492  0.066104   \n",
              "1    log_clf1  [14441, 2627, 28, 94]  0.845550  0.770492  0.066127   \n",
              "2  bayes_clf0  [1326, 15742, 0, 122]  0.084235  1.000000  0.015263   \n",
              "3  bayes_clf1   [592, 16476, 0, 122]  0.041536  1.000000  0.014593   \n",
              "4  bayes_clf2     [0, 17068, 0, 122]  0.007097  1.000000  0.014094   \n",
              "5  neigh_clf0   [16979, 89, 10, 112]  0.994241  0.918033  0.693498   \n",
              "6  neigh_clf1   [17035, 33, 10, 112]  0.997499  0.918033  0.838951   \n",
              "7  neigh_clf2   [16847, 221, 6, 116]  0.986795  0.950820  0.505447   \n",
              "\n",
              "   roc_auc_score  \n",
              "0       0.808260  \n",
              "1       0.808289  \n",
              "2       0.538845  \n",
              "3       0.517342  \n",
              "4       0.500000  \n",
              "5       0.956409  \n",
              "6       0.958050  \n",
              "7       0.968936  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-9821785e-7225-4dca-a311-2a261150c507\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>model_name</th>\n",
              "      <th>confusion_matrix</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>recall</th>\n",
              "      <th>f1_score</th>\n",
              "      <th>roc_auc_score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>log_clf0</td>\n",
              "      <td>[14440, 2628, 28, 94]</td>\n",
              "      <td>0.845492</td>\n",
              "      <td>0.770492</td>\n",
              "      <td>0.066104</td>\n",
              "      <td>0.808260</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>log_clf1</td>\n",
              "      <td>[14441, 2627, 28, 94]</td>\n",
              "      <td>0.845550</td>\n",
              "      <td>0.770492</td>\n",
              "      <td>0.066127</td>\n",
              "      <td>0.808289</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>bayes_clf0</td>\n",
              "      <td>[1326, 15742, 0, 122]</td>\n",
              "      <td>0.084235</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.015263</td>\n",
              "      <td>0.538845</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>bayes_clf1</td>\n",
              "      <td>[592, 16476, 0, 122]</td>\n",
              "      <td>0.041536</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.014593</td>\n",
              "      <td>0.517342</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>bayes_clf2</td>\n",
              "      <td>[0, 17068, 0, 122]</td>\n",
              "      <td>0.007097</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.014094</td>\n",
              "      <td>0.500000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>neigh_clf0</td>\n",
              "      <td>[16979, 89, 10, 112]</td>\n",
              "      <td>0.994241</td>\n",
              "      <td>0.918033</td>\n",
              "      <td>0.693498</td>\n",
              "      <td>0.956409</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>neigh_clf1</td>\n",
              "      <td>[17035, 33, 10, 112]</td>\n",
              "      <td>0.997499</td>\n",
              "      <td>0.918033</td>\n",
              "      <td>0.838951</td>\n",
              "      <td>0.958050</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>neigh_clf2</td>\n",
              "      <td>[16847, 221, 6, 116]</td>\n",
              "      <td>0.986795</td>\n",
              "      <td>0.950820</td>\n",
              "      <td>0.505447</td>\n",
              "      <td>0.968936</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-9821785e-7225-4dca-a311-2a261150c507')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-9821785e-7225-4dca-a311-2a261150c507 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-9821785e-7225-4dca-a311-2a261150c507');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# RandomizedSearchCV\n",
        "\n",
        "random_grid = {\n",
        "                \"n_neighbors\": [int(x) for x in np.linspace(1, 20, num = 20)],\n",
        "                \"algorithm\": ['auto', 'kd_tree','ball_tree']\n",
        "              }\n",
        "\n",
        "neigh_random = RandomizedSearchCV(estimator = neigh_clf, \n",
        "                                  param_distributions = random_grid, \n",
        "                                  n_iter = 50, \n",
        "                                  cv = 3, \n",
        "                                  verbose=2, \n",
        "                                  scoring='recall',\n",
        "                                  random_state=10)\n",
        "\n",
        "neigh_random.fit(X_train, y_train)\n",
        "neigh_random.best_params_"
      ],
      "metadata": {
        "id": "SlJiuLzfen_x",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8a3a7f97-fabc-4a6c-b175-0981ed5126d8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 3 folds for each of 50 candidates, totalling 150 fits\n",
            "[CV] END ..................algorithm=kd_tree, n_neighbors=12; total time=  29.9s\n",
            "[CV] END ..................algorithm=kd_tree, n_neighbors=12; total time=  29.8s\n",
            "[CV] END ..................algorithm=kd_tree, n_neighbors=12; total time=  29.8s\n",
            "[CV] END ......................algorithm=auto, n_neighbors=4; total time=  17.1s\n",
            "[CV] END ......................algorithm=auto, n_neighbors=4; total time=  18.8s\n",
            "[CV] END ......................algorithm=auto, n_neighbors=4; total time=  16.3s\n",
            "[CV] END ..................algorithm=kd_tree, n_neighbors=19; total time=  34.2s\n",
            "[CV] END ..................algorithm=kd_tree, n_neighbors=19; total time=  33.2s\n",
            "[CV] END ..................algorithm=kd_tree, n_neighbors=19; total time=  35.3s\n",
            "[CV] END ...................algorithm=kd_tree, n_neighbors=8; total time=  24.2s\n",
            "[CV] END ...................algorithm=kd_tree, n_neighbors=8; total time=  24.3s\n",
            "[CV] END ...................algorithm=kd_tree, n_neighbors=8; total time=  24.7s\n",
            "[CV] END ...................algorithm=kd_tree, n_neighbors=2; total time=  13.1s\n",
            "[CV] END ...................algorithm=kd_tree, n_neighbors=2; total time=  12.9s\n",
            "[CV] END ...................algorithm=kd_tree, n_neighbors=2; total time=  14.9s\n",
            "[CV] END .....................algorithm=auto, n_neighbors=18; total time=  35.7s\n",
            "[CV] END .....................algorithm=auto, n_neighbors=18; total time=  34.9s\n",
            "[CV] END .....................algorithm=auto, n_neighbors=18; total time=  36.1s\n",
            "[CV] END .................algorithm=ball_tree, n_neighbors=7; total time= 4.9min\n",
            "[CV] END .................algorithm=ball_tree, n_neighbors=7; total time= 5.1min\n",
            "[CV] END .................algorithm=ball_tree, n_neighbors=7; total time= 5.1min\n",
            "[CV] END ......................algorithm=auto, n_neighbors=3; total time=  14.7s\n",
            "[CV] END ......................algorithm=auto, n_neighbors=3; total time=  14.7s\n",
            "[CV] END ......................algorithm=auto, n_neighbors=3; total time=  17.4s\n",
            "[CV] END ...................algorithm=kd_tree, n_neighbors=4; total time=  17.8s\n",
            "[CV] END ...................algorithm=kd_tree, n_neighbors=4; total time=  17.8s\n",
            "[CV] END ...................algorithm=kd_tree, n_neighbors=4; total time=  18.0s\n",
            "[CV] END ...................algorithm=kd_tree, n_neighbors=7; total time=  23.5s\n",
            "[CV] END ...................algorithm=kd_tree, n_neighbors=7; total time=  22.3s\n",
            "[CV] END ...................algorithm=kd_tree, n_neighbors=7; total time=  21.9s\n",
            "[CV] END ..................algorithm=kd_tree, n_neighbors=16; total time=  32.7s\n",
            "[CV] END ..................algorithm=kd_tree, n_neighbors=16; total time=  34.3s\n",
            "[CV] END ..................algorithm=kd_tree, n_neighbors=16; total time=  31.7s\n",
            "[CV] END ..................algorithm=kd_tree, n_neighbors=20; total time=  39.6s\n",
            "[CV] END ..................algorithm=kd_tree, n_neighbors=20; total time=  38.0s\n",
            "[CV] END ..................algorithm=kd_tree, n_neighbors=20; total time=  35.6s\n",
            "[CV] END ...................algorithm=kd_tree, n_neighbors=1; total time=   9.1s\n",
            "[CV] END ...................algorithm=kd_tree, n_neighbors=1; total time=   9.2s\n",
            "[CV] END ...................algorithm=kd_tree, n_neighbors=1; total time=   9.0s\n",
            "[CV] END ..................algorithm=kd_tree, n_neighbors=18; total time=  34.2s\n",
            "[CV] END ..................algorithm=kd_tree, n_neighbors=18; total time=  36.0s\n",
            "[CV] END ..................algorithm=kd_tree, n_neighbors=18; total time=  33.6s\n",
            "[CV] END ......................algorithm=auto, n_neighbors=8; total time=  23.3s\n",
            "[CV] END ......................algorithm=auto, n_neighbors=8; total time=  24.9s\n",
            "[CV] END ......................algorithm=auto, n_neighbors=8; total time=  22.9s\n",
            "[CV] END ......................algorithm=auto, n_neighbors=7; total time=  22.2s\n",
            "[CV] END ......................algorithm=auto, n_neighbors=7; total time=  22.1s\n",
            "[CV] END ......................algorithm=auto, n_neighbors=7; total time=  22.0s\n",
            "[CV] END .................algorithm=ball_tree, n_neighbors=6; total time= 4.5min\n",
            "[CV] END .................algorithm=ball_tree, n_neighbors=6; total time= 4.7min\n",
            "[CV] END .................algorithm=ball_tree, n_neighbors=6; total time= 4.6min\n",
            "[CV] END ................algorithm=ball_tree, n_neighbors=18; total time= 4.7min\n",
            "[CV] END ................algorithm=ball_tree, n_neighbors=18; total time= 5.0min\n",
            "[CV] END ................algorithm=ball_tree, n_neighbors=18; total time= 5.1min\n",
            "[CV] END .................algorithm=ball_tree, n_neighbors=8; total time= 4.4min\n",
            "[CV] END .................algorithm=ball_tree, n_neighbors=8; total time= 4.7min\n",
            "[CV] END .................algorithm=ball_tree, n_neighbors=8; total time= 4.7min\n",
            "[CV] END .....................algorithm=auto, n_neighbors=11; total time=  26.6s\n",
            "[CV] END .....................algorithm=auto, n_neighbors=11; total time=  26.1s\n",
            "[CV] END .....................algorithm=auto, n_neighbors=11; total time=  26.3s\n",
            "[CV] END .................algorithm=ball_tree, n_neighbors=5; total time= 4.2min\n",
            "[CV] END .................algorithm=ball_tree, n_neighbors=5; total time= 4.5min\n",
            "[CV] END .................algorithm=ball_tree, n_neighbors=5; total time= 4.5min\n",
            "[CV] END ................algorithm=ball_tree, n_neighbors=11; total time= 4.5min\n",
            "[CV] END ................algorithm=ball_tree, n_neighbors=11; total time= 4.8min\n",
            "[CV] END ................algorithm=ball_tree, n_neighbors=11; total time= 4.8min\n",
            "[CV] END .....................algorithm=auto, n_neighbors=19; total time=  36.6s\n",
            "[CV] END .....................algorithm=auto, n_neighbors=19; total time=  36.4s\n",
            "[CV] END .....................algorithm=auto, n_neighbors=19; total time=  34.1s\n",
            "[CV] END ......................algorithm=auto, n_neighbors=5; total time=  18.7s\n",
            "[CV] END ......................algorithm=auto, n_neighbors=5; total time=  18.3s\n",
            "[CV] END ......................algorithm=auto, n_neighbors=5; total time=  18.3s\n",
            "[CV] END ......................algorithm=auto, n_neighbors=2; total time=  12.5s\n",
            "[CV] END ......................algorithm=auto, n_neighbors=2; total time=  12.0s\n",
            "[CV] END ......................algorithm=auto, n_neighbors=2; total time=  12.0s\n",
            "[CV] END .....................algorithm=auto, n_neighbors=13; total time=  31.2s\n",
            "[CV] END .....................algorithm=auto, n_neighbors=13; total time=  30.6s\n",
            "[CV] END .....................algorithm=auto, n_neighbors=13; total time=  29.3s\n",
            "[CV] END ..................algorithm=kd_tree, n_neighbors=11; total time=  27.2s\n",
            "[CV] END ..................algorithm=kd_tree, n_neighbors=11; total time=  26.3s\n",
            "[CV] END ..................algorithm=kd_tree, n_neighbors=11; total time=  26.9s\n",
            "[CV] END ...................algorithm=kd_tree, n_neighbors=3; total time=  14.6s\n",
            "[CV] END ...................algorithm=kd_tree, n_neighbors=3; total time=  14.4s\n",
            "[CV] END ...................algorithm=kd_tree, n_neighbors=3; total time=  14.7s\n",
            "[CV] END ................algorithm=ball_tree, n_neighbors=15; total time= 4.9min\n",
            "[CV] END ................algorithm=ball_tree, n_neighbors=15; total time= 5.2min\n",
            "[CV] END ................algorithm=ball_tree, n_neighbors=15; total time= 5.2min\n",
            "[CV] END ..................algorithm=kd_tree, n_neighbors=13; total time=  29.6s\n",
            "[CV] END ..................algorithm=kd_tree, n_neighbors=13; total time=  29.3s\n",
            "[CV] END ..................algorithm=kd_tree, n_neighbors=13; total time=  33.9s\n",
            "[CV] END ................algorithm=ball_tree, n_neighbors=14; total time= 4.7min\n",
            "[CV] END ................algorithm=ball_tree, n_neighbors=14; total time= 4.8min\n",
            "[CV] END ................algorithm=ball_tree, n_neighbors=14; total time= 4.9min\n",
            "[CV] END .....................algorithm=auto, n_neighbors=20; total time=  34.9s\n",
            "[CV] END .....................algorithm=auto, n_neighbors=20; total time=  37.6s\n",
            "[CV] END .....................algorithm=auto, n_neighbors=20; total time=  35.5s\n",
            "[CV] END ..................algorithm=kd_tree, n_neighbors=15; total time=  30.8s\n",
            "[CV] END ..................algorithm=kd_tree, n_neighbors=15; total time=  30.2s\n",
            "[CV] END ..................algorithm=kd_tree, n_neighbors=15; total time=  30.4s\n",
            "[CV] END ......................algorithm=auto, n_neighbors=6; total time=  20.1s\n",
            "[CV] END ......................algorithm=auto, n_neighbors=6; total time=  19.7s\n",
            "[CV] END ......................algorithm=auto, n_neighbors=6; total time=  19.6s\n",
            "[CV] END .....................algorithm=auto, n_neighbors=14; total time=  29.7s\n",
            "[CV] END .....................algorithm=auto, n_neighbors=14; total time=  33.9s\n",
            "[CV] END .....................algorithm=auto, n_neighbors=14; total time=  29.2s\n",
            "[CV] END .....................algorithm=auto, n_neighbors=15; total time=  30.4s\n",
            "[CV] END .....................algorithm=auto, n_neighbors=15; total time=  30.1s\n",
            "[CV] END .....................algorithm=auto, n_neighbors=15; total time=  30.3s\n",
            "[CV] END .................algorithm=ball_tree, n_neighbors=2; total time= 3.8min\n",
            "[CV] END .................algorithm=ball_tree, n_neighbors=2; total time= 4.1min\n",
            "[CV] END .................algorithm=ball_tree, n_neighbors=2; total time= 4.1min\n",
            "[CV] END ................algorithm=ball_tree, n_neighbors=12; total time= 4.5min\n",
            "[CV] END ................algorithm=ball_tree, n_neighbors=12; total time= 4.8min\n",
            "[CV] END ................algorithm=ball_tree, n_neighbors=12; total time= 4.9min\n",
            "[CV] END ..................algorithm=kd_tree, n_neighbors=14; total time=  29.9s\n",
            "[CV] END ..................algorithm=kd_tree, n_neighbors=14; total time=  29.3s\n",
            "[CV] END ..................algorithm=kd_tree, n_neighbors=14; total time=  29.8s\n",
            "[CV] END ...................algorithm=kd_tree, n_neighbors=5; total time=  18.3s\n",
            "[CV] END ...................algorithm=kd_tree, n_neighbors=5; total time=  18.4s\n",
            "[CV] END ...................algorithm=kd_tree, n_neighbors=5; total time=  18.4s\n",
            "[CV] END .....................algorithm=auto, n_neighbors=12; total time=  32.8s\n",
            "[CV] END .....................algorithm=auto, n_neighbors=12; total time=  27.4s\n",
            "[CV] END .....................algorithm=auto, n_neighbors=12; total time=  27.6s\n",
            "[CV] END .................algorithm=ball_tree, n_neighbors=4; total time= 4.1min\n",
            "[CV] END .................algorithm=ball_tree, n_neighbors=4; total time= 4.4min\n",
            "[CV] END .................algorithm=ball_tree, n_neighbors=4; total time= 5.1min\n",
            "[CV] END .....................algorithm=auto, n_neighbors=17; total time=  34.7s\n",
            "[CV] END .....................algorithm=auto, n_neighbors=17; total time=  39.0s\n",
            "[CV] END .....................algorithm=auto, n_neighbors=17; total time=  34.3s\n",
            "[CV] END ................algorithm=ball_tree, n_neighbors=19; total time= 5.1min\n",
            "[CV] END ................algorithm=ball_tree, n_neighbors=19; total time= 5.5min\n",
            "[CV] END ................algorithm=ball_tree, n_neighbors=19; total time= 5.3min\n",
            "[CV] END .................algorithm=ball_tree, n_neighbors=1; total time= 3.7min\n",
            "[CV] END .................algorithm=ball_tree, n_neighbors=1; total time= 3.9min\n",
            "[CV] END .................algorithm=ball_tree, n_neighbors=1; total time= 4.0min\n",
            "[CV] END .................algorithm=ball_tree, n_neighbors=3; total time= 4.0min\n",
            "[CV] END .................algorithm=ball_tree, n_neighbors=3; total time= 4.5min\n",
            "[CV] END .................algorithm=ball_tree, n_neighbors=3; total time= 4.5min\n",
            "[CV] END ................algorithm=ball_tree, n_neighbors=17; total time= 5.0min\n",
            "[CV] END ................algorithm=ball_tree, n_neighbors=17; total time= 5.1min\n",
            "[CV] END ................algorithm=ball_tree, n_neighbors=17; total time= 5.0min\n",
            "[CV] END ................algorithm=ball_tree, n_neighbors=20; total time= 4.8min\n",
            "[CV] END ................algorithm=ball_tree, n_neighbors=20; total time= 5.0min\n",
            "[CV] END ................algorithm=ball_tree, n_neighbors=20; total time= 5.2min\n",
            "[CV] END ......................algorithm=auto, n_neighbors=9; total time=  24.3s\n",
            "[CV] END ......................algorithm=auto, n_neighbors=9; total time=  28.6s\n",
            "[CV] END ......................algorithm=auto, n_neighbors=9; total time=  23.9s\n",
            "[CV] END ................algorithm=ball_tree, n_neighbors=16; total time= 4.6min\n",
            "[CV] END ................algorithm=ball_tree, n_neighbors=16; total time= 5.0min\n",
            "[CV] END ................algorithm=ball_tree, n_neighbors=16; total time= 5.1min\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'n_neighbors': 19, 'algorithm': 'kd_tree'}"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "neigh_random.best_params_"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2G3z6f8vP21Z",
        "outputId": "491ee692-3a77-464f-d121-167eb516e28b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'n_neighbors': 19, 'algorithm': 'kd_tree'}"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "neigh_random.best_score_"
      ],
      "metadata": {
        "id": "kTB3Zxm-PUu4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Decision Tree\n",
        "\n",
        "- Library: Scikit-learn"
      ],
      "metadata": {
        "id": "brtgIH7pt1jO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Training\n",
        "\n",
        "name = 'tree_clf'\n",
        "\n",
        "train = pd.DataFrame(columns = ['criterion', 'splitter', 'min_samples_leaf', 'max_features', 'max_depth', 'n_jobs', 'random_state'])\n",
        "train = train.append({'criterion' : 'gini', 'splitter': 'best', 'min_samples_leaf': 1, 'max_features': 9, 'max_depth': None, 'random_state': 10}, ignore_index=True)\n",
        "train = train.append({'criterion' : 'entropy', 'splitter': 'best', 'min_samples_leaf': 1, 'max_features': 9, 'max_depth': None, 'random_state': 10}, ignore_index=True)\n",
        "train = train.append({'criterion' : 'gini', 'splitter': 'random', 'min_samples_leaf': 1, 'max_features': \"auto\", 'max_depth': None, 'random_state': 10}, ignore_index=True)\n",
        "train = train.append({'criterion' : 'entropy', 'splitter': 'random', 'min_samples_leaf': 1, 'max_features': \"auto\", 'max_depth': None, 'random_state': 10}, ignore_index=True)\n",
        "\n",
        "train = train.reset_index()\n",
        "for index, row in train.iterrows():\n",
        "    model_name = name + str(index)\n",
        "    tree_clf = DecisionTreeClassifier(criterion = row['criterion'], splitter = row['splitter'], max_depth = None, random_state = row['random_state'])\n",
        "    tree_clf.fit(X_train, y_train)\n",
        "    \n",
        "    y_true = y_val\n",
        "    y_pred = tree_clf.predict(X_val)\n",
        "    evaluation_results = evaluation_metrics(y_true, y_pred)\n",
        "\n",
        "    models = models.append({'model_name': model_name, \n",
        "                            'model': tree_clf, \n",
        "                            'parameters': tree_clf.get_params()}, \n",
        "                            ignore_index=True)\n",
        "    \n",
        "    models_eval = models_eval.append({'model_name': model_name, \n",
        "                                      'confusion_matrix' : evaluation_results[0], \n",
        "                                      'accuracy': evaluation_results[1], \n",
        "                                      'recall' : evaluation_results[2], \n",
        "                                      'f1_score': evaluation_results[3], \n",
        "                                      'roc_auc_score': evaluation_results[4]}, \n",
        "                                      ignore_index=True)"
      ],
      "metadata": {
        "id": "sgwicO4LbXRt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "display(models_eval)"
      ],
      "metadata": {
        "id": "YC01I-OZbZQU",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 175
        },
        "outputId": "4c6a2c29-9607-407e-8c17-c34c75b134bf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  model_name      confusion_matrix  accuracy    recall  f1_score  \\\n",
              "0  tree_clf0  [17023, 45, 11, 111]  0.996742  0.909836  0.798561   \n",
              "1  tree_clf1   [17016, 52, 7, 115]  0.996568  0.942623  0.795848   \n",
              "2  tree_clf2  [17003, 65, 13, 109]  0.995462  0.893443  0.736486   \n",
              "3  tree_clf3   [17010, 58, 8, 114]  0.996161  0.934426  0.775510   \n",
              "\n",
              "   roc_auc_score  \n",
              "0       0.953600  \n",
              "1       0.969788  \n",
              "2       0.944817  \n",
              "3       0.965514  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-39a1b37d-490d-449f-a2ce-7ba553ca2376\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>model_name</th>\n",
              "      <th>confusion_matrix</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>recall</th>\n",
              "      <th>f1_score</th>\n",
              "      <th>roc_auc_score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>tree_clf0</td>\n",
              "      <td>[17023, 45, 11, 111]</td>\n",
              "      <td>0.996742</td>\n",
              "      <td>0.909836</td>\n",
              "      <td>0.798561</td>\n",
              "      <td>0.953600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>tree_clf1</td>\n",
              "      <td>[17016, 52, 7, 115]</td>\n",
              "      <td>0.996568</td>\n",
              "      <td>0.942623</td>\n",
              "      <td>0.795848</td>\n",
              "      <td>0.969788</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>tree_clf2</td>\n",
              "      <td>[17003, 65, 13, 109]</td>\n",
              "      <td>0.995462</td>\n",
              "      <td>0.893443</td>\n",
              "      <td>0.736486</td>\n",
              "      <td>0.944817</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>tree_clf3</td>\n",
              "      <td>[17010, 58, 8, 114]</td>\n",
              "      <td>0.996161</td>\n",
              "      <td>0.934426</td>\n",
              "      <td>0.775510</td>\n",
              "      <td>0.965514</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-39a1b37d-490d-449f-a2ce-7ba553ca2376')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-39a1b37d-490d-449f-a2ce-7ba553ca2376 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-39a1b37d-490d-449f-a2ce-7ba553ca2376');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# RandomizedSearchCV\n",
        "\n",
        "max_depth = list([int(x) for x in np.linspace(2, 6, num = 5)])\n",
        "max_depth.append(None)\n",
        "\n",
        "random_grid = {\n",
        "              \"max_depth\": max_depth,\n",
        "              \"max_features\": [int(x) for x in np.linspace(1, len(df.columns), num = len(df.columns))],\n",
        "              \"min_samples_leaf\": [int(x) for x in np.linspace(1, len(df.columns), num = len(df.columns))],\n",
        "              \"criterion\": [\"gini\", \"entropy\", \"log_loss\"],\n",
        "              \"splitter\": [\"random\", \"best\"]\n",
        "              }\n",
        "\n",
        "tree_random = RandomizedSearchCV(estimator = tree_clf, \n",
        "                                 param_distributions = random_grid, \n",
        "                                 n_iter = 100, \n",
        "                                 cv = 3, \n",
        "                                 verbose=2, \n",
        "                                 scoring='recall',\n",
        "                                 random_state=10)\n",
        "\n",
        "tree_random.fit(X_train, y_train)\n",
        "tree_random.best_params_"
      ],
      "metadata": {
        "id": "HuK06hK8bZ_r",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "87ba3bb4-b780-48fe-a864-3d0d50fc86dd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 3 folds for each of 100 candidates, totalling 300 fits\n",
            "[CV] END criterion=log_loss, max_depth=3, max_features=12, min_samples_leaf=13, splitter=random; total time=   0.1s\n",
            "[CV] END criterion=log_loss, max_depth=3, max_features=12, min_samples_leaf=13, splitter=random; total time=   0.0s\n",
            "[CV] END criterion=log_loss, max_depth=3, max_features=12, min_samples_leaf=13, splitter=random; total time=   0.0s\n",
            "[CV] END criterion=gini, max_depth=5, max_features=13, min_samples_leaf=4, splitter=random; total time=   0.2s\n",
            "[CV] END criterion=gini, max_depth=5, max_features=13, min_samples_leaf=4, splitter=random; total time=   0.2s\n",
            "[CV] END criterion=gini, max_depth=5, max_features=13, min_samples_leaf=4, splitter=random; total time=   0.2s\n",
            "[CV] END criterion=log_loss, max_depth=3, max_features=11, min_samples_leaf=3, splitter=random; total time=   0.1s\n",
            "[CV] END criterion=log_loss, max_depth=3, max_features=11, min_samples_leaf=3, splitter=random; total time=   0.0s\n",
            "[CV] END criterion=log_loss, max_depth=3, max_features=11, min_samples_leaf=3, splitter=random; total time=   0.0s\n",
            "[CV] END criterion=gini, max_depth=4, max_features=8, min_samples_leaf=11, splitter=best; total time=   0.6s\n",
            "[CV] END criterion=gini, max_depth=4, max_features=8, min_samples_leaf=11, splitter=best; total time=   0.6s\n",
            "[CV] END criterion=gini, max_depth=4, max_features=8, min_samples_leaf=11, splitter=best; total time=   0.6s\n",
            "[CV] END criterion=gini, max_depth=3, max_features=1, min_samples_leaf=6, splitter=best; total time=   0.2s\n",
            "[CV] END criterion=gini, max_depth=3, max_features=1, min_samples_leaf=6, splitter=best; total time=   0.2s\n",
            "[CV] END criterion=gini, max_depth=3, max_features=1, min_samples_leaf=6, splitter=best; total time=   0.2s\n",
            "[CV] END criterion=gini, max_depth=5, max_features=10, min_samples_leaf=5, splitter=random; total time=   0.2s\n",
            "[CV] END criterion=gini, max_depth=5, max_features=10, min_samples_leaf=5, splitter=random; total time=   0.2s\n",
            "[CV] END criterion=gini, max_depth=5, max_features=10, min_samples_leaf=5, splitter=random; total time=   0.2s\n",
            "[CV] END criterion=log_loss, max_depth=4, max_features=12, min_samples_leaf=10, splitter=random; total time=   0.1s\n",
            "[CV] END criterion=log_loss, max_depth=4, max_features=12, min_samples_leaf=10, splitter=random; total time=   0.0s\n",
            "[CV] END criterion=log_loss, max_depth=4, max_features=12, min_samples_leaf=10, splitter=random; total time=   0.0s\n",
            "[CV] END criterion=gini, max_depth=3, max_features=6, min_samples_leaf=4, splitter=random; total time=   0.1s\n",
            "[CV] END criterion=gini, max_depth=3, max_features=6, min_samples_leaf=4, splitter=random; total time=   0.1s\n",
            "[CV] END criterion=gini, max_depth=3, max_features=6, min_samples_leaf=4, splitter=random; total time=   0.1s\n",
            "[CV] END criterion=entropy, max_depth=None, max_features=3, min_samples_leaf=5, splitter=random; total time=   0.2s\n",
            "[CV] END criterion=entropy, max_depth=None, max_features=3, min_samples_leaf=5, splitter=random; total time=   0.2s\n",
            "[CV] END criterion=entropy, max_depth=None, max_features=3, min_samples_leaf=5, splitter=random; total time=   0.2s\n",
            "[CV] END criterion=log_loss, max_depth=5, max_features=12, min_samples_leaf=11, splitter=best; total time=   0.0s\n",
            "[CV] END criterion=log_loss, max_depth=5, max_features=12, min_samples_leaf=11, splitter=best; total time=   0.0s\n",
            "[CV] END criterion=log_loss, max_depth=5, max_features=12, min_samples_leaf=11, splitter=best; total time=   0.0s\n",
            "[CV] END criterion=gini, max_depth=3, max_features=5, min_samples_leaf=7, splitter=random; total time=   0.1s\n",
            "[CV] END criterion=gini, max_depth=3, max_features=5, min_samples_leaf=7, splitter=random; total time=   0.1s\n",
            "[CV] END criterion=gini, max_depth=3, max_features=5, min_samples_leaf=7, splitter=random; total time=   0.1s\n",
            "[CV] END criterion=gini, max_depth=6, max_features=2, min_samples_leaf=7, splitter=best; total time=   0.3s\n",
            "[CV] END criterion=gini, max_depth=6, max_features=2, min_samples_leaf=7, splitter=best; total time=   0.3s\n",
            "[CV] END criterion=gini, max_depth=6, max_features=2, min_samples_leaf=7, splitter=best; total time=   0.3s\n",
            "[CV] END criterion=entropy, max_depth=4, max_features=6, min_samples_leaf=12, splitter=best; total time=   0.6s\n",
            "[CV] END criterion=entropy, max_depth=4, max_features=6, min_samples_leaf=12, splitter=best; total time=   0.6s\n",
            "[CV] END criterion=entropy, max_depth=4, max_features=6, min_samples_leaf=12, splitter=best; total time=   0.9s\n",
            "[CV] END criterion=entropy, max_depth=6, max_features=8, min_samples_leaf=13, splitter=random; total time=   0.3s\n",
            "[CV] END criterion=entropy, max_depth=6, max_features=8, min_samples_leaf=13, splitter=random; total time=   0.3s\n",
            "[CV] END criterion=entropy, max_depth=6, max_features=8, min_samples_leaf=13, splitter=random; total time=   0.3s\n",
            "[CV] END criterion=log_loss, max_depth=6, max_features=8, min_samples_leaf=3, splitter=best; total time=   0.1s\n",
            "[CV] END criterion=log_loss, max_depth=6, max_features=8, min_samples_leaf=3, splitter=best; total time=   0.1s\n",
            "[CV] END criterion=log_loss, max_depth=6, max_features=8, min_samples_leaf=3, splitter=best; total time=   0.1s\n",
            "[CV] END criterion=gini, max_depth=2, max_features=3, min_samples_leaf=4, splitter=random; total time=   0.2s\n",
            "[CV] END criterion=gini, max_depth=2, max_features=3, min_samples_leaf=4, splitter=random; total time=   0.1s\n",
            "[CV] END criterion=gini, max_depth=2, max_features=3, min_samples_leaf=4, splitter=random; total time=   0.1s\n",
            "[CV] END criterion=gini, max_depth=3, max_features=10, min_samples_leaf=12, splitter=random; total time=   0.2s\n",
            "[CV] END criterion=gini, max_depth=3, max_features=10, min_samples_leaf=12, splitter=random; total time=   0.2s\n",
            "[CV] END criterion=gini, max_depth=3, max_features=10, min_samples_leaf=12, splitter=random; total time=   0.2s\n",
            "[CV] END criterion=gini, max_depth=2, max_features=5, min_samples_leaf=10, splitter=best; total time=   0.4s\n",
            "[CV] END criterion=gini, max_depth=2, max_features=5, min_samples_leaf=10, splitter=best; total time=   0.4s\n",
            "[CV] END criterion=gini, max_depth=2, max_features=5, min_samples_leaf=10, splitter=best; total time=   0.3s\n",
            "[CV] END criterion=entropy, max_depth=5, max_features=5, min_samples_leaf=10, splitter=best; total time=   0.6s\n",
            "[CV] END criterion=entropy, max_depth=5, max_features=5, min_samples_leaf=10, splitter=best; total time=   0.6s\n",
            "[CV] END criterion=entropy, max_depth=5, max_features=5, min_samples_leaf=10, splitter=best; total time=   0.7s\n",
            "[CV] END criterion=entropy, max_depth=5, max_features=11, min_samples_leaf=11, splitter=random; total time=   0.2s\n",
            "[CV] END criterion=entropy, max_depth=5, max_features=11, min_samples_leaf=11, splitter=random; total time=   0.2s\n",
            "[CV] END criterion=entropy, max_depth=5, max_features=11, min_samples_leaf=11, splitter=random; total time=   0.2s\n",
            "[CV] END criterion=gini, max_depth=3, max_features=9, min_samples_leaf=4, splitter=random; total time=   0.1s\n",
            "[CV] END criterion=gini, max_depth=3, max_features=9, min_samples_leaf=4, splitter=random; total time=   0.2s\n",
            "[CV] END criterion=gini, max_depth=3, max_features=9, min_samples_leaf=4, splitter=random; total time=   0.1s\n",
            "[CV] END criterion=entropy, max_depth=None, max_features=6, min_samples_leaf=2, splitter=random; total time=   0.3s\n",
            "[CV] END criterion=entropy, max_depth=None, max_features=6, min_samples_leaf=2, splitter=random; total time=   0.3s\n",
            "[CV] END criterion=entropy, max_depth=None, max_features=6, min_samples_leaf=2, splitter=random; total time=   0.3s\n",
            "[CV] END criterion=entropy, max_depth=None, max_features=1, min_samples_leaf=8, splitter=best; total time=   0.4s\n",
            "[CV] END criterion=entropy, max_depth=None, max_features=1, min_samples_leaf=8, splitter=best; total time=   0.4s\n",
            "[CV] END criterion=entropy, max_depth=None, max_features=1, min_samples_leaf=8, splitter=best; total time=   0.4s\n",
            "[CV] END criterion=log_loss, max_depth=3, max_features=13, min_samples_leaf=6, splitter=best; total time=   0.0s\n",
            "[CV] END criterion=log_loss, max_depth=3, max_features=13, min_samples_leaf=6, splitter=best; total time=   0.0s\n",
            "[CV] END criterion=log_loss, max_depth=3, max_features=13, min_samples_leaf=6, splitter=best; total time=   0.0s\n",
            "[CV] END criterion=entropy, max_depth=3, max_features=14, min_samples_leaf=5, splitter=random; total time=   0.2s\n",
            "[CV] END criterion=entropy, max_depth=3, max_features=14, min_samples_leaf=5, splitter=random; total time=   0.2s\n",
            "[CV] END criterion=entropy, max_depth=3, max_features=14, min_samples_leaf=5, splitter=random; total time=   0.2s\n",
            "[CV] END criterion=log_loss, max_depth=3, max_features=12, min_samples_leaf=15, splitter=random; total time=   0.0s\n",
            "[CV] END criterion=log_loss, max_depth=3, max_features=12, min_samples_leaf=15, splitter=random; total time=   0.0s\n",
            "[CV] END criterion=log_loss, max_depth=3, max_features=12, min_samples_leaf=15, splitter=random; total time=   0.0s\n",
            "[CV] END criterion=entropy, max_depth=5, max_features=3, min_samples_leaf=2, splitter=random; total time=   0.1s\n",
            "[CV] END criterion=entropy, max_depth=5, max_features=3, min_samples_leaf=2, splitter=random; total time=   0.1s\n",
            "[CV] END criterion=entropy, max_depth=5, max_features=3, min_samples_leaf=2, splitter=random; total time=   0.1s\n",
            "[CV] END criterion=gini, max_depth=3, max_features=4, min_samples_leaf=9, splitter=random; total time=   0.1s\n",
            "[CV] END criterion=gini, max_depth=3, max_features=4, min_samples_leaf=9, splitter=random; total time=   0.1s\n",
            "[CV] END criterion=gini, max_depth=3, max_features=4, min_samples_leaf=9, splitter=random; total time=   0.1s\n",
            "[CV] END criterion=log_loss, max_depth=6, max_features=6, min_samples_leaf=11, splitter=best; total time=   0.0s\n",
            "[CV] END criterion=log_loss, max_depth=6, max_features=6, min_samples_leaf=11, splitter=best; total time=   0.1s\n",
            "[CV] END criterion=log_loss, max_depth=6, max_features=6, min_samples_leaf=11, splitter=best; total time=   0.1s\n",
            "[CV] END criterion=log_loss, max_depth=5, max_features=6, min_samples_leaf=13, splitter=random; total time=   0.0s\n",
            "[CV] END criterion=log_loss, max_depth=5, max_features=6, min_samples_leaf=13, splitter=random; total time=   0.0s\n",
            "[CV] END criterion=log_loss, max_depth=5, max_features=6, min_samples_leaf=13, splitter=random; total time=   0.0s\n",
            "[CV] END criterion=gini, max_depth=None, max_features=14, min_samples_leaf=1, splitter=best; total time=   2.8s\n",
            "[CV] END criterion=gini, max_depth=None, max_features=14, min_samples_leaf=1, splitter=best; total time=   2.7s\n",
            "[CV] END criterion=gini, max_depth=None, max_features=14, min_samples_leaf=1, splitter=best; total time=   2.8s\n",
            "[CV] END criterion=log_loss, max_depth=3, max_features=1, min_samples_leaf=10, splitter=random; total time=   0.0s\n",
            "[CV] END criterion=log_loss, max_depth=3, max_features=1, min_samples_leaf=10, splitter=random; total time=   0.0s\n",
            "[CV] END criterion=log_loss, max_depth=3, max_features=1, min_samples_leaf=10, splitter=random; total time=   0.0s\n",
            "[CV] END criterion=log_loss, max_depth=3, max_features=13, min_samples_leaf=4, splitter=best; total time=   0.0s\n",
            "[CV] END criterion=log_loss, max_depth=3, max_features=13, min_samples_leaf=4, splitter=best; total time=   0.0s\n",
            "[CV] END criterion=log_loss, max_depth=3, max_features=13, min_samples_leaf=4, splitter=best; total time=   0.0s\n",
            "[CV] END criterion=log_loss, max_depth=None, max_features=6, min_samples_leaf=8, splitter=random; total time=   0.0s\n",
            "[CV] END criterion=log_loss, max_depth=None, max_features=6, min_samples_leaf=8, splitter=random; total time=   0.0s\n",
            "[CV] END criterion=log_loss, max_depth=None, max_features=6, min_samples_leaf=8, splitter=random; total time=   0.0s\n",
            "[CV] END criterion=gini, max_depth=3, max_features=10, min_samples_leaf=8, splitter=best; total time=   0.6s\n",
            "[CV] END criterion=gini, max_depth=3, max_features=10, min_samples_leaf=8, splitter=best; total time=   0.6s\n",
            "[CV] END criterion=gini, max_depth=3, max_features=10, min_samples_leaf=8, splitter=best; total time=   0.6s\n",
            "[CV] END criterion=log_loss, max_depth=3, max_features=6, min_samples_leaf=10, splitter=best; total time=   0.0s\n",
            "[CV] END criterion=log_loss, max_depth=3, max_features=6, min_samples_leaf=10, splitter=best; total time=   0.0s\n",
            "[CV] END criterion=log_loss, max_depth=3, max_features=6, min_samples_leaf=10, splitter=best; total time=   0.0s\n",
            "[CV] END criterion=gini, max_depth=6, max_features=11, min_samples_leaf=13, splitter=best; total time=   1.0s\n",
            "[CV] END criterion=gini, max_depth=6, max_features=11, min_samples_leaf=13, splitter=best; total time=   1.1s\n",
            "[CV] END criterion=gini, max_depth=6, max_features=11, min_samples_leaf=13, splitter=best; total time=   1.0s\n",
            "[CV] END criterion=gini, max_depth=2, max_features=5, min_samples_leaf=3, splitter=best; total time=   0.3s\n",
            "[CV] END criterion=gini, max_depth=2, max_features=5, min_samples_leaf=3, splitter=best; total time=   0.3s\n",
            "[CV] END criterion=gini, max_depth=2, max_features=5, min_samples_leaf=3, splitter=best; total time=   0.3s\n",
            "[CV] END criterion=gini, max_depth=None, max_features=2, min_samples_leaf=6, splitter=random; total time=   0.2s\n",
            "[CV] END criterion=gini, max_depth=None, max_features=2, min_samples_leaf=6, splitter=random; total time=   0.2s\n",
            "[CV] END criterion=gini, max_depth=None, max_features=2, min_samples_leaf=6, splitter=random; total time=   0.2s\n",
            "[CV] END criterion=gini, max_depth=4, max_features=9, min_samples_leaf=12, splitter=best; total time=   0.6s\n",
            "[CV] END criterion=gini, max_depth=4, max_features=9, min_samples_leaf=12, splitter=best; total time=   0.7s\n",
            "[CV] END criterion=gini, max_depth=4, max_features=9, min_samples_leaf=12, splitter=best; total time=   0.7s\n",
            "[CV] END criterion=gini, max_depth=None, max_features=1, min_samples_leaf=3, splitter=best; total time=   0.3s\n",
            "[CV] END criterion=gini, max_depth=None, max_features=1, min_samples_leaf=3, splitter=best; total time=   0.4s\n",
            "[CV] END criterion=gini, max_depth=None, max_features=1, min_samples_leaf=3, splitter=best; total time=   0.3s\n",
            "[CV] END criterion=entropy, max_depth=None, max_features=5, min_samples_leaf=3, splitter=random; total time=   0.3s\n",
            "[CV] END criterion=entropy, max_depth=None, max_features=5, min_samples_leaf=3, splitter=random; total time=   0.2s\n",
            "[CV] END criterion=entropy, max_depth=None, max_features=5, min_samples_leaf=3, splitter=random; total time=   0.3s\n",
            "[CV] END criterion=log_loss, max_depth=5, max_features=10, min_samples_leaf=4, splitter=best; total time=   0.0s\n",
            "[CV] END criterion=log_loss, max_depth=5, max_features=10, min_samples_leaf=4, splitter=best; total time=   0.0s\n",
            "[CV] END criterion=log_loss, max_depth=5, max_features=10, min_samples_leaf=4, splitter=best; total time=   0.0s\n",
            "[CV] END criterion=gini, max_depth=2, max_features=4, min_samples_leaf=14, splitter=random; total time=   0.1s\n",
            "[CV] END criterion=gini, max_depth=2, max_features=4, min_samples_leaf=14, splitter=random; total time=   0.1s\n",
            "[CV] END criterion=gini, max_depth=2, max_features=4, min_samples_leaf=14, splitter=random; total time=   0.1s\n",
            "[CV] END criterion=entropy, max_depth=5, max_features=14, min_samples_leaf=14, splitter=random; total time=   0.2s\n",
            "[CV] END criterion=entropy, max_depth=5, max_features=14, min_samples_leaf=14, splitter=random; total time=   0.2s\n",
            "[CV] END criterion=entropy, max_depth=5, max_features=14, min_samples_leaf=14, splitter=random; total time=   0.2s\n",
            "[CV] END criterion=gini, max_depth=None, max_features=6, min_samples_leaf=15, splitter=best; total time=   1.0s\n",
            "[CV] END criterion=gini, max_depth=None, max_features=6, min_samples_leaf=15, splitter=best; total time=   1.1s\n",
            "[CV] END criterion=gini, max_depth=None, max_features=6, min_samples_leaf=15, splitter=best; total time=   1.1s\n",
            "[CV] END criterion=log_loss, max_depth=6, max_features=12, min_samples_leaf=5, splitter=best; total time=   0.0s\n",
            "[CV] END criterion=log_loss, max_depth=6, max_features=12, min_samples_leaf=5, splitter=best; total time=   0.0s\n",
            "[CV] END criterion=log_loss, max_depth=6, max_features=12, min_samples_leaf=5, splitter=best; total time=   0.0s\n",
            "[CV] END criterion=entropy, max_depth=4, max_features=1, min_samples_leaf=13, splitter=best; total time=   0.2s\n",
            "[CV] END criterion=entropy, max_depth=4, max_features=1, min_samples_leaf=13, splitter=best; total time=   0.2s\n",
            "[CV] END criterion=entropy, max_depth=4, max_features=1, min_samples_leaf=13, splitter=best; total time=   0.7s\n",
            "[CV] END criterion=log_loss, max_depth=3, max_features=3, min_samples_leaf=14, splitter=random; total time=   0.2s\n",
            "[CV] END criterion=log_loss, max_depth=3, max_features=3, min_samples_leaf=14, splitter=random; total time=   0.1s\n",
            "[CV] END criterion=log_loss, max_depth=3, max_features=3, min_samples_leaf=14, splitter=random; total time=   0.1s\n",
            "[CV] END criterion=entropy, max_depth=6, max_features=7, min_samples_leaf=15, splitter=best; total time=   1.1s\n",
            "[CV] END criterion=entropy, max_depth=6, max_features=7, min_samples_leaf=15, splitter=best; total time=   0.9s\n",
            "[CV] END criterion=entropy, max_depth=6, max_features=7, min_samples_leaf=15, splitter=best; total time=   0.9s\n",
            "[CV] END criterion=log_loss, max_depth=3, max_features=12, min_samples_leaf=14, splitter=best; total time=   0.0s\n",
            "[CV] END criterion=log_loss, max_depth=3, max_features=12, min_samples_leaf=14, splitter=best; total time=   0.0s\n",
            "[CV] END criterion=log_loss, max_depth=3, max_features=12, min_samples_leaf=14, splitter=best; total time=   0.0s\n",
            "[CV] END criterion=log_loss, max_depth=None, max_features=15, min_samples_leaf=1, splitter=best; total time=   0.0s\n",
            "[CV] END criterion=log_loss, max_depth=None, max_features=15, min_samples_leaf=1, splitter=best; total time=   0.1s\n",
            "[CV] END criterion=log_loss, max_depth=None, max_features=15, min_samples_leaf=1, splitter=best; total time=   0.0s\n",
            "[CV] END criterion=entropy, max_depth=2, max_features=14, min_samples_leaf=12, splitter=random; total time=   0.1s\n",
            "[CV] END criterion=entropy, max_depth=2, max_features=14, min_samples_leaf=12, splitter=random; total time=   0.2s\n",
            "[CV] END criterion=entropy, max_depth=2, max_features=14, min_samples_leaf=12, splitter=random; total time=   0.1s\n",
            "[CV] END criterion=gini, max_depth=2, max_features=1, min_samples_leaf=11, splitter=best; total time=   0.2s\n",
            "[CV] END criterion=gini, max_depth=2, max_features=1, min_samples_leaf=11, splitter=best; total time=   0.2s\n",
            "[CV] END criterion=gini, max_depth=2, max_features=1, min_samples_leaf=11, splitter=best; total time=   0.2s\n",
            "[CV] END criterion=gini, max_depth=2, max_features=12, min_samples_leaf=6, splitter=best; total time=   0.5s\n",
            "[CV] END criterion=gini, max_depth=2, max_features=12, min_samples_leaf=6, splitter=best; total time=   0.5s\n",
            "[CV] END criterion=gini, max_depth=2, max_features=12, min_samples_leaf=6, splitter=best; total time=   0.5s\n",
            "[CV] END criterion=entropy, max_depth=4, max_features=14, min_samples_leaf=6, splitter=best; total time=   1.2s\n",
            "[CV] END criterion=entropy, max_depth=4, max_features=14, min_samples_leaf=6, splitter=best; total time=   1.2s\n",
            "[CV] END criterion=entropy, max_depth=4, max_features=14, min_samples_leaf=6, splitter=best; total time=   1.2s\n",
            "[CV] END criterion=log_loss, max_depth=4, max_features=7, min_samples_leaf=14, splitter=random; total time=   0.0s\n",
            "[CV] END criterion=log_loss, max_depth=4, max_features=7, min_samples_leaf=14, splitter=random; total time=   0.0s\n",
            "[CV] END criterion=log_loss, max_depth=4, max_features=7, min_samples_leaf=14, splitter=random; total time=   0.0s\n",
            "[CV] END criterion=gini, max_depth=5, max_features=1, min_samples_leaf=10, splitter=best; total time=   0.2s\n",
            "[CV] END criterion=gini, max_depth=5, max_features=1, min_samples_leaf=10, splitter=best; total time=   0.2s\n",
            "[CV] END criterion=gini, max_depth=5, max_features=1, min_samples_leaf=10, splitter=best; total time=   0.2s\n",
            "[CV] END criterion=entropy, max_depth=3, max_features=8, min_samples_leaf=10, splitter=random; total time=   0.1s\n",
            "[CV] END criterion=entropy, max_depth=3, max_features=8, min_samples_leaf=10, splitter=random; total time=   0.2s\n",
            "[CV] END criterion=entropy, max_depth=3, max_features=8, min_samples_leaf=10, splitter=random; total time=   0.1s\n",
            "[CV] END criterion=log_loss, max_depth=3, max_features=2, min_samples_leaf=14, splitter=random; total time=   0.0s\n",
            "[CV] END criterion=log_loss, max_depth=3, max_features=2, min_samples_leaf=14, splitter=random; total time=   0.1s\n",
            "[CV] END criterion=log_loss, max_depth=3, max_features=2, min_samples_leaf=14, splitter=random; total time=   0.0s\n",
            "[CV] END criterion=log_loss, max_depth=4, max_features=14, min_samples_leaf=11, splitter=random; total time=   0.0s\n",
            "[CV] END criterion=log_loss, max_depth=4, max_features=14, min_samples_leaf=11, splitter=random; total time=   0.0s\n",
            "[CV] END criterion=log_loss, max_depth=4, max_features=14, min_samples_leaf=11, splitter=random; total time=   0.0s\n",
            "[CV] END criterion=log_loss, max_depth=2, max_features=4, min_samples_leaf=8, splitter=best; total time=   0.0s\n",
            "[CV] END criterion=log_loss, max_depth=2, max_features=4, min_samples_leaf=8, splitter=best; total time=   0.0s\n",
            "[CV] END criterion=log_loss, max_depth=2, max_features=4, min_samples_leaf=8, splitter=best; total time=   0.0s\n",
            "[CV] END criterion=entropy, max_depth=6, max_features=12, min_samples_leaf=5, splitter=random; total time=   0.2s\n",
            "[CV] END criterion=entropy, max_depth=6, max_features=12, min_samples_leaf=5, splitter=random; total time=   0.3s\n",
            "[CV] END criterion=entropy, max_depth=6, max_features=12, min_samples_leaf=5, splitter=random; total time=   0.2s\n",
            "[CV] END criterion=entropy, max_depth=3, max_features=10, min_samples_leaf=11, splitter=random; total time=   0.2s\n",
            "[CV] END criterion=entropy, max_depth=3, max_features=10, min_samples_leaf=11, splitter=random; total time=   0.2s\n",
            "[CV] END criterion=entropy, max_depth=3, max_features=10, min_samples_leaf=11, splitter=random; total time=   0.1s\n",
            "[CV] END criterion=log_loss, max_depth=4, max_features=1, min_samples_leaf=11, splitter=random; total time=   0.0s\n",
            "[CV] END criterion=log_loss, max_depth=4, max_features=1, min_samples_leaf=11, splitter=random; total time=   0.0s\n",
            "[CV] END criterion=log_loss, max_depth=4, max_features=1, min_samples_leaf=11, splitter=random; total time=   0.0s\n",
            "[CV] END criterion=log_loss, max_depth=5, max_features=1, min_samples_leaf=15, splitter=best; total time=   0.0s\n",
            "[CV] END criterion=log_loss, max_depth=5, max_features=1, min_samples_leaf=15, splitter=best; total time=   0.0s\n",
            "[CV] END criterion=log_loss, max_depth=5, max_features=1, min_samples_leaf=15, splitter=best; total time=   0.0s\n",
            "[CV] END criterion=entropy, max_depth=None, max_features=12, min_samples_leaf=11, splitter=random; total time=   0.4s\n",
            "[CV] END criterion=entropy, max_depth=None, max_features=12, min_samples_leaf=11, splitter=random; total time=   0.4s\n",
            "[CV] END criterion=entropy, max_depth=None, max_features=12, min_samples_leaf=11, splitter=random; total time=   0.4s\n",
            "[CV] END criterion=entropy, max_depth=6, max_features=5, min_samples_leaf=5, splitter=best; total time=   0.8s\n",
            "[CV] END criterion=entropy, max_depth=6, max_features=5, min_samples_leaf=5, splitter=best; total time=   0.8s\n",
            "[CV] END criterion=entropy, max_depth=6, max_features=5, min_samples_leaf=5, splitter=best; total time=   0.8s\n",
            "[CV] END criterion=log_loss, max_depth=2, max_features=14, min_samples_leaf=12, splitter=best; total time=   0.0s\n",
            "[CV] END criterion=log_loss, max_depth=2, max_features=14, min_samples_leaf=12, splitter=best; total time=   0.0s\n",
            "[CV] END criterion=log_loss, max_depth=2, max_features=14, min_samples_leaf=12, splitter=best; total time=   0.0s\n",
            "[CV] END criterion=entropy, max_depth=3, max_features=6, min_samples_leaf=9, splitter=best; total time=   0.5s\n",
            "[CV] END criterion=entropy, max_depth=3, max_features=6, min_samples_leaf=9, splitter=best; total time=   1.2s\n",
            "[CV] END criterion=entropy, max_depth=3, max_features=6, min_samples_leaf=9, splitter=best; total time=   0.7s\n",
            "[CV] END criterion=log_loss, max_depth=6, max_features=5, min_samples_leaf=13, splitter=best; total time=   0.2s\n",
            "[CV] END criterion=log_loss, max_depth=6, max_features=5, min_samples_leaf=13, splitter=best; total time=   0.2s\n",
            "[CV] END criterion=log_loss, max_depth=6, max_features=5, min_samples_leaf=13, splitter=best; total time=   0.2s\n",
            "[CV] END criterion=log_loss, max_depth=3, max_features=8, min_samples_leaf=13, splitter=best; total time=   0.2s\n",
            "[CV] END criterion=log_loss, max_depth=3, max_features=8, min_samples_leaf=13, splitter=best; total time=   0.2s\n",
            "[CV] END criterion=log_loss, max_depth=3, max_features=8, min_samples_leaf=13, splitter=best; total time=   0.1s\n",
            "[CV] END criterion=entropy, max_depth=6, max_features=14, min_samples_leaf=3, splitter=random; total time=   0.3s\n",
            "[CV] END criterion=entropy, max_depth=6, max_features=14, min_samples_leaf=3, splitter=random; total time=   0.3s\n",
            "[CV] END criterion=entropy, max_depth=6, max_features=14, min_samples_leaf=3, splitter=random; total time=   0.3s\n",
            "[CV] END criterion=log_loss, max_depth=3, max_features=2, min_samples_leaf=2, splitter=random; total time=   0.0s\n",
            "[CV] END criterion=log_loss, max_depth=3, max_features=2, min_samples_leaf=2, splitter=random; total time=   0.0s\n",
            "[CV] END criterion=log_loss, max_depth=3, max_features=2, min_samples_leaf=2, splitter=random; total time=   0.1s\n",
            "[CV] END criterion=log_loss, max_depth=3, max_features=2, min_samples_leaf=11, splitter=random; total time=   0.2s\n",
            "[CV] END criterion=log_loss, max_depth=3, max_features=2, min_samples_leaf=11, splitter=random; total time=   0.2s\n",
            "[CV] END criterion=log_loss, max_depth=3, max_features=2, min_samples_leaf=11, splitter=random; total time=   0.1s\n",
            "[CV] END criterion=log_loss, max_depth=4, max_features=10, min_samples_leaf=7, splitter=best; total time=   0.1s\n",
            "[CV] END criterion=log_loss, max_depth=4, max_features=10, min_samples_leaf=7, splitter=best; total time=   0.1s\n",
            "[CV] END criterion=log_loss, max_depth=4, max_features=10, min_samples_leaf=7, splitter=best; total time=   0.0s\n",
            "[CV] END criterion=log_loss, max_depth=5, max_features=4, min_samples_leaf=5, splitter=random; total time=   0.0s\n",
            "[CV] END criterion=log_loss, max_depth=5, max_features=4, min_samples_leaf=5, splitter=random; total time=   0.0s\n",
            "[CV] END criterion=log_loss, max_depth=5, max_features=4, min_samples_leaf=5, splitter=random; total time=   0.0s\n",
            "[CV] END criterion=log_loss, max_depth=None, max_features=4, min_samples_leaf=7, splitter=best; total time=   0.0s\n",
            "[CV] END criterion=log_loss, max_depth=None, max_features=4, min_samples_leaf=7, splitter=best; total time=   0.0s\n",
            "[CV] END criterion=log_loss, max_depth=None, max_features=4, min_samples_leaf=7, splitter=best; total time=   0.0s\n",
            "[CV] END criterion=gini, max_depth=4, max_features=7, min_samples_leaf=1, splitter=random; total time=   0.2s\n",
            "[CV] END criterion=gini, max_depth=4, max_features=7, min_samples_leaf=1, splitter=random; total time=   0.1s\n",
            "[CV] END criterion=gini, max_depth=4, max_features=7, min_samples_leaf=1, splitter=random; total time=   0.1s\n",
            "[CV] END criterion=entropy, max_depth=None, max_features=7, min_samples_leaf=15, splitter=random; total time=   0.3s\n",
            "[CV] END criterion=entropy, max_depth=None, max_features=7, min_samples_leaf=15, splitter=random; total time=   0.3s\n",
            "[CV] END criterion=entropy, max_depth=None, max_features=7, min_samples_leaf=15, splitter=random; total time=   0.3s\n",
            "[CV] END criterion=entropy, max_depth=5, max_features=9, min_samples_leaf=7, splitter=random; total time=   0.2s\n",
            "[CV] END criterion=entropy, max_depth=5, max_features=9, min_samples_leaf=7, splitter=random; total time=   0.2s\n",
            "[CV] END criterion=entropy, max_depth=5, max_features=9, min_samples_leaf=7, splitter=random; total time=   0.2s\n",
            "[CV] END criterion=entropy, max_depth=3, max_features=5, min_samples_leaf=4, splitter=random; total time=   0.1s\n",
            "[CV] END criterion=entropy, max_depth=3, max_features=5, min_samples_leaf=4, splitter=random; total time=   0.1s\n",
            "[CV] END criterion=entropy, max_depth=3, max_features=5, min_samples_leaf=4, splitter=random; total time=   0.1s\n",
            "[CV] END criterion=log_loss, max_depth=2, max_features=11, min_samples_leaf=13, splitter=best; total time=   0.0s\n",
            "[CV] END criterion=log_loss, max_depth=2, max_features=11, min_samples_leaf=13, splitter=best; total time=   0.0s\n",
            "[CV] END criterion=log_loss, max_depth=2, max_features=11, min_samples_leaf=13, splitter=best; total time=   0.0s\n",
            "[CV] END criterion=entropy, max_depth=3, max_features=11, min_samples_leaf=13, splitter=best; total time=   0.7s\n",
            "[CV] END criterion=entropy, max_depth=3, max_features=11, min_samples_leaf=13, splitter=best; total time=   0.7s\n",
            "[CV] END criterion=entropy, max_depth=3, max_features=11, min_samples_leaf=13, splitter=best; total time=   0.7s\n",
            "[CV] END criterion=entropy, max_depth=2, max_features=5, min_samples_leaf=14, splitter=random; total time=   0.1s\n",
            "[CV] END criterion=entropy, max_depth=2, max_features=5, min_samples_leaf=14, splitter=random; total time=   0.1s\n",
            "[CV] END criterion=entropy, max_depth=2, max_features=5, min_samples_leaf=14, splitter=random; total time=   0.1s\n",
            "[CV] END criterion=gini, max_depth=4, max_features=8, min_samples_leaf=12, splitter=random; total time=   0.2s\n",
            "[CV] END criterion=gini, max_depth=4, max_features=8, min_samples_leaf=12, splitter=random; total time=   0.2s\n",
            "[CV] END criterion=gini, max_depth=4, max_features=8, min_samples_leaf=12, splitter=random; total time=   0.2s\n",
            "[CV] END criterion=gini, max_depth=None, max_features=12, min_samples_leaf=6, splitter=best; total time=   2.3s\n",
            "[CV] END criterion=gini, max_depth=None, max_features=12, min_samples_leaf=6, splitter=best; total time=   2.1s\n",
            "[CV] END criterion=gini, max_depth=None, max_features=12, min_samples_leaf=6, splitter=best; total time=   2.2s\n",
            "[CV] END criterion=log_loss, max_depth=5, max_features=15, min_samples_leaf=5, splitter=best; total time=   0.1s\n",
            "[CV] END criterion=log_loss, max_depth=5, max_features=15, min_samples_leaf=5, splitter=best; total time=   0.0s\n",
            "[CV] END criterion=log_loss, max_depth=5, max_features=15, min_samples_leaf=5, splitter=best; total time=   0.0s\n",
            "[CV] END criterion=log_loss, max_depth=4, max_features=6, min_samples_leaf=15, splitter=best; total time=   0.0s\n",
            "[CV] END criterion=log_loss, max_depth=4, max_features=6, min_samples_leaf=15, splitter=best; total time=   0.0s\n",
            "[CV] END criterion=log_loss, max_depth=4, max_features=6, min_samples_leaf=15, splitter=best; total time=   0.0s\n",
            "[CV] END criterion=log_loss, max_depth=4, max_features=3, min_samples_leaf=7, splitter=best; total time=   0.0s\n",
            "[CV] END criterion=log_loss, max_depth=4, max_features=3, min_samples_leaf=7, splitter=best; total time=   0.0s\n",
            "[CV] END criterion=log_loss, max_depth=4, max_features=3, min_samples_leaf=7, splitter=best; total time=   0.0s\n",
            "[CV] END criterion=entropy, max_depth=5, max_features=13, min_samples_leaf=6, splitter=best; total time=   1.3s\n",
            "[CV] END criterion=entropy, max_depth=5, max_features=13, min_samples_leaf=6, splitter=best; total time=   1.3s\n",
            "[CV] END criterion=entropy, max_depth=5, max_features=13, min_samples_leaf=6, splitter=best; total time=   1.4s\n",
            "[CV] END criterion=gini, max_depth=None, max_features=14, min_samples_leaf=4, splitter=best; total time=   2.7s\n",
            "[CV] END criterion=gini, max_depth=None, max_features=14, min_samples_leaf=4, splitter=best; total time=   2.6s\n",
            "[CV] END criterion=gini, max_depth=None, max_features=14, min_samples_leaf=4, splitter=best; total time=   2.7s\n",
            "[CV] END criterion=log_loss, max_depth=6, max_features=1, min_samples_leaf=13, splitter=best; total time=   0.0s\n",
            "[CV] END criterion=log_loss, max_depth=6, max_features=1, min_samples_leaf=13, splitter=best; total time=   0.0s\n",
            "[CV] END criterion=log_loss, max_depth=6, max_features=1, min_samples_leaf=13, splitter=best; total time=   0.0s\n",
            "[CV] END criterion=entropy, max_depth=5, max_features=10, min_samples_leaf=9, splitter=best; total time=   1.1s\n",
            "[CV] END criterion=entropy, max_depth=5, max_features=10, min_samples_leaf=9, splitter=best; total time=   1.1s\n",
            "[CV] END criterion=entropy, max_depth=5, max_features=10, min_samples_leaf=9, splitter=best; total time=   1.1s\n",
            "[CV] END criterion=entropy, max_depth=6, max_features=6, min_samples_leaf=15, splitter=random; total time=   0.2s\n",
            "[CV] END criterion=entropy, max_depth=6, max_features=6, min_samples_leaf=15, splitter=random; total time=   0.2s\n",
            "[CV] END criterion=entropy, max_depth=6, max_features=6, min_samples_leaf=15, splitter=random; total time=   0.2s\n",
            "[CV] END criterion=entropy, max_depth=None, max_features=2, min_samples_leaf=1, splitter=random; total time=   0.2s\n",
            "[CV] END criterion=entropy, max_depth=None, max_features=2, min_samples_leaf=1, splitter=random; total time=   0.2s\n",
            "[CV] END criterion=entropy, max_depth=None, max_features=2, min_samples_leaf=1, splitter=random; total time=   0.2s\n",
            "[CV] END criterion=gini, max_depth=5, max_features=6, min_samples_leaf=12, splitter=best; total time=   0.6s\n",
            "[CV] END criterion=gini, max_depth=5, max_features=6, min_samples_leaf=12, splitter=best; total time=   0.6s\n",
            "[CV] END criterion=gini, max_depth=5, max_features=6, min_samples_leaf=12, splitter=best; total time=   0.6s\n",
            "[CV] END criterion=gini, max_depth=6, max_features=10, min_samples_leaf=3, splitter=best; total time=   1.0s\n",
            "[CV] END criterion=gini, max_depth=6, max_features=10, min_samples_leaf=3, splitter=best; total time=   1.0s\n",
            "[CV] END criterion=gini, max_depth=6, max_features=10, min_samples_leaf=3, splitter=best; total time=   1.0s\n",
            "[CV] END criterion=gini, max_depth=4, max_features=7, min_samples_leaf=6, splitter=random; total time=   0.1s\n",
            "[CV] END criterion=gini, max_depth=4, max_features=7, min_samples_leaf=6, splitter=random; total time=   0.2s\n",
            "[CV] END criterion=gini, max_depth=4, max_features=7, min_samples_leaf=6, splitter=random; total time=   0.1s\n",
            "[CV] END criterion=gini, max_depth=6, max_features=12, min_samples_leaf=9, splitter=best; total time=   1.1s\n",
            "[CV] END criterion=gini, max_depth=6, max_features=12, min_samples_leaf=9, splitter=best; total time=   1.1s\n",
            "[CV] END criterion=gini, max_depth=6, max_features=12, min_samples_leaf=9, splitter=best; total time=   1.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/model_selection/_validation.py:372: FitFailedWarning: \n",
            "111 fits failed out of a total of 300.\n",
            "The score on these train-test partitions for these parameters will be set to nan.\n",
            "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
            "\n",
            "Below are more details about the failures:\n",
            "--------------------------------------------------------------------------------\n",
            "105 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/sklearn/tree/_classes.py\", line 937, in fit\n",
            "    super().fit(\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/sklearn/tree/_classes.py\", line 352, in fit\n",
            "    criterion = CRITERIA_CLF[self.criterion](\n",
            "KeyError: 'log_loss'\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "6 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/sklearn/tree/_classes.py\", line 937, in fit\n",
            "    super().fit(\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/sklearn/tree/_classes.py\", line 308, in fit\n",
            "    raise ValueError(\"max_features must be in (0, n_features]\")\n",
            "ValueError: max_features must be in (0, n_features]\n",
            "\n",
            "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/model_selection/_search.py:969: UserWarning: One or more of the test scores are non-finite: [       nan 0.88759434        nan 0.90655121 0.5308576  0.86865285\n",
            "        nan 0.76641475 0.98408555        nan 0.83595884 0.90023976\n",
            " 0.89020432 0.8830863         nan 0.99107882 0.78224861 0.76586497\n",
            " 0.93886401 0.9639268  0.92087497 0.99615884 0.96531947        nan\n",
            " 0.76586497        nan 0.77340063 0.76297686        nan        nan\n",
            " 0.99710446        nan        nan        nan 0.86132961        nan\n",
            " 0.94035207 0.76586497 0.97540629 0.9556067  0.98018569 0.99524986\n",
            "        nan 0.77977818 0.8578693  0.99167991        nan 0.69574905\n",
            "        nan 0.95451435        nan        nan 0.88045479 0.47809292\n",
            " 0.85928441 0.94834955        nan 0.79311913 0.71056379        nan\n",
            "        nan        nan 0.87434852 0.75634274        nan        nan\n",
            " 0.99347588 0.93036845        nan 0.74412281        nan        nan\n",
            " 0.92504587        nan        nan        nan        nan        nan\n",
            " 0.78107568 0.98970069 0.88412745 0.83595884        nan 0.83626675\n",
            " 0.38583167 0.79311964 0.99454613        nan        nan        nan\n",
            " 0.94917792 0.99518388        nan 0.9507613  0.8338406  0.99743434\n",
            " 0.91963614 0.95904468 0.78107568 0.95735133]\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'splitter': 'random',\n",
              " 'min_samples_leaf': 1,\n",
              " 'max_features': 2,\n",
              " 'max_depth': None,\n",
              " 'criterion': 'entropy'}"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tree_random.best_params_"
      ],
      "metadata": {
        "id": "PdUJI6Wmba8H",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "73a25ced-9706-4b5b-c3fb-1d88b66e190b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'splitter': 'random',\n",
              " 'min_samples_leaf': 1,\n",
              " 'max_features': 2,\n",
              " 'max_depth': None,\n",
              " 'criterion': 'entropy'}"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tree_random.best_score_"
      ],
      "metadata": {
        "id": "fwLfoUltPYnO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Random Forest Classifier\n",
        "\n",
        "- Library: Scikit-learn"
      ],
      "metadata": {
        "id": "e5dbRikwt1ov"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Training\n",
        "\n",
        "name = 'rnd_clf'\n",
        "\n",
        "train = pd.DataFrame(columns = ['n_estimators', 'min_samples_split', 'min_samples_leaf', 'max_features','max_depth', 'n_jobs', 'random_state'])\n",
        "train = train.append({'n_estimators' : 100, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'auto', 'max_depth' : None, 'n_jobs': -1, 'random_state': 10}, ignore_index=True)\n",
        "train = train.append({'n_estimators' : 300, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_features': 'auto', 'max_depth' : 31, 'n_jobs': -1, 'random_state': 10}, ignore_index=True)\n",
        "train = train.append({'n_estimators' : 300, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_features': 'auto', 'max_depth' : None, 'n_jobs': -1, 'random_state': 10}, ignore_index=True)\n",
        "\n",
        "train = train.reset_index()\n",
        "for index, row in train.iterrows():\n",
        "    model_name = name + str(index)\n",
        "    rnd_clf = RandomForestClassifier(n_estimators = int(row['n_estimators']), max_depth = None, \n",
        "                                    n_jobs = int(row['n_jobs']), random_state = int(row['random_state']))\n",
        "    rnd_clf.fit(X_train, y_train)\n",
        "    \n",
        "    y_true = y_val\n",
        "    y_pred = rnd_clf.predict(X_val)\n",
        "    evaluation_results = evaluation_metrics(y_true, y_pred)\n",
        "\n",
        "    models = models.append({'model_name': model_name, \n",
        "                            'model': rnd_clf, \n",
        "                            'parameters': rnd_clf.get_params()}, \n",
        "                            ignore_index=True)\n",
        "    \n",
        "    models_eval = models_eval.append({'model_name': model_name, \n",
        "                                      'confusion_matrix' : evaluation_results[0], \n",
        "                                      'accuracy': evaluation_results[1], \n",
        "                                      'recall' : evaluation_results[2], \n",
        "                                      'f1_score': evaluation_results[3], \n",
        "                                      'roc_auc_score': evaluation_results[4]}, \n",
        "                                      ignore_index=True)"
      ],
      "metadata": {
        "id": "_n_M-g9kZTyK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "display(models_eval)"
      ],
      "metadata": {
        "id": "jo4WWeMIe3G6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        },
        "outputId": "4cf82c1f-c307-468d-8771-8923a33bc28c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  model_name      confusion_matrix  accuracy    recall  f1_score  \\\n",
              "0  tree_clf0  [17023, 45, 11, 111]  0.996742  0.909836  0.798561   \n",
              "1  tree_clf1   [17016, 52, 7, 115]  0.996568  0.942623  0.795848   \n",
              "2  tree_clf2  [17003, 65, 13, 109]  0.995462  0.893443  0.736486   \n",
              "3  tree_clf3   [17010, 58, 8, 114]  0.996161  0.934426  0.775510   \n",
              "4   rnd_clf0   [17047, 21, 9, 113]  0.998255  0.926230  0.882812   \n",
              "5   rnd_clf1   [17045, 23, 8, 114]  0.998197  0.934426  0.880309   \n",
              "6   rnd_clf2   [17045, 23, 8, 114]  0.998197  0.934426  0.880309   \n",
              "\n",
              "   roc_auc_score  \n",
              "0       0.953600  \n",
              "1       0.969788  \n",
              "2       0.944817  \n",
              "3       0.965514  \n",
              "4       0.962500  \n",
              "5       0.966539  \n",
              "6       0.966539  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-ef9ea07e-2103-476f-93e9-2085a02b3099\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>model_name</th>\n",
              "      <th>confusion_matrix</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>recall</th>\n",
              "      <th>f1_score</th>\n",
              "      <th>roc_auc_score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>tree_clf0</td>\n",
              "      <td>[17023, 45, 11, 111]</td>\n",
              "      <td>0.996742</td>\n",
              "      <td>0.909836</td>\n",
              "      <td>0.798561</td>\n",
              "      <td>0.953600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>tree_clf1</td>\n",
              "      <td>[17016, 52, 7, 115]</td>\n",
              "      <td>0.996568</td>\n",
              "      <td>0.942623</td>\n",
              "      <td>0.795848</td>\n",
              "      <td>0.969788</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>tree_clf2</td>\n",
              "      <td>[17003, 65, 13, 109]</td>\n",
              "      <td>0.995462</td>\n",
              "      <td>0.893443</td>\n",
              "      <td>0.736486</td>\n",
              "      <td>0.944817</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>tree_clf3</td>\n",
              "      <td>[17010, 58, 8, 114]</td>\n",
              "      <td>0.996161</td>\n",
              "      <td>0.934426</td>\n",
              "      <td>0.775510</td>\n",
              "      <td>0.965514</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>rnd_clf0</td>\n",
              "      <td>[17047, 21, 9, 113]</td>\n",
              "      <td>0.998255</td>\n",
              "      <td>0.926230</td>\n",
              "      <td>0.882812</td>\n",
              "      <td>0.962500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>rnd_clf1</td>\n",
              "      <td>[17045, 23, 8, 114]</td>\n",
              "      <td>0.998197</td>\n",
              "      <td>0.934426</td>\n",
              "      <td>0.880309</td>\n",
              "      <td>0.966539</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>rnd_clf2</td>\n",
              "      <td>[17045, 23, 8, 114]</td>\n",
              "      <td>0.998197</td>\n",
              "      <td>0.934426</td>\n",
              "      <td>0.880309</td>\n",
              "      <td>0.966539</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ef9ea07e-2103-476f-93e9-2085a02b3099')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-ef9ea07e-2103-476f-93e9-2085a02b3099 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-ef9ea07e-2103-476f-93e9-2085a02b3099');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "[ tn , fp , fn , tp ]"
      ],
      "metadata": {
        "id": "Naz8KZG_esG7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# RandomizedSearchCV\n",
        "\n",
        "# Number of trees in random forest\n",
        "n_estimators = [int(x) for x in np.linspace(start = 300, stop = 500, num = 20)]\n",
        "# Number of features to consider at every split\n",
        "max_features = [int(x) for x in np.linspace(1, len(df.columns), num = len(df.columns))]\n",
        "# Maximum number of levels in tree\n",
        "max_depth = [int(x) for x in np.linspace(15, 35, num = 7)]\n",
        "max_depth.append(None)\n",
        "# Minimum number of samples required to split a node\n",
        "min_samples_split = [2, 3, 4, 5, 6]\n",
        "# Minimum number of samples required at each leaf node\n",
        "min_samples_leaf = [1, 2, 4]\n",
        "\n",
        "# Create the random grid\n",
        "random_grid = {\n",
        "               'n_estimators': n_estimators,\n",
        "               'max_features': max_features,\n",
        "               'max_depth': max_depth,\n",
        "               'min_samples_split': min_samples_split,\n",
        "               'min_samples_leaf': min_samples_leaf,\n",
        "              }\n",
        "\n",
        "rnd_random = RandomizedSearchCV(estimator = rnd_clf, \n",
        "                                param_distributions = random_grid, \n",
        "                                n_iter = 50, \n",
        "                                cv = 3, \n",
        "                                verbose=2, \n",
        "                                scoring='recall',\n",
        "                                random_state=10)\n",
        "\n",
        "rnd_random.fit(X_train, y_train)\n",
        "rnd_random.best_params_"
      ],
      "metadata": {
        "id": "dgYq_K9tOh9o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rnd_random.best_params_"
      ],
      "metadata": {
        "id": "dIcZeJETrMKG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rnd_random.best_score_"
      ],
      "metadata": {
        "id": "ucgtEE38Pfzr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Gradient Boosting Classifier\n",
        "\n",
        "- Library: Scikit-learn"
      ],
      "metadata": {
        "id": "-0VzXIIcuTah"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Training\n",
        "\n",
        "name = 'gboost_clf'\n",
        "\n",
        "train = pd.DataFrame(columns = ['n_estimators', 'learning_rate', 'max_depth', 'random_state'])\n",
        "train = train.append({'n_estimators': 100, 'learning_rate':0.1, 'max_depth':3, 'random_state':10}, ignore_index=True)\n",
        "train = train.append({'n_estimators': 500, 'learning_rate':0.5, 'max_depth':1, 'random_state':10}, ignore_index=True)\n",
        "train = train.append({'n_estimators': 50, 'learning_rate':0.01, 'max_depth':10, 'random_state':10}, ignore_index=True)\n",
        "\n",
        "train = train.reset_index()\n",
        "for index, row in train.iterrows():\n",
        "    model_name = name + str(index)\n",
        "    gboost_clf = GradientBoostingClassifier(n_estimators=int(row['n_estimators']), learning_rate=row['learning_rate'],\n",
        "                                            max_depth=int(row['max_depth']), random_state=int(row['random_state']))\n",
        "    gboost_clf.fit(X_train, y_train)\n",
        "   \n",
        "    y_true = y_val\n",
        "    y_pred = gboost_clf.predict(X_val)\n",
        "    evaluation_results = evaluation_metrics(y_true, y_pred)\n",
        "\n",
        "    models = models.append({'model_name': model_name, \n",
        "                            'model': gboost_clf, \n",
        "                            'parameters': gboost_clf.get_params()}, \n",
        "                            ignore_index=True)\n",
        "   \n",
        "    models_eval = models_eval.append({'model_name': model_name, \n",
        "                                      'confusion_matrix' : evaluation_results[0], \n",
        "                                      'accuracy': evaluation_results[1], \n",
        "                                      'recall' : evaluation_results[2], \n",
        "                                      'f1_score': evaluation_results[3], \n",
        "                                      'roc_auc_score': evaluation_results[4]}, \n",
        "                                      ignore_index=True)"
      ],
      "metadata": {
        "id": "kORFOSQnhgIy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "display(models_eval)"
      ],
      "metadata": {
        "id": "Yg8lIErGhhMF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# RandomizedSearchCV\n",
        "\n",
        "random_grid = {\n",
        "              \"n_estimators\": [100, 500, 750, 1000, 2000],\n",
        "              \"learning_rate\": [0.01, 0.05, 0.10, 0.15, 0.20, 0.25, 0.30, 0.50],\n",
        "              \"max_depth\": [1, 3, 5, 8, 10, 15]\n",
        "              }\n",
        "\n",
        "gboost_random = RandomizedSearchCV(estimator = gboost_clf, \n",
        "                                 param_distributions = random_grid, \n",
        "                                 n_iter = 70, \n",
        "                                 cv = 3, \n",
        "                                 verbose=2, \n",
        "                                 scoring='recall',\n",
        "                                 random_state=10)\n",
        "\n",
        "gboost_random.fit(X_train, y_train)\n",
        "gboost_random.best_params_"
      ],
      "metadata": {
        "id": "1FhLDX1nN6bT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gboost_random.best_params_"
      ],
      "metadata": {
        "id": "K7cjmSC7rOLM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gboost_random.best_score_"
      ],
      "metadata": {
        "id": "QhgTUxPnPiyZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## XGBoost\n",
        "\n",
        "- Library: xgboost"
      ],
      "metadata": {
        "id": "J3M3ob9buTHm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Training\n",
        "\n",
        "name = 'xgboost_clf'\n",
        "\n",
        "train = pd.DataFrame(columns = ['n_estimators', 'learning_rate', 'max_depth', 'random_state'])\n",
        "train = train.append({'n_estimators': 1000, 'learning_rate':0.0001, 'max_depth':3, 'random_state':10}, ignore_index=True)\n",
        "train = train.append({'n_estimators': 500, 'learning_rate':0.5, 'max_depth':1, 'random_state':10}, ignore_index=True)\n",
        "train = train.append({'n_estimators': 750, 'learning_rate':0.01, 'max_depth':10, 'random_state':10}, ignore_index=True)\n",
        "\n",
        "train = train.reset_index()\n",
        "for index, row in train.iterrows():\n",
        "    model_name = name + str(index)\n",
        "    xgboost_clf = XGBClassifier(n_estimators=int(row['n_estimators']), learning_rate=row['learning_rate'],\n",
        "                                max_depth=int(row['max_depth']), random_state=int(row['random_state']))\n",
        "    xgboost_clf.fit(X_train, y_train)\n",
        "    \n",
        "    y_true = y_val\n",
        "    y_pred = xgboost_clf.predict(X_val)\n",
        "    evaluation_results = evaluation_metrics(y_true, y_pred)\n",
        "\n",
        "    models = models.append({'model_name': model_name, \n",
        "                            'model': xgboost_clf, \n",
        "                            'parameters': xgboost_clf.get_params()}, \n",
        "                            ignore_index=True)\n",
        "    \n",
        "    models_eval = models_eval.append({'model_name': model_name, \n",
        "                                      'confusion_matrix' : evaluation_results[0], \n",
        "                                      'accuracy': evaluation_results[1], \n",
        "                                      'recall' : evaluation_results[2], \n",
        "                                      'f1_score': evaluation_results[3], \n",
        "                                      'roc_auc_score': evaluation_results[4]}, \n",
        "                                      ignore_index=True)"
      ],
      "metadata": {
        "id": "evYZbB-MZVmF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "display(models_eval)"
      ],
      "metadata": {
        "id": "PSc4LKMTq3qd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# RandomizedSearchCV\n",
        "\n",
        "random_grid = {\n",
        "              \"n_estimators\": [100, 500, 750, 1000, 2000],\n",
        "              \"learning_rate\": [0.01, 0.05, 0.10, 0.15, 0.20, 0.25, 0.30, 0.50],\n",
        "              \"max_depth\": [1, 3, 5, 8, 10, 15],\n",
        "              \"min_child_weight\" : [1, 3, 5, 7]\n",
        "              }\n",
        "\n",
        "xgboost_random = RandomizedSearchCV(estimator = xgboost_clf, \n",
        "                                 param_distributions = random_grid, \n",
        "                                 n_iter = 70, \n",
        "                                 cv = 3, \n",
        "                                 verbose=2, \n",
        "                                 scoring='recall',\n",
        "                                 random_state=10)\n",
        "\n",
        "xgboost_random.fit(X_train, y_train)\n",
        "xgboost_random.best_params_"
      ],
      "metadata": {
        "id": "DJEXkDKKPtx_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "xgboost_random.best_params_"
      ],
      "metadata": {
        "id": "YgegJlH_Pm86"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "xgboost_random.best_score_"
      ],
      "metadata": {
        "id": "Z1hMgf8SnLmG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## LightGBM\n",
        "\n",
        "- Library: lightbgm"
      ],
      "metadata": {
        "id": "p3iAdzksueOk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Training\n",
        "\n",
        "name = 'lightgbm_clf'\n",
        "\n",
        "train = pd.DataFrame(columns = ['n_estimators', 'learning_rate', 'max_depth', 'random_state'])\n",
        "train = train.append({'n_estimators': 1000, 'learning_rate':0.1, 'max_depth':3, 'random_state':10}, ignore_index=True)\n",
        "train = train.append({'n_estimators': 500, 'learning_rate':0.5, 'max_depth':1, 'random_state':10}, ignore_index=True)\n",
        "train = train.append({'n_estimators': 750, 'learning_rate':0.01, 'max_depth':10, 'random_state':10}, ignore_index=True)\n",
        "\n",
        "train = train.reset_index()\n",
        "for index, row in train.iterrows():\n",
        "    model_name = name + str(index)\n",
        "    lightgbm_clf = LGBMClassifier(n_estimators=int(row['n_estimators']), learning_rate=row['learning_rate'],\n",
        "                                max_depth=int(row['max_depth']), random_state=int(row['random_state']))\n",
        "    lightgbm_clf.fit(X_train, y_train)\n",
        "    \n",
        "    y_true = y_val\n",
        "    y_pred = lightgbm_clf.predict(X_val)\n",
        "    evaluation_results = evaluation_metrics(y_true, y_pred)   \n",
        "\n",
        "    models = models.append({'model_name': model_name, \n",
        "                            'model': lightgbm_clf, \n",
        "                            'parameters': lightgbm_clf.get_params()}, \n",
        "                            ignore_index=True)\n",
        "    \n",
        "    models_eval = models_eval.append({'model_name': model_name, \n",
        "                                      'confusion_matrix' : evaluation_results[0], \n",
        "                                      'accuracy': evaluation_results[1], \n",
        "                                      'recall' : evaluation_results[2], \n",
        "                                      'f1_score': evaluation_results[3], \n",
        "                                      'roc_auc_score': evaluation_results[4]}, \n",
        "                                      ignore_index=True)"
      ],
      "metadata": {
        "id": "sh_I5t-TZVaP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "display(models_eval)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "id": "HXwRGqZRmoDv",
        "outputId": "580343a5-ab92-4a7d-b947-6f5cf56b2bfa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "      model_name       confusion_matrix  accuracy    recall  f1_score  \\\n",
              "0       log_clf0  [14440, 2628, 28, 94]  0.845492  0.770492  0.066104   \n",
              "1       log_clf1  [14441, 2627, 28, 94]  0.845550  0.770492  0.066127   \n",
              "2     bayes_clf0  [1326, 15742, 0, 122]  0.084235  1.000000  0.015263   \n",
              "3     bayes_clf1   [592, 16476, 0, 122]  0.041536  1.000000  0.014593   \n",
              "4     bayes_clf2     [0, 17068, 0, 122]  0.007097  1.000000  0.014094   \n",
              "5  lightgbm_clf0    [16971, 97, 5, 117]  0.994066  0.959016  0.696429   \n",
              "6  lightgbm_clf1   [16458, 610, 4, 118]  0.964282  0.967213  0.277647   \n",
              "7  lightgbm_clf2   [16878, 190, 3, 119]  0.988773  0.975410  0.552204   \n",
              "\n",
              "   roc_auc_score  \n",
              "0       0.808260  \n",
              "1       0.808289  \n",
              "2       0.538845  \n",
              "3       0.517342  \n",
              "4       0.500000  \n",
              "5       0.976667  \n",
              "6       0.965737  \n",
              "7       0.982139  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-16922944-b13f-4fa6-9f46-90e0386dadd3\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>model_name</th>\n",
              "      <th>confusion_matrix</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>recall</th>\n",
              "      <th>f1_score</th>\n",
              "      <th>roc_auc_score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>log_clf0</td>\n",
              "      <td>[14440, 2628, 28, 94]</td>\n",
              "      <td>0.845492</td>\n",
              "      <td>0.770492</td>\n",
              "      <td>0.066104</td>\n",
              "      <td>0.808260</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>log_clf1</td>\n",
              "      <td>[14441, 2627, 28, 94]</td>\n",
              "      <td>0.845550</td>\n",
              "      <td>0.770492</td>\n",
              "      <td>0.066127</td>\n",
              "      <td>0.808289</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>bayes_clf0</td>\n",
              "      <td>[1326, 15742, 0, 122]</td>\n",
              "      <td>0.084235</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.015263</td>\n",
              "      <td>0.538845</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>bayes_clf1</td>\n",
              "      <td>[592, 16476, 0, 122]</td>\n",
              "      <td>0.041536</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.014593</td>\n",
              "      <td>0.517342</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>bayes_clf2</td>\n",
              "      <td>[0, 17068, 0, 122]</td>\n",
              "      <td>0.007097</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.014094</td>\n",
              "      <td>0.500000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>lightgbm_clf0</td>\n",
              "      <td>[16971, 97, 5, 117]</td>\n",
              "      <td>0.994066</td>\n",
              "      <td>0.959016</td>\n",
              "      <td>0.696429</td>\n",
              "      <td>0.976667</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>lightgbm_clf1</td>\n",
              "      <td>[16458, 610, 4, 118]</td>\n",
              "      <td>0.964282</td>\n",
              "      <td>0.967213</td>\n",
              "      <td>0.277647</td>\n",
              "      <td>0.965737</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>lightgbm_clf2</td>\n",
              "      <td>[16878, 190, 3, 119]</td>\n",
              "      <td>0.988773</td>\n",
              "      <td>0.975410</td>\n",
              "      <td>0.552204</td>\n",
              "      <td>0.982139</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-16922944-b13f-4fa6-9f46-90e0386dadd3')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-16922944-b13f-4fa6-9f46-90e0386dadd3 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-16922944-b13f-4fa6-9f46-90e0386dadd3');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# RandomizedSearchCV\n",
        "\n",
        "random_grid = {\n",
        "              \"n_estimators\": [100, 500, 750, 1000, 2000],\n",
        "              \"learning_rate\": [0.01, 0.05, 0.10, 0.15, 0.20, 0.25, 0.30, 0.50],\n",
        "              \"max_depth\": [1, 3, 5, 8, 10, 15, 20],\n",
        "              \"num_leaves\": [10, 31, 50, 100, 200, 500],\n",
        "              \"min_data_in_leaf\": [10, 20, 25, 50, 100]\n",
        "              }\n",
        "\n",
        "lightgbm_random = RandomizedSearchCV(estimator = lightgbm_clf, \n",
        "                                 param_distributions = random_grid, \n",
        "                                 n_iter = 100, \n",
        "                                 cv = 3, \n",
        "                                 verbose=2, \n",
        "                                 scoring='recall',\n",
        "                                 random_state=10)\n",
        "\n",
        "lightgbm_random.fit(X_train, y_train)\n",
        "lightgbm_random.best_params_"
      ],
      "metadata": {
        "id": "-P5Jw0-sQ6Vn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fce6c8bf-8aae-4e17-da02-f762bcf8cd5d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 3 folds for each of 150 candidates, totalling 450 fits\n",
            "[CV] END learning_rate=0.5, max_depth=1, min_data_in_leaf=10, n_estimators=2000, num_leaves=500; total time=  23.9s\n",
            "[CV] END learning_rate=0.5, max_depth=1, min_data_in_leaf=10, n_estimators=2000, num_leaves=500; total time=  25.2s\n",
            "[CV] END learning_rate=0.5, max_depth=1, min_data_in_leaf=10, n_estimators=2000, num_leaves=500; total time=  23.0s\n",
            "[CV] END learning_rate=0.3, max_depth=20, min_data_in_leaf=10, n_estimators=2000, num_leaves=50; total time=  51.9s\n",
            "[CV] END learning_rate=0.3, max_depth=20, min_data_in_leaf=10, n_estimators=2000, num_leaves=50; total time=  58.6s\n",
            "[CV] END learning_rate=0.3, max_depth=20, min_data_in_leaf=10, n_estimators=2000, num_leaves=50; total time=  58.0s\n",
            "[CV] END learning_rate=0.15, max_depth=15, min_data_in_leaf=10, n_estimators=100, num_leaves=50; total time=   3.8s\n",
            "[CV] END learning_rate=0.15, max_depth=15, min_data_in_leaf=10, n_estimators=100, num_leaves=50; total time=   3.8s\n",
            "[CV] END learning_rate=0.15, max_depth=15, min_data_in_leaf=10, n_estimators=100, num_leaves=50; total time=   3.8s\n",
            "[CV] END learning_rate=0.25, max_depth=1, min_data_in_leaf=50, n_estimators=2000, num_leaves=200; total time=  26.5s\n",
            "[CV] END learning_rate=0.25, max_depth=1, min_data_in_leaf=50, n_estimators=2000, num_leaves=200; total time=  23.2s\n",
            "[CV] END learning_rate=0.25, max_depth=1, min_data_in_leaf=50, n_estimators=2000, num_leaves=200; total time=  24.0s\n",
            "[CV] END learning_rate=0.5, max_depth=1, min_data_in_leaf=100, n_estimators=500, num_leaves=10; total time=   6.1s\n",
            "[CV] END learning_rate=0.5, max_depth=1, min_data_in_leaf=100, n_estimators=500, num_leaves=10; total time=   6.1s\n",
            "[CV] END learning_rate=0.5, max_depth=1, min_data_in_leaf=100, n_estimators=500, num_leaves=10; total time=   6.1s\n",
            "[CV] END learning_rate=0.1, max_depth=8, min_data_in_leaf=100, n_estimators=2000, num_leaves=50; total time= 1.0min\n",
            "[CV] END learning_rate=0.1, max_depth=8, min_data_in_leaf=100, n_estimators=2000, num_leaves=50; total time= 1.0min\n",
            "[CV] END learning_rate=0.1, max_depth=8, min_data_in_leaf=100, n_estimators=2000, num_leaves=50; total time= 1.0min\n",
            "[CV] END learning_rate=0.25, max_depth=5, min_data_in_leaf=20, n_estimators=100, num_leaves=50; total time=   2.8s\n",
            "[CV] END learning_rate=0.25, max_depth=5, min_data_in_leaf=20, n_estimators=100, num_leaves=50; total time=   2.8s\n",
            "[CV] END learning_rate=0.25, max_depth=5, min_data_in_leaf=20, n_estimators=100, num_leaves=50; total time=   2.9s\n",
            "[CV] END learning_rate=0.2, max_depth=10, min_data_in_leaf=100, n_estimators=100, num_leaves=500; total time=   5.5s\n",
            "[CV] END learning_rate=0.2, max_depth=10, min_data_in_leaf=100, n_estimators=100, num_leaves=500; total time=   5.3s\n",
            "[CV] END learning_rate=0.2, max_depth=10, min_data_in_leaf=100, n_estimators=100, num_leaves=500; total time=   5.3s\n",
            "[CV] END learning_rate=0.05, max_depth=5, min_data_in_leaf=20, n_estimators=1000, num_leaves=10; total time=  22.6s\n",
            "[CV] END learning_rate=0.05, max_depth=5, min_data_in_leaf=20, n_estimators=1000, num_leaves=10; total time=  19.4s\n",
            "[CV] END learning_rate=0.05, max_depth=5, min_data_in_leaf=20, n_estimators=1000, num_leaves=10; total time=  19.3s\n",
            "[CV] END learning_rate=0.2, max_depth=10, min_data_in_leaf=50, n_estimators=2000, num_leaves=31; total time=  52.4s\n",
            "[CV] END learning_rate=0.2, max_depth=10, min_data_in_leaf=50, n_estimators=2000, num_leaves=31; total time=  55.7s\n",
            "[CV] END learning_rate=0.2, max_depth=10, min_data_in_leaf=50, n_estimators=2000, num_leaves=31; total time=  53.6s\n",
            "[CV] END learning_rate=0.1, max_depth=8, min_data_in_leaf=100, n_estimators=100, num_leaves=100; total time=   4.0s\n",
            "[CV] END learning_rate=0.1, max_depth=8, min_data_in_leaf=100, n_estimators=100, num_leaves=100; total time=   4.0s\n",
            "[CV] END learning_rate=0.1, max_depth=8, min_data_in_leaf=100, n_estimators=100, num_leaves=100; total time=   4.0s\n",
            "[CV] END learning_rate=0.15, max_depth=8, min_data_in_leaf=20, n_estimators=750, num_leaves=500; total time=  27.3s\n",
            "[CV] END learning_rate=0.15, max_depth=8, min_data_in_leaf=20, n_estimators=750, num_leaves=500; total time=  27.7s\n",
            "[CV] END learning_rate=0.15, max_depth=8, min_data_in_leaf=20, n_estimators=750, num_leaves=500; total time=  30.2s\n",
            "[CV] END learning_rate=0.05, max_depth=1, min_data_in_leaf=100, n_estimators=750, num_leaves=50; total time=   9.0s\n",
            "[CV] END learning_rate=0.05, max_depth=1, min_data_in_leaf=100, n_estimators=750, num_leaves=50; total time=   9.1s\n",
            "[CV] END learning_rate=0.05, max_depth=1, min_data_in_leaf=100, n_estimators=750, num_leaves=50; total time=   9.1s\n",
            "[CV] END learning_rate=0.25, max_depth=8, min_data_in_leaf=20, n_estimators=100, num_leaves=200; total time=   4.5s\n",
            "[CV] END learning_rate=0.25, max_depth=8, min_data_in_leaf=20, n_estimators=100, num_leaves=200; total time=   4.4s\n",
            "[CV] END learning_rate=0.25, max_depth=8, min_data_in_leaf=20, n_estimators=100, num_leaves=200; total time=   4.4s\n",
            "[CV] END learning_rate=0.05, max_depth=5, min_data_in_leaf=50, n_estimators=2000, num_leaves=500; total time=  50.0s\n",
            "[CV] END learning_rate=0.05, max_depth=5, min_data_in_leaf=50, n_estimators=2000, num_leaves=500; total time=  52.7s\n",
            "[CV] END learning_rate=0.05, max_depth=5, min_data_in_leaf=50, n_estimators=2000, num_leaves=500; total time=  49.9s\n",
            "[CV] END learning_rate=0.15, max_depth=15, min_data_in_leaf=100, n_estimators=1000, num_leaves=31; total time=  26.4s\n",
            "[CV] END learning_rate=0.15, max_depth=15, min_data_in_leaf=100, n_estimators=1000, num_leaves=31; total time=  36.5s\n",
            "[CV] END learning_rate=0.15, max_depth=15, min_data_in_leaf=100, n_estimators=1000, num_leaves=31; total time=  36.3s\n",
            "[CV] END learning_rate=0.3, max_depth=20, min_data_in_leaf=50, n_estimators=1000, num_leaves=10; total time=  17.1s\n",
            "[CV] END learning_rate=0.3, max_depth=20, min_data_in_leaf=50, n_estimators=1000, num_leaves=10; total time=  18.3s\n",
            "[CV] END learning_rate=0.3, max_depth=20, min_data_in_leaf=50, n_estimators=1000, num_leaves=10; total time=  18.4s\n",
            "[CV] END learning_rate=0.25, max_depth=20, min_data_in_leaf=50, n_estimators=100, num_leaves=10; total time=   2.5s\n",
            "[CV] END learning_rate=0.25, max_depth=20, min_data_in_leaf=50, n_estimators=100, num_leaves=10; total time=   2.5s\n",
            "[CV] END learning_rate=0.25, max_depth=20, min_data_in_leaf=50, n_estimators=100, num_leaves=10; total time=   2.5s\n",
            "[CV] END learning_rate=0.05, max_depth=3, min_data_in_leaf=50, n_estimators=500, num_leaves=500; total time=   9.8s\n",
            "[CV] END learning_rate=0.05, max_depth=3, min_data_in_leaf=50, n_estimators=500, num_leaves=500; total time=  10.8s\n",
            "[CV] END learning_rate=0.05, max_depth=3, min_data_in_leaf=50, n_estimators=500, num_leaves=500; total time=  18.4s\n",
            "[CV] END learning_rate=0.01, max_depth=8, min_data_in_leaf=50, n_estimators=750, num_leaves=200; total time=  57.9s\n",
            "[CV] END learning_rate=0.01, max_depth=8, min_data_in_leaf=50, n_estimators=750, num_leaves=200; total time=  43.1s\n",
            "[CV] END learning_rate=0.01, max_depth=8, min_data_in_leaf=50, n_estimators=750, num_leaves=200; total time=  41.3s\n",
            "[CV] END learning_rate=0.1, max_depth=20, min_data_in_leaf=10, n_estimators=500, num_leaves=200; total time=  48.1s\n",
            "[CV] END learning_rate=0.1, max_depth=20, min_data_in_leaf=10, n_estimators=500, num_leaves=200; total time=  24.6s\n",
            "[CV] END learning_rate=0.1, max_depth=20, min_data_in_leaf=10, n_estimators=500, num_leaves=200; total time=  25.8s\n",
            "[CV] END learning_rate=0.1, max_depth=20, min_data_in_leaf=10, n_estimators=1000, num_leaves=500; total time= 1.0min\n",
            "[CV] END learning_rate=0.1, max_depth=20, min_data_in_leaf=10, n_estimators=1000, num_leaves=500; total time=  48.9s\n",
            "[CV] END learning_rate=0.1, max_depth=20, min_data_in_leaf=10, n_estimators=1000, num_leaves=500; total time=  42.8s\n",
            "[CV] END learning_rate=0.3, max_depth=1, min_data_in_leaf=20, n_estimators=750, num_leaves=31; total time=  11.2s\n",
            "[CV] END learning_rate=0.3, max_depth=1, min_data_in_leaf=20, n_estimators=750, num_leaves=31; total time=   9.0s\n",
            "[CV] END learning_rate=0.3, max_depth=1, min_data_in_leaf=20, n_estimators=750, num_leaves=31; total time=   9.0s\n",
            "[CV] END learning_rate=0.05, max_depth=3, min_data_in_leaf=25, n_estimators=750, num_leaves=10; total time=  13.5s\n",
            "[CV] END learning_rate=0.05, max_depth=3, min_data_in_leaf=25, n_estimators=750, num_leaves=10; total time=  13.3s\n",
            "[CV] END learning_rate=0.05, max_depth=3, min_data_in_leaf=25, n_estimators=750, num_leaves=10; total time=  13.4s\n",
            "[CV] END learning_rate=0.5, max_depth=3, min_data_in_leaf=25, n_estimators=2000, num_leaves=500; total time=  38.9s\n",
            "[CV] END learning_rate=0.5, max_depth=3, min_data_in_leaf=25, n_estimators=2000, num_leaves=500; total time=  38.6s\n",
            "[CV] END learning_rate=0.5, max_depth=3, min_data_in_leaf=25, n_estimators=2000, num_leaves=500; total time=  22.2s\n",
            "[CV] END learning_rate=0.05, max_depth=15, min_data_in_leaf=50, n_estimators=100, num_leaves=31; total time=   3.4s\n",
            "[CV] END learning_rate=0.05, max_depth=15, min_data_in_leaf=50, n_estimators=100, num_leaves=31; total time=   3.4s\n",
            "[CV] END learning_rate=0.05, max_depth=15, min_data_in_leaf=50, n_estimators=100, num_leaves=31; total time=   3.4s\n",
            "[CV] END learning_rate=0.3, max_depth=8, min_data_in_leaf=100, n_estimators=1000, num_leaves=500; total time=  29.9s\n",
            "[CV] END learning_rate=0.3, max_depth=8, min_data_in_leaf=100, n_estimators=1000, num_leaves=500; total time=  30.0s\n",
            "[CV] END learning_rate=0.3, max_depth=8, min_data_in_leaf=100, n_estimators=1000, num_leaves=500; total time=  33.2s\n",
            "[CV] END learning_rate=0.2, max_depth=8, min_data_in_leaf=50, n_estimators=100, num_leaves=100; total time=   4.1s\n",
            "[CV] END learning_rate=0.2, max_depth=8, min_data_in_leaf=50, n_estimators=100, num_leaves=100; total time=   4.0s\n",
            "[CV] END learning_rate=0.2, max_depth=8, min_data_in_leaf=50, n_estimators=100, num_leaves=100; total time=   4.1s\n",
            "[CV] END learning_rate=0.5, max_depth=8, min_data_in_leaf=20, n_estimators=500, num_leaves=31; total time=  10.3s\n",
            "[CV] END learning_rate=0.5, max_depth=8, min_data_in_leaf=20, n_estimators=500, num_leaves=31; total time=  10.3s\n",
            "[CV] END learning_rate=0.5, max_depth=8, min_data_in_leaf=20, n_estimators=500, num_leaves=31; total time=  10.8s\n",
            "[CV] END learning_rate=0.01, max_depth=3, min_data_in_leaf=20, n_estimators=750, num_leaves=31; total time=  13.8s\n",
            "[CV] END learning_rate=0.01, max_depth=3, min_data_in_leaf=20, n_estimators=750, num_leaves=31; total time=  13.9s\n",
            "[CV] END learning_rate=0.01, max_depth=3, min_data_in_leaf=20, n_estimators=750, num_leaves=31; total time=  13.7s\n",
            "[CV] END learning_rate=0.1, max_depth=5, min_data_in_leaf=25, n_estimators=100, num_leaves=10; total time=   2.5s\n",
            "[CV] END learning_rate=0.1, max_depth=5, min_data_in_leaf=25, n_estimators=100, num_leaves=10; total time=   2.5s\n",
            "[CV] END learning_rate=0.1, max_depth=5, min_data_in_leaf=25, n_estimators=100, num_leaves=10; total time=   2.5s\n",
            "[CV] END learning_rate=0.3, max_depth=5, min_data_in_leaf=50, n_estimators=1000, num_leaves=10; total time=  17.1s\n",
            "[CV] END learning_rate=0.3, max_depth=5, min_data_in_leaf=50, n_estimators=1000, num_leaves=10; total time=  20.1s\n",
            "[CV] END learning_rate=0.3, max_depth=5, min_data_in_leaf=50, n_estimators=1000, num_leaves=10; total time=  19.4s\n",
            "[CV] END learning_rate=0.2, max_depth=8, min_data_in_leaf=50, n_estimators=1000, num_leaves=200; total time=  32.0s\n",
            "[CV] END learning_rate=0.2, max_depth=8, min_data_in_leaf=50, n_estimators=1000, num_leaves=200; total time=  32.0s\n",
            "[CV] END learning_rate=0.2, max_depth=8, min_data_in_leaf=50, n_estimators=1000, num_leaves=200; total time=  32.0s\n",
            "[CV] END learning_rate=0.2, max_depth=1, min_data_in_leaf=25, n_estimators=100, num_leaves=500; total time=   1.6s\n",
            "[CV] END learning_rate=0.2, max_depth=1, min_data_in_leaf=25, n_estimators=100, num_leaves=500; total time=   1.6s\n",
            "[CV] END learning_rate=0.2, max_depth=1, min_data_in_leaf=25, n_estimators=100, num_leaves=500; total time=   1.6s\n",
            "[CV] END learning_rate=0.15, max_depth=1, min_data_in_leaf=20, n_estimators=1000, num_leaves=50; total time=  11.7s\n",
            "[CV] END learning_rate=0.15, max_depth=1, min_data_in_leaf=20, n_estimators=1000, num_leaves=50; total time=  11.6s\n",
            "[CV] END learning_rate=0.15, max_depth=1, min_data_in_leaf=20, n_estimators=1000, num_leaves=50; total time=  14.5s\n",
            "[CV] END learning_rate=0.2, max_depth=10, min_data_in_leaf=100, n_estimators=750, num_leaves=100; total time=  25.6s\n",
            "[CV] END learning_rate=0.2, max_depth=10, min_data_in_leaf=100, n_estimators=750, num_leaves=100; total time=  26.4s\n",
            "[CV] END learning_rate=0.2, max_depth=10, min_data_in_leaf=100, n_estimators=750, num_leaves=100; total time=  26.5s\n",
            "[CV] END learning_rate=0.2, max_depth=15, min_data_in_leaf=50, n_estimators=2000, num_leaves=500; total time= 1.0min\n",
            "[CV] END learning_rate=0.2, max_depth=15, min_data_in_leaf=50, n_estimators=2000, num_leaves=500; total time= 1.1min\n",
            "[CV] END learning_rate=0.2, max_depth=15, min_data_in_leaf=50, n_estimators=2000, num_leaves=500; total time= 1.1min\n",
            "[CV] END learning_rate=0.15, max_depth=15, min_data_in_leaf=10, n_estimators=500, num_leaves=100; total time=  23.4s\n",
            "[CV] END learning_rate=0.15, max_depth=15, min_data_in_leaf=10, n_estimators=500, num_leaves=100; total time=  20.6s\n",
            "[CV] END learning_rate=0.15, max_depth=15, min_data_in_leaf=10, n_estimators=500, num_leaves=100; total time=  20.7s\n",
            "[CV] END learning_rate=0.25, max_depth=10, min_data_in_leaf=10, n_estimators=500, num_leaves=50; total time=  16.2s\n",
            "[CV] END learning_rate=0.25, max_depth=10, min_data_in_leaf=10, n_estimators=500, num_leaves=50; total time=  16.2s\n",
            "[CV] END learning_rate=0.25, max_depth=10, min_data_in_leaf=10, n_estimators=500, num_leaves=50; total time=  16.2s\n",
            "[CV] END learning_rate=0.2, max_depth=20, min_data_in_leaf=25, n_estimators=100, num_leaves=10; total time=   2.5s\n",
            "[CV] END learning_rate=0.2, max_depth=20, min_data_in_leaf=25, n_estimators=100, num_leaves=10; total time=   2.5s\n",
            "[CV] END learning_rate=0.2, max_depth=20, min_data_in_leaf=25, n_estimators=100, num_leaves=10; total time=   2.5s\n",
            "[CV] END learning_rate=0.2, max_depth=8, min_data_in_leaf=100, n_estimators=750, num_leaves=200; total time=  25.4s\n",
            "[CV] END learning_rate=0.2, max_depth=8, min_data_in_leaf=100, n_estimators=750, num_leaves=200; total time=  28.5s\n",
            "[CV] END learning_rate=0.2, max_depth=8, min_data_in_leaf=100, n_estimators=750, num_leaves=200; total time=  25.5s\n",
            "[CV] END learning_rate=0.01, max_depth=5, min_data_in_leaf=50, n_estimators=1000, num_leaves=500; total time=  25.5s\n",
            "[CV] END learning_rate=0.01, max_depth=5, min_data_in_leaf=50, n_estimators=1000, num_leaves=500; total time=  25.9s\n",
            "[CV] END learning_rate=0.01, max_depth=5, min_data_in_leaf=50, n_estimators=1000, num_leaves=500; total time=  25.5s\n",
            "[CV] END learning_rate=0.05, max_depth=5, min_data_in_leaf=10, n_estimators=2000, num_leaves=100; total time=  52.9s\n",
            "[CV] END learning_rate=0.05, max_depth=5, min_data_in_leaf=10, n_estimators=2000, num_leaves=100; total time=  50.6s\n",
            "[CV] END learning_rate=0.05, max_depth=5, min_data_in_leaf=10, n_estimators=2000, num_leaves=100; total time=  51.1s\n",
            "[CV] END learning_rate=0.05, max_depth=15, min_data_in_leaf=100, n_estimators=100, num_leaves=500; total time=   7.8s\n",
            "[CV] END learning_rate=0.05, max_depth=15, min_data_in_leaf=100, n_estimators=100, num_leaves=500; total time=   7.9s\n",
            "[CV] END learning_rate=0.05, max_depth=15, min_data_in_leaf=100, n_estimators=100, num_leaves=500; total time=   7.9s\n",
            "[CV] END learning_rate=0.3, max_depth=3, min_data_in_leaf=25, n_estimators=500, num_leaves=31; total time=  11.7s\n",
            "[CV] END learning_rate=0.3, max_depth=3, min_data_in_leaf=25, n_estimators=500, num_leaves=31; total time=   9.0s\n",
            "[CV] END learning_rate=0.3, max_depth=3, min_data_in_leaf=25, n_estimators=500, num_leaves=31; total time=   9.1s\n",
            "[CV] END learning_rate=0.1, max_depth=10, min_data_in_leaf=20, n_estimators=2000, num_leaves=31; total time=  54.7s\n",
            "[CV] END learning_rate=0.1, max_depth=10, min_data_in_leaf=20, n_estimators=2000, num_leaves=31; total time=  53.7s\n",
            "[CV] END learning_rate=0.1, max_depth=10, min_data_in_leaf=20, n_estimators=2000, num_leaves=31; total time=  56.8s\n",
            "[CV] END learning_rate=0.15, max_depth=3, min_data_in_leaf=25, n_estimators=1000, num_leaves=100; total time=  17.2s\n",
            "[CV] END learning_rate=0.15, max_depth=3, min_data_in_leaf=25, n_estimators=1000, num_leaves=100; total time=  17.1s\n",
            "[CV] END learning_rate=0.15, max_depth=3, min_data_in_leaf=25, n_estimators=1000, num_leaves=100; total time=  17.3s\n",
            "[CV] END learning_rate=0.2, max_depth=20, min_data_in_leaf=50, n_estimators=500, num_leaves=200; total time=  18.9s\n",
            "[CV] END learning_rate=0.2, max_depth=20, min_data_in_leaf=50, n_estimators=500, num_leaves=200; total time=  19.9s\n",
            "[CV] END learning_rate=0.2, max_depth=20, min_data_in_leaf=50, n_estimators=500, num_leaves=200; total time=  23.0s\n",
            "[CV] END learning_rate=0.05, max_depth=15, min_data_in_leaf=100, n_estimators=500, num_leaves=50; total time=  16.7s\n",
            "[CV] END learning_rate=0.05, max_depth=15, min_data_in_leaf=100, n_estimators=500, num_leaves=50; total time=  16.8s\n",
            "[CV] END learning_rate=0.05, max_depth=15, min_data_in_leaf=100, n_estimators=500, num_leaves=50; total time=  16.6s\n",
            "[CV] END learning_rate=0.25, max_depth=8, min_data_in_leaf=25, n_estimators=2000, num_leaves=10; total time=  33.6s\n",
            "[CV] END learning_rate=0.25, max_depth=8, min_data_in_leaf=25, n_estimators=2000, num_leaves=10; total time=  36.0s\n",
            "[CV] END learning_rate=0.25, max_depth=8, min_data_in_leaf=25, n_estimators=2000, num_leaves=10; total time=  38.9s\n",
            "[CV] END learning_rate=0.05, max_depth=1, min_data_in_leaf=10, n_estimators=500, num_leaves=500; total time=   6.1s\n",
            "[CV] END learning_rate=0.05, max_depth=1, min_data_in_leaf=10, n_estimators=500, num_leaves=500; total time=   6.1s\n",
            "[CV] END learning_rate=0.05, max_depth=1, min_data_in_leaf=10, n_estimators=500, num_leaves=500; total time=   6.2s\n",
            "[CV] END learning_rate=0.05, max_depth=20, min_data_in_leaf=10, n_estimators=2000, num_leaves=200; total time= 1.3min\n",
            "[CV] END learning_rate=0.05, max_depth=20, min_data_in_leaf=10, n_estimators=2000, num_leaves=200; total time= 1.4min\n",
            "[CV] END learning_rate=0.05, max_depth=20, min_data_in_leaf=10, n_estimators=2000, num_leaves=200; total time= 1.3min\n",
            "[CV] END learning_rate=0.1, max_depth=15, min_data_in_leaf=25, n_estimators=100, num_leaves=50; total time=   3.8s\n",
            "[CV] END learning_rate=0.1, max_depth=15, min_data_in_leaf=25, n_estimators=100, num_leaves=50; total time=   3.8s\n",
            "[CV] END learning_rate=0.1, max_depth=15, min_data_in_leaf=25, n_estimators=100, num_leaves=50; total time=   3.8s\n",
            "[CV] END learning_rate=0.5, max_depth=5, min_data_in_leaf=50, n_estimators=1000, num_leaves=50; total time=  15.5s\n",
            "[CV] END learning_rate=0.5, max_depth=5, min_data_in_leaf=50, n_estimators=1000, num_leaves=50; total time=  23.1s\n",
            "[CV] END learning_rate=0.5, max_depth=5, min_data_in_leaf=50, n_estimators=1000, num_leaves=50; total time=  22.9s\n",
            "[CV] END learning_rate=0.2, max_depth=15, min_data_in_leaf=100, n_estimators=750, num_leaves=100; total time=  25.8s\n",
            "[CV] END learning_rate=0.2, max_depth=15, min_data_in_leaf=100, n_estimators=750, num_leaves=100; total time=  26.8s\n",
            "[CV] END learning_rate=0.2, max_depth=15, min_data_in_leaf=100, n_estimators=750, num_leaves=100; total time=  26.6s\n",
            "[CV] END learning_rate=0.05, max_depth=20, min_data_in_leaf=100, n_estimators=2000, num_leaves=200; total time= 1.4min\n",
            "[CV] END learning_rate=0.05, max_depth=20, min_data_in_leaf=100, n_estimators=2000, num_leaves=200; total time= 1.4min\n",
            "[CV] END learning_rate=0.05, max_depth=20, min_data_in_leaf=100, n_estimators=2000, num_leaves=200; total time= 1.4min\n",
            "[CV] END learning_rate=0.2, max_depth=15, min_data_in_leaf=100, n_estimators=2000, num_leaves=100; total time=  56.1s\n",
            "[CV] END learning_rate=0.2, max_depth=15, min_data_in_leaf=100, n_estimators=2000, num_leaves=100; total time= 1.1min\n",
            "[CV] END learning_rate=0.2, max_depth=15, min_data_in_leaf=100, n_estimators=2000, num_leaves=100; total time= 1.0min\n",
            "[CV] END learning_rate=0.3, max_depth=20, min_data_in_leaf=10, n_estimators=500, num_leaves=50; total time=  15.9s\n",
            "[CV] END learning_rate=0.3, max_depth=20, min_data_in_leaf=10, n_estimators=500, num_leaves=50; total time=  19.2s\n",
            "[CV] END learning_rate=0.3, max_depth=20, min_data_in_leaf=10, n_estimators=500, num_leaves=50; total time=  16.4s\n",
            "[CV] END learning_rate=0.01, max_depth=5, min_data_in_leaf=50, n_estimators=100, num_leaves=50; total time=   2.8s\n",
            "[CV] END learning_rate=0.01, max_depth=5, min_data_in_leaf=50, n_estimators=100, num_leaves=50; total time=   2.8s\n",
            "[CV] END learning_rate=0.01, max_depth=5, min_data_in_leaf=50, n_estimators=100, num_leaves=50; total time=   2.9s\n",
            "[CV] END learning_rate=0.05, max_depth=3, min_data_in_leaf=100, n_estimators=1000, num_leaves=10; total time=  17.8s\n",
            "[CV] END learning_rate=0.05, max_depth=3, min_data_in_leaf=100, n_estimators=1000, num_leaves=10; total time=  17.6s\n",
            "[CV] END learning_rate=0.05, max_depth=3, min_data_in_leaf=100, n_estimators=1000, num_leaves=10; total time=  17.6s\n",
            "[CV] END learning_rate=0.5, max_depth=20, min_data_in_leaf=50, n_estimators=500, num_leaves=200; total time=  15.3s\n",
            "[CV] END learning_rate=0.5, max_depth=20, min_data_in_leaf=50, n_estimators=500, num_leaves=200; total time=  16.1s\n",
            "[CV] END learning_rate=0.5, max_depth=20, min_data_in_leaf=50, n_estimators=500, num_leaves=200; total time=   8.1s\n",
            "[CV] END learning_rate=0.5, max_depth=10, min_data_in_leaf=20, n_estimators=750, num_leaves=500; total time=  21.4s\n",
            "[CV] END learning_rate=0.5, max_depth=10, min_data_in_leaf=20, n_estimators=750, num_leaves=500; total time=  25.3s\n",
            "[CV] END learning_rate=0.5, max_depth=10, min_data_in_leaf=20, n_estimators=750, num_leaves=500; total time=  22.8s\n",
            "[CV] END learning_rate=0.25, max_depth=1, min_data_in_leaf=20, n_estimators=750, num_leaves=100; total time=   9.0s\n",
            "[CV] END learning_rate=0.25, max_depth=1, min_data_in_leaf=20, n_estimators=750, num_leaves=100; total time=   8.9s\n",
            "[CV] END learning_rate=0.25, max_depth=1, min_data_in_leaf=20, n_estimators=750, num_leaves=100; total time=   9.0s\n",
            "[CV] END learning_rate=0.2, max_depth=3, min_data_in_leaf=25, n_estimators=750, num_leaves=500; total time=  13.1s\n",
            "[CV] END learning_rate=0.2, max_depth=3, min_data_in_leaf=25, n_estimators=750, num_leaves=500; total time=  14.3s\n",
            "[CV] END learning_rate=0.2, max_depth=3, min_data_in_leaf=25, n_estimators=750, num_leaves=500; total time=  14.4s\n",
            "[CV] END learning_rate=0.3, max_depth=5, min_data_in_leaf=10, n_estimators=750, num_leaves=10; total time=  13.6s\n",
            "[CV] END learning_rate=0.3, max_depth=5, min_data_in_leaf=10, n_estimators=750, num_leaves=10; total time=  13.8s\n",
            "[CV] END learning_rate=0.3, max_depth=5, min_data_in_leaf=10, n_estimators=750, num_leaves=10; total time=  16.1s\n",
            "[CV] END learning_rate=0.3, max_depth=5, min_data_in_leaf=25, n_estimators=2000, num_leaves=200; total time=  45.9s\n",
            "[CV] END learning_rate=0.3, max_depth=5, min_data_in_leaf=25, n_estimators=2000, num_leaves=200; total time=  46.3s\n",
            "[CV] END learning_rate=0.3, max_depth=5, min_data_in_leaf=25, n_estimators=2000, num_leaves=200; total time=  45.9s\n",
            "[CV] END learning_rate=0.05, max_depth=1, min_data_in_leaf=100, n_estimators=100, num_leaves=100; total time=   1.6s\n",
            "[CV] END learning_rate=0.05, max_depth=1, min_data_in_leaf=100, n_estimators=100, num_leaves=100; total time=   1.6s\n",
            "[CV] END learning_rate=0.05, max_depth=1, min_data_in_leaf=100, n_estimators=100, num_leaves=100; total time=   1.7s\n",
            "[CV] END learning_rate=0.05, max_depth=10, min_data_in_leaf=100, n_estimators=500, num_leaves=31; total time=  16.7s\n",
            "[CV] END learning_rate=0.05, max_depth=10, min_data_in_leaf=100, n_estimators=500, num_leaves=31; total time=  14.3s\n",
            "[CV] END learning_rate=0.05, max_depth=10, min_data_in_leaf=100, n_estimators=500, num_leaves=31; total time=  14.1s\n",
            "[CV] END learning_rate=0.5, max_depth=10, min_data_in_leaf=10, n_estimators=2000, num_leaves=500; total time=  49.0s\n",
            "[CV] END learning_rate=0.5, max_depth=10, min_data_in_leaf=10, n_estimators=2000, num_leaves=500; total time=  51.9s\n",
            "[CV] END learning_rate=0.5, max_depth=10, min_data_in_leaf=10, n_estimators=2000, num_leaves=500; total time=  24.8s\n",
            "[CV] END learning_rate=0.2, max_depth=5, min_data_in_leaf=50, n_estimators=100, num_leaves=500; total time=   2.8s\n",
            "[CV] END learning_rate=0.2, max_depth=5, min_data_in_leaf=50, n_estimators=100, num_leaves=500; total time=   2.8s\n",
            "[CV] END learning_rate=0.2, max_depth=5, min_data_in_leaf=50, n_estimators=100, num_leaves=500; total time=   2.8s\n",
            "[CV] END learning_rate=0.5, max_depth=8, min_data_in_leaf=50, n_estimators=500, num_leaves=100; total time=  14.4s\n",
            "[CV] END learning_rate=0.5, max_depth=8, min_data_in_leaf=50, n_estimators=500, num_leaves=100; total time=  14.5s\n",
            "[CV] END learning_rate=0.5, max_depth=8, min_data_in_leaf=50, n_estimators=500, num_leaves=100; total time=  14.5s\n",
            "[CV] END learning_rate=0.01, max_depth=1, min_data_in_leaf=100, n_estimators=1000, num_leaves=31; total time=  11.6s\n",
            "[CV] END learning_rate=0.01, max_depth=1, min_data_in_leaf=100, n_estimators=1000, num_leaves=31; total time=  11.7s\n",
            "[CV] END learning_rate=0.01, max_depth=1, min_data_in_leaf=100, n_estimators=1000, num_leaves=31; total time=  11.7s\n",
            "[CV] END learning_rate=0.05, max_depth=1, min_data_in_leaf=20, n_estimators=100, num_leaves=10; total time=   1.6s\n",
            "[CV] END learning_rate=0.05, max_depth=1, min_data_in_leaf=20, n_estimators=100, num_leaves=10; total time=   1.6s\n",
            "[CV] END learning_rate=0.05, max_depth=1, min_data_in_leaf=20, n_estimators=100, num_leaves=10; total time=   1.6s\n",
            "[CV] END learning_rate=0.3, max_depth=20, min_data_in_leaf=50, n_estimators=500, num_leaves=50; total time=  22.7s\n",
            "[CV] END learning_rate=0.3, max_depth=20, min_data_in_leaf=50, n_estimators=500, num_leaves=50; total time=  19.5s\n",
            "[CV] END learning_rate=0.3, max_depth=20, min_data_in_leaf=50, n_estimators=500, num_leaves=50; total time=  16.1s\n",
            "[CV] END learning_rate=0.3, max_depth=20, min_data_in_leaf=50, n_estimators=1000, num_leaves=200; total time=  29.4s\n",
            "[CV] END learning_rate=0.3, max_depth=20, min_data_in_leaf=50, n_estimators=1000, num_leaves=200; total time=  31.2s\n",
            "[CV] END learning_rate=0.3, max_depth=20, min_data_in_leaf=50, n_estimators=1000, num_leaves=200; total time=  31.8s\n",
            "[CV] END learning_rate=0.25, max_depth=10, min_data_in_leaf=25, n_estimators=100, num_leaves=500; total time=   5.8s\n",
            "[CV] END learning_rate=0.25, max_depth=10, min_data_in_leaf=25, n_estimators=100, num_leaves=500; total time=   5.8s\n",
            "[CV] END learning_rate=0.25, max_depth=10, min_data_in_leaf=25, n_estimators=100, num_leaves=500; total time=   5.8s\n",
            "[CV] END learning_rate=0.15, max_depth=15, min_data_in_leaf=50, n_estimators=2000, num_leaves=50; total time= 1.0min\n",
            "[CV] END learning_rate=0.15, max_depth=15, min_data_in_leaf=50, n_estimators=2000, num_leaves=50; total time=  59.4s\n",
            "[CV] END learning_rate=0.15, max_depth=15, min_data_in_leaf=50, n_estimators=2000, num_leaves=50; total time= 1.0min\n",
            "[CV] END learning_rate=0.15, max_depth=10, min_data_in_leaf=25, n_estimators=750, num_leaves=10; total time=  13.8s\n",
            "[CV] END learning_rate=0.15, max_depth=10, min_data_in_leaf=25, n_estimators=750, num_leaves=10; total time=  13.8s\n",
            "[CV] END learning_rate=0.15, max_depth=10, min_data_in_leaf=25, n_estimators=750, num_leaves=10; total time=  14.0s\n",
            "[CV] END learning_rate=0.25, max_depth=8, min_data_in_leaf=50, n_estimators=1000, num_leaves=100; total time=  29.5s\n",
            "[CV] END learning_rate=0.25, max_depth=8, min_data_in_leaf=50, n_estimators=1000, num_leaves=100; total time=  29.5s\n",
            "[CV] END learning_rate=0.25, max_depth=8, min_data_in_leaf=50, n_estimators=1000, num_leaves=100; total time=  29.7s\n",
            "[CV] END learning_rate=0.25, max_depth=5, min_data_in_leaf=50, n_estimators=100, num_leaves=200; total time=   5.6s\n",
            "[CV] END learning_rate=0.25, max_depth=5, min_data_in_leaf=50, n_estimators=100, num_leaves=200; total time=   2.8s\n",
            "[CV] END learning_rate=0.25, max_depth=5, min_data_in_leaf=50, n_estimators=100, num_leaves=200; total time=   2.8s\n",
            "[CV] END learning_rate=0.01, max_depth=1, min_data_in_leaf=25, n_estimators=1000, num_leaves=100; total time=  11.7s\n",
            "[CV] END learning_rate=0.01, max_depth=1, min_data_in_leaf=25, n_estimators=1000, num_leaves=100; total time=  11.6s\n",
            "[CV] END learning_rate=0.01, max_depth=1, min_data_in_leaf=25, n_estimators=1000, num_leaves=100; total time=  11.6s\n",
            "[CV] END learning_rate=0.01, max_depth=20, min_data_in_leaf=25, n_estimators=2000, num_leaves=10; total time=  41.3s\n",
            "[CV] END learning_rate=0.01, max_depth=20, min_data_in_leaf=25, n_estimators=2000, num_leaves=10; total time=  41.4s\n",
            "[CV] END learning_rate=0.01, max_depth=20, min_data_in_leaf=25, n_estimators=2000, num_leaves=10; total time=  44.2s\n",
            "[CV] END learning_rate=0.01, max_depth=10, min_data_in_leaf=10, n_estimators=100, num_leaves=500; total time=   5.7s\n",
            "[CV] END learning_rate=0.01, max_depth=10, min_data_in_leaf=10, n_estimators=100, num_leaves=500; total time=   5.8s\n",
            "[CV] END learning_rate=0.01, max_depth=10, min_data_in_leaf=10, n_estimators=100, num_leaves=500; total time=   5.9s\n",
            "[CV] END learning_rate=0.3, max_depth=8, min_data_in_leaf=25, n_estimators=500, num_leaves=31; total time=  12.5s\n",
            "[CV] END learning_rate=0.3, max_depth=8, min_data_in_leaf=25, n_estimators=500, num_leaves=31; total time=  13.0s\n",
            "[CV] END learning_rate=0.3, max_depth=8, min_data_in_leaf=25, n_estimators=500, num_leaves=31; total time=  13.1s\n",
            "[CV] END learning_rate=0.01, max_depth=10, min_data_in_leaf=25, n_estimators=1000, num_leaves=100; total time=  40.4s\n",
            "[CV] END learning_rate=0.01, max_depth=10, min_data_in_leaf=25, n_estimators=1000, num_leaves=100; total time=  42.4s\n",
            "[CV] END learning_rate=0.01, max_depth=10, min_data_in_leaf=25, n_estimators=1000, num_leaves=100; total time=  40.7s\n",
            "[CV] END learning_rate=0.2, max_depth=10, min_data_in_leaf=50, n_estimators=1000, num_leaves=50; total time=  30.5s\n",
            "[CV] END learning_rate=0.2, max_depth=10, min_data_in_leaf=50, n_estimators=1000, num_leaves=50; total time=  30.6s\n",
            "[CV] END learning_rate=0.2, max_depth=10, min_data_in_leaf=50, n_estimators=1000, num_leaves=50; total time=  30.6s\n",
            "[CV] END learning_rate=0.01, max_depth=1, min_data_in_leaf=50, n_estimators=2000, num_leaves=50; total time=  25.7s\n",
            "[CV] END learning_rate=0.01, max_depth=1, min_data_in_leaf=50, n_estimators=2000, num_leaves=50; total time=  22.9s\n",
            "[CV] END learning_rate=0.01, max_depth=1, min_data_in_leaf=50, n_estimators=2000, num_leaves=50; total time=  23.4s\n",
            "[CV] END learning_rate=0.05, max_depth=8, min_data_in_leaf=100, n_estimators=500, num_leaves=50; total time=  16.2s\n",
            "[CV] END learning_rate=0.05, max_depth=8, min_data_in_leaf=100, n_estimators=500, num_leaves=50; total time=  15.9s\n",
            "[CV] END learning_rate=0.05, max_depth=8, min_data_in_leaf=100, n_estimators=500, num_leaves=50; total time=  16.0s\n",
            "[CV] END learning_rate=0.5, max_depth=15, min_data_in_leaf=100, n_estimators=100, num_leaves=50; total time=   3.6s\n",
            "[CV] END learning_rate=0.5, max_depth=15, min_data_in_leaf=100, n_estimators=100, num_leaves=50; total time=   3.4s\n",
            "[CV] END learning_rate=0.5, max_depth=15, min_data_in_leaf=100, n_estimators=100, num_leaves=50; total time=   3.5s\n",
            "[CV] END learning_rate=0.05, max_depth=5, min_data_in_leaf=20, n_estimators=2000, num_leaves=500; total time=  52.1s\n",
            "[CV] END learning_rate=0.05, max_depth=5, min_data_in_leaf=20, n_estimators=2000, num_leaves=500; total time=  49.7s\n",
            "[CV] END learning_rate=0.05, max_depth=5, min_data_in_leaf=20, n_estimators=2000, num_leaves=500; total time=  49.3s\n",
            "[CV] END learning_rate=0.05, max_depth=10, min_data_in_leaf=10, n_estimators=500, num_leaves=500; total time=  32.1s\n",
            "[CV] END learning_rate=0.05, max_depth=10, min_data_in_leaf=10, n_estimators=500, num_leaves=500; total time=  31.3s\n",
            "[CV] END learning_rate=0.05, max_depth=10, min_data_in_leaf=10, n_estimators=500, num_leaves=500; total time=  30.9s\n",
            "[CV] END learning_rate=0.25, max_depth=15, min_data_in_leaf=20, n_estimators=750, num_leaves=500; total time=  25.3s\n",
            "[CV] END learning_rate=0.25, max_depth=15, min_data_in_leaf=20, n_estimators=750, num_leaves=500; total time=  26.6s\n",
            "[CV] END learning_rate=0.25, max_depth=15, min_data_in_leaf=20, n_estimators=750, num_leaves=500; total time=  26.7s\n",
            "[CV] END learning_rate=0.01, max_depth=20, min_data_in_leaf=25, n_estimators=750, num_leaves=10; total time=  19.1s\n",
            "[CV] END learning_rate=0.01, max_depth=20, min_data_in_leaf=25, n_estimators=750, num_leaves=10; total time=  16.6s\n",
            "[CV] END learning_rate=0.01, max_depth=20, min_data_in_leaf=25, n_estimators=750, num_leaves=10; total time=  16.5s\n",
            "[CV] END learning_rate=0.15, max_depth=20, min_data_in_leaf=20, n_estimators=750, num_leaves=200; total time=  27.4s\n",
            "[CV] END learning_rate=0.15, max_depth=20, min_data_in_leaf=20, n_estimators=750, num_leaves=200; total time=  28.8s\n",
            "[CV] END learning_rate=0.15, max_depth=20, min_data_in_leaf=20, n_estimators=750, num_leaves=200; total time=  29.0s\n",
            "[CV] END learning_rate=0.05, max_depth=20, min_data_in_leaf=50, n_estimators=1000, num_leaves=500; total time= 1.7min\n",
            "[CV] END learning_rate=0.05, max_depth=20, min_data_in_leaf=50, n_estimators=1000, num_leaves=500; total time= 1.4min\n",
            "[CV] END learning_rate=0.05, max_depth=20, min_data_in_leaf=50, n_estimators=1000, num_leaves=500; total time= 1.0min\n",
            "[CV] END learning_rate=0.2, max_depth=3, min_data_in_leaf=10, n_estimators=1000, num_leaves=10; total time=  17.2s\n",
            "[CV] END learning_rate=0.2, max_depth=3, min_data_in_leaf=10, n_estimators=1000, num_leaves=10; total time=  19.7s\n",
            "[CV] END learning_rate=0.2, max_depth=3, min_data_in_leaf=10, n_estimators=1000, num_leaves=10; total time=  17.2s\n",
            "[CV] END learning_rate=0.25, max_depth=3, min_data_in_leaf=20, n_estimators=750, num_leaves=31; total time=  12.8s\n",
            "[CV] END learning_rate=0.25, max_depth=3, min_data_in_leaf=20, n_estimators=750, num_leaves=31; total time=  13.0s\n",
            "[CV] END learning_rate=0.25, max_depth=3, min_data_in_leaf=20, n_estimators=750, num_leaves=31; total time=  16.9s\n",
            "[CV] END learning_rate=0.2, max_depth=15, min_data_in_leaf=100, n_estimators=1000, num_leaves=500; total time=  35.2s\n",
            "[CV] END learning_rate=0.2, max_depth=15, min_data_in_leaf=100, n_estimators=1000, num_leaves=500; total time=  36.8s\n",
            "[CV] END learning_rate=0.2, max_depth=15, min_data_in_leaf=100, n_estimators=1000, num_leaves=500; total time=  37.9s\n",
            "[CV] END learning_rate=0.1, max_depth=3, min_data_in_leaf=100, n_estimators=500, num_leaves=50; total time=   8.8s\n",
            "[CV] END learning_rate=0.1, max_depth=3, min_data_in_leaf=100, n_estimators=500, num_leaves=50; total time=   8.7s\n",
            "[CV] END learning_rate=0.1, max_depth=3, min_data_in_leaf=100, n_estimators=500, num_leaves=50; total time=   8.8s\n",
            "[CV] END learning_rate=0.2, max_depth=8, min_data_in_leaf=100, n_estimators=1000, num_leaves=200; total time=  34.0s\n",
            "[CV] END learning_rate=0.2, max_depth=8, min_data_in_leaf=100, n_estimators=1000, num_leaves=200; total time=  31.6s\n",
            "[CV] END learning_rate=0.2, max_depth=8, min_data_in_leaf=100, n_estimators=1000, num_leaves=200; total time=  31.5s\n",
            "[CV] END learning_rate=0.3, max_depth=3, min_data_in_leaf=100, n_estimators=500, num_leaves=200; total time=   8.8s\n",
            "[CV] END learning_rate=0.3, max_depth=3, min_data_in_leaf=100, n_estimators=500, num_leaves=200; total time=   8.8s\n",
            "[CV] END learning_rate=0.3, max_depth=3, min_data_in_leaf=100, n_estimators=500, num_leaves=200; total time=   8.9s\n",
            "[CV] END learning_rate=0.15, max_depth=1, min_data_in_leaf=10, n_estimators=1000, num_leaves=10; total time=  11.6s\n",
            "[CV] END learning_rate=0.15, max_depth=1, min_data_in_leaf=10, n_estimators=1000, num_leaves=10; total time=  11.6s\n",
            "[CV] END learning_rate=0.15, max_depth=1, min_data_in_leaf=10, n_estimators=1000, num_leaves=10; total time=  14.4s\n",
            "[CV] END learning_rate=0.3, max_depth=20, min_data_in_leaf=50, n_estimators=100, num_leaves=50; total time=   3.6s\n",
            "[CV] END learning_rate=0.3, max_depth=20, min_data_in_leaf=50, n_estimators=100, num_leaves=50; total time=   3.6s\n",
            "[CV] END learning_rate=0.3, max_depth=20, min_data_in_leaf=50, n_estimators=100, num_leaves=50; total time=   3.7s\n",
            "[CV] END learning_rate=0.25, max_depth=15, min_data_in_leaf=20, n_estimators=750, num_leaves=100; total time=  24.0s\n",
            "[CV] END learning_rate=0.25, max_depth=15, min_data_in_leaf=20, n_estimators=750, num_leaves=100; total time=  25.1s\n",
            "[CV] END learning_rate=0.25, max_depth=15, min_data_in_leaf=20, n_estimators=750, num_leaves=100; total time=  25.2s\n",
            "[CV] END learning_rate=0.2, max_depth=10, min_data_in_leaf=25, n_estimators=1000, num_leaves=100; total time=  31.4s\n",
            "[CV] END learning_rate=0.2, max_depth=10, min_data_in_leaf=25, n_estimators=1000, num_leaves=100; total time=  34.2s\n",
            "[CV] END learning_rate=0.2, max_depth=10, min_data_in_leaf=25, n_estimators=1000, num_leaves=100; total time=  32.2s\n",
            "[CV] END learning_rate=0.5, max_depth=10, min_data_in_leaf=10, n_estimators=1000, num_leaves=200; total time=  12.5s\n",
            "[CV] END learning_rate=0.5, max_depth=10, min_data_in_leaf=10, n_estimators=1000, num_leaves=200; total time=  30.6s\n",
            "[CV] END learning_rate=0.5, max_depth=10, min_data_in_leaf=10, n_estimators=1000, num_leaves=200; total time=  18.3s\n",
            "[CV] END learning_rate=0.15, max_depth=3, min_data_in_leaf=10, n_estimators=750, num_leaves=500; total time=  13.0s\n",
            "[CV] END learning_rate=0.15, max_depth=3, min_data_in_leaf=10, n_estimators=750, num_leaves=500; total time=  14.9s\n",
            "[CV] END learning_rate=0.15, max_depth=3, min_data_in_leaf=10, n_estimators=750, num_leaves=500; total time=  13.4s\n",
            "[CV] END learning_rate=0.05, max_depth=5, min_data_in_leaf=10, n_estimators=500, num_leaves=500; total time=  12.2s\n",
            "[CV] END learning_rate=0.05, max_depth=5, min_data_in_leaf=10, n_estimators=500, num_leaves=500; total time=  28.1s\n",
            "[CV] END learning_rate=0.05, max_depth=5, min_data_in_leaf=10, n_estimators=500, num_leaves=500; total time=  12.0s\n",
            "[CV] END learning_rate=0.01, max_depth=1, min_data_in_leaf=25, n_estimators=500, num_leaves=10; total time=   6.1s\n",
            "[CV] END learning_rate=0.01, max_depth=1, min_data_in_leaf=25, n_estimators=500, num_leaves=10; total time=   6.2s\n",
            "[CV] END learning_rate=0.01, max_depth=1, min_data_in_leaf=25, n_estimators=500, num_leaves=10; total time=   6.1s\n",
            "[CV] END learning_rate=0.01, max_depth=15, min_data_in_leaf=100, n_estimators=1000, num_leaves=200; total time=  53.5s\n",
            "[CV] END learning_rate=0.01, max_depth=15, min_data_in_leaf=100, n_estimators=1000, num_leaves=200; total time=  56.0s\n",
            "[CV] END learning_rate=0.01, max_depth=15, min_data_in_leaf=100, n_estimators=1000, num_leaves=200; total time=  54.2s\n",
            "[CV] END learning_rate=0.1, max_depth=1, min_data_in_leaf=25, n_estimators=2000, num_leaves=10; total time=  22.8s\n",
            "[CV] END learning_rate=0.1, max_depth=1, min_data_in_leaf=25, n_estimators=2000, num_leaves=10; total time=  22.7s\n",
            "[CV] END learning_rate=0.1, max_depth=1, min_data_in_leaf=25, n_estimators=2000, num_leaves=10; total time=  22.8s\n",
            "[CV] END learning_rate=0.5, max_depth=8, min_data_in_leaf=100, n_estimators=500, num_leaves=10; total time=   8.5s\n",
            "[CV] END learning_rate=0.5, max_depth=8, min_data_in_leaf=100, n_estimators=500, num_leaves=10; total time=   8.3s\n",
            "[CV] END learning_rate=0.5, max_depth=8, min_data_in_leaf=100, n_estimators=500, num_leaves=10; total time=  11.4s\n",
            "[CV] END learning_rate=0.25, max_depth=15, min_data_in_leaf=25, n_estimators=1000, num_leaves=10; total time=  17.9s\n",
            "[CV] END learning_rate=0.25, max_depth=15, min_data_in_leaf=25, n_estimators=1000, num_leaves=10; total time=  16.4s\n",
            "[CV] END learning_rate=0.25, max_depth=15, min_data_in_leaf=25, n_estimators=1000, num_leaves=10; total time=  17.8s\n",
            "[CV] END learning_rate=0.15, max_depth=3, min_data_in_leaf=100, n_estimators=2000, num_leaves=100; total time=  34.4s\n",
            "[CV] END learning_rate=0.15, max_depth=3, min_data_in_leaf=100, n_estimators=2000, num_leaves=100; total time=  34.6s\n",
            "[CV] END learning_rate=0.15, max_depth=3, min_data_in_leaf=100, n_estimators=2000, num_leaves=100; total time=  37.2s\n",
            "[CV] END learning_rate=0.01, max_depth=10, min_data_in_leaf=50, n_estimators=750, num_leaves=500; total time=  42.4s\n",
            "[CV] END learning_rate=0.01, max_depth=10, min_data_in_leaf=50, n_estimators=750, num_leaves=500; total time=  42.5s\n",
            "[CV] END learning_rate=0.01, max_depth=10, min_data_in_leaf=50, n_estimators=750, num_leaves=500; total time=  43.1s\n",
            "[CV] END learning_rate=0.15, max_depth=10, min_data_in_leaf=25, n_estimators=100, num_leaves=200; total time=   5.1s\n",
            "[CV] END learning_rate=0.15, max_depth=10, min_data_in_leaf=25, n_estimators=100, num_leaves=200; total time=   5.1s\n",
            "[CV] END learning_rate=0.15, max_depth=10, min_data_in_leaf=25, n_estimators=100, num_leaves=200; total time=   7.9s\n",
            "[CV] END learning_rate=0.05, max_depth=15, min_data_in_leaf=50, n_estimators=100, num_leaves=200; total time=   6.4s\n",
            "[CV] END learning_rate=0.05, max_depth=15, min_data_in_leaf=50, n_estimators=100, num_leaves=200; total time=   6.7s\n",
            "[CV] END learning_rate=0.05, max_depth=15, min_data_in_leaf=50, n_estimators=100, num_leaves=200; total time=   5.2s\n",
            "[CV] END learning_rate=0.05, max_depth=5, min_data_in_leaf=25, n_estimators=2000, num_leaves=100; total time=  48.7s\n",
            "[CV] END learning_rate=0.05, max_depth=5, min_data_in_leaf=25, n_estimators=2000, num_leaves=100; total time=  49.3s\n",
            "[CV] END learning_rate=0.05, max_depth=5, min_data_in_leaf=25, n_estimators=2000, num_leaves=100; total time=  52.1s\n",
            "[CV] END learning_rate=0.1, max_depth=8, min_data_in_leaf=25, n_estimators=2000, num_leaves=50; total time=  59.2s\n",
            "[CV] END learning_rate=0.1, max_depth=8, min_data_in_leaf=25, n_estimators=2000, num_leaves=50; total time=  58.6s\n",
            "[CV] END learning_rate=0.1, max_depth=8, min_data_in_leaf=25, n_estimators=2000, num_leaves=50; total time= 1.0min\n",
            "[CV] END learning_rate=0.15, max_depth=3, min_data_in_leaf=10, n_estimators=100, num_leaves=200; total time=   2.2s\n",
            "[CV] END learning_rate=0.15, max_depth=3, min_data_in_leaf=10, n_estimators=100, num_leaves=200; total time=   2.2s\n",
            "[CV] END learning_rate=0.15, max_depth=3, min_data_in_leaf=10, n_estimators=100, num_leaves=200; total time=   2.2s\n",
            "[CV] END learning_rate=0.2, max_depth=20, min_data_in_leaf=100, n_estimators=500, num_leaves=100; total time=  19.0s\n",
            "[CV] END learning_rate=0.2, max_depth=20, min_data_in_leaf=100, n_estimators=500, num_leaves=100; total time=  19.3s\n",
            "[CV] END learning_rate=0.2, max_depth=20, min_data_in_leaf=100, n_estimators=500, num_leaves=100; total time=  19.3s\n",
            "[CV] END learning_rate=0.2, max_depth=20, min_data_in_leaf=20, n_estimators=1000, num_leaves=500; total time=  32.0s\n",
            "[CV] END learning_rate=0.2, max_depth=20, min_data_in_leaf=20, n_estimators=1000, num_leaves=500; total time=  37.3s\n",
            "[CV] END learning_rate=0.2, max_depth=20, min_data_in_leaf=20, n_estimators=1000, num_leaves=500; total time=  35.3s\n",
            "[CV] END learning_rate=0.2, max_depth=15, min_data_in_leaf=10, n_estimators=500, num_leaves=500; total time=  19.6s\n",
            "[CV] END learning_rate=0.2, max_depth=15, min_data_in_leaf=10, n_estimators=500, num_leaves=500; total time=  20.2s\n",
            "[CV] END learning_rate=0.2, max_depth=15, min_data_in_leaf=10, n_estimators=500, num_leaves=500; total time=  20.3s\n",
            "[CV] END learning_rate=0.3, max_depth=15, min_data_in_leaf=25, n_estimators=500, num_leaves=100; total time=  16.8s\n",
            "[CV] END learning_rate=0.3, max_depth=15, min_data_in_leaf=25, n_estimators=500, num_leaves=100; total time=  17.4s\n",
            "[CV] END learning_rate=0.3, max_depth=15, min_data_in_leaf=25, n_estimators=500, num_leaves=100; total time=  20.3s\n",
            "[CV] END learning_rate=0.05, max_depth=10, min_data_in_leaf=25, n_estimators=750, num_leaves=31; total time=  20.5s\n",
            "[CV] END learning_rate=0.05, max_depth=10, min_data_in_leaf=25, n_estimators=750, num_leaves=31; total time=  20.4s\n",
            "[CV] END learning_rate=0.05, max_depth=10, min_data_in_leaf=25, n_estimators=750, num_leaves=31; total time=  20.3s\n",
            "[CV] END learning_rate=0.1, max_depth=15, min_data_in_leaf=50, n_estimators=750, num_leaves=500; total time=  35.5s\n",
            "[CV] END learning_rate=0.1, max_depth=15, min_data_in_leaf=50, n_estimators=750, num_leaves=500; total time=  36.7s\n",
            "[CV] END learning_rate=0.1, max_depth=15, min_data_in_leaf=50, n_estimators=750, num_leaves=500; total time=  39.6s\n",
            "[CV] END learning_rate=0.3, max_depth=5, min_data_in_leaf=20, n_estimators=100, num_leaves=10; total time=   2.4s\n",
            "[CV] END learning_rate=0.3, max_depth=5, min_data_in_leaf=20, n_estimators=100, num_leaves=10; total time=   2.4s\n",
            "[CV] END learning_rate=0.3, max_depth=5, min_data_in_leaf=20, n_estimators=100, num_leaves=10; total time=   2.4s\n",
            "[CV] END learning_rate=0.2, max_depth=8, min_data_in_leaf=10, n_estimators=2000, num_leaves=31; total time=  51.3s\n",
            "[CV] END learning_rate=0.2, max_depth=8, min_data_in_leaf=10, n_estimators=2000, num_leaves=31; total time=  51.3s\n",
            "[CV] END learning_rate=0.2, max_depth=8, min_data_in_leaf=10, n_estimators=2000, num_leaves=31; total time=  54.5s\n",
            "[CV] END learning_rate=0.15, max_depth=5, min_data_in_leaf=50, n_estimators=2000, num_leaves=100; total time=  47.6s\n",
            "[CV] END learning_rate=0.15, max_depth=5, min_data_in_leaf=50, n_estimators=2000, num_leaves=100; total time=  47.7s\n",
            "[CV] END learning_rate=0.15, max_depth=5, min_data_in_leaf=50, n_estimators=2000, num_leaves=100; total time=  50.8s\n",
            "[CV] END learning_rate=0.05, max_depth=20, min_data_in_leaf=20, n_estimators=500, num_leaves=200; total time=  28.6s\n",
            "[CV] END learning_rate=0.05, max_depth=20, min_data_in_leaf=20, n_estimators=500, num_leaves=200; total time=  28.7s\n",
            "[CV] END learning_rate=0.05, max_depth=20, min_data_in_leaf=20, n_estimators=500, num_leaves=200; total time=  29.1s\n",
            "[CV] END learning_rate=0.05, max_depth=3, min_data_in_leaf=20, n_estimators=750, num_leaves=200; total time=  13.0s\n",
            "[CV] END learning_rate=0.05, max_depth=3, min_data_in_leaf=20, n_estimators=750, num_leaves=200; total time=  13.0s\n",
            "[CV] END learning_rate=0.05, max_depth=3, min_data_in_leaf=20, n_estimators=750, num_leaves=200; total time=  15.6s\n",
            "[CV] END learning_rate=0.5, max_depth=5, min_data_in_leaf=20, n_estimators=2000, num_leaves=31; total time=  22.0s\n",
            "[CV] END learning_rate=0.5, max_depth=5, min_data_in_leaf=20, n_estimators=2000, num_leaves=31; total time=  21.7s\n",
            "[CV] END learning_rate=0.5, max_depth=5, min_data_in_leaf=20, n_estimators=2000, num_leaves=31; total time=  22.0s\n",
            "[CV] END learning_rate=0.2, max_depth=20, min_data_in_leaf=25, n_estimators=500, num_leaves=500; total time=  19.3s\n",
            "[CV] END learning_rate=0.2, max_depth=20, min_data_in_leaf=25, n_estimators=500, num_leaves=500; total time=  20.8s\n",
            "[CV] END learning_rate=0.2, max_depth=20, min_data_in_leaf=25, n_estimators=500, num_leaves=500; total time=  20.5s\n",
            "[CV] END learning_rate=0.3, max_depth=15, min_data_in_leaf=25, n_estimators=100, num_leaves=100; total time=   4.6s\n",
            "[CV] END learning_rate=0.3, max_depth=15, min_data_in_leaf=25, n_estimators=100, num_leaves=100; total time=   4.5s\n",
            "[CV] END learning_rate=0.3, max_depth=15, min_data_in_leaf=25, n_estimators=100, num_leaves=100; total time=   4.6s\n",
            "[CV] END learning_rate=0.2, max_depth=1, min_data_in_leaf=25, n_estimators=100, num_leaves=31; total time=   1.6s\n",
            "[CV] END learning_rate=0.2, max_depth=1, min_data_in_leaf=25, n_estimators=100, num_leaves=31; total time=   1.6s\n",
            "[CV] END learning_rate=0.2, max_depth=1, min_data_in_leaf=25, n_estimators=100, num_leaves=31; total time=   1.6s\n",
            "[CV] END learning_rate=0.15, max_depth=3, min_data_in_leaf=100, n_estimators=750, num_leaves=50; total time=  15.6s\n",
            "[CV] END learning_rate=0.15, max_depth=3, min_data_in_leaf=100, n_estimators=750, num_leaves=50; total time=  12.8s\n",
            "[CV] END learning_rate=0.15, max_depth=3, min_data_in_leaf=100, n_estimators=750, num_leaves=50; total time=  12.8s\n",
            "[CV] END learning_rate=0.15, max_depth=20, min_data_in_leaf=20, n_estimators=100, num_leaves=10; total time=   2.5s\n",
            "[CV] END learning_rate=0.15, max_depth=20, min_data_in_leaf=20, n_estimators=100, num_leaves=10; total time=   2.5s\n",
            "[CV] END learning_rate=0.15, max_depth=20, min_data_in_leaf=20, n_estimators=100, num_leaves=10; total time=   2.5s\n",
            "[CV] END learning_rate=0.1, max_depth=5, min_data_in_leaf=10, n_estimators=500, num_leaves=200; total time=  11.9s\n",
            "[CV] END learning_rate=0.1, max_depth=5, min_data_in_leaf=10, n_estimators=500, num_leaves=200; total time=  11.9s\n",
            "[CV] END learning_rate=0.1, max_depth=5, min_data_in_leaf=10, n_estimators=500, num_leaves=200; total time=  12.0s\n",
            "[CV] END learning_rate=0.5, max_depth=20, min_data_in_leaf=100, n_estimators=2000, num_leaves=10; total time=  25.2s\n",
            "[CV] END learning_rate=0.5, max_depth=20, min_data_in_leaf=100, n_estimators=2000, num_leaves=10; total time=  26.0s\n",
            "[CV] END learning_rate=0.5, max_depth=20, min_data_in_leaf=100, n_estimators=2000, num_leaves=10; total time=  24.6s\n",
            "[CV] END learning_rate=0.5, max_depth=8, min_data_in_leaf=50, n_estimators=100, num_leaves=50; total time=   6.3s\n",
            "[CV] END learning_rate=0.5, max_depth=8, min_data_in_leaf=50, n_estimators=100, num_leaves=50; total time=   3.5s\n",
            "[CV] END learning_rate=0.5, max_depth=8, min_data_in_leaf=50, n_estimators=100, num_leaves=50; total time=   3.5s\n",
            "[CV] END learning_rate=0.1, max_depth=10, min_data_in_leaf=20, n_estimators=750, num_leaves=100; total time=  29.0s\n",
            "[CV] END learning_rate=0.1, max_depth=10, min_data_in_leaf=20, n_estimators=750, num_leaves=100; total time=  28.9s\n",
            "[CV] END learning_rate=0.1, max_depth=10, min_data_in_leaf=20, n_estimators=750, num_leaves=100; total time=  29.2s\n",
            "[CV] END learning_rate=0.3, max_depth=3, min_data_in_leaf=50, n_estimators=1000, num_leaves=10; total time=  17.1s\n",
            "[CV] END learning_rate=0.3, max_depth=3, min_data_in_leaf=50, n_estimators=1000, num_leaves=10; total time=  17.2s\n",
            "[CV] END learning_rate=0.3, max_depth=3, min_data_in_leaf=50, n_estimators=1000, num_leaves=10; total time=  16.6s\n",
            "[CV] END learning_rate=0.1, max_depth=5, min_data_in_leaf=25, n_estimators=2000, num_leaves=10; total time=  39.2s\n",
            "[CV] END learning_rate=0.1, max_depth=5, min_data_in_leaf=25, n_estimators=2000, num_leaves=10; total time=  36.2s\n",
            "[CV] END learning_rate=0.1, max_depth=5, min_data_in_leaf=25, n_estimators=2000, num_leaves=10; total time=  36.3s\n",
            "[CV] END learning_rate=0.3, max_depth=3, min_data_in_leaf=100, n_estimators=100, num_leaves=10; total time=   2.2s\n",
            "[CV] END learning_rate=0.3, max_depth=3, min_data_in_leaf=100, n_estimators=100, num_leaves=10; total time=   2.1s\n",
            "[CV] END learning_rate=0.3, max_depth=3, min_data_in_leaf=100, n_estimators=100, num_leaves=10; total time=   2.1s\n",
            "[CV] END learning_rate=0.05, max_depth=20, min_data_in_leaf=25, n_estimators=500, num_leaves=50; total time=  16.4s\n",
            "[CV] END learning_rate=0.05, max_depth=20, min_data_in_leaf=25, n_estimators=500, num_leaves=50; total time=  16.5s\n",
            "[CV] END learning_rate=0.05, max_depth=20, min_data_in_leaf=25, n_estimators=500, num_leaves=50; total time=  19.2s\n",
            "[CV] END learning_rate=0.05, max_depth=15, min_data_in_leaf=50, n_estimators=2000, num_leaves=31; total time=  51.3s\n",
            "[CV] END learning_rate=0.05, max_depth=15, min_data_in_leaf=50, n_estimators=2000, num_leaves=31; total time=  51.7s\n",
            "[CV] END learning_rate=0.05, max_depth=15, min_data_in_leaf=50, n_estimators=2000, num_leaves=31; total time=  54.7s\n",
            "[CV] END learning_rate=0.2, max_depth=8, min_data_in_leaf=10, n_estimators=500, num_leaves=10; total time=   9.4s\n",
            "[CV] END learning_rate=0.2, max_depth=8, min_data_in_leaf=10, n_estimators=500, num_leaves=10; total time=   9.6s\n",
            "[CV] END learning_rate=0.2, max_depth=8, min_data_in_leaf=10, n_estimators=500, num_leaves=10; total time=   9.4s\n",
            "[CV] END learning_rate=0.3, max_depth=3, min_data_in_leaf=25, n_estimators=2000, num_leaves=10; total time=  35.1s\n",
            "[CV] END learning_rate=0.3, max_depth=3, min_data_in_leaf=25, n_estimators=2000, num_leaves=10; total time=  45.0s\n",
            "[CV] END learning_rate=0.3, max_depth=3, min_data_in_leaf=25, n_estimators=2000, num_leaves=10; total time=  27.6s\n",
            "[CV] END learning_rate=0.5, max_depth=8, min_data_in_leaf=10, n_estimators=500, num_leaves=200; total time=  14.5s\n",
            "[CV] END learning_rate=0.5, max_depth=8, min_data_in_leaf=10, n_estimators=500, num_leaves=200; total time=  12.1s\n",
            "[CV] END learning_rate=0.5, max_depth=8, min_data_in_leaf=10, n_estimators=500, num_leaves=200; total time=   8.9s\n",
            "[CV] END learning_rate=0.15, max_depth=1, min_data_in_leaf=10, n_estimators=100, num_leaves=500; total time=   1.6s\n",
            "[CV] END learning_rate=0.15, max_depth=1, min_data_in_leaf=10, n_estimators=100, num_leaves=500; total time=   1.6s\n",
            "[CV] END learning_rate=0.15, max_depth=1, min_data_in_leaf=10, n_estimators=100, num_leaves=500; total time=   1.6s\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'num_leaves': 500,\n",
              " 'n_estimators': 100,\n",
              " 'min_data_in_leaf': 100,\n",
              " 'max_depth': 10,\n",
              " 'learning_rate': 0.2}"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lightgbm_random.best_params_"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gosX6phBODjz",
        "outputId": "baf566dc-21d7-426d-a89a-52526b2f3528"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'num_leaves': 500,\n",
              " 'n_estimators': 100,\n",
              " 'min_data_in_leaf': 100,\n",
              " 'max_depth': 10,\n",
              " 'learning_rate': 0.2}"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lightgbm_random.best_score_"
      ],
      "metadata": {
        "id": "raSCdJiuPsjy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Artificial Neural Network\n",
        "\n",
        "- Library: Keras, Tensorflow"
      ],
      "metadata": {
        "id": "QpthCMRHuhWe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tf.random.set_seed(10)\n",
        "\n",
        "print(tf.__version__)\n",
        "print(keras.__version__)"
      ],
      "metadata": {
        "id": "fJ6kS48GZVH3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Experiment 1: Base Model"
      ],
      "metadata": {
        "id": "vivojhGnfeEz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train.info()"
      ],
      "metadata": {
        "id": "XO7_fl_pfaEP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ann_clf = keras.models.Sequential([\n",
        "    keras.layers.Dense(15, input_shape=(X_train.shape[1],), activation='relu'), # No bias term\n",
        "    keras.layers.Dense(10, activation='relu'), \n",
        "    keras.layers.Dense(10, activation='relu'), \n",
        "    keras.layers.Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "ann_clf.summary()"
      ],
      "metadata": {
        "id": "OVpParvzfhtl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ann_clf.layers"
      ],
      "metadata": {
        "id": "eLJhQfiHfi14"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ann_clf.compile(optimizer = 'adam',\n",
        "#                 metrics=['accuracy'],\n",
        "#                 loss = 'binary_crossentropy')\n",
        "\n",
        "ann_clf.compile(optimizer = 'adam', \n",
        "                loss ='binary_crossentropy',\n",
        "                metrics=[tf.keras.metrics.Accuracy(), tf.keras.metrics.Recall()])\n",
        "\n",
        "record = ann_clf.fit(\n",
        "            X_train, \n",
        "            y_train, \n",
        "            validation_data = (X_val, y_val), \n",
        "            batch_size = 10, \n",
        "            epochs = 50)"
      ],
      "metadata": {
        "id": "bK1SXteMfln5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "keras.utils.plot_model(ann_clf, show_shapes=True, rankdir=\"LR\")"
      ],
      "metadata": {
        "id": "ChuhGr3Ufmgq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "_, train_acc = ann_clf.evaluate(X_train, y_train, verbose=0)\n",
        "_, val_acc = ann_clf.evaluate(X_val, y_val, verbose=0)\n",
        "_, test_acc = ann_clf.evaluate(X_test, y_test, verbose=0)\n",
        "print('Train: %.3f, Validation: %.3f, Test: %.3f' % (train_acc, val_acc, test_acc))"
      ],
      "metadata": {
        "id": "rsSZTcIlfnQa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(record.history['accuracy'], label='Training')\n",
        "plt.plot(record.history['val_accuracy'], label='Validation')\n",
        "plt.legend()\n",
        "plt.xlabel('Epochs', fontsize=16)\n",
        "plt.ylabel('Accuracy', fontsize=16)\n",
        "plt.title('Accuracy Curves', fontsize=16)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Jvmnf03BfoDj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# plot training history\n",
        "plt.plot(record.history['loss'], label='Training')\n",
        "plt.plot(record.history['val_loss'], label='Validation')\n",
        "plt.legend()\n",
        "plt.xlabel('Epochs', fontsize=14)\n",
        "plt.ylabel('Loss', fontsize=14)\n",
        "plt.title('Loss Curves', fontsize=16)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Bk9KBNCCfpw5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Experiment 2: Different Batch Sizes"
      ],
      "metadata": {
        "id": "hy1WHdJSfrl1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Fit a Model and Plot Learning Curve\n",
        "\n",
        "def fit_model_1(X_train, y_train, X_val, y_val, n_batch):\n",
        "  \n",
        "  # Define Model\n",
        "  ann_clf = keras.models.Sequential([\n",
        "      keras.layers.Dense(15, input_shape=(X_train.shape[1],), activation='relu'), # No bias term\n",
        "      keras.layers.Dense(10, activation='relu'), \n",
        "      keras.layers.Dense(10, activation='relu'), \n",
        "      keras.layers.Dense(1, activation='sigmoid')\n",
        "  ])\n",
        "\n",
        "  # Compile Model\n",
        "  ann_clf.compile(optimizer = 'adam', \n",
        "                  loss ='binary_crossentropy',\n",
        "                  metrics=[tf.keras.metrics.Accuracy(), tf.keras.metrics.Recall()])\n",
        "\n",
        "  \n",
        "  # Fit Model\n",
        "  history = ann_clf.fit(X_train,\n",
        "                      y_train,\n",
        "                      validation_data=(X_val, y_val),\n",
        "                      epochs=100,\n",
        "                      verbose=0,\n",
        "                      batch_size=n_batch)\n",
        "\n",
        "  # Plot Learning Curves\n",
        "  plt.plot(history.history['accuracy'], label='train') \n",
        "  plt.plot(history.history['val_accuracy'], label='test') \n",
        "  plt.title('batch='+str(n_batch)) \n",
        "  plt.legend()"
      ],
      "metadata": {
        "id": "EbpRvs_nfsV4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create Learning Curves for Different Batch Sizes\n",
        "\n",
        "# batch_sizes = [4, 6, 10, 16, 32, 64, 128, 260]\n",
        "batch_sizes = [5, 10, 15, 20, 25, 30]\n",
        "\n",
        "plt.figure(figsize=(10,15))\n",
        "for i in range(len(batch_sizes)):\n",
        "\n",
        "  # Determine the Plot Number\n",
        "  plot_no = 420 + (i+1)\n",
        "  plt.subplot(plot_no)\n",
        "\n",
        "  # Fit Model and Plot Learning Curves for a Batch Size\n",
        "  fit_model_1(X_train, y_train, X_val, y_val, batch_sizes[i])\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "govzlyT3fwI0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Experiment 3: Different EPOCHs"
      ],
      "metadata": {
        "id": "jDdPwZjcfxsF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Fit a Model and Plot Learning Curve\n",
        "\n",
        "def fit_model_2(X_train, y_train, X_val, y_val, n_epoch):\n",
        "\n",
        "  # Define Model\n",
        "  ann_clf = keras.models.Sequential([\n",
        "      keras.layers.Dense(15, input_shape=(X_train.shape[1],), activation='relu'), # No bias term\n",
        "      keras.layers.Dense(10, activation='relu'), \n",
        "      keras.layers.Dense(10, activation='relu'), \n",
        "      keras.layers.Dense(1, activation='sigmoid')\n",
        "  ])\n",
        "\n",
        "  # Compile Model\n",
        "  ann_clf.compile(optimizer = 'adam', \n",
        "                  loss ='binary_crossentropy',\n",
        "                  metrics=[tf.keras.metrics.Accuracy(), tf.keras.metrics.Recall()])\n",
        "\n",
        "    \n",
        "  # Fit Model\n",
        "  history = ann_clf.fit(X_train,\n",
        "                      y_train,\n",
        "                      validation_data=(X_val, y_val),\n",
        "                      epochs=n_epoch,\n",
        "                      verbose=0,\n",
        "                      batch_size=6)\n",
        "    \n",
        "  # Plot Learning Curves\n",
        "  plt.plot(history.history['accuracy'], label='train')\n",
        "  plt.plot(history.history['val_accuracy'], label='test')\n",
        "  plt.title('epoch='+str(n_epoch))\n",
        "  plt.legend()"
      ],
      "metadata": {
        "id": "gjSGc9u6fxTv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create Learning Curves for Different EPOCHs\n",
        "\n",
        "# epochs = [20, 50, 100, 120, 150, 200, 300, 400]\n",
        "epochs = [20, 50, 80, 100, 150, 200]\n",
        "\n",
        "plt.figure(figsize=(10,15))\n",
        "for i in range(len(batch_sizes)):\n",
        "\n",
        "  # Determine the Plot Number\n",
        "  plot_no = 420 + (i+1)\n",
        "  plt.subplot(plot_no)\n",
        "\n",
        "  # Fit Model and Plot Learning Curves for an EPOCH\n",
        "  fit_model_2(X_train, y_train, X_val, y_val, epochs[i])\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "SP2zm_ySfznt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Experiment 4: Early Stopping"
      ],
      "metadata": {
        "id": "3_QvFWOmf0JZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.callbacks import EarlyStopping\n",
        "from keras.callbacks import ModelCheckpoint"
      ],
      "metadata": {
        "id": "3AUOp_Qwf2_U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def fit_model_3():\n",
        "\n",
        "  # Define Model\n",
        "  ann_clf = keras.models.Sequential([\n",
        "      keras.layers.Dense(15, input_shape=(X_train.shape[1],), activation='relu'), # No bias term\n",
        "      keras.layers.Dense(10, activation='relu'), \n",
        "      keras.layers.Dense(10, activation='relu'), \n",
        "      keras.layers.Dropout(0.2),\n",
        "      keras.layers.Dense(1, activation='sigmoid')\n",
        "  ])\n",
        "\n",
        "  # Compile Model\n",
        "  ann_clf.compile(optimizer = 'adam', \n",
        "                  loss ='binary_crossentropy',\n",
        "                  metrics=[tf.keras.metrics.Accuracy(), tf.keras.metrics.Recall()])\n",
        "\n",
        "  return ann_clf\n",
        "\n",
        "ann_clf = fit_model_3()\n",
        "\n",
        "es = EarlyStopping(monitor='val_loss',\n",
        "                   mode='min',\n",
        "                   verbose=1,\n",
        "                   patience=150)\n",
        "\n",
        "mc = ModelCheckpoint('best_model.h5',\n",
        "                     monitor='val_accuracy',\n",
        "                     mode='max',\n",
        "                     verbose=1,\n",
        "                     save_best_only=True)\n",
        "\n",
        "history = ann_clf.fit(X_train,\n",
        "                    y_train,\n",
        "                    validation_data=(X_val, y_val),\n",
        "                    epochs=50,\n",
        "                    verbose=0,\n",
        "                    batch_size=25,\n",
        "                    callbacks=[es, mc])"
      ],
      "metadata": {
        "id": "8uidzovhf4S6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# plot training history\n",
        "plt.plot(history.history['loss'], label='Training')\n",
        "plt.plot(history.history['val_loss'], label='Validation')\n",
        "plt.legend()\n",
        "plt.xlabel('Epochs', fontsize=14)\n",
        "plt.ylabel('Loss', fontsize=14)\n",
        "plt.title('Loss Curves', fontsize=16)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "JAVLJDzLf6Ce"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=[8,5])\n",
        "plt.plot(history.history['accuracy'], label='Training')\n",
        "plt.plot(history.history['val_accuracy'], label='Validation')\n",
        "plt.legend()\n",
        "plt.xlabel('Epochs', fontsize=16)\n",
        "plt.ylabel('Accuracy', fontsize=16)\n",
        "plt.title('Accuracy Curves', fontsize=16)\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "sPPqcZCyf6zy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Voting Classifier\n",
        "\n",
        "- Library: Scikit-learn, Keras, Tensorflow\n",
        "- Shuffling does not affect the model building. No random_state.\n",
        "- No need for RandomizedSearchCV since there is only 1 important parameter: voting"
      ],
      "metadata": {
        "id": "4rBdGe3Gukv6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "display(models_eval)"
      ],
      "metadata": {
        "id": "YCHV8rR-ZU5c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Re-Train Top 3 Models Using Their Parameters Specifically\n",
        "\n",
        "model_1 = LGBMClassifier(n_estimators=1000, learning_rate=0.1, max_depth=3, random_state=10)\n",
        "model_2 = GradientBoostingClassifier(n_estimators=500, learning_rate=0.5, max_depth=1, random_state=10)\n",
        "model_3 = RandomForestClassifier(n_estimators=1000, max_depth = None, n_jobs =-1, random_state=10)\n",
        "\n",
        "name = 'ensem_clf'\n",
        "\n",
        "train = pd.DataFrame(columns = ['voting', 'n_jobs'])\n",
        "train = train.append({'voting': 'hard', 'n_jobs': -1}, ignore_index=True)\n",
        "train = train.append({'voting': 'soft', 'n_jobs': -1}, ignore_index=True)\n",
        "train = train.reset_index()\n",
        "\n",
        "for index, row in train.iterrows():\n",
        "    model_name = name + str(index)\n",
        "    ens_clf = VotingClassifier(estimators=[('m1', model_1), ('m2', model_2), ('m3', model_3)],\n",
        "                               voting = row['voting'],\n",
        "                               n_jobs = int(row['n_jobs']))\n",
        "    ens_clf.fit(X_train, y_train)\n",
        "    y_true = y_val\n",
        "    y_pred = ens_clf.predict(X_val)\n",
        "    evaluation_results = evaluation_metrics(y_true, y_pred)\n",
        "\n",
        "    models = models.append({'model_name': model_name, \n",
        "                            'model': ens_clf, \n",
        "                            'parameters': ens_clf.get_params()}, \n",
        "                            ignore_index=True)\n",
        "    \n",
        "    models_eval = models_eval.append({'model_name': model_name, \n",
        "                                      'confusion_matrix' : evaluation_results[0], \n",
        "                                      'accuracy': evaluation_results[1], \n",
        "                                      'recall' : evaluation_results[2], \n",
        "                                      'f1_score': evaluation_results[3], \n",
        "                                      'roc_auc_score': evaluation_results[4]}, \n",
        "                                      ignore_index=True)"
      ],
      "metadata": {
        "id": "YIe8XVe4gBMX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Result Discussions"
      ],
      "metadata": {
        "id": "VSpOrrm2gNXL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "display(models)"
      ],
      "metadata": {
        "id": "EZfBQi4KgLrV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "display(models_eval)"
      ],
      "metadata": {
        "id": "2LY9af70gM_6"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}