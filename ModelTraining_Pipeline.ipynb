{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyOF8QN1lga6OGnZdk8lgOKj"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Model Training & Evaluation Pipeline"
      ],
      "metadata": {
        "id": "COF7WWOtCQRP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Details: [Model Training Specifications](https://docs.google.com/document/d/1UiDi8nyTcfMeMNIAz3KntlVZBlYrpoMAURuDccTt-wk/edit?usp=sharing)\n",
        "\n",
        "Model Evaluation: Identify best parameters for each model"
      ],
      "metadata": {
        "id": "kNbJ7WYUXWks"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qK_KRJw0rpA9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ea8fb523-1f4b-47cb-ddb4-8ba062ea76d4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "# Basic Libraries\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sb\n",
        "import matplotlib.pyplot as plt\n",
        "from datetime import datetime\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Data Source\n",
        "\n",
        "df = pd.read_csv(\"/content/drive/MyDrive/Senior Project/Datasets/cleaned_gee_data.csv\")\n",
        "df = df.drop(columns = ['Unnamed: 0'], axis=1)\n",
        "df.head()"
      ],
      "metadata": {
        "id": "BTKpuPDqvTli",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "outputId": "8054cb66-b703-47f2-fb60-f3206276453c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   LATITUDE  LONGITUDE  ACQ_DATE  ACQ_TIME  OPEN_TIME  CLOSE_TIME  BRIGHTNESS  \\\n",
              "0 -5.466232  -0.176027 -1.866392  0.634294   0.506405    0.526945   -2.231078   \n",
              "1 -5.466232  -0.176027 -1.866392  0.634294   0.506405    0.526945   -2.231078   \n",
              "2 -5.466232  -0.176027 -1.866392  0.634294   0.506405    0.526945   -2.231078   \n",
              "3 -5.466232  -0.176027 -1.866392  0.634294   0.506405    0.526945   -2.231078   \n",
              "4 -5.433352  -0.197441 -1.723773  0.634294   2.286080    1.793843   -1.141613   \n",
              "\n",
              "   FIRE_OCCURRED  CO_MOL/M2  SO2_MOL/M2  NO2_MOL/M2  O3_MOL/M2  LOCATION  \\\n",
              "0              0  -0.024223   -0.474440   -1.152277  -0.511001 -1.159086   \n",
              "1              0   0.113599   -0.474440   -1.152277  -0.511001 -1.159086   \n",
              "2              0  -0.024223   -0.474440   -1.361255  -0.511001 -1.159086   \n",
              "3              0   0.113599   -0.474440   -1.361255  -0.511001 -1.159086   \n",
              "4              0  -0.967684    0.339667   -1.251770   0.426114 -1.159086   \n",
              "\n",
              "   INSTRUMENT  DRY_SEASON  \n",
              "0           0           1  \n",
              "1           0           1  \n",
              "2           0           1  \n",
              "3           0           1  \n",
              "4           0           1  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-462ef932-3160-4387-8a52-8a2bfb8fc8fc\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>LATITUDE</th>\n",
              "      <th>LONGITUDE</th>\n",
              "      <th>ACQ_DATE</th>\n",
              "      <th>ACQ_TIME</th>\n",
              "      <th>OPEN_TIME</th>\n",
              "      <th>CLOSE_TIME</th>\n",
              "      <th>BRIGHTNESS</th>\n",
              "      <th>FIRE_OCCURRED</th>\n",
              "      <th>CO_MOL/M2</th>\n",
              "      <th>SO2_MOL/M2</th>\n",
              "      <th>NO2_MOL/M2</th>\n",
              "      <th>O3_MOL/M2</th>\n",
              "      <th>LOCATION</th>\n",
              "      <th>INSTRUMENT</th>\n",
              "      <th>DRY_SEASON</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>-5.466232</td>\n",
              "      <td>-0.176027</td>\n",
              "      <td>-1.866392</td>\n",
              "      <td>0.634294</td>\n",
              "      <td>0.506405</td>\n",
              "      <td>0.526945</td>\n",
              "      <td>-2.231078</td>\n",
              "      <td>0</td>\n",
              "      <td>-0.024223</td>\n",
              "      <td>-0.474440</td>\n",
              "      <td>-1.152277</td>\n",
              "      <td>-0.511001</td>\n",
              "      <td>-1.159086</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>-5.466232</td>\n",
              "      <td>-0.176027</td>\n",
              "      <td>-1.866392</td>\n",
              "      <td>0.634294</td>\n",
              "      <td>0.506405</td>\n",
              "      <td>0.526945</td>\n",
              "      <td>-2.231078</td>\n",
              "      <td>0</td>\n",
              "      <td>0.113599</td>\n",
              "      <td>-0.474440</td>\n",
              "      <td>-1.152277</td>\n",
              "      <td>-0.511001</td>\n",
              "      <td>-1.159086</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>-5.466232</td>\n",
              "      <td>-0.176027</td>\n",
              "      <td>-1.866392</td>\n",
              "      <td>0.634294</td>\n",
              "      <td>0.506405</td>\n",
              "      <td>0.526945</td>\n",
              "      <td>-2.231078</td>\n",
              "      <td>0</td>\n",
              "      <td>-0.024223</td>\n",
              "      <td>-0.474440</td>\n",
              "      <td>-1.361255</td>\n",
              "      <td>-0.511001</td>\n",
              "      <td>-1.159086</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>-5.466232</td>\n",
              "      <td>-0.176027</td>\n",
              "      <td>-1.866392</td>\n",
              "      <td>0.634294</td>\n",
              "      <td>0.506405</td>\n",
              "      <td>0.526945</td>\n",
              "      <td>-2.231078</td>\n",
              "      <td>0</td>\n",
              "      <td>0.113599</td>\n",
              "      <td>-0.474440</td>\n",
              "      <td>-1.361255</td>\n",
              "      <td>-0.511001</td>\n",
              "      <td>-1.159086</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>-5.433352</td>\n",
              "      <td>-0.197441</td>\n",
              "      <td>-1.723773</td>\n",
              "      <td>0.634294</td>\n",
              "      <td>2.286080</td>\n",
              "      <td>1.793843</td>\n",
              "      <td>-1.141613</td>\n",
              "      <td>0</td>\n",
              "      <td>-0.967684</td>\n",
              "      <td>0.339667</td>\n",
              "      <td>-1.251770</td>\n",
              "      <td>0.426114</td>\n",
              "      <td>-1.159086</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-462ef932-3160-4387-8a52-8a2bfb8fc8fc')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-462ef932-3160-4387-8a52-8a2bfb8fc8fc button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-462ef932-3160-4387-8a52-8a2bfb8fc8fc');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vigF6PJAfy9R",
        "outputId": "24819c6d-f0bc-4cf0-a76c-e9d63f40e4c6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 171893 entries, 0 to 171892\n",
            "Data columns (total 15 columns):\n",
            " #   Column         Non-Null Count   Dtype  \n",
            "---  ------         --------------   -----  \n",
            " 0   LATITUDE       171893 non-null  float64\n",
            " 1   LONGITUDE      171893 non-null  float64\n",
            " 2   ACQ_DATE       171893 non-null  float64\n",
            " 3   ACQ_TIME       171893 non-null  float64\n",
            " 4   OPEN_TIME      171893 non-null  float64\n",
            " 5   CLOSE_TIME     171893 non-null  float64\n",
            " 6   BRIGHTNESS     171893 non-null  float64\n",
            " 7   FIRE_OCCURRED  171893 non-null  int64  \n",
            " 8   CO_MOL/M2      171893 non-null  float64\n",
            " 9   SO2_MOL/M2     171893 non-null  float64\n",
            " 10  NO2_MOL/M2     171893 non-null  float64\n",
            " 11  O3_MOL/M2      171893 non-null  float64\n",
            " 12  LOCATION       171893 non-null  float64\n",
            " 13  INSTRUMENT     171893 non-null  int64  \n",
            " 14  DRY_SEASON     171893 non-null  int64  \n",
            "dtypes: float64(12), int64(3)\n",
            "memory usage: 19.7 MB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "display(df['FIRE_OCCURRED'].value_counts())"
      ],
      "metadata": {
        "id": "2z3siI-MvbQs",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "outputId": "ef8667b4-01e1-4f93-cf8c-578ab6a6ea2a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "0    170544\n",
              "1      1349\n",
              "Name: FIRE_OCCURRED, dtype: int64"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X = df.drop('FIRE_OCCURRED', axis=1)\n",
        "y = df['FIRE_OCCURRED']"
      ],
      "metadata": {
        "id": "GEBLWi5ooiTO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Training, Validation, Testing Split\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# 80:10:10\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.10, random_state=10, shuffle=True)\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=1/9, random_state=10, shuffle=True)\n",
        "\n",
        "Original = [X_train, X_val, X_test, y_train, y_val, y_test] # For reference"
      ],
      "metadata": {
        "id": "96m0rNH7vhDg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if len(X_train)==len(y_train) and len(X_test) == len(y_test) and len(X_val) == len(y_val):\n",
        "  print(\"X and y data length matching\")\n",
        "else:\n",
        "  print(\"Error in data preparation pipeline\")\n",
        "print()\n",
        "print(\"No. of training data = %d\" % len(X_train))\n",
        "print(\"No. of validation data = %d\" % len(X_val))\n",
        "print(\"No. of testing data = %d\" % len(X_test))"
      ],
      "metadata": {
        "id": "oihO76nhvifX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "85008cbf-150c-4210-dda7-a99b0760585f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X and y data length matching\n",
            "\n",
            "No. of training data = 137513\n",
            "No. of validation data = 17190\n",
            "No. of testing data = 17190\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "display(y_test.value_counts())"
      ],
      "metadata": {
        "id": "1ZcyP7nRvlYp",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "outputId": "d3bd9699-0195-426b-8fb7-d7ae80b44ac1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "0    17059\n",
              "1      131\n",
              "Name: FIRE_OCCURRED, dtype: int64"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# SMOTE\n",
        "\n",
        "from collections import Counter\n",
        "from imblearn.over_sampling import SMOTE \n",
        "\n",
        "print('Original dataset shape %s' % Counter(y_train))\n",
        "sm = SMOTE(random_state=10)\n",
        "X_train, y_train = sm.fit_resample(X_train, y_train)\n",
        "print('Resampled dataset shape %s' % Counter(y_train))"
      ],
      "metadata": {
        "id": "T8MI03z-vmdA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "69680f48-1d2c-4025-f6ff-e93ccb1bae67"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original dataset shape Counter({0: 136417, 1: 1096})\n",
            "Resampled dataset shape Counter({0: 136417, 1: 136417})\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluation Metrics\n",
        "\n",
        "from sklearn.metrics import confusion_matrix, recall_score, f1_score, roc_auc_score, accuracy_score\n",
        "\n",
        "def evaluation_metrics(y_true, y_pred):\n",
        "  cfm = confusion_matrix(y_true, y_pred).ravel()\n",
        "  acc = accuracy_score(y_true, y_pred)\n",
        "  recs = recall_score(y_true, y_pred, average='binary')\n",
        "  f1s = f1_score(y_true, y_pred, average='binary')\n",
        "  rocs = roc_auc_score(y_true, y_pred, average='macro')\n",
        "  return [cfm, acc, recs, f1s, rocs]"
      ],
      "metadata": {
        "id": "5pMqZtYUvo3T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Confusion matrix format : [ tn , fp , fn , tp ]"
      ],
      "metadata": {
        "id": "bDAw6kBSvqrd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Store Model Parameters and Eval\n",
        "\n",
        "models = pd.DataFrame(columns = ['model_name', 'model', 'parameters'])\n",
        "models_eval = pd.DataFrame(columns = ['model_name', 'confusion_matrix', 'accuracy', 'recall', 'f1_score', 'roc_auc_score'])"
      ],
      "metadata": {
        "id": "2m4kHhLmvnxj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Import ML Algorithms\n",
        "\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "import xgboost\n",
        "from xgboost import XGBClassifier\n",
        "import lightgbm\n",
        "from lightgbm import LGBMClassifier\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from sklearn.ensemble import VotingClassifier\n",
        "\n",
        "# RandomizedSearchCV\n",
        "\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "\n",
        "# Save Model\n",
        "\n",
        "import pickle"
      ],
      "metadata": {
        "id": "fFvGo3IYwC3h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Logistic Regression\n",
        "\n",
        "- Library: Scikit-learn"
      ],
      "metadata": {
        "id": "ez3z3utYt1Y4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Training\n",
        "\n",
        "name = 'log_clf'\n",
        "\n",
        "train = pd.DataFrame(columns = ['penalty', 'warm_start', 'solver', 'max_iter', 'dual', 'n_jobs','random_state'])\n",
        "train = train.append({'penalty' : 'none', 'warm_start': False, 'solver': 'newton-cg',  'max_iter': 247,  'dual': False, 'n_jobs': -1, 'random_state': 10}, ignore_index=True)\n",
        "train = train.append({'penalty' : 'l2', 'warm_start': False, 'solver': 'newton-cg',  'max_iter': 100,  'dual': False, 'n_jobs': -1, 'random_state': 10}, ignore_index=True)\n",
        "\n",
        "\n",
        "train = train.reset_index()\n",
        "for index, row in train.iterrows():\n",
        "    model_name = name + str(index)\n",
        "    log_clf = LogisticRegression(penalty = row['penalty'], n_jobs = int(row['n_jobs']), random_state = int(row['random_state']))\n",
        "    log_clf.fit(X_train, y_train)\n",
        "   \n",
        "    y_true = y_val\n",
        "    y_pred = log_clf.predict(X_val)\n",
        "    evaluation_results = evaluation_metrics(y_true, y_pred)\n",
        "\n",
        "    models = models.append({'model_name': model_name, \n",
        "                            'model': log_clf, \n",
        "                            'parameters': log_clf.get_params()}, \n",
        "                           ignore_index=True)\n",
        "   \n",
        "    models_eval = models_eval.append({'model_name': model_name, \n",
        "                                      'confusion_matrix' : evaluation_results[0], \n",
        "                                      'accuracy': evaluation_results[1], \n",
        "                                      'recall' : evaluation_results[2], \n",
        "                                      'f1_score': evaluation_results[3], \n",
        "                                      'roc_auc_score': evaluation_results[4]}, \n",
        "                                     ignore_index=True)"
      ],
      "metadata": {
        "id": "fiXiFiYsZSB6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# RandomizedSearchCV\n",
        "\n",
        "random_grid = {\n",
        "                \"penalty\": ['l1', 'l2', 'elasticnet', 'none'],\n",
        "                \"dual\": [True, False],\n",
        "                \"max_iter\" : [int(x) for x in np.linspace(100, 500, num = 20)],\n",
        "                \"warm_start\" : [True, False],\n",
        "                \"solver\" : ['lbfgs', 'newton-cg', 'liblinear'],\n",
        "                \"C\" : [int(x) for x in np.linspace(0, 1, num = 50)]\n",
        "              }\n",
        "\n",
        "log_random = RandomizedSearchCV(estimator = log_clf, \n",
        "                                param_distributions = random_grid, \n",
        "                                n_iter = 50, \n",
        "                                cv = 3, \n",
        "                                verbose=2, \n",
        "                                scoring='recall'\n",
        "                                random_state=10)\n",
        "\n",
        "log_random.fit(X_train, y_train)\n",
        "log_random.best_params_"
      ],
      "metadata": {
        "id": "09I9B42LX8mb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "display(models_eval)"
      ],
      "metadata": {
        "id": "w5hD6F2kX9ih"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Support Vector Machine (SVM)\n",
        "\n",
        "- Library: Scikit-learn\n",
        "- Deprecated. Poor performance no matter what."
      ],
      "metadata": {
        "id": "oBBQ_iust1eb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "SVMs is very computationally expensive and demanding\n",
        "\n",
        "Kernelized SVMs require the computation of a distance function between each point in the dataset, which is the dominating cost of $n$ features x $ùëõ^{2}$ observations\n",
        "\n",
        "If the cache is getting thrashed then the running time blows up to $n$ features √ó $ùëõ^{3}$ observations)\n",
        "\n",
        "Solutions:\n",
        "* Scale data to $[-1,1]$\n",
        "* Use less samples"
      ],
      "metadata": {
        "id": "KwM5PeTvdHG_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_SVM = Original[0]\n",
        "X_val_SVM = Original[1]\n",
        "y_train_SVM = Original[3]\n",
        "y_val_SVM = Original[4]"
      ],
      "metadata": {
        "id": "tsq0c55qZSVE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "display(y_train_SVM.value_counts())"
      ],
      "metadata": {
        "id": "OlCn_HS1dItl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Undersampling\n",
        "\n",
        "from imblearn.under_sampling import RandomUnderSampler\n",
        "\n",
        "rus = RandomUnderSampler(random_state=10)\n",
        "X_train_SVM, y_train_SVM = rus.fit_resample(X_train_SVM, y_train_SVM)"
      ],
      "metadata": {
        "id": "wPwHlXKMdiO9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "display(y_train_SVM.value_counts())"
      ],
      "metadata": {
        "id": "9by4YC8tdj47"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Training\n",
        "\n",
        "name = 'svc_clf'\n",
        "\n",
        "train = pd.DataFrame(columns = ['kernel', 'random_state'])\n",
        "train = train.append({'kernel' : 'rbf', 'random_state': 10}, ignore_index=True)\n",
        "train = train.append({'kernel' : 'sigmoid', 'random_state': 10}, ignore_index=True)\n",
        "train = train.append({'kernel' : 'linear', 'random_state': 10}, ignore_index=True)\n",
        "\n",
        "train = train.reset_index()\n",
        "for index, row in train.iterrows():\n",
        "    model_name = name + str(index)\n",
        "    print(\"Currently at :\" , model_name)\n",
        "    svc_clf = SVC(kernel=row[\"kernel\"], random_state = int(row[\"random_state\"]))\n",
        "    svc_clf.fit(X_train_SVM, y_train_SVM)\n",
        "    \n",
        "    y_true = y_val_SVM\n",
        "    y_pred = svc_clf.predict(X_val_SVM)\n",
        "    evaluation_results = evaluation_metrics(y_true, y_pred)\n",
        "\n",
        "    models = models.append({'model_name': model_name, \n",
        "                            'model': svc_clf, \n",
        "                            'parameters': svc_clf.get_params()}, \n",
        "                           ignore_index=True)\n",
        "    \n",
        "    models_eval = models_eval.append({'model_name': model_name, \n",
        "                                      'confusion_matrix' : evaluation_results[0], \n",
        "                                      'accuracy': evaluation_results[1], \n",
        "                                      'recall' : evaluation_results[2], \n",
        "                                      'f1_score': evaluation_results[3], \n",
        "                                      'roc_auc_score': evaluation_results[4]}, \n",
        "                                     ignore_index=True)"
      ],
      "metadata": {
        "id": "XsSKT8gmdoVT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# RandomizedSearchCV\n",
        "\n",
        "random_grid = {\n",
        "              \"kernel\": ['linear', 'poly', 'rbf', 'sigmoid'],\n",
        "              \"C\": np.arange(2, 10, 2),\n",
        "              \"gamma\": np.arange(0.1, 1, 0.2)\n",
        "             }\n",
        "\n",
        "svc_random = RandomizedSearchCV(estimator = svc_clf, \n",
        "                                param_distributions = random_grid, \n",
        "                                n_iter = 50, \n",
        "                                cv = 3, \n",
        "                                verbose=2, \n",
        "                                scoring='recall'.\n",
        "                                random_state=10)\n",
        "\n",
        "svc_random.fit(X_train, y_train)\n",
        "svc_random.best_params_"
      ],
      "metadata": {
        "id": "7ZlA9AUldq5L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "display(models_eval)"
      ],
      "metadata": {
        "id": "ouPtk_gtdt0I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Naive Bayes\n",
        "\n",
        "- Library: Scikit-learn\n",
        "- Shuffling does not affect the model building. No random_state.\n",
        "- RandomizedSearchCV is not appropriate since there is only 1 parameter and the value is close to 0. Choose from models_eval."
      ],
      "metadata": {
        "id": "Tzx0wl2ht1R1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Training\n",
        "\n",
        "name = 'bayes_clf'\n",
        "\n",
        "train = pd.DataFrame(columns = ['var_smoothing'])\n",
        "train = train.append({'var_smoothing': 1e-10}, ignore_index=True)\n",
        "train = train.append({'var_smoothing': 1e-20}, ignore_index=True)\n",
        "train = train.append({'var_smoothing': 0}, ignore_index=True)\n",
        "\n",
        "train = train.reset_index()\n",
        "for index, row in train.iterrows():\n",
        "    model_name = name + str(index)\n",
        "    bayes_clf = GaussianNB(var_smoothing = row['var_smoothing'])\n",
        "    bayes_clf.fit(X_train, y_train)\n",
        "    \n",
        "    y_true = y_val\n",
        "    y_pred = bayes_clf.predict(X_val)\n",
        "    evaluation_results = evaluation_metrics(y_true, y_pred)\n",
        "\n",
        "    models = models.append({'model_name': model_name, \n",
        "                            'model': bayes_clf, \n",
        "                            'parameters': bayes_clf.get_params()}, \n",
        "                           ignore_index=True)\n",
        "    \n",
        "    models_eval = models_eval.append({'model_name': model_name, \n",
        "                                      'confusion_matrix' : evaluation_results[0], \n",
        "                                      'accuracy': evaluation_results[1], \n",
        "                                      'recall' : evaluation_results[2], \n",
        "                                      'f1_score': evaluation_results[3], \n",
        "                                      'roc_auc_score': evaluation_results[4]}, \n",
        "                                     ignore_index=True)"
      ],
      "metadata": {
        "id": "tAmU3wsqZSwf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "display(models_eval)"
      ],
      "metadata": {
        "id": "n7Ad5Gr5eH_U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## K-Nearest Neighbor\n",
        "\n",
        "- Library: Scikit-learn\n",
        "- Shuffling does not affect the model building. No random_state."
      ],
      "metadata": {
        "id": "M_gEyKKnt00q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Training\n",
        "\n",
        "name = 'neigh_clf'\n",
        "\n",
        "train = pd.DataFrame(columns = ['n_neighbors', 'algorithm', 'n_jobs'])\n",
        "train = train.append({'n_neighbors': 5, 'algorithm':'auto', 'n_jobs':-1}, ignore_index=True)\n",
        "train = train.append({'n_neighbors': 1, 'algorithm':'auto', 'n_jobs':-1}, ignore_index=True)\n",
        "train = train.append({'n_neighbors': 20, 'algorithm':'kd_tree', 'n_jobs':-1}, ignore_index=True)\n",
        "\n",
        "train = train.reset_index()\n",
        "for index, row in train.iterrows():\n",
        "    model_name = name + str(index)\n",
        "    neigh_clf = KNeighborsClassifier(n_neighbors=int(row['n_neighbors']), algorithm = row['algorithm'], n_jobs = int(row['n_jobs']))\n",
        "    neigh_clf.fit(X_train, y_train)\n",
        "    \n",
        "    y_true = y_val\n",
        "    y_pred = neigh_clf.predict(X_val)\n",
        "    evaluation_results = evaluation_metrics(y_true, y_pred)\n",
        "\n",
        "    models = models.append({'model_name': model_name, \n",
        "                            'model': neigh_clf, \n",
        "                            'parameters': neigh_clf.get_params()}, \n",
        "                           ignore_index=True)\n",
        "    \n",
        "    models_eval = models_eval.append({'model_name': model_name, \n",
        "                                      'confusion_matrix' : evaluation_results[0], \n",
        "                                      'accuracy': evaluation_results[1], \n",
        "                                      'recall' : evaluation_results[2], \n",
        "                                      'f1_score': evaluation_results[3], \n",
        "                                      'roc_auc_score': evaluation_results[4]}, \n",
        "                                     ignore_index=True)"
      ],
      "metadata": {
        "id": "Vw5TiOkaZTHW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# RandomizedSearchCV\n",
        "\n",
        "random_grid = {\n",
        "                \"n_neighbors\": [int(x) for x in np.linspace(1, 20, num = 20)],\n",
        "                \"algorithm\": ['auto', 'kd_tree','ball_tree']\n",
        "              }\n",
        "\n",
        "neigh_random = RandomizedSearchCV(estimator = neigh_clf, \n",
        "                                  param_distributions = random_grid, \n",
        "                                  n_iter = 50, \n",
        "                                  cv = 3, \n",
        "                                  verbose=2, \n",
        "                                  scoring='recall',\n",
        "                                  random_state=10)\n",
        "\n",
        "rand = RandomizedSearchCV(knn, param_grid, cv=10, scoring='accuracy', n_iter=10, random_state=10)\n",
        "\n",
        "neigh_random.fit(X_train, y_train)\n",
        "neigh_random.best_params_"
      ],
      "metadata": {
        "id": "SlJiuLzfen_x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "display(models_eval)"
      ],
      "metadata": {
        "id": "EvI_e6r-exRk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Decision Tree\n",
        "\n",
        "- Library: Scikit-learn"
      ],
      "metadata": {
        "id": "brtgIH7pt1jO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Training\n",
        "\n",
        "name = 'tree_clf'\n",
        "\n",
        "train = pd.DataFrame(columns = ['criterion', 'splitter', 'min_samples_leaf', 'max_features', 'max_depth', 'n_jobs', 'random_state'])\n",
        "train = train.append({'criterion' : 'gini', 'splitter': 'best', 'min_samples_leaf': 1, 'max_features': 9, 'max_depth': None, 'random_state': 10}, ignore_index=True)\n",
        "train = train.append({'criterion' : 'entropy', 'splitter': 'best', 'min_samples_leaf': 1, 'max_features': 9, 'max_depth': None, 'random_state': 10}, ignore_index=True)\n",
        "train = train.append({'criterion' : 'gini', 'splitter': 'random', 'min_samples_leaf': 1, 'max_features': \"auto\", 'max_depth': None, 'random_state': 10}, ignore_index=True)\n",
        "train = train.append({'criterion' : 'entropy', 'splitter': 'random', 'min_samples_leaf': 1, 'max_features': \"auto\", 'max_depth': None, 'random_state': 10}, ignore_index=True)\n",
        "\n",
        "train = train.reset_index()\n",
        "for index, row in train.iterrows():\n",
        "    model_name = name + str(index)\n",
        "    tree_clf = DecisionTreeClassifier(criterion = row['criterion'], splitter = row['splitter'], max_depth = None, random_state = row['random_state'])\n",
        "    tree_clf.fit(X_train, y_train)\n",
        "    \n",
        "    y_true = y_val\n",
        "    y_pred = tree_clf.predict(X_val)\n",
        "    evaluation_results = evaluation_metrics(y_true, y_pred)\n",
        "\n",
        "    models = models.append({'model_name': model_name, \n",
        "                            'model': tree_clf, \n",
        "                            'parameters': tree_clf.get_params()}, \n",
        "                           ignore_index=True)\n",
        "    \n",
        "    models_eval = models_eval.append({'model_name': model_name, \n",
        "                                      'confusion_matrix' : evaluation_results[0], \n",
        "                                      'accuracy': evaluation_results[1], \n",
        "                                      'recall' : evaluation_results[2], \n",
        "                                      'f1_score': evaluation_results[3], \n",
        "                                      'roc_auc_score': evaluation_results[4]}, \n",
        "                                     ignore_index=True)"
      ],
      "metadata": {
        "id": "le5Xgsd8ZUHB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# RandomizedSearchCV\n",
        "\n",
        "max_depth = list([int(x) for x in np.linspace(2, 6, num = 5)])\n",
        "max_depth.append(None)\n",
        "\n",
        "random_grid = {\n",
        "              \"max_depth\": max_depth,\n",
        "              \"max_features\": [int(x) for x in np.linspace(1, len(df.columns), num = len(df.columns))],\n",
        "              \"min_samples_leaf\": [int(x) for x in np.linspace(1, len(df.columns), num = len(df.columns))],\n",
        "              \"criterion\": [\"gini\", \"entropy\", \"log_loss\"],\n",
        "              \"splitter\": [\"random\", \"best\"]\n",
        "              }\n",
        "\n",
        "tree_random = RandomizedSearchCV(estimator = tree_clf, \n",
        "                                 param_distributions = random_grid, \n",
        "                                 n_iter = 50, \n",
        "                                 cv = 3, \n",
        "                                 verbose=2, \n",
        "                                 scoring='recall',\n",
        "                                 random_state=10)\n",
        "\n",
        "tree_random.fit(X_train, y_train)\n",
        "tree_random.best_params_"
      ],
      "metadata": {
        "id": "8lLlrOw_fGlc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 831
        },
        "outputId": "c9f65516-f66a-43b0-e051-c4e7582bf446"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 3 folds for each of 50 candidates, totalling 150 fits\n",
            "[CV] END criterion=gini, max_depth=5, max_features=11, min_samples_leaf=8, splitter=best; total time=   0.6s\n",
            "[CV] END criterion=gini, max_depth=5, max_features=11, min_samples_leaf=8, splitter=best; total time=   0.6s\n",
            "[CV] END criterion=gini, max_depth=5, max_features=11, min_samples_leaf=8, splitter=best; total time=   0.6s\n",
            "[CV] END criterion=log_loss, max_depth=3, max_features=9, min_samples_leaf=11, splitter=best; total time=   0.0s\n",
            "[CV] END criterion=log_loss, max_depth=3, max_features=9, min_samples_leaf=11, splitter=best; total time=   0.0s\n",
            "[CV] END criterion=log_loss, max_depth=3, max_features=9, min_samples_leaf=11, splitter=best; total time=   0.0s\n",
            "[CV] END criterion=gini, max_depth=5, max_features=13, min_samples_leaf=10, splitter=random; total time=   0.0s\n",
            "[CV] END criterion=gini, max_depth=5, max_features=13, min_samples_leaf=10, splitter=random; total time=   0.0s\n",
            "[CV] END criterion=gini, max_depth=5, max_features=13, min_samples_leaf=10, splitter=random; total time=   0.0s\n",
            "[CV] END criterion=entropy, max_depth=6, max_features=3, min_samples_leaf=5, splitter=best; total time=   0.3s\n",
            "[CV] END criterion=entropy, max_depth=6, max_features=3, min_samples_leaf=5, splitter=best; total time=   0.3s\n",
            "[CV] END criterion=entropy, max_depth=6, max_features=3, min_samples_leaf=5, splitter=best; total time=   0.3s\n",
            "[CV] END criterion=gini, max_depth=5, max_features=7, min_samples_leaf=6, splitter=random; total time=   0.1s\n",
            "[CV] END criterion=gini, max_depth=5, max_features=7, min_samples_leaf=6, splitter=random; total time=   0.1s\n",
            "[CV] END criterion=gini, max_depth=5, max_features=7, min_samples_leaf=6, splitter=random; total time=   0.1s\n",
            "[CV] END criterion=gini, max_depth=None, max_features=13, min_samples_leaf=4, splitter=best; total time=   0.0s\n",
            "[CV] END criterion=gini, max_depth=None, max_features=13, min_samples_leaf=4, splitter=best; total time=   0.0s\n",
            "[CV] END criterion=gini, max_depth=None, max_features=13, min_samples_leaf=4, splitter=best; total time=   0.0s\n",
            "[CV] END criterion=log_loss, max_depth=4, max_features=4, min_samples_leaf=10, splitter=best; total time=   0.0s\n",
            "[CV] END criterion=log_loss, max_depth=4, max_features=4, min_samples_leaf=10, splitter=best; total time=   0.0s\n",
            "[CV] END criterion=log_loss, max_depth=4, max_features=4, min_samples_leaf=10, splitter=best; total time=   0.0s\n",
            "[CV] END criterion=gini, max_depth=6, max_features=7, min_samples_leaf=7, splitter=random; total time=   0.1s\n",
            "[CV] END criterion=gini, max_depth=6, max_features=7, min_samples_leaf=7, splitter=random; total time=   0.1s\n",
            "[CV] END criterion=gini, max_depth=6, max_features=7, min_samples_leaf=7, splitter=random; total time=   0.1s\n",
            "[CV] END criterion=gini, max_depth=None, max_features=10, min_samples_leaf=13, splitter=best; total time=   1.1s\n",
            "[CV] END criterion=gini, max_depth=None, max_features=10, min_samples_leaf=13, splitter=best; total time=   1.1s\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-102-a3d5fadb8339>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     19\u001b[0m                                  random_state=10)\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m \u001b[0mtree_random\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m \u001b[0mtree_random\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_params_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    889\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    890\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 891\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    892\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    893\u001b[0m             \u001b[0;31m# multimetric is determined here because in the case of a callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36m_run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1764\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1765\u001b[0m         \u001b[0;34m\"\"\"Search n_iter candidates from param_distributions\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1766\u001b[0;31m         evaluate_candidates(\n\u001b[0m\u001b[1;32m   1767\u001b[0m             ParameterSampler(\n\u001b[1;32m   1768\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparam_distributions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_iter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mevaluate_candidates\u001b[0;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[1;32m    836\u001b[0m                     )\n\u001b[1;32m    837\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 838\u001b[0;31m                 out = parallel(\n\u001b[0m\u001b[1;32m    839\u001b[0m                     delayed(_fit_and_score)(\n\u001b[1;32m    840\u001b[0m                         \u001b[0mclone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbase_estimator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1086\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1087\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1088\u001b[0;31m             \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1089\u001b[0m                 \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1090\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    899\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    900\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 901\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    902\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    903\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    817\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    818\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 819\u001b[0;31m             \u001b[0mjob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    820\u001b[0m             \u001b[0;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    821\u001b[0m             \u001b[0;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    206\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    207\u001b[0m         \u001b[0;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 208\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    209\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    595\u001b[0m         \u001b[0;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    596\u001b[0m         \u001b[0;31m# arguments in memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 597\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    598\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    599\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    286\u001b[0m         \u001b[0;31m# change the default number of processes to -1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    287\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 288\u001b[0;31m             return [func(*args, **kwargs)\n\u001b[0m\u001b[1;32m    289\u001b[0m                     for func, args, kwargs in self.items]\n\u001b[1;32m    290\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    286\u001b[0m         \u001b[0;31m# change the default number of processes to -1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    287\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 288\u001b[0;31m             return [func(*args, **kwargs)\n\u001b[0m\u001b[1;32m    289\u001b[0m                     for func, args, kwargs in self.items]\n\u001b[1;32m    290\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/sklearn/utils/fixes.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    214\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mconfig_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 216\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    217\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36m_fit_and_score\u001b[0;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, split_progress, candidate_progress, error_score)\u001b[0m\n\u001b[1;32m    678\u001b[0m             \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    679\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 680\u001b[0;31m             \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    681\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    682\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/sklearn/tree/_classes.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[1;32m    935\u001b[0m         \"\"\"\n\u001b[1;32m    936\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 937\u001b[0;31m         super().fit(\n\u001b[0m\u001b[1;32m    938\u001b[0m             \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    939\u001b[0m             \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/sklearn/tree/_classes.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[1;32m    418\u001b[0m             )\n\u001b[1;32m    419\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 420\u001b[0;31m         \u001b[0mbuilder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtree_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    421\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    422\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_outputs_\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mis_classifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "display(models_eval)"
      ],
      "metadata": {
        "id": "aW_Ztq6rfEiS",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 520
        },
        "outputId": "7b6262f6-d952-40f3-a727-7c7a2887397b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "   model_name      confusion_matrix  accuracy    recall  f1_score  \\\n",
              "0    rnd_clf0   [15249, 4, 10, 177]  0.999093  0.946524  0.961957   \n",
              "1    rnd_clf1    [15248, 5, 9, 178]  0.999093  0.951872  0.962162   \n",
              "2    rnd_clf2    [15248, 5, 9, 178]  0.999093  0.951872  0.962162   \n",
              "3   tree_clf0   [15234, 19, 9, 178]  0.998187  0.951872  0.927083   \n",
              "4   tree_clf1   [15228, 25, 6, 181]  0.997992  0.967914  0.921120   \n",
              "5   tree_clf2   [15230, 23, 9, 178]  0.997927  0.951872  0.917526   \n",
              "6   tree_clf3  [15227, 26, 10, 177]  0.997668  0.946524  0.907692   \n",
              "7   tree_clf0  [15227, 26, 10, 177]  0.997668  0.946524  0.907692   \n",
              "8   tree_clf1   [15228, 25, 6, 181]  0.997992  0.967914  0.921120   \n",
              "9   tree_clf2   [15230, 23, 9, 178]  0.997927  0.951872  0.917526   \n",
              "10  tree_clf3  [15227, 26, 10, 177]  0.997668  0.946524  0.907692   \n",
              "11  tree_clf0   [15234, 19, 9, 178]  0.998187  0.951872  0.927083   \n",
              "12  tree_clf1   [15228, 25, 6, 181]  0.997992  0.967914  0.921120   \n",
              "13  tree_clf2   [15230, 23, 9, 178]  0.997927  0.951872  0.917526   \n",
              "14  tree_clf3  [15227, 26, 10, 177]  0.997668  0.946524  0.907692   \n",
              "\n",
              "    roc_auc_score  \n",
              "0        0.973131  \n",
              "1        0.975772  \n",
              "2        0.975772  \n",
              "3        0.975313  \n",
              "4        0.983138  \n",
              "5        0.975182  \n",
              "6        0.972410  \n",
              "7        0.972410  \n",
              "8        0.983138  \n",
              "9        0.975182  \n",
              "10       0.972410  \n",
              "11       0.975313  \n",
              "12       0.983138  \n",
              "13       0.975182  \n",
              "14       0.972410  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-10784ce4-2f8f-4f3e-9e8b-bc3766b57d7c\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>model_name</th>\n",
              "      <th>confusion_matrix</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>recall</th>\n",
              "      <th>f1_score</th>\n",
              "      <th>roc_auc_score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>rnd_clf0</td>\n",
              "      <td>[15249, 4, 10, 177]</td>\n",
              "      <td>0.999093</td>\n",
              "      <td>0.946524</td>\n",
              "      <td>0.961957</td>\n",
              "      <td>0.973131</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>rnd_clf1</td>\n",
              "      <td>[15248, 5, 9, 178]</td>\n",
              "      <td>0.999093</td>\n",
              "      <td>0.951872</td>\n",
              "      <td>0.962162</td>\n",
              "      <td>0.975772</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>rnd_clf2</td>\n",
              "      <td>[15248, 5, 9, 178]</td>\n",
              "      <td>0.999093</td>\n",
              "      <td>0.951872</td>\n",
              "      <td>0.962162</td>\n",
              "      <td>0.975772</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>tree_clf0</td>\n",
              "      <td>[15234, 19, 9, 178]</td>\n",
              "      <td>0.998187</td>\n",
              "      <td>0.951872</td>\n",
              "      <td>0.927083</td>\n",
              "      <td>0.975313</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>tree_clf1</td>\n",
              "      <td>[15228, 25, 6, 181]</td>\n",
              "      <td>0.997992</td>\n",
              "      <td>0.967914</td>\n",
              "      <td>0.921120</td>\n",
              "      <td>0.983138</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>tree_clf2</td>\n",
              "      <td>[15230, 23, 9, 178]</td>\n",
              "      <td>0.997927</td>\n",
              "      <td>0.951872</td>\n",
              "      <td>0.917526</td>\n",
              "      <td>0.975182</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>tree_clf3</td>\n",
              "      <td>[15227, 26, 10, 177]</td>\n",
              "      <td>0.997668</td>\n",
              "      <td>0.946524</td>\n",
              "      <td>0.907692</td>\n",
              "      <td>0.972410</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>tree_clf0</td>\n",
              "      <td>[15227, 26, 10, 177]</td>\n",
              "      <td>0.997668</td>\n",
              "      <td>0.946524</td>\n",
              "      <td>0.907692</td>\n",
              "      <td>0.972410</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>tree_clf1</td>\n",
              "      <td>[15228, 25, 6, 181]</td>\n",
              "      <td>0.997992</td>\n",
              "      <td>0.967914</td>\n",
              "      <td>0.921120</td>\n",
              "      <td>0.983138</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>tree_clf2</td>\n",
              "      <td>[15230, 23, 9, 178]</td>\n",
              "      <td>0.997927</td>\n",
              "      <td>0.951872</td>\n",
              "      <td>0.917526</td>\n",
              "      <td>0.975182</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>tree_clf3</td>\n",
              "      <td>[15227, 26, 10, 177]</td>\n",
              "      <td>0.997668</td>\n",
              "      <td>0.946524</td>\n",
              "      <td>0.907692</td>\n",
              "      <td>0.972410</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>tree_clf0</td>\n",
              "      <td>[15234, 19, 9, 178]</td>\n",
              "      <td>0.998187</td>\n",
              "      <td>0.951872</td>\n",
              "      <td>0.927083</td>\n",
              "      <td>0.975313</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>tree_clf1</td>\n",
              "      <td>[15228, 25, 6, 181]</td>\n",
              "      <td>0.997992</td>\n",
              "      <td>0.967914</td>\n",
              "      <td>0.921120</td>\n",
              "      <td>0.983138</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>tree_clf2</td>\n",
              "      <td>[15230, 23, 9, 178]</td>\n",
              "      <td>0.997927</td>\n",
              "      <td>0.951872</td>\n",
              "      <td>0.917526</td>\n",
              "      <td>0.975182</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>tree_clf3</td>\n",
              "      <td>[15227, 26, 10, 177]</td>\n",
              "      <td>0.997668</td>\n",
              "      <td>0.946524</td>\n",
              "      <td>0.907692</td>\n",
              "      <td>0.972410</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-10784ce4-2f8f-4f3e-9e8b-bc3766b57d7c')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-10784ce4-2f8f-4f3e-9e8b-bc3766b57d7c button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-10784ce4-2f8f-4f3e-9e8b-bc3766b57d7c');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Random Forest Classifier\n",
        "\n",
        "- Library: Scikit-learn"
      ],
      "metadata": {
        "id": "e5dbRikwt1ov"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Training\n",
        "\n",
        "name = 'rnd_clf'\n",
        "\n",
        "train = pd.DataFrame(columns = ['n_estimators', 'min_samples_split', 'min_samples_leaf', 'max_features','max_depth', 'n_jobs', 'random_state'])\n",
        "train = train.append({'n_estimators' : 100, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'auto', 'max_depth' : None, 'n_jobs': -1, 'random_state': 10}, ignore_index=True)\n",
        "train = train.append({'n_estimators' : 300, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_features': 'auto', 'max_depth' : 31, 'n_jobs': -1, 'random_state': 10}, ignore_index=True)\n",
        "train = train.append({'n_estimators' : 300, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_features': 'auto', 'max_depth' : None, 'n_jobs': -1, 'random_state': 10}, ignore_index=True)\n",
        "\n",
        "train = train.reset_index()\n",
        "for index, row in train.iterrows():\n",
        "    model_name = name + str(index)\n",
        "    rnd_clf = RandomForestClassifier(n_estimators = int(row['n_estimators']), max_depth = None, \n",
        "                                    n_jobs = int(row['n_jobs']), random_state = int(row['random_state']))\n",
        "    rnd_clf.fit(X_train, y_train)\n",
        "    \n",
        "    y_true = y_val\n",
        "    y_pred = rnd_clf.predict(X_val)\n",
        "    evaluation_results = evaluation_metrics(y_true, y_pred)\n",
        "\n",
        "    models = models.append({'model_name': model_name, \n",
        "                            'model': rnd_clf, \n",
        "                            'parameters': rnd_clf.get_params()}, \n",
        "                           ignore_index=True)\n",
        "    \n",
        "    models_eval = models_eval.append({'model_name': model_name, \n",
        "                                      'confusion_matrix' : evaluation_results[0], \n",
        "                                      'accuracy': evaluation_results[1], \n",
        "                                      'recall' : evaluation_results[2], \n",
        "                                      'f1_score': evaluation_results[3], \n",
        "                                      'roc_auc_score': evaluation_results[4]}, \n",
        "                                     ignore_index=True)"
      ],
      "metadata": {
        "id": "_n_M-g9kZTyK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# RandomizedSearchCV\n",
        "\n",
        "# Number of trees in random forest\n",
        "n_estimators = [int(x) for x in np.linspace(start = 300, stop = 500, num = 20)]\n",
        "# Number of features to consider at every split\n",
        "max_features = [int(x) for x in np.linspace(1, len(df.columns), num = len(df.columns))]\n",
        "# Maximum number of levels in tree\n",
        "max_depth = [int(x) for x in np.linspace(15, 35, num = 7)]\n",
        "max_depth.append(None)\n",
        "# Minimum number of samples required to split a node\n",
        "min_samples_split = [2, 3, 4, 5, 6]\n",
        "# Minimum number of samples required at each leaf node\n",
        "min_samples_leaf = [1, 2, 4]\n",
        "\n",
        "# Create the random grid\n",
        "random_grid = {\n",
        "               'n_estimators': n_estimators,\n",
        "               'max_features': max_features,\n",
        "               'max_depth': max_depth,\n",
        "               'min_samples_split': min_samples_split,\n",
        "               'min_samples_leaf': min_samples_leaf,\n",
        "              }\n",
        "\n",
        "rnd_random = RandomizedSearchCV(estimator = rnd_clf, \n",
        "                                param_distributions = random_grid, \n",
        "                                n_iter = 50, \n",
        "                                cv = 3, \n",
        "                                verbose=2, \n",
        "                                scoring='recall',\n",
        "                                random_state=10)\n",
        "\n",
        "rnd_random.fit(X_train, y_train)\n",
        "rnd_random.best_params_"
      ],
      "metadata": {
        "id": "WskTBZDQe43o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "display(models_eval)"
      ],
      "metadata": {
        "id": "jo4WWeMIe3G6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        },
        "outputId": "fdd79b73-c8ec-449c-e74a-44d9445df1b0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  model_name     confusion_matrix  accuracy    recall  f1_score  roc_auc_score\n",
              "0   rnd_clf0  [15249, 4, 10, 177]  0.999093  0.946524  0.961957       0.973131\n",
              "1   rnd_clf1   [15248, 5, 9, 178]  0.999093  0.951872  0.962162       0.975772\n",
              "2   rnd_clf2   [15248, 5, 9, 178]  0.999093  0.951872  0.962162       0.975772"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-00443d69-a7a1-4d35-af39-eb6d859c3b63\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>model_name</th>\n",
              "      <th>confusion_matrix</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>recall</th>\n",
              "      <th>f1_score</th>\n",
              "      <th>roc_auc_score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>rnd_clf0</td>\n",
              "      <td>[15249, 4, 10, 177]</td>\n",
              "      <td>0.999093</td>\n",
              "      <td>0.946524</td>\n",
              "      <td>0.961957</td>\n",
              "      <td>0.973131</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>rnd_clf1</td>\n",
              "      <td>[15248, 5, 9, 178]</td>\n",
              "      <td>0.999093</td>\n",
              "      <td>0.951872</td>\n",
              "      <td>0.962162</td>\n",
              "      <td>0.975772</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>rnd_clf2</td>\n",
              "      <td>[15248, 5, 9, 178]</td>\n",
              "      <td>0.999093</td>\n",
              "      <td>0.951872</td>\n",
              "      <td>0.962162</td>\n",
              "      <td>0.975772</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-00443d69-a7a1-4d35-af39-eb6d859c3b63')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-00443d69-a7a1-4d35-af39-eb6d859c3b63 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-00443d69-a7a1-4d35-af39-eb6d859c3b63');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Gradient Boosting Classifier\n",
        "\n",
        "- Library: Scikit-learn"
      ],
      "metadata": {
        "id": "-0VzXIIcuTah"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Training\n",
        "\n",
        "name = 'gboost_clf'\n",
        "\n",
        "train = pd.DataFrame(columns = ['n_estimators', 'learning_rate', 'max_depth', 'random_state'])\n",
        "train = train.append({'n_estimators': 100, 'learning_rate':0.1, 'max_depth':3, 'random_state':10}, ignore_index=True)\n",
        "train = train.append({'n_estimators': 500, 'learning_rate':0.5, 'max_depth':1, 'random_state':10}, ignore_index=True)\n",
        "train = train.append({'n_estimators': 50, 'learning_rate':0.01, 'max_depth':10, 'random_state':10}, ignore_index=True)\n",
        "\n",
        "train = train.reset_index()\n",
        "for index, row in train.iterrows():\n",
        "    model_name = name + str(index)\n",
        "    gboost_clf = GradientBoostingClassifier(n_estimators=int(row['n_estimators']), learning_rate=row['learning_rate'],\n",
        "                                            max_depth=int(row['max_depth']), random_state=int(row['random_state']))\n",
        "    gboost_clf.fit(X_train, y_train)\n",
        "   \n",
        "    y_true = y_val\n",
        "    y_pred = gboost_clf.predict(X_val)\n",
        "    evaluation_results = evaluation_metrics(y_true, y_pred)\n",
        "\n",
        "    models = models.append({'model_name': model_name, \n",
        "                            'model': gboost_clf, \n",
        "                            'parameters': gboost_clf.get_params()}, \n",
        "                           ignore_index=True)\n",
        "   \n",
        "    models_eval = models_eval.append({'model_name': model_name, \n",
        "                                      'confusion_matrix' : evaluation_results[0], \n",
        "                                      'accuracy': evaluation_results[1], \n",
        "                                      'recall' : evaluation_results[2], \n",
        "                                      'f1_score': evaluation_results[3], \n",
        "                                      'roc_auc_score': evaluation_results[4]}, \n",
        "                                     ignore_index=True)"
      ],
      "metadata": {
        "id": "xRoZe1r0ZUd-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# RandomizedSearchCV\n",
        "\n",
        "random_grid = {\n",
        "              \"n_estimators\": [100, 500, 750, 1000, 2000],\n",
        "              \"learning_rate\": [0.01, 0.05, 0.10, 0.15, 0.20, 0.25, 0.30, 0.50],\n",
        "              \"max_depth\": [1, 3, 5, 8, 10, 15]\n",
        "              }\n",
        "\n",
        "gboost_random = RandomizedSearchCV(estimator = gboost_clf, \n",
        "                                 param_distributions = random_grid, \n",
        "                                 n_iter = 50, \n",
        "                                 cv = 3, \n",
        "                                 verbose=2, \n",
        "                                 scoring='recall',\n",
        "                                 random_state=10)\n",
        "\n",
        "gboost_random.fit(X_train, y_train)\n",
        "gboost_random.best_params_"
      ],
      "metadata": {
        "id": "1FhLDX1nN6bT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## XGBoost\n",
        "\n",
        "- Library: xgboost"
      ],
      "metadata": {
        "id": "J3M3ob9buTHm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Training\n",
        "\n",
        "name = 'xgboost_clf'\n",
        "\n",
        "train = pd.DataFrame(columns = ['n_estimators', 'learning_rate', 'max_depth', 'random_state'])\n",
        "train = train.append({'n_estimators': 1000, 'learning_rate':0.0001, 'max_depth':3, 'random_state':10}, ignore_index=True)\n",
        "train = train.append({'n_estimators': 500, 'learning_rate':0.5, 'max_depth':1, 'random_state':10}, ignore_index=True)\n",
        "train = train.append({'n_estimators': 750, 'learning_rate':0.01, 'max_depth':10, 'random_state':10}, ignore_index=True)\n",
        "\n",
        "train = train.reset_index()\n",
        "for index, row in train.iterrows():\n",
        "    model_name = name + str(index)\n",
        "    xgboost_clf = XGBClassifier(n_estimators=int(row['n_estimators']), learning_rate=row['learning_rate'],\n",
        "                                max_depth=int(row['max_depth']), random_state=int(row['random_state']))\n",
        "    xgboost_clf.fit(X_train, y_train)\n",
        "    \n",
        "    y_true = y_val\n",
        "    y_pred = xgboost_clf.predict(X_val)\n",
        "    evaluation_results = evaluation_metrics(y_true, y_pred)\n",
        "\n",
        "    models = models.append({'model_name': model_name, \n",
        "                            'model': xgboost_clf, \n",
        "                            'parameters': xgboost_clf.get_params()}, \n",
        "                           ignore_index=True)\n",
        "    \n",
        "    models_eval = models_eval.append({'model_name': model_name, \n",
        "                                      'confusion_matrix' : evaluation_results[0], \n",
        "                                      'accuracy': evaluation_results[1], \n",
        "                                      'recall' : evaluation_results[2], \n",
        "                                      'f1_score': evaluation_results[3], \n",
        "                                      'roc_auc_score': evaluation_results[4]}, \n",
        "                                     ignore_index=True)"
      ],
      "metadata": {
        "id": "evYZbB-MZVmF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# RandomizedSearchCV\n",
        "\n",
        "random_grid = {\n",
        "              \"n_estimators\": [100, 500, 750, 1000, 2000],\n",
        "              \"learning_rate\": [0.01, 0.05, 0.10, 0.15, 0.20, 0.25, 0.30, 0.50],\n",
        "              \"max_depth\": [2, 4, 6, 8, 10, 12, 14],\n",
        "              \"min_child_weight\" : [1, 3, 5, 8, 10, 15]\n",
        "              }\n",
        "\n",
        "xgboost_random = RandomizedSearchCV(estimator = xgboost_clf, \n",
        "                                 param_distributions = random_grid, \n",
        "                                 n_iter = 50, \n",
        "                                 cv = 3, \n",
        "                                 verbose=2, \n",
        "                                 scoring='recall',\n",
        "                                 random_state=10)\n",
        "\n",
        "xgboost_random.fit(X_train, y_train)\n",
        "xgboost_random.best_params_"
      ],
      "metadata": {
        "id": "DJEXkDKKPtx_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## LightGBM\n",
        "\n",
        "- Library: lightbgm"
      ],
      "metadata": {
        "id": "p3iAdzksueOk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Training\n",
        "\n",
        "name = 'lightgbm_clf'\n",
        "\n",
        "train = pd.DataFrame(columns = ['n_estimators', 'learning_rate', 'max_depth', 'random_state'])\n",
        "train = train.append({'n_estimators': 1000, 'learning_rate':0.1, 'max_depth':3, 'random_state':10}, ignore_index=True)\n",
        "train = train.append({'n_estimators': 500, 'learning_rate':0.5, 'max_depth':1, 'random_state':10}, ignore_index=True)\n",
        "train = train.append({'n_estimators': 750, 'learning_rate':0.01, 'max_depth':10, 'random_state':10}, ignore_index=True)\n",
        "\n",
        "train = train.reset_index()\n",
        "for index, row in train.iterrows():\n",
        "    model_name = name + str(index)\n",
        "    lightgbm_clf = LGBMClassifier(n_estimators=int(row['n_estimators']), learning_rate=row['learning_rate'],\n",
        "                                max_depth=int(row['max_depth']), random_state=int(row['random_state']))\n",
        "    lightgbm_clf.fit(X_train, y_train)\n",
        "    \n",
        "    y_true = y_val\n",
        "    y_pred = lightgbm_clf.predict(X_val)\n",
        "    evaluation_results = evaluation_metrics(y_true, y_pred)   \n",
        "\n",
        "    models = models.append({'model_name': model_name, \n",
        "                            'model': lightgbm_clf, \n",
        "                            'parameters': lightgbm_clf.get_params()}, \n",
        "                           ignore_index=True)\n",
        "    \n",
        "    models_eval = models_eval.append({'model_name': model_name, \n",
        "                                      'confusion_matrix' : evaluation_results[0], \n",
        "                                      'accuracy': evaluation_results[1], \n",
        "                                      'recall' : evaluation_results[2], \n",
        "                                      'f1_score': evaluation_results[3], \n",
        "                                      'roc_auc_score': evaluation_results[4]}, \n",
        "                                     ignore_index=True)"
      ],
      "metadata": {
        "id": "sh_I5t-TZVaP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# RandomizedSearchCV\n",
        "\n",
        "random_grid = {\n",
        "              \"n_estimators\": [100, 500, 750, 1000, 2000],\n",
        "              \"learning_rate\": [0.01, 0.05, 0.10, 0.15, 0.20, 0.25, 0.30, 0.50],\n",
        "              \"max_depth\": [1, 3, 5, 8, 10, 15],\n",
        "              \"num_leaves\": [31, 50, 100, 200]\n",
        "              }\n",
        "\n",
        "xgboost_random = RandomizedSearchCV(estimator = xgboost_clf, \n",
        "                                 param_distributions = random_grid, \n",
        "                                 n_iter = 50, \n",
        "                                 cv = 3, \n",
        "                                 verbose=2, \n",
        "                                 scoring='recall',\n",
        "                                 random_state=10)\n",
        "\n",
        "xgboost_random.fit(X_train, y_train)\n",
        "xgboost_random.best_params_"
      ],
      "metadata": {
        "id": "-P5Jw0-sQ6Vn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Artificial Neural Network\n",
        "\n",
        "- Library: Keras, Tensorflow"
      ],
      "metadata": {
        "id": "QpthCMRHuhWe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tf.random.set_seed(10)\n",
        "\n",
        "print(tf.__version__)\n",
        "print(keras.__version__)"
      ],
      "metadata": {
        "id": "fJ6kS48GZVH3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Experiment 1: Base Model"
      ],
      "metadata": {
        "id": "vivojhGnfeEz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train.info()"
      ],
      "metadata": {
        "id": "XO7_fl_pfaEP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ann_clf = keras.models.Sequential([\n",
        "    keras.layers.Dense(17, input_shape=(X_train.shape[1],), activation='relu'), # 16 columns. 1 bias term to accelerate activation of a node.\n",
        "    keras.layers.Dense(8, activation='relu'), # One hidden layer is sufficient for the large majority of problems. \n",
        "    # Set the number of neurons in the hidden layer as the mean of the neurons in the input and output layers.\n",
        "    keras.layers.Dense(1, activation='sigmoid'), # Only 1 acceptable unless softmax activation function is used\n",
        "])\n",
        "\n",
        "ann_clf.summary()"
      ],
      "metadata": {
        "id": "OVpParvzfhtl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ann_clf.layers"
      ],
      "metadata": {
        "id": "eLJhQfiHfi14"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Shuffle Data since SMOTE appends many 1s at the end\n",
        "\n",
        "from sklearn.utils import shuffle\n",
        "\n",
        "X_train_ANN, y_train_ANN = shuffle(X_train, y_train, random_state = 10)\n",
        "y_train_ANN.value_counts()"
      ],
      "metadata": {
        "id": "ldBEbhztfjvj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ann_clf.compile(optimizer = 'adam', \n",
        "                metrics=['accuracy'], \n",
        "                loss ='binary_crossentropy')\n",
        "\n",
        "record = ann_clf.fit(\n",
        "            X_train_ANN, \n",
        "            y_train_ANN, \n",
        "            validation_data = (X_val, y_val), \n",
        "            batch_size = 10, \n",
        "            epochs = 50)"
      ],
      "metadata": {
        "id": "bK1SXteMfln5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "keras.utils.plot_model(ann_clf, show_shapes=True, rankdir=\"LR\")"
      ],
      "metadata": {
        "id": "ChuhGr3Ufmgq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "_, train_acc = ann_clf.evaluate(X_train, y_train, verbose=0)\n",
        "_, val_acc = ann_clf.evaluate(X_val, y_val, verbose=0)\n",
        "_, test_acc = ann_clf.evaluate(X_test, y_test, verbose=0)\n",
        "print('Train: %.3f, Validation: %.3f, Test: %.3f' % (train_acc, val_acc, test_acc))"
      ],
      "metadata": {
        "id": "rsSZTcIlfnQa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(record.history['accuracy'], label='Training')\n",
        "plt.plot(record.history['val_accuracy'], label='Validation')\n",
        "plt.legend()\n",
        "plt.xlabel('Epochs', fontsize=16)\n",
        "plt.ylabel('Accuracy', fontsize=16)\n",
        "plt.title('Accuracy Curves', fontsize=16)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Jvmnf03BfoDj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# plot training history\n",
        "plt.plot(record.history['loss'], label='Training')\n",
        "plt.plot(record.history['val_loss'], label='Validation')\n",
        "plt.legend()\n",
        "plt.xlabel('Epochs', fontsize=14)\n",
        "plt.ylabel('Loss', fontsize=14)\n",
        "plt.title('Loss Curves', fontsize=16)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Bk9KBNCCfpw5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Experiment 2: Different Batch Sizes"
      ],
      "metadata": {
        "id": "hy1WHdJSfrl1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Fit a model and plot learning curve\n",
        "def fit_model_1(X_train, y_train, X_test, y_test, n_batch):\n",
        "  # Define Model\n",
        "  ann_clf = keras.models.Sequential([\n",
        "      keras.layers.Dense(6, input_shape=(X_train.shape[1],), activation='sigmoid'),\n",
        "      keras.layers.Dense(6, activation='sigmoid'),\n",
        "      keras.layers.Dense(6, activation='sigmoid'), \n",
        "      # keras.layers.Dropout(0.2),\n",
        "      keras.layers.Dense(1, activation = 'sigmoid')\n",
        "  ])\n",
        "\n",
        "  # Compile Model\n",
        "  ann_clf.compile(optimizer = 'adam',\n",
        "                metrics=['accuracy'],\n",
        "                loss = 'binary_crossentropy')\n",
        "  \n",
        "  # Fit Model\n",
        "  history = ann_clf.fit(X_train_ANN,\n",
        "                      y_train_ANN,\n",
        "                      validation_data=(X_test, y_test),\n",
        "                      epochs=100,\n",
        "                      verbose=0,\n",
        "                      batch_size=n_batch)\n",
        "\n",
        "  # Plot Learning Curves\n",
        "  plt.plot(history.history['accuracy'], label='train') \n",
        "  plt.plot(history.history['val_accuracy'], label='test') \n",
        "  plt.title('batch='+str(n_batch)) \n",
        "  plt.legend()"
      ],
      "metadata": {
        "id": "EbpRvs_nfsV4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create learning curves for different batch sizes\n",
        "# batch_sizes = [4, 6, 10, 16, 32, 64, 128, 260]\n",
        "batch_sizes = [10, 15, 20, 25, 30]\n",
        "\n",
        "plt.figure(figsize=(10,15))\n",
        "for i in range(len(batch_sizes)):\n",
        "\n",
        "  # Determine the Plot Number\n",
        "  plot_no = 420 + (i+1)\n",
        "  plt.subplot(plot_no)\n",
        "\n",
        "  # Fit model and plot learning curves for a batch size\n",
        "  fit_model_1(X_train, y_train, X_test, y_test, batch_sizes[i])\n",
        "\n",
        "# Show learning curves\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "govzlyT3fwI0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Experiment 3: Different EPOCHs"
      ],
      "metadata": {
        "id": "jDdPwZjcfxsF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Fit a model and plot learning curve\n",
        "def fit_model_2(trainX, trainy, validX, validy, n_epoch):\n",
        "  # Define Model\n",
        "  ann_clf = keras.models.Sequential([\n",
        "      keras.layers.Dense(6, input_shape=(X_train.shape[1],), activation='sigmoid'),\n",
        "      keras.layers.Dense(6, activation='sigmoid'),\n",
        "      keras.layers.Dense(6, activation='sigmoid'), \n",
        "      # keras.layers.Dropout(0.2),\n",
        "      keras.layers.Dense(1, activation = 'sigmoid')\n",
        "  ])\n",
        "\n",
        "  # Compile Model\n",
        "  ann_clf.compile(optimizer = 'adam',\n",
        "                metrics=['accuracy'],\n",
        "                loss = 'binary_crossentropy')\n",
        "    \n",
        "  # fit model\n",
        "  history = ann_clf.fit(X_train_ANN,\n",
        "                      y_train_ANN,\n",
        "                      validation_data=(X_test, y_test),\n",
        "                      epochs=n_epoch,\n",
        "                      verbose=0,\n",
        "                      batch_size=6)\n",
        "    \n",
        "  # plot learning curves\n",
        "  plt.plot(history.history['accuracy'], label='train')\n",
        "  plt.plot(history.history['val_accuracy'], label='test')\n",
        "  plt.title('epoch='+str(n_epoch))\n",
        "  plt.legend()"
      ],
      "metadata": {
        "id": "gjSGc9u6fxTv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create learning curves for different batch sizes\n",
        "# epochs = [20, 50, 100, 120, 150, 200, 300, 400]\n",
        "epochs = [50, 60, 70, 80, 90, 100]\n",
        "\n",
        "plt.figure(figsize=(10,15))\n",
        "for i in range(len(batch_sizes)):\n",
        "\n",
        "  # Determine the Plot Number\n",
        "  plot_no = 420 + (i+1)\n",
        "  plt.subplot(plot_no)\n",
        "\n",
        "  # Fit model and plot learning curves for a batch size\n",
        "  fit_model_2(X_train, y_train, X_test, y_test, epochs[i])\n",
        "\n",
        "# Show learning curves\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "SP2zm_ySfznt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Experiment 4: Early Stopping"
      ],
      "metadata": {
        "id": "3_QvFWOmf0JZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.callbacks import EarlyStopping\n",
        "from keras.callbacks import ModelCheckpoint"
      ],
      "metadata": {
        "id": "3AUOp_Qwf2_U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def init_model():\n",
        "  # Define Model\n",
        "  ann_clf = keras.models.Sequential([\n",
        "      keras.layers.Dense(6, input_shape=(X_train.shape[1],), activation='sigmoid'),\n",
        "      keras.layers.Dense(6, activation='sigmoid'),\n",
        "      keras.layers.Dense(6, activation='sigmoid'), \n",
        "      keras.layers.Dropout(0.2),\n",
        "      keras.layers.Dense(1, activation = 'sigmoid')\n",
        "  ])\n",
        "\n",
        "  # Compile Model\n",
        "  ann_clf.compile(optimizer = 'adam',\n",
        "                metrics=['accuracy'],\n",
        "                loss = 'binary_crossentropy')\n",
        "  return ann_clf\n",
        "\n",
        "# init model\n",
        "ann_clf = init_model()\n",
        "# simple early stopping\n",
        "es = EarlyStopping(monitor='val_loss',\n",
        "                   mode='min',\n",
        "                   verbose=1,\n",
        "                   patience=150)\n",
        "mc = ModelCheckpoint('best_model.h5',\n",
        "                     monitor='val_accuracy',\n",
        "                     mode='max',\n",
        "                     verbose=1,\n",
        "                     save_best_only=True)\n",
        "history = ann_clf.fit(X_train_ANN,\n",
        "                    y_train_ANN,\n",
        "                    validation_data=(X_test, y_test),\n",
        "                    epochs=50,\n",
        "                    verbose=0,\n",
        "                    batch_size=25,\n",
        "                    callbacks=[es, mc])"
      ],
      "metadata": {
        "id": "8uidzovhf4S6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# plot training history\n",
        "plt.plot(history.history['loss'], label='Training')\n",
        "plt.plot(history.history['val_loss'], label='Validation')\n",
        "plt.legend()\n",
        "plt.xlabel('Epochs', fontsize=14)\n",
        "plt.ylabel('Loss', fontsize=14)\n",
        "plt.title('Loss Curves', fontsize=16)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "JAVLJDzLf6Ce"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=[8,5])\n",
        "plt.plot(history.history['accuracy'], label='Training')\n",
        "plt.plot(history.history['val_accuracy'], label='Validation')\n",
        "plt.legend()\n",
        "plt.xlabel('Epochs', fontsize=16)\n",
        "plt.ylabel('Accuracy', fontsize=16)\n",
        "plt.title('Accuracy Curves', fontsize=16)\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "sPPqcZCyf6zy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Voting Classifier\n",
        "\n",
        "- Library: Scikit-learn, Keras, Tensorflow\n",
        "- Shuffling does not affect the model building. No random_state.\n",
        "- No need for RandomizedSearchCV since there is only 1 important parameter: voting"
      ],
      "metadata": {
        "id": "4rBdGe3Gukv6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "display(models_eval)"
      ],
      "metadata": {
        "id": "YCHV8rR-ZU5c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Re-Train Top 3 Models Using Their Parameters Specifically\n",
        "\n",
        "model_1 = LGBMClassifier(n_estimators=1000, learning_rate=0.1, max_depth=3, random_state=10)\n",
        "model_2 = GradientBoostingClassifier(n_estimators=500, learning_rate=0.5, max_depth=1, random_state=10)\n",
        "model_3 = RandomForestClassifier(n_estimators=1000, max_depth = None, n_jobs =-1, random_state=10)\n",
        "\n",
        "name = 'ensem_clf'\n",
        "\n",
        "train = pd.DataFrame(columns = ['voting', 'n_jobs'])\n",
        "train = train.append({'voting': 'hard', 'n_jobs': -1}, ignore_index=True)\n",
        "train = train.append({'voting': 'soft', 'n_jobs': -1}, ignore_index=True)\n",
        "train = train.reset_index()\n",
        "\n",
        "for index, row in train.iterrows():\n",
        "    model_name = name + str(index)\n",
        "    ens_clf = VotingClassifier(estimators=[('m1', model_1), ('m2', model_2), ('m3', model_3)],\n",
        "                               voting = row['voting'],\n",
        "                               n_jobs = int(row['n_jobs']))\n",
        "    ens_clf.fit(X_train, y_train)\n",
        "    y_true = y_val\n",
        "    y_pred = ens_clf.predict(X_val)\n",
        "    evaluation_results = evaluation_metrics(y_true, y_pred)\n",
        "\n",
        "    models = models.append({'model_name': model_name, \n",
        "                            'model': ens_clf, \n",
        "                            'parameters': ens_clf.get_params()}, \n",
        "                           ignore_index=True)\n",
        "    \n",
        "    models_eval = models_eval.append({'model_name': model_name, \n",
        "                                      'confusion_matrix' : evaluation_results[0], \n",
        "                                      'accuracy': evaluation_results[1], \n",
        "                                      'recall' : evaluation_results[2], \n",
        "                                      'f1_score': evaluation_results[3], \n",
        "                                      'roc_auc_score': evaluation_results[4]}, \n",
        "                                     ignore_index=True)"
      ],
      "metadata": {
        "id": "YIe8XVe4gBMX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Discussion"
      ],
      "metadata": {
        "id": "VSpOrrm2gNXL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "display(models)"
      ],
      "metadata": {
        "id": "EZfBQi4KgLrV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "display(models_eval)"
      ],
      "metadata": {
        "id": "2LY9af70gM_6"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}