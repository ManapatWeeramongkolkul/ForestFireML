{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "COF7WWOtCQRP"
      },
      "source": [
        "# Model Training & Evaluation Pipeline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kNbJ7WYUXWks"
      },
      "source": [
        "Details: [Model Training Specifications](https://docs.google.com/document/d/1UiDi8nyTcfMeMNIAz3KntlVZBlYrpoMAURuDccTt-wk/edit?usp=sharing)\n",
        "\n",
        "Model Evaluation: Identify best parameters for each model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qK_KRJw0rpA9",
        "outputId": "2cccae5a-2a3f-41cb-a0d4-f33254eac81c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "# Basic Libraries\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sb\n",
        "import matplotlib.pyplot as plt\n",
        "from datetime import datetime\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "BTKpuPDqvTli",
        "outputId": "b5d41773-a7a7-4a87-cca7-2d2fef483dcc"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   LATITUDE  LONGITUDE  CO_MOL/M2  SO2_MOL/M2  NO2_MOL/M2  O3_MOL/M2  \\\n",
              "0  0.079561   0.356387   0.252793    0.175102    0.048868   0.390066   \n",
              "1  0.079561   0.356387   0.267145    0.175102    0.048868   0.390066   \n",
              "2  0.079561   0.356387   0.252793    0.175102    0.041340   0.390066   \n",
              "3  0.079561   0.356387   0.267145    0.175102    0.041340   0.390066   \n",
              "4  0.083532   0.351189   0.154547    0.210118    0.045284   0.550787   \n",
              "\n",
              "   FIRE_OCCURRED  \n",
              "0              0  \n",
              "1              0  \n",
              "2              0  \n",
              "3              0  \n",
              "4              0  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-c11127af-6720-488c-9176-d94a65a3d05f\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>LATITUDE</th>\n",
              "      <th>LONGITUDE</th>\n",
              "      <th>CO_MOL/M2</th>\n",
              "      <th>SO2_MOL/M2</th>\n",
              "      <th>NO2_MOL/M2</th>\n",
              "      <th>O3_MOL/M2</th>\n",
              "      <th>FIRE_OCCURRED</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.079561</td>\n",
              "      <td>0.356387</td>\n",
              "      <td>0.252793</td>\n",
              "      <td>0.175102</td>\n",
              "      <td>0.048868</td>\n",
              "      <td>0.390066</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.079561</td>\n",
              "      <td>0.356387</td>\n",
              "      <td>0.267145</td>\n",
              "      <td>0.175102</td>\n",
              "      <td>0.048868</td>\n",
              "      <td>0.390066</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.079561</td>\n",
              "      <td>0.356387</td>\n",
              "      <td>0.252793</td>\n",
              "      <td>0.175102</td>\n",
              "      <td>0.041340</td>\n",
              "      <td>0.390066</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.079561</td>\n",
              "      <td>0.356387</td>\n",
              "      <td>0.267145</td>\n",
              "      <td>0.175102</td>\n",
              "      <td>0.041340</td>\n",
              "      <td>0.390066</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.083532</td>\n",
              "      <td>0.351189</td>\n",
              "      <td>0.154547</td>\n",
              "      <td>0.210118</td>\n",
              "      <td>0.045284</td>\n",
              "      <td>0.550787</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c11127af-6720-488c-9176-d94a65a3d05f')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-c11127af-6720-488c-9176-d94a65a3d05f button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-c11127af-6720-488c-9176-d94a65a3d05f');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ],
      "source": [
        "# Data Source\n",
        "\n",
        "df = pd.read_csv(\"/content/drive/MyDrive/cleaned_gee_data_v3.csv\")\n",
        "df = df.drop(columns = ['Unnamed: 0'], axis=1) # Drop index\n",
        "df.head() "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vigF6PJAfy9R",
        "outputId": "61a1ba87-02e8-4b4d-ce18-9fd34f106b1f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 171893 entries, 0 to 171892\n",
            "Data columns (total 7 columns):\n",
            " #   Column         Non-Null Count   Dtype  \n",
            "---  ------         --------------   -----  \n",
            " 0   LATITUDE       171893 non-null  float64\n",
            " 1   LONGITUDE      171893 non-null  float64\n",
            " 2   CO_MOL/M2      171893 non-null  float64\n",
            " 3   SO2_MOL/M2     171893 non-null  float64\n",
            " 4   NO2_MOL/M2     171893 non-null  float64\n",
            " 5   O3_MOL/M2      171893 non-null  float64\n",
            " 6   FIRE_OCCURRED  171893 non-null  int64  \n",
            "dtypes: float64(6), int64(1)\n",
            "memory usage: 9.2 MB\n"
          ]
        }
      ],
      "source": [
        "df.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "id": "2z3siI-MvbQs",
        "outputId": "14c9b938-1721-4206-ff71-c8f8cd02af96"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "0    170544\n",
              "1      1349\n",
              "Name: FIRE_OCCURRED, dtype: int64"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "display(df['FIRE_OCCURRED'].value_counts())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bmVgX-C_pJrz"
      },
      "source": [
        "0.785% of FIRE_OCCURRED = 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "GEBLWi5ooiTO"
      },
      "outputs": [],
      "source": [
        "X = df.drop('FIRE_OCCURRED', axis=1)\n",
        "y = df['FIRE_OCCURRED']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "96m0rNH7vhDg"
      },
      "outputs": [],
      "source": [
        "# Training, Validation, Testing Split\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# 80:10:10\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.10, random_state=10, shuffle=True)\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=1/9, random_state=10, shuffle=True)\n",
        "\n",
        "Original = [X_train, X_val, X_test, y_train, y_val, y_test] # For reference"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oihO76nhvifX",
        "outputId": "ef5dff68-ce99-4672-de44-36180f7ca5a0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X and y data length matching\n",
            "\n",
            "No. of training data = 137513\n",
            "No. of validation data = 17190\n",
            "No. of testing data = 17190\n"
          ]
        }
      ],
      "source": [
        "if len(X_train)==len(y_train) and len(X_test) == len(y_test) and len(X_val) == len(y_val):\n",
        "  print(\"X and y data length matching\")\n",
        "else:\n",
        "  print(\"Error in data preparation pipeline\")\n",
        "print()\n",
        "print(\"No. of training data = %d\" % len(X_train))\n",
        "print(\"No. of validation data = %d\" % len(X_val))\n",
        "print(\"No. of testing data = %d\" % len(X_test))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "id": "MVofMah3XWOo",
        "outputId": "fca2b2de-d9e5-437d-ccfa-ef2e21141632"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "0    17068\n",
              "1      122\n",
              "Name: FIRE_OCCURRED, dtype: int64"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "display(y_val.value_counts())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "id": "1ZcyP7nRvlYp",
        "outputId": "9a0fca1b-780b-45be-9a6f-d7c2cb91de7f"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "0    17059\n",
              "1      131\n",
              "Name: FIRE_OCCURRED, dtype: int64"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "display(y_test.value_counts())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T8MI03z-vmdA",
        "outputId": "7688387f-1266-40db-ad4e-88a33350d820"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original dataset shape Counter({0: 136417, 1: 1096})\n",
            "Resampled dataset shape Counter({0: 136417, 1: 136417})\n"
          ]
        }
      ],
      "source": [
        "# SMOTE\n",
        "\n",
        "from collections import Counter\n",
        "from imblearn.over_sampling import SMOTE \n",
        "\n",
        "print('Original dataset shape %s' % Counter(y_train))\n",
        "sm = SMOTE(random_state=10)\n",
        "X_train, y_train = sm.fit_resample(X_train, y_train)\n",
        "print('Resampled dataset shape %s' % Counter(y_train))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "Ts3u8k7ZoTmA"
      },
      "outputs": [],
      "source": [
        "# Shuffle Data since SMOTE appended many 1s at the end\n",
        "# Required for some algorithms such as ANN\n",
        "\n",
        "from sklearn.utils import shuffle\n",
        "\n",
        "X_train, y_train = shuffle(X_train, y_train, random_state = 10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "5pMqZtYUvo3T"
      },
      "outputs": [],
      "source": [
        "# Evaluation Metrics\n",
        "\n",
        "from sklearn.metrics import confusion_matrix, recall_score, f1_score, roc_auc_score, accuracy_score\n",
        "\n",
        "def evaluation_metrics(y_true, y_pred):\n",
        "  cfm = confusion_matrix(y_true, y_pred).ravel()\n",
        "  acc = accuracy_score(y_true, y_pred)\n",
        "  recs = recall_score(y_true, y_pred, average='binary')\n",
        "  f1s = f1_score(y_true, y_pred, average='binary')\n",
        "  rocs = roc_auc_score(y_true, y_pred, average='macro')\n",
        "  return [cfm, acc, recs, f1s, rocs]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bDAw6kBSvqrd"
      },
      "source": [
        "Confusion matrix format : [ tn , fp , fn , tp ]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "2m4kHhLmvnxj"
      },
      "outputs": [],
      "source": [
        "# Store Model Parameters and Eval\n",
        "\n",
        "models = pd.DataFrame(columns = ['model_name', 'model', 'parameters'])\n",
        "models_eval = pd.DataFrame(columns = ['model_name', 'confusion_matrix', 'accuracy', 'recall', 'f1_score', 'roc_auc_score'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "fFvGo3IYwC3h"
      },
      "outputs": [],
      "source": [
        "# Import ML Algorithms\n",
        "\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "import xgboost\n",
        "from xgboost import XGBClassifier\n",
        "import lightgbm\n",
        "from lightgbm import LGBMClassifier\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from sklearn.ensemble import VotingClassifier\n",
        "\n",
        "# RandomizedSearchCV\n",
        "\n",
        "from sklearn.model_selection import RandomizedSearchCV"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ez3z3utYt1Y4"
      },
      "source": [
        "## Logistic Regression\n",
        "\n",
        "- Library: Scikit-learn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fiXiFiYsZSB6",
        "outputId": "6b6b3002-9e9c-4548-cfe8-055e0172f9d4"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "# Training\n",
        "\n",
        "name = 'log_clf'\n",
        "\n",
        "train = pd.DataFrame(columns = ['penalty', 'warm_start', 'solver', 'max_iter', 'dual', 'n_jobs','random_state'])\n",
        "train = train.append({'penalty' : 'none', 'warm_start': False, 'solver': 'newton-cg',  'max_iter': 247,  'dual': False, 'n_jobs': -1, 'random_state': 10}, ignore_index=True)\n",
        "train = train.append({'penalty' : 'l2', 'warm_start': False, 'solver': 'newton-cg',  'max_iter': 100,  'dual': False, 'n_jobs': -1, 'random_state': 10}, ignore_index=True)\n",
        "\n",
        "train = train.reset_index()\n",
        "for index, row in train.iterrows():\n",
        "    model_name = name + str(index)\n",
        "    log_clf = LogisticRegression(penalty = row['penalty'], n_jobs = int(row['n_jobs']), random_state = int(row['random_state']))\n",
        "    log_clf.fit(X_train, y_train)\n",
        "   \n",
        "    y_true = y_val\n",
        "    y_pred = log_clf.predict(X_val)\n",
        "    evaluation_results = evaluation_metrics(y_true, y_pred)\n",
        "\n",
        "    models = models.append({'model_name': model_name, \n",
        "                            'model': log_clf, \n",
        "                            'parameters': log_clf.get_params()}, \n",
        "                            ignore_index=True)\n",
        "   \n",
        "    models_eval = models_eval.append({'model_name': model_name, \n",
        "                                      'confusion_matrix' : evaluation_results[0], \n",
        "                                      'accuracy': evaluation_results[1], \n",
        "                                      'recall' : evaluation_results[2], \n",
        "                                      'f1_score': evaluation_results[3], \n",
        "                                      'roc_auc_score': evaluation_results[4]}, \n",
        "                                      ignore_index=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 112
        },
        "id": "w5hD6F2kX9ih",
        "outputId": "c116ce4a-2d69-4f53-e011-9428832622f6"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-ad0965aa-673a-4810-81ec-f89593fe2553\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>model_name</th>\n",
              "      <th>confusion_matrix</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>recall</th>\n",
              "      <th>f1_score</th>\n",
              "      <th>roc_auc_score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>log_clf0</td>\n",
              "      <td>[10551, 6517, 38, 84]</td>\n",
              "      <td>0.618674</td>\n",
              "      <td>0.688525</td>\n",
              "      <td>0.024989</td>\n",
              "      <td>0.653349</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>log_clf1</td>\n",
              "      <td>[10551, 6517, 39, 83]</td>\n",
              "      <td>0.618615</td>\n",
              "      <td>0.680328</td>\n",
              "      <td>0.024695</td>\n",
              "      <td>0.649251</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ad0965aa-673a-4810-81ec-f89593fe2553')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-ad0965aa-673a-4810-81ec-f89593fe2553 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-ad0965aa-673a-4810-81ec-f89593fe2553');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "  model_name       confusion_matrix  accuracy    recall  f1_score  \\\n",
              "0   log_clf0  [10551, 6517, 38, 84]  0.618674  0.688525  0.024989   \n",
              "1   log_clf1  [10551, 6517, 39, 83]  0.618615  0.680328  0.024695   \n",
              "\n",
              "   roc_auc_score  \n",
              "0       0.653349  \n",
              "1       0.649251  "
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "display(models_eval)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "efHl6tpGCRSI",
        "outputId": "55cf461f-56b4-4297-e006-335c70242ae6"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[array([0. , 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1. ])]"
            ]
          },
          "execution_count": 25,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "[np.arange(0, 1.1, 0.1)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "09I9B42LX8mb",
        "outputId": "88e38302-fb71-4620-e8d6-839fab2555bb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fitting 3 folds for each of 70 candidates, totalling 210 fits\n",
            "[CV 1/3] END C=0.2, max_iter=100, penalty=l1, solver=newton-cg, warm_start=False;, score=nan total time=   0.0s\n",
            "[CV 2/3] END C=0.2, max_iter=100, penalty=l1, solver=newton-cg, warm_start=False;, score=nan total time=   0.0s\n",
            "[CV 3/3] END C=0.2, max_iter=100, penalty=l1, solver=newton-cg, warm_start=False;, score=nan total time=   0.0s\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_logistic.py:1211: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 2.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 1/3] END C=0.8, max_iter=400, penalty=l1, solver=liblinear, warm_start=True;, score=0.659 total time=  13.4s\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_logistic.py:1211: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 2.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 2/3] END C=0.8, max_iter=400, penalty=l1, solver=liblinear, warm_start=True;, score=0.650 total time=   9.7s\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_logistic.py:1211: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 2.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 3/3] END C=0.8, max_iter=400, penalty=l1, solver=liblinear, warm_start=True;, score=0.656 total time=   7.5s\n",
            "[CV 1/3] END C=0.8, max_iter=400, penalty=l1, solver=newton-cg, warm_start=True;, score=nan total time=   0.0s\n",
            "[CV 2/3] END C=0.8, max_iter=400, penalty=l1, solver=newton-cg, warm_start=True;, score=nan total time=   0.0s\n",
            "[CV 3/3] END C=0.8, max_iter=400, penalty=l1, solver=newton-cg, warm_start=True;, score=nan total time=   0.0s\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 1/3] END C=0.4, max_iter=300, penalty=none, solver=lbfgs, warm_start=True;, score=0.658 total time=   2.0s\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 2/3] END C=0.4, max_iter=300, penalty=none, solver=lbfgs, warm_start=True;, score=0.650 total time=   1.5s\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 3/3] END C=0.4, max_iter=300, penalty=none, solver=lbfgs, warm_start=True;, score=0.656 total time=   1.9s\n",
            "[CV 1/3] END C=0.7, max_iter=100, penalty=l2, solver=lbfgs, warm_start=True;, score=0.659 total time=   2.2s\n",
            "[CV 2/3] END C=0.7, max_iter=100, penalty=l2, solver=lbfgs, warm_start=True;, score=0.652 total time=   2.0s\n",
            "[CV 3/3] END C=0.7, max_iter=100, penalty=l2, solver=lbfgs, warm_start=True;, score=0.654 total time=   2.0s\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_logistic.py:1211: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 2.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 1/3] END C=0.5, max_iter=200, penalty=l1, solver=liblinear, warm_start=True;, score=0.659 total time=   6.8s\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_logistic.py:1211: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 2.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 2/3] END C=0.5, max_iter=200, penalty=l1, solver=liblinear, warm_start=True;, score=0.651 total time=   8.1s\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_logistic.py:1211: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 2.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 3/3] END C=0.5, max_iter=200, penalty=l1, solver=liblinear, warm_start=True;, score=0.656 total time=   6.9s\n",
            "[CV 1/3] END C=0.5, max_iter=100, penalty=l1, solver=newton-cg, warm_start=False;, score=nan total time=   0.0s\n",
            "[CV 2/3] END C=0.5, max_iter=100, penalty=l1, solver=newton-cg, warm_start=False;, score=nan total time=   0.0s\n",
            "[CV 3/3] END C=0.5, max_iter=100, penalty=l1, solver=newton-cg, warm_start=False;, score=nan total time=   0.0s\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 1/3] END C=0.1, max_iter=300, penalty=none, solver=lbfgs, warm_start=False;, score=0.658 total time=   1.9s\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 2/3] END C=0.1, max_iter=300, penalty=none, solver=lbfgs, warm_start=False;, score=0.650 total time=   1.9s\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 3/3] END C=0.1, max_iter=300, penalty=none, solver=lbfgs, warm_start=False;, score=0.656 total time=   2.1s\n",
            "[CV 1/3] END C=0.5, max_iter=500, penalty=none, solver=liblinear, warm_start=True;, score=nan total time=   0.0s\n",
            "[CV 2/3] END C=0.5, max_iter=500, penalty=none, solver=liblinear, warm_start=True;, score=nan total time=   0.0s\n",
            "[CV 3/3] END C=0.5, max_iter=500, penalty=none, solver=liblinear, warm_start=True;, score=nan total time=   0.0s\n",
            "[CV 1/3] END C=0.8, max_iter=100, penalty=l1, solver=lbfgs, warm_start=True;, score=nan total time=   0.0s\n",
            "[CV 2/3] END C=0.8, max_iter=100, penalty=l1, solver=lbfgs, warm_start=True;, score=nan total time=   0.0s\n",
            "[CV 3/3] END C=0.8, max_iter=100, penalty=l1, solver=lbfgs, warm_start=True;, score=nan total time=   0.0s\n",
            "[CV 1/3] END C=0.1, max_iter=400, penalty=elasticnet, solver=newton-cg, warm_start=False;, score=nan total time=   0.0s\n",
            "[CV 2/3] END C=0.1, max_iter=400, penalty=elasticnet, solver=newton-cg, warm_start=False;, score=nan total time=   0.0s\n",
            "[CV 3/3] END C=0.1, max_iter=400, penalty=elasticnet, solver=newton-cg, warm_start=False;, score=nan total time=   0.0s\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_logistic.py:1211: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 2.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 1/3] END C=0.8, max_iter=500, penalty=l1, solver=liblinear, warm_start=False;, score=0.659 total time=   7.3s\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_logistic.py:1211: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 2.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 2/3] END C=0.8, max_iter=500, penalty=l1, solver=liblinear, warm_start=False;, score=0.650 total time=   7.4s\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_logistic.py:1211: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 2.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 3/3] END C=0.8, max_iter=500, penalty=l1, solver=liblinear, warm_start=False;, score=0.656 total time=   8.5s\n",
            "[CV 1/3] END C=0.2, max_iter=300, penalty=none, solver=liblinear, warm_start=True;, score=nan total time=   0.0s\n",
            "[CV 2/3] END C=0.2, max_iter=300, penalty=none, solver=liblinear, warm_start=True;, score=nan total time=   0.0s\n",
            "[CV 3/3] END C=0.2, max_iter=300, penalty=none, solver=liblinear, warm_start=True;, score=nan total time=   0.0s\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 1/3] END C=0.8, max_iter=100, penalty=none, solver=lbfgs, warm_start=True;, score=0.658 total time=   1.9s\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 2/3] END C=0.8, max_iter=100, penalty=none, solver=lbfgs, warm_start=True;, score=0.650 total time=   1.9s\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 3/3] END C=0.8, max_iter=100, penalty=none, solver=lbfgs, warm_start=True;, score=0.656 total time=   1.8s\n",
            "[CV 1/3] END C=1.0, max_iter=300, penalty=l2, solver=newton-cg, warm_start=True;, score=0.659 total time=   1.2s\n",
            "[CV 2/3] END C=1.0, max_iter=300, penalty=l2, solver=newton-cg, warm_start=True;, score=0.651 total time=   1.7s\n",
            "[CV 3/3] END C=1.0, max_iter=300, penalty=l2, solver=newton-cg, warm_start=True;, score=0.655 total time=   1.2s\n",
            "[CV 1/3] END C=0.8, max_iter=300, penalty=l2, solver=lbfgs, warm_start=True;, score=0.659 total time=   1.9s\n",
            "[CV 2/3] END C=0.8, max_iter=300, penalty=l2, solver=lbfgs, warm_start=True;, score=0.652 total time=   1.9s\n",
            "[CV 3/3] END C=0.8, max_iter=300, penalty=l2, solver=lbfgs, warm_start=True;, score=0.655 total time=   1.7s\n",
            "[CV 1/3] END C=0.4, max_iter=100, penalty=l1, solver=newton-cg, warm_start=False;, score=nan total time=   0.0s\n",
            "[CV 2/3] END C=0.4, max_iter=100, penalty=l1, solver=newton-cg, warm_start=False;, score=nan total time=   0.0s\n",
            "[CV 3/3] END C=0.4, max_iter=100, penalty=l1, solver=newton-cg, warm_start=False;, score=nan total time=   0.0s\n",
            "[CV 1/3] END C=0.2, max_iter=500, penalty=elasticnet, solver=lbfgs, warm_start=True;, score=nan total time=   0.0s\n",
            "[CV 2/3] END C=0.2, max_iter=500, penalty=elasticnet, solver=lbfgs, warm_start=True;, score=nan total time=   0.0s\n",
            "[CV 3/3] END C=0.2, max_iter=500, penalty=elasticnet, solver=lbfgs, warm_start=True;, score=nan total time=   0.0s\n",
            "[CV 1/3] END C=0.1, max_iter=400, penalty=l1, solver=newton-cg, warm_start=True;, score=nan total time=   0.0s\n",
            "[CV 2/3] END C=0.1, max_iter=400, penalty=l1, solver=newton-cg, warm_start=True;, score=nan total time=   0.0s\n",
            "[CV 3/3] END C=0.1, max_iter=400, penalty=l1, solver=newton-cg, warm_start=True;, score=nan total time=   0.0s\n",
            "[CV 1/3] END C=0.2, max_iter=100, penalty=none, solver=liblinear, warm_start=True;, score=nan total time=   0.0s\n",
            "[CV 2/3] END C=0.2, max_iter=100, penalty=none, solver=liblinear, warm_start=True;, score=nan total time=   0.0s\n",
            "[CV 3/3] END C=0.2, max_iter=100, penalty=none, solver=liblinear, warm_start=True;, score=nan total time=   0.0s\n",
            "[CV 1/3] END C=0.1, max_iter=200, penalty=l2, solver=lbfgs, warm_start=False;, score=0.674 total time=   1.7s\n",
            "[CV 2/3] END C=0.1, max_iter=200, penalty=l2, solver=lbfgs, warm_start=False;, score=0.669 total time=   1.8s\n",
            "[CV 3/3] END C=0.1, max_iter=200, penalty=l2, solver=lbfgs, warm_start=False;, score=0.673 total time=   1.7s\n",
            "[CV 1/3] END C=0.5, max_iter=500, penalty=l2, solver=newton-cg, warm_start=False;, score=0.661 total time=   0.9s\n",
            "[CV 2/3] END C=0.5, max_iter=500, penalty=l2, solver=newton-cg, warm_start=False;, score=0.653 total time=   0.8s\n",
            "[CV 3/3] END C=0.5, max_iter=500, penalty=l2, solver=newton-cg, warm_start=False;, score=0.654 total time=   1.2s\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_logistic.py:1211: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 2.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 1/3] END C=0.4, max_iter=300, penalty=l1, solver=liblinear, warm_start=False;, score=0.659 total time=   8.2s\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_logistic.py:1211: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 2.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 2/3] END C=0.4, max_iter=300, penalty=l1, solver=liblinear, warm_start=False;, score=0.651 total time=   7.2s\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_logistic.py:1211: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 2.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 3/3] END C=0.4, max_iter=300, penalty=l1, solver=liblinear, warm_start=False;, score=0.656 total time=   8.3s\n",
            "[CV 1/3] END C=1.0, max_iter=500, penalty=none, solver=liblinear, warm_start=False;, score=nan total time=   0.0s\n",
            "[CV 2/3] END C=1.0, max_iter=500, penalty=none, solver=liblinear, warm_start=False;, score=nan total time=   0.0s\n",
            "[CV 3/3] END C=1.0, max_iter=500, penalty=none, solver=liblinear, warm_start=False;, score=nan total time=   0.0s\n",
            "[CV 1/3] END C=0.8, max_iter=300, penalty=l2, solver=lbfgs, warm_start=False;, score=0.659 total time=   1.7s\n",
            "[CV 2/3] END C=0.8, max_iter=300, penalty=l2, solver=lbfgs, warm_start=False;, score=0.652 total time=   1.6s\n",
            "[CV 3/3] END C=0.8, max_iter=300, penalty=l2, solver=lbfgs, warm_start=False;, score=0.655 total time=   1.7s\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_logistic.py:1211: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 2.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 1/3] END C=0.4, max_iter=400, penalty=l2, solver=liblinear, warm_start=False;, score=0.661 total time=   0.5s\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_logistic.py:1211: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 2.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 2/3] END C=0.4, max_iter=400, penalty=l2, solver=liblinear, warm_start=False;, score=0.655 total time=   0.5s\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_logistic.py:1211: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 2.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 3/3] END C=0.4, max_iter=400, penalty=l2, solver=liblinear, warm_start=False;, score=0.654 total time=   0.5s\n",
            "[CV 1/3] END C=1.0, max_iter=400, penalty=elasticnet, solver=liblinear, warm_start=True;, score=nan total time=   0.0s\n",
            "[CV 2/3] END C=1.0, max_iter=400, penalty=elasticnet, solver=liblinear, warm_start=True;, score=nan total time=   0.0s\n",
            "[CV 3/3] END C=1.0, max_iter=400, penalty=elasticnet, solver=liblinear, warm_start=True;, score=nan total time=   0.0s\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 1/3] END C=0.3, max_iter=100, penalty=none, solver=newton-cg, warm_start=False;, score=0.658 total time=   0.8s\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 2/3] END C=0.3, max_iter=100, penalty=none, solver=newton-cg, warm_start=False;, score=0.650 total time=   1.0s\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 3/3] END C=0.3, max_iter=100, penalty=none, solver=newton-cg, warm_start=False;, score=0.656 total time=   1.1s\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_logistic.py:1211: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 2.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 1/3] END C=0.2, max_iter=100, penalty=l2, solver=liblinear, warm_start=False;, score=0.666 total time=   0.7s\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_logistic.py:1211: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 2.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 2/3] END C=0.2, max_iter=100, penalty=l2, solver=liblinear, warm_start=False;, score=0.660 total time=   0.6s\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_logistic.py:1211: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 2.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 3/3] END C=0.2, max_iter=100, penalty=l2, solver=liblinear, warm_start=False;, score=0.658 total time=   0.7s\n",
            "[CV 1/3] END C=0.8, max_iter=100, penalty=none, solver=liblinear, warm_start=True;, score=nan total time=   0.0s\n",
            "[CV 2/3] END C=0.8, max_iter=100, penalty=none, solver=liblinear, warm_start=True;, score=nan total time=   0.0s\n",
            "[CV 3/3] END C=0.8, max_iter=100, penalty=none, solver=liblinear, warm_start=True;, score=nan total time=   0.0s\n",
            "[CV 1/3] END C=0.2, max_iter=500, penalty=elasticnet, solver=newton-cg, warm_start=True;, score=nan total time=   0.0s\n",
            "[CV 2/3] END C=0.2, max_iter=500, penalty=elasticnet, solver=newton-cg, warm_start=True;, score=nan total time=   0.0s\n",
            "[CV 3/3] END C=0.2, max_iter=500, penalty=elasticnet, solver=newton-cg, warm_start=True;, score=nan total time=   0.0s\n",
            "[CV 1/3] END C=0.4, max_iter=100, penalty=l2, solver=lbfgs, warm_start=True;, score=0.661 total time=   1.9s\n",
            "[CV 2/3] END C=0.4, max_iter=100, penalty=l2, solver=lbfgs, warm_start=True;, score=0.655 total time=   1.8s\n",
            "[CV 3/3] END C=0.4, max_iter=100, penalty=l2, solver=lbfgs, warm_start=True;, score=0.654 total time=   1.8s\n",
            "[CV 1/3] END C=0.3, max_iter=500, penalty=elasticnet, solver=lbfgs, warm_start=False;, score=nan total time=   0.0s\n",
            "[CV 2/3] END C=0.3, max_iter=500, penalty=elasticnet, solver=lbfgs, warm_start=False;, score=nan total time=   0.0s\n",
            "[CV 3/3] END C=0.3, max_iter=500, penalty=elasticnet, solver=lbfgs, warm_start=False;, score=nan total time=   0.0s\n",
            "[CV 1/3] END C=0.6, max_iter=300, penalty=l2, solver=newton-cg, warm_start=False;, score=0.659 total time=   0.9s\n",
            "[CV 2/3] END C=0.6, max_iter=300, penalty=l2, solver=newton-cg, warm_start=False;, score=0.652 total time=   0.9s\n",
            "[CV 3/3] END C=0.6, max_iter=300, penalty=l2, solver=newton-cg, warm_start=False;, score=0.654 total time=   0.9s\n",
            "[CV 1/3] END C=0.7, max_iter=500, penalty=none, solver=liblinear, warm_start=False;, score=nan total time=   0.0s\n",
            "[CV 2/3] END C=0.7, max_iter=500, penalty=none, solver=liblinear, warm_start=False;, score=nan total time=   0.0s\n",
            "[CV 3/3] END C=0.7, max_iter=500, penalty=none, solver=liblinear, warm_start=False;, score=nan total time=   0.0s\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 1/3] END C=0.4, max_iter=100, penalty=none, solver=newton-cg, warm_start=False;, score=0.658 total time=   0.8s\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 2/3] END C=0.4, max_iter=100, penalty=none, solver=newton-cg, warm_start=False;, score=0.650 total time=   0.9s\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 3/3] END C=0.4, max_iter=100, penalty=none, solver=newton-cg, warm_start=False;, score=0.656 total time=   0.9s\n",
            "[CV 1/3] END C=0.8, max_iter=100, penalty=l2, solver=lbfgs, warm_start=True;, score=0.659 total time=   1.7s\n",
            "[CV 2/3] END C=0.8, max_iter=100, penalty=l2, solver=lbfgs, warm_start=True;, score=0.652 total time=   1.9s\n",
            "[CV 3/3] END C=0.8, max_iter=100, penalty=l2, solver=lbfgs, warm_start=True;, score=0.655 total time=   2.0s\n",
            "[CV 1/3] END C=0.2, max_iter=500, penalty=l1, solver=lbfgs, warm_start=False;, score=nan total time=   0.0s\n",
            "[CV 2/3] END C=0.2, max_iter=500, penalty=l1, solver=lbfgs, warm_start=False;, score=nan total time=   0.0s\n",
            "[CV 3/3] END C=0.2, max_iter=500, penalty=l1, solver=lbfgs, warm_start=False;, score=nan total time=   0.0s\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 1/3] END C=0.7, max_iter=400, penalty=none, solver=lbfgs, warm_start=True;, score=0.658 total time=   2.0s\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 2/3] END C=0.7, max_iter=400, penalty=none, solver=lbfgs, warm_start=True;, score=0.650 total time=   1.7s\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 3/3] END C=0.7, max_iter=400, penalty=none, solver=lbfgs, warm_start=True;, score=0.656 total time=   1.7s\n",
            "[CV 1/3] END C=1.0, max_iter=200, penalty=none, solver=liblinear, warm_start=False;, score=nan total time=   0.0s\n",
            "[CV 2/3] END C=1.0, max_iter=200, penalty=none, solver=liblinear, warm_start=False;, score=nan total time=   0.0s\n",
            "[CV 3/3] END C=1.0, max_iter=200, penalty=none, solver=liblinear, warm_start=False;, score=nan total time=   0.0s\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_logistic.py:1211: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 2.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 1/3] END C=0.3, max_iter=200, penalty=l2, solver=liblinear, warm_start=True;, score=0.663 total time=   0.5s\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_logistic.py:1211: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 2.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 2/3] END C=0.3, max_iter=200, penalty=l2, solver=liblinear, warm_start=True;, score=0.657 total time=   0.5s\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_logistic.py:1211: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 2.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 3/3] END C=0.3, max_iter=200, penalty=l2, solver=liblinear, warm_start=True;, score=0.655 total time=   0.5s\n",
            "[CV 1/3] END C=0.7, max_iter=200, penalty=elasticnet, solver=newton-cg, warm_start=True;, score=nan total time=   0.0s\n",
            "[CV 2/3] END C=0.7, max_iter=200, penalty=elasticnet, solver=newton-cg, warm_start=True;, score=nan total time=   0.0s\n",
            "[CV 3/3] END C=0.7, max_iter=200, penalty=elasticnet, solver=newton-cg, warm_start=True;, score=nan total time=   0.0s\n",
            "[CV 1/3] END C=0.1, max_iter=100, penalty=l2, solver=lbfgs, warm_start=False;, score=0.674 total time=   1.7s\n",
            "[CV 2/3] END C=0.1, max_iter=100, penalty=l2, solver=lbfgs, warm_start=False;, score=0.669 total time=   1.7s\n",
            "[CV 3/3] END C=0.1, max_iter=100, penalty=l2, solver=lbfgs, warm_start=False;, score=0.673 total time=   1.9s\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 1/3] END C=0.1, max_iter=300, penalty=none, solver=newton-cg, warm_start=False;, score=0.658 total time=   1.1s\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 2/3] END C=0.1, max_iter=300, penalty=none, solver=newton-cg, warm_start=False;, score=0.650 total time=   1.2s\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 3/3] END C=0.1, max_iter=300, penalty=none, solver=newton-cg, warm_start=False;, score=0.656 total time=   1.1s\n",
            "[CV 1/3] END C=0.3, max_iter=500, penalty=l2, solver=newton-cg, warm_start=False;, score=0.663 total time=   1.0s\n",
            "[CV 2/3] END C=0.3, max_iter=500, penalty=l2, solver=newton-cg, warm_start=False;, score=0.657 total time=   0.9s\n",
            "[CV 3/3] END C=0.3, max_iter=500, penalty=l2, solver=newton-cg, warm_start=False;, score=0.655 total time=   0.8s\n",
            "[CV 1/3] END C=0.3, max_iter=500, penalty=none, solver=liblinear, warm_start=True;, score=nan total time=   0.0s\n",
            "[CV 2/3] END C=0.3, max_iter=500, penalty=none, solver=liblinear, warm_start=True;, score=nan total time=   0.0s\n",
            "[CV 3/3] END C=0.3, max_iter=500, penalty=none, solver=liblinear, warm_start=True;, score=nan total time=   0.0s\n",
            "[CV 1/3] END C=0.4, max_iter=100, penalty=elasticnet, solver=lbfgs, warm_start=False;, score=nan total time=   0.0s\n",
            "[CV 2/3] END C=0.4, max_iter=100, penalty=elasticnet, solver=lbfgs, warm_start=False;, score=nan total time=   0.0s\n",
            "[CV 3/3] END C=0.4, max_iter=100, penalty=elasticnet, solver=lbfgs, warm_start=False;, score=nan total time=   0.0s\n",
            "[CV 1/3] END C=0.7, max_iter=400, penalty=l2, solver=newton-cg, warm_start=True;, score=0.659 total time=   0.8s\n",
            "[CV 2/3] END C=0.7, max_iter=400, penalty=l2, solver=newton-cg, warm_start=True;, score=0.652 total time=   0.9s\n",
            "[CV 3/3] END C=0.7, max_iter=400, penalty=l2, solver=newton-cg, warm_start=True;, score=0.654 total time=   0.9s\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 1/3] END C=0.6, max_iter=400, penalty=none, solver=newton-cg, warm_start=False;, score=0.658 total time=   0.9s\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 2/3] END C=0.6, max_iter=400, penalty=none, solver=newton-cg, warm_start=False;, score=0.650 total time=   0.9s\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 3/3] END C=0.6, max_iter=400, penalty=none, solver=newton-cg, warm_start=False;, score=0.656 total time=   0.9s\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_logistic.py:1211: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 2.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 1/3] END C=1.0, max_iter=300, penalty=l1, solver=liblinear, warm_start=True;, score=0.659 total time=   9.3s\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_logistic.py:1211: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 2.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 2/3] END C=1.0, max_iter=300, penalty=l1, solver=liblinear, warm_start=True;, score=0.650 total time=   7.5s\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_logistic.py:1211: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 2.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 3/3] END C=1.0, max_iter=300, penalty=l1, solver=liblinear, warm_start=True;, score=0.656 total time=   8.3s\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 1/3] END C=1.0, max_iter=200, penalty=none, solver=newton-cg, warm_start=False;, score=0.658 total time=   1.1s\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 2/3] END C=1.0, max_iter=200, penalty=none, solver=newton-cg, warm_start=False;, score=0.650 total time=   0.9s\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 3/3] END C=1.0, max_iter=200, penalty=none, solver=newton-cg, warm_start=False;, score=0.656 total time=   0.9s\n",
            "[CV 1/3] END C=0.2, max_iter=500, penalty=l1, solver=newton-cg, warm_start=True;, score=nan total time=   0.0s\n",
            "[CV 2/3] END C=0.2, max_iter=500, penalty=l1, solver=newton-cg, warm_start=True;, score=nan total time=   0.0s\n",
            "[CV 3/3] END C=0.2, max_iter=500, penalty=l1, solver=newton-cg, warm_start=True;, score=nan total time=   0.0s\n",
            "[CV 1/3] END C=0.4, max_iter=300, penalty=l2, solver=newton-cg, warm_start=True;, score=0.661 total time=   0.9s\n",
            "[CV 2/3] END C=0.4, max_iter=300, penalty=l2, solver=newton-cg, warm_start=True;, score=0.655 total time=   0.9s\n",
            "[CV 3/3] END C=0.4, max_iter=300, penalty=l2, solver=newton-cg, warm_start=True;, score=0.654 total time=   0.9s\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 1/3] END C=0.2, max_iter=400, penalty=none, solver=lbfgs, warm_start=False;, score=0.658 total time=   1.8s\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 2/3] END C=0.2, max_iter=400, penalty=none, solver=lbfgs, warm_start=False;, score=0.650 total time=   1.7s\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 3/3] END C=0.2, max_iter=400, penalty=none, solver=lbfgs, warm_start=False;, score=0.656 total time=   1.7s\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 1/3] END C=0.8, max_iter=100, penalty=none, solver=newton-cg, warm_start=False;, score=0.658 total time=   1.2s\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 2/3] END C=0.8, max_iter=100, penalty=none, solver=newton-cg, warm_start=False;, score=0.650 total time=   1.2s\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 3/3] END C=0.8, max_iter=100, penalty=none, solver=newton-cg, warm_start=False;, score=0.656 total time=   1.2s\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 1/3] END C=0.2, max_iter=100, penalty=none, solver=lbfgs, warm_start=False;, score=0.658 total time=   2.0s\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 2/3] END C=0.2, max_iter=100, penalty=none, solver=lbfgs, warm_start=False;, score=0.650 total time=   1.7s\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 3/3] END C=0.2, max_iter=100, penalty=none, solver=lbfgs, warm_start=False;, score=0.656 total time=   1.7s\n",
            "[CV 1/3] END C=0.8, max_iter=200, penalty=none, solver=liblinear, warm_start=False;, score=nan total time=   0.0s\n",
            "[CV 2/3] END C=0.8, max_iter=200, penalty=none, solver=liblinear, warm_start=False;, score=nan total time=   0.0s\n",
            "[CV 3/3] END C=0.8, max_iter=200, penalty=none, solver=liblinear, warm_start=False;, score=nan total time=   0.0s\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_logistic.py:1211: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 2.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 1/3] END C=0.7, max_iter=300, penalty=l2, solver=liblinear, warm_start=True;, score=0.659 total time=   0.5s\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_logistic.py:1211: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 2.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 2/3] END C=0.7, max_iter=300, penalty=l2, solver=liblinear, warm_start=True;, score=0.652 total time=   0.5s\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_logistic.py:1211: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 2.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 3/3] END C=0.7, max_iter=300, penalty=l2, solver=liblinear, warm_start=True;, score=0.654 total time=   0.5s\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_logistic.py:1211: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 2.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 1/3] END C=0.4, max_iter=500, penalty=l1, solver=liblinear, warm_start=False;, score=0.659 total time=   7.5s\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_logistic.py:1211: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 2.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 2/3] END C=0.4, max_iter=500, penalty=l1, solver=liblinear, warm_start=False;, score=0.651 total time=   7.7s\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_logistic.py:1211: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 2.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 3/3] END C=0.4, max_iter=500, penalty=l1, solver=liblinear, warm_start=False;, score=0.656 total time=   7.2s\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 1/3] END C=0.7, max_iter=100, penalty=none, solver=newton-cg, warm_start=True;, score=0.658 total time=   1.2s\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 2/3] END C=0.7, max_iter=100, penalty=none, solver=newton-cg, warm_start=True;, score=0.650 total time=   1.2s\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 3/3] END C=0.7, max_iter=100, penalty=none, solver=newton-cg, warm_start=True;, score=0.656 total time=   1.1s\n",
            "[CV 1/3] END C=0.8, max_iter=400, penalty=l2, solver=newton-cg, warm_start=True;, score=0.659 total time=   1.2s\n",
            "[CV 2/3] END C=0.8, max_iter=400, penalty=l2, solver=newton-cg, warm_start=True;, score=0.652 total time=   1.1s\n",
            "[CV 3/3] END C=0.8, max_iter=400, penalty=l2, solver=newton-cg, warm_start=True;, score=0.655 total time=   0.9s\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_logistic.py:1211: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 2.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 1/3] END C=0.1, max_iter=200, penalty=l2, solver=liblinear, warm_start=False;, score=0.674 total time=   0.5s\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_logistic.py:1211: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 2.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 2/3] END C=0.1, max_iter=200, penalty=l2, solver=liblinear, warm_start=False;, score=0.669 total time=   0.5s\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_logistic.py:1211: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 2.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 3/3] END C=0.1, max_iter=200, penalty=l2, solver=liblinear, warm_start=False;, score=0.673 total time=   0.5s\n",
            "[CV 1/3] END C=0.4, max_iter=400, penalty=none, solver=liblinear, warm_start=True;, score=nan total time=   0.0s\n",
            "[CV 2/3] END C=0.4, max_iter=400, penalty=none, solver=liblinear, warm_start=True;, score=nan total time=   0.0s\n",
            "[CV 3/3] END C=0.4, max_iter=400, penalty=none, solver=liblinear, warm_start=True;, score=nan total time=   0.0s\n",
            "[CV 1/3] END C=0.8, max_iter=200, penalty=elasticnet, solver=liblinear, warm_start=True;, score=nan total time=   0.0s\n",
            "[CV 2/3] END C=0.8, max_iter=200, penalty=elasticnet, solver=liblinear, warm_start=True;, score=nan total time=   0.0s\n",
            "[CV 3/3] END C=0.8, max_iter=200, penalty=elasticnet, solver=liblinear, warm_start=True;, score=nan total time=   0.0s\n",
            "[CV 1/3] END C=0.5, max_iter=500, penalty=elasticnet, solver=lbfgs, warm_start=False;, score=nan total time=   0.0s\n",
            "[CV 2/3] END C=0.5, max_iter=500, penalty=elasticnet, solver=lbfgs, warm_start=False;, score=nan total time=   0.0s\n",
            "[CV 3/3] END C=0.5, max_iter=500, penalty=elasticnet, solver=lbfgs, warm_start=False;, score=nan total time=   0.0s\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_logistic.py:1211: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 2.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 1/3] END C=0.1, max_iter=100, penalty=l2, solver=liblinear, warm_start=False;, score=0.674 total time=   0.5s\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_logistic.py:1211: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 2.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 2/3] END C=0.1, max_iter=100, penalty=l2, solver=liblinear, warm_start=False;, score=0.669 total time=   0.5s\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_logistic.py:1211: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 2.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 3/3] END C=0.1, max_iter=100, penalty=l2, solver=liblinear, warm_start=False;, score=0.673 total time=   0.5s\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 1/3] END C=0.1, max_iter=200, penalty=none, solver=lbfgs, warm_start=False;, score=0.658 total time=   1.8s\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 2/3] END C=0.1, max_iter=200, penalty=none, solver=lbfgs, warm_start=False;, score=0.650 total time=   1.7s\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 3/3] END C=0.1, max_iter=200, penalty=none, solver=lbfgs, warm_start=False;, score=0.656 total time=   1.7s\n",
            "[CV 1/3] END C=0.3, max_iter=400, penalty=none, solver=liblinear, warm_start=True;, score=nan total time=   0.0s\n",
            "[CV 2/3] END C=0.3, max_iter=400, penalty=none, solver=liblinear, warm_start=True;, score=nan total time=   0.0s\n",
            "[CV 3/3] END C=0.3, max_iter=400, penalty=none, solver=liblinear, warm_start=True;, score=nan total time=   0.0s\n",
            "[CV 1/3] END C=0.5, max_iter=300, penalty=l1, solver=lbfgs, warm_start=False;, score=nan total time=   0.0s\n",
            "[CV 2/3] END C=0.5, max_iter=300, penalty=l1, solver=lbfgs, warm_start=False;, score=nan total time=   0.0s\n",
            "[CV 3/3] END C=0.5, max_iter=300, penalty=l1, solver=lbfgs, warm_start=False;, score=nan total time=   0.0s\n",
            "[CV 1/3] END C=0.3, max_iter=200, penalty=l2, solver=newton-cg, warm_start=False;, score=0.663 total time=   1.1s\n",
            "[CV 2/3] END C=0.3, max_iter=200, penalty=l2, solver=newton-cg, warm_start=False;, score=0.657 total time=   1.2s\n",
            "[CV 3/3] END C=0.3, max_iter=200, penalty=l2, solver=newton-cg, warm_start=False;, score=0.655 total time=   1.1s\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/model_selection/_validation.py:378: FitFailedWarning: \n",
            "87 fits failed out of a total of 210.\n",
            "The score on these train-test partitions for these parameters will be set to nan.\n",
            "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
            "\n",
            "Below are more details about the failures:\n",
            "--------------------------------------------------------------------------------\n",
            "18 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_logistic.py\", line 1162, in fit\n",
            "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_logistic.py\", line 54, in _check_solver\n",
            "    raise ValueError(\n",
            "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got l1 penalty.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "33 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_logistic.py\", line 1162, in fit\n",
            "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_logistic.py\", line 71, in _check_solver\n",
            "    raise ValueError(\"penalty='none' is not supported for the liblinear solver\")\n",
            "ValueError: penalty='none' is not supported for the liblinear solver\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "9 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_logistic.py\", line 1162, in fit\n",
            "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_logistic.py\", line 54, in _check_solver\n",
            "    raise ValueError(\n",
            "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "9 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_logistic.py\", line 1162, in fit\n",
            "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_logistic.py\", line 54, in _check_solver\n",
            "    raise ValueError(\n",
            "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "12 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_logistic.py\", line 1162, in fit\n",
            "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_logistic.py\", line 54, in _check_solver\n",
            "    raise ValueError(\n",
            "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "6 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_logistic.py\", line 1162, in fit\n",
            "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_logistic.py\", line 64, in _check_solver\n",
            "    raise ValueError(\n",
            "ValueError: Only 'saga' solver supports elasticnet penalty, got solver=liblinear.\n",
            "\n",
            "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/model_selection/_search.py:952: UserWarning: One or more of the test scores are non-finite: [       nan 0.65506502        nan 0.65466185 0.65505035 0.65542421\n",
            "        nan 0.65466185        nan        nan        nan 0.65506502\n",
            "        nan 0.65466185 0.6552776  0.65510166        nan        nan\n",
            "        nan        nan 0.67200571 0.65582005 0.65550485        nan\n",
            " 0.65510166 0.65683897        nan 0.6546985  0.66119326        nan\n",
            "        nan 0.65683164        nan 0.65506501        nan 0.6546985\n",
            " 0.65510166        nan 0.65466185        nan 0.65848099        nan\n",
            " 0.67200571 0.6546985  0.65853231        nan        nan 0.65507967\n",
            " 0.6546985  0.65499172 0.6546985         nan 0.65685363 0.65466185\n",
            " 0.6546985  0.65466185        nan 0.65516031 0.65550485 0.6546985\n",
            " 0.65507967 0.67188842        nan        nan        nan 0.67188842\n",
            " 0.65466185        nan        nan 0.65853231]\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "{'warm_start': False,\n",
              " 'solver': 'lbfgs',\n",
              " 'penalty': 'l2',\n",
              " 'max_iter': 200,\n",
              " 'C': 0.1}"
            ]
          },
          "execution_count": 29,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# RandomizedSearchCV\n",
        "\n",
        "random_grid = {\n",
        "                \"penalty\": ['l1', 'l2', 'elasticnet', 'none'],\n",
        "                \"max_iter\" :[100, 200, 300, 400, 500],\n",
        "                \"warm_start\" : [True, False],\n",
        "                \"solver\" : ['lbfgs', 'newton-cg', 'liblinear'],\n",
        "                \"C\" : [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.8, 1.0]\n",
        "              }\n",
        "\n",
        "log_random = RandomizedSearchCV(estimator = log_clf, \n",
        "                                param_distributions = random_grid, \n",
        "                                n_iter = 70, \n",
        "                                cv = 3, \n",
        "                                verbose = 3, \n",
        "                                scoring = 'recall',\n",
        "                                random_state = 10)\n",
        "\n",
        "log_random.fit(X_train, y_train)\n",
        "log_random.best_params_"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K6pDMCgDBqPd"
      },
      "source": [
        "Errors expected because there are different supported penalties for different solvers. Increase RandomizedSearchCV iterations to compensate.\n",
        "\n",
        "* lbfgs - [l2, None]\n",
        "* liblinear - [l1, l2]\n",
        "* newton-cg - [l2, None]\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GQf2Kg82OkuJ",
        "outputId": "364ff0cb-0b19-4d8e-f029-950a31f16f7d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'warm_start': False,\n",
              " 'solver': 'lbfgs',\n",
              " 'penalty': 'l2',\n",
              " 'max_iter': 200,\n",
              " 'C': 0.1}"
            ]
          },
          "execution_count": 30,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "log_random.best_params_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rSyim973PLda",
        "outputId": "13a4612e-f8bb-4e1f-da24-e4463ac36b8e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.6720057102218798"
            ]
          },
          "execution_count": 31,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "log_random.best_score_"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oBBQ_iust1eb"
      },
      "source": [
        "## Support Vector Machine (SVM)\n",
        "\n",
        "- Library: Scikit-learn"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-DJDztBnUV6b"
      },
      "source": [
        "Approach 1: Undersampling to lower number of training samples and reduce learning time"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tsq0c55qZSVE"
      },
      "outputs": [],
      "source": [
        "X_train_SVM = Original[0]\n",
        "X_val_SVM = Original[1]\n",
        "y_train_SVM = Original[3]\n",
        "y_val_SVM = Original[4]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "id": "OlCn_HS1dItl",
        "outputId": "c24dc36d-986d-4050-e91f-c2d536ae540c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0    136417\n",
              "1      1096\n",
              "Name: FIRE_OCCURRED, dtype: int64"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "display(y_train_SVM.value_counts())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wPwHlXKMdiO9"
      },
      "outputs": [],
      "source": [
        "# Undersampling & Shuffle\n",
        "\n",
        "from imblearn.under_sampling import RandomUnderSampler\n",
        "\n",
        "rus = RandomUnderSampler(random_state=10)\n",
        "X_train_SVM, y_train_SVM = rus.fit_resample(X_train_SVM, y_train_SVM)\n",
        "X_train_SVM, y_train_SVM = shuffle(X_train_SVM, y_train_SVM, random_state = 10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "id": "9by4YC8tdj47",
        "outputId": "76d130ec-edfa-495e-e572-d20ae1221512"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0    1096\n",
              "1    1096\n",
              "Name: FIRE_OCCURRED, dtype: int64"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "display(y_train_SVM.value_counts())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XsSKT8gmdoVT",
        "outputId": "a9c7a59b-b0cd-48f2-9222-5b6e1e307efb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Currently at : svc_clf0\n",
            "Currently at : svc_clf1\n",
            "Currently at : svc_clf2\n"
          ]
        }
      ],
      "source": [
        "# Training\n",
        "\n",
        "name = 'svc_clf'\n",
        "\n",
        "train = pd.DataFrame(columns = ['kernel', 'random_state'])\n",
        "train = train.append({'kernel' : 'rbf', 'random_state': 10}, ignore_index=True)\n",
        "train = train.append({'kernel' : 'poly', 'random_state': 10}, ignore_index=True)\n",
        "train = train.append({'kernel' : 'sigmoid', 'random_state': 10}, ignore_index=True)\n",
        "\n",
        "train = train.reset_index()\n",
        "for index, row in train.iterrows():\n",
        "    model_name = name + str(index)\n",
        "    print(\"Currently at :\" , model_name)\n",
        "    svc_clf = SVC(kernel=row[\"kernel\"], random_state = int(row[\"random_state\"]))\n",
        "    svc_clf.fit(X_train_SVM, y_train_SVM)\n",
        "    \n",
        "    y_true = y_val_SVM\n",
        "    y_pred = svc_clf.predict(X_val_SVM)\n",
        "    evaluation_results = evaluation_metrics(y_true, y_pred)\n",
        "\n",
        "    models = models.append({'model_name': model_name, \n",
        "                            'model': svc_clf, \n",
        "                            'parameters': svc_clf.get_params()}, \n",
        "                            ignore_index=True)\n",
        "    \n",
        "    models_eval = models_eval.append({'model_name': model_name, \n",
        "                                      'confusion_matrix' : evaluation_results[0], \n",
        "                                      'accuracy': evaluation_results[1], \n",
        "                                      'recall' : evaluation_results[2], \n",
        "                                      'f1_score': evaluation_results[3], \n",
        "                                      'roc_auc_score': evaluation_results[4]}, \n",
        "                                      ignore_index=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "Wb-YSYc9VwpI",
        "outputId": "b4bea4f1-97ff-431b-9724-50ba2a289b5d"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-52679dcb-170c-41e5-92fb-cfc08d38429a\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>model_name</th>\n",
              "      <th>confusion_matrix</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>recall</th>\n",
              "      <th>f1_score</th>\n",
              "      <th>roc_auc_score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>log_clf0</td>\n",
              "      <td>[10551, 6517, 38, 84]</td>\n",
              "      <td>0.618674</td>\n",
              "      <td>0.688525</td>\n",
              "      <td>0.024989</td>\n",
              "      <td>0.653349</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>log_clf1</td>\n",
              "      <td>[10551, 6517, 39, 83]</td>\n",
              "      <td>0.618615</td>\n",
              "      <td>0.680328</td>\n",
              "      <td>0.024695</td>\n",
              "      <td>0.649251</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>svc_clf0</td>\n",
              "      <td>[12395, 4673, 25, 97]</td>\n",
              "      <td>0.726702</td>\n",
              "      <td>0.795082</td>\n",
              "      <td>0.039657</td>\n",
              "      <td>0.760647</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>svc_clf1</td>\n",
              "      <td>[10750, 6318, 19, 103]</td>\n",
              "      <td>0.631355</td>\n",
              "      <td>0.844262</td>\n",
              "      <td>0.031484</td>\n",
              "      <td>0.737048</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>svc_clf2</td>\n",
              "      <td>[7181, 9887, 38, 84]</td>\n",
              "      <td>0.422629</td>\n",
              "      <td>0.688525</td>\n",
              "      <td>0.016645</td>\n",
              "      <td>0.554627</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-52679dcb-170c-41e5-92fb-cfc08d38429a')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-52679dcb-170c-41e5-92fb-cfc08d38429a button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-52679dcb-170c-41e5-92fb-cfc08d38429a');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "  model_name        confusion_matrix  accuracy    recall  f1_score  \\\n",
              "0   log_clf0   [10551, 6517, 38, 84]  0.618674  0.688525  0.024989   \n",
              "1   log_clf1   [10551, 6517, 39, 83]  0.618615  0.680328  0.024695   \n",
              "2   svc_clf0   [12395, 4673, 25, 97]  0.726702  0.795082  0.039657   \n",
              "3   svc_clf1  [10750, 6318, 19, 103]  0.631355  0.844262  0.031484   \n",
              "4   svc_clf2    [7181, 9887, 38, 84]  0.422629  0.688525  0.016645   \n",
              "\n",
              "   roc_auc_score  \n",
              "0       0.653349  \n",
              "1       0.649251  \n",
              "2       0.760647  \n",
              "3       0.737048  \n",
              "4       0.554627  "
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "display(models_eval)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qrWtVscoHjwp"
      },
      "source": [
        "The best kernel is rbf for recall score. All kernel gives poor F1-score"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dMGtSxvfUekT"
      },
      "source": [
        "Approach 2: Class-weighted SVM with original amount of data (before SMOTE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ySImEnhqGWbH"
      },
      "outputs": [],
      "source": [
        "X_train_SVM = Original[0]\n",
        "X_val_SVM = Original[1]\n",
        "y_train_SVM = Original[3]\n",
        "y_val_SVM = Original[4]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ugeOje0B-dZ1"
      },
      "outputs": [],
      "source": [
        "# Shuffle\n",
        "\n",
        "X_train_SVM, y_train_SVM = shuffle(X_train_SVM, y_train_SVM, random_state = 10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "id": "A88D9hpjGYf-",
        "outputId": "03727a4e-071e-41e1-ab0c-a690ffc7f002"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0    136417\n",
              "1      1096\n",
              "Name: FIRE_OCCURRED, dtype: int64"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "display(y_train_SVM.value_counts())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QGpzJBu7VRov",
        "outputId": "7f207fb7-f957-421e-83c3-d02ffaa13f22"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Current at  svc_clf3\n",
            "Current at  svc_clf4\n",
            "Current at  svc_clf5\n",
            "Current at  svc_clf6\n"
          ]
        }
      ],
      "source": [
        "# Training\n",
        "\n",
        "name = 'svc_clf'\n",
        "\n",
        "train = pd.DataFrame(columns = ['kernel', 'random_state'])\n",
        "train = train.append({'kernel' : 'rbf', 'C': 1, 'random_state': 10}, ignore_index=True)\n",
        "train = train.append({'kernel' : 'rbf', 'C': 2, 'random_state': 10}, ignore_index=True)\n",
        "train = train.append({'kernel' : 'rbf', 'C': 4, 'random_state': 10}, ignore_index=True)\n",
        "train = train.append({'kernel' : 'rbf', 'C': 8, 'random_state': 10}, ignore_index=True)\n",
        "\n",
        "train = train.reset_index()\n",
        "for index, row in train.iterrows():\n",
        "    index = index + 3\n",
        "    model_name = name + str(index)\n",
        "    print(\"Current at \", model_name)\n",
        "    svc_clf = SVC(kernel = row[\"kernel\"], class_weight='balanced', C = int(row[\"C\"]), random_state = int(row[\"random_state\"]))\n",
        "    svc_clf.fit(X_train_SVM, y_train_SVM)\n",
        "    \n",
        "    y_true = y_val_SVM\n",
        "    y_pred = svc_clf.predict(X_val_SVM)\n",
        "    evaluation_results = evaluation_metrics(y_true, y_pred)\n",
        "\n",
        "    models = models.append({'model_name': model_name, \n",
        "                            'model': svc_clf, \n",
        "                            'parameters': svc_clf.get_params()}, \n",
        "                            ignore_index=True)\n",
        "    \n",
        "    models_eval = models_eval.append({'model_name': model_name, \n",
        "                                      'confusion_matrix' : evaluation_results[0], \n",
        "                                      'accuracy': evaluation_results[1], \n",
        "                                      'recall' : evaluation_results[2], \n",
        "                                      'f1_score': evaluation_results[3], \n",
        "                                      'roc_auc_score': evaluation_results[4]}, \n",
        "                                      ignore_index=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 331
        },
        "id": "_18Aktz2aTn5",
        "outputId": "f6c47110-ec33-4f74-ca6c-2c143decb302"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-b484cc1b-5ab1-42d1-8529-2dc89c7a90ec\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>model_name</th>\n",
              "      <th>model</th>\n",
              "      <th>parameters</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>log_clf0</td>\n",
              "      <td>LogisticRegression(n_jobs=-1, penalty='none', ...</td>\n",
              "      <td>{'C': 1.0, 'class_weight': None, 'dual': False...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>log_clf1</td>\n",
              "      <td>LogisticRegression(n_jobs=-1, random_state=10)</td>\n",
              "      <td>{'C': 1.0, 'class_weight': None, 'dual': False...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>svc_clf0</td>\n",
              "      <td>SVC(random_state=10)</td>\n",
              "      <td>{'C': 1.0, 'break_ties': False, 'cache_size': ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>svc_clf1</td>\n",
              "      <td>SVC(kernel='poly', random_state=10)</td>\n",
              "      <td>{'C': 1.0, 'break_ties': False, 'cache_size': ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>svc_clf2</td>\n",
              "      <td>SVC(kernel='sigmoid', random_state=10)</td>\n",
              "      <td>{'C': 1.0, 'break_ties': False, 'cache_size': ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>svc_clf3</td>\n",
              "      <td>SVC(C=1, class_weight='balanced', random_state...</td>\n",
              "      <td>{'C': 1, 'break_ties': False, 'cache_size': 20...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>svc_clf4</td>\n",
              "      <td>SVC(C=2, class_weight='balanced', random_state...</td>\n",
              "      <td>{'C': 2, 'break_ties': False, 'cache_size': 20...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>svc_clf5</td>\n",
              "      <td>SVC(C=4, class_weight='balanced', random_state...</td>\n",
              "      <td>{'C': 4, 'break_ties': False, 'cache_size': 20...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>svc_clf6</td>\n",
              "      <td>SVC(C=8, class_weight='balanced', random_state...</td>\n",
              "      <td>{'C': 8, 'break_ties': False, 'cache_size': 20...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b484cc1b-5ab1-42d1-8529-2dc89c7a90ec')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-b484cc1b-5ab1-42d1-8529-2dc89c7a90ec button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-b484cc1b-5ab1-42d1-8529-2dc89c7a90ec');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "  model_name                                              model  \\\n",
              "0   log_clf0  LogisticRegression(n_jobs=-1, penalty='none', ...   \n",
              "1   log_clf1     LogisticRegression(n_jobs=-1, random_state=10)   \n",
              "2   svc_clf0                               SVC(random_state=10)   \n",
              "3   svc_clf1                SVC(kernel='poly', random_state=10)   \n",
              "4   svc_clf2             SVC(kernel='sigmoid', random_state=10)   \n",
              "5   svc_clf3  SVC(C=1, class_weight='balanced', random_state...   \n",
              "6   svc_clf4  SVC(C=2, class_weight='balanced', random_state...   \n",
              "7   svc_clf5  SVC(C=4, class_weight='balanced', random_state...   \n",
              "8   svc_clf6  SVC(C=8, class_weight='balanced', random_state...   \n",
              "\n",
              "                                          parameters  \n",
              "0  {'C': 1.0, 'class_weight': None, 'dual': False...  \n",
              "1  {'C': 1.0, 'class_weight': None, 'dual': False...  \n",
              "2  {'C': 1.0, 'break_ties': False, 'cache_size': ...  \n",
              "3  {'C': 1.0, 'break_ties': False, 'cache_size': ...  \n",
              "4  {'C': 1.0, 'break_ties': False, 'cache_size': ...  \n",
              "5  {'C': 1, 'break_ties': False, 'cache_size': 20...  \n",
              "6  {'C': 2, 'break_ties': False, 'cache_size': 20...  \n",
              "7  {'C': 4, 'break_ties': False, 'cache_size': 20...  \n",
              "8  {'C': 8, 'break_ties': False, 'cache_size': 20...  "
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "display(models)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 331
        },
        "id": "FOc0QQ_FaUTL",
        "outputId": "8224a72f-ebe8-4de3-c381-094c7a2fbbe5"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-eb2020af-6819-485e-b0ae-00270439075e\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>model_name</th>\n",
              "      <th>confusion_matrix</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>recall</th>\n",
              "      <th>f1_score</th>\n",
              "      <th>roc_auc_score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>log_clf0</td>\n",
              "      <td>[10551, 6517, 38, 84]</td>\n",
              "      <td>0.618674</td>\n",
              "      <td>0.688525</td>\n",
              "      <td>0.024989</td>\n",
              "      <td>0.653349</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>log_clf1</td>\n",
              "      <td>[10551, 6517, 39, 83]</td>\n",
              "      <td>0.618615</td>\n",
              "      <td>0.680328</td>\n",
              "      <td>0.024695</td>\n",
              "      <td>0.649251</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>svc_clf0</td>\n",
              "      <td>[12395, 4673, 25, 97]</td>\n",
              "      <td>0.726702</td>\n",
              "      <td>0.795082</td>\n",
              "      <td>0.039657</td>\n",
              "      <td>0.760647</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>svc_clf1</td>\n",
              "      <td>[10750, 6318, 19, 103]</td>\n",
              "      <td>0.631355</td>\n",
              "      <td>0.844262</td>\n",
              "      <td>0.031484</td>\n",
              "      <td>0.737048</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>svc_clf2</td>\n",
              "      <td>[7181, 9887, 38, 84]</td>\n",
              "      <td>0.422629</td>\n",
              "      <td>0.688525</td>\n",
              "      <td>0.016645</td>\n",
              "      <td>0.554627</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>svc_clf3</td>\n",
              "      <td>[14126, 2942, 22, 100]</td>\n",
              "      <td>0.827574</td>\n",
              "      <td>0.819672</td>\n",
              "      <td>0.063211</td>\n",
              "      <td>0.823651</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>svc_clf4</td>\n",
              "      <td>[14240, 2828, 23, 99]</td>\n",
              "      <td>0.834148</td>\n",
              "      <td>0.811475</td>\n",
              "      <td>0.064939</td>\n",
              "      <td>0.822893</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>svc_clf5</td>\n",
              "      <td>[14296, 2772, 24, 98]</td>\n",
              "      <td>0.837347</td>\n",
              "      <td>0.803279</td>\n",
              "      <td>0.065508</td>\n",
              "      <td>0.820435</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>svc_clf6</td>\n",
              "      <td>[14335, 2733, 22, 100]</td>\n",
              "      <td>0.839732</td>\n",
              "      <td>0.819672</td>\n",
              "      <td>0.067682</td>\n",
              "      <td>0.829774</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-eb2020af-6819-485e-b0ae-00270439075e')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-eb2020af-6819-485e-b0ae-00270439075e button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-eb2020af-6819-485e-b0ae-00270439075e');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "  model_name        confusion_matrix  accuracy    recall  f1_score  \\\n",
              "0   log_clf0   [10551, 6517, 38, 84]  0.618674  0.688525  0.024989   \n",
              "1   log_clf1   [10551, 6517, 39, 83]  0.618615  0.680328  0.024695   \n",
              "2   svc_clf0   [12395, 4673, 25, 97]  0.726702  0.795082  0.039657   \n",
              "3   svc_clf1  [10750, 6318, 19, 103]  0.631355  0.844262  0.031484   \n",
              "4   svc_clf2    [7181, 9887, 38, 84]  0.422629  0.688525  0.016645   \n",
              "5   svc_clf3  [14126, 2942, 22, 100]  0.827574  0.819672  0.063211   \n",
              "6   svc_clf4   [14240, 2828, 23, 99]  0.834148  0.811475  0.064939   \n",
              "7   svc_clf5   [14296, 2772, 24, 98]  0.837347  0.803279  0.065508   \n",
              "8   svc_clf6  [14335, 2733, 22, 100]  0.839732  0.819672  0.067682   \n",
              "\n",
              "   roc_auc_score  \n",
              "0       0.653349  \n",
              "1       0.649251  \n",
              "2       0.760647  \n",
              "3       0.737048  \n",
              "4       0.554627  \n",
              "5       0.823651  \n",
              "6       0.822893  \n",
              "7       0.820435  \n",
              "8       0.829774  "
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "display(models_eval)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v35KdCcEGL7J"
      },
      "source": [
        "Best Parameters: \n",
        "\n",
        "{'kernel': 'rbf', 'C' : '8', 'class_weight'='balanced'}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tzx0wl2ht1R1"
      },
      "source": [
        "## Naive Bayes\n",
        "\n",
        "- Library: Scikit-learn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xDhLdEgHaVwR"
      },
      "outputs": [],
      "source": [
        "# Training\n",
        "\n",
        "name = 'bayes_clf'\n",
        "\n",
        "train = pd.DataFrame(columns = ['var_smoothing'])\n",
        "train = train.append({'var_smoothing': 1e-0}, ignore_index=True)\n",
        "train = train.append({'var_smoothing': 1e-1}, ignore_index=True)\n",
        "train = train.append({'var_smoothing': 1e-3}, ignore_index=True)\n",
        "train = train.append({'var_smoothing': 1e-5}, ignore_index=True)\n",
        "train = train.append({'var_smoothing': 1e-9}, ignore_index=True)\n",
        "train = train.append({'var_smoothing': 1e-10}, ignore_index=True)\n",
        "train = train.append({'var_smoothing': 1e-20}, ignore_index=True)\n",
        "\n",
        "train = train.reset_index()\n",
        "for index, row in train.iterrows():\n",
        "    model_name = name + str(index)\n",
        "    bayes_clf = GaussianNB(var_smoothing = row['var_smoothing'])\n",
        "    bayes_clf.fit(X_train, y_train)\n",
        "    \n",
        "    y_true = y_val\n",
        "    y_pred = bayes_clf.predict(X_val)\n",
        "    evaluation_results = evaluation_metrics(y_true, y_pred)\n",
        "\n",
        "    models = models.append({'model_name': model_name, \n",
        "                            'model': bayes_clf, \n",
        "                            'parameters': bayes_clf.get_params()}, \n",
        "                            ignore_index=True)\n",
        "    \n",
        "    models_eval = models_eval.append({'model_name': model_name, \n",
        "                                      'confusion_matrix' : evaluation_results[0], \n",
        "                                      'accuracy': evaluation_results[1], \n",
        "                                      'recall' : evaluation_results[2], \n",
        "                                      'f1_score': evaluation_results[3], \n",
        "                                      'roc_auc_score': evaluation_results[4]}, \n",
        "                                      ignore_index=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 551
        },
        "id": "n7Ad5Gr5eH_U",
        "outputId": "0aef31d5-3ac5-46d8-8173-b2105b8662ee"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-c8524943-3274-4998-9d6f-5dce78b338b3\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>model_name</th>\n",
              "      <th>confusion_matrix</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>recall</th>\n",
              "      <th>f1_score</th>\n",
              "      <th>roc_auc_score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>log_clf0</td>\n",
              "      <td>[10551, 6517, 38, 84]</td>\n",
              "      <td>0.618674</td>\n",
              "      <td>0.688525</td>\n",
              "      <td>0.024989</td>\n",
              "      <td>0.653349</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>log_clf1</td>\n",
              "      <td>[10551, 6517, 39, 83]</td>\n",
              "      <td>0.618615</td>\n",
              "      <td>0.680328</td>\n",
              "      <td>0.024695</td>\n",
              "      <td>0.649251</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>svc_clf0</td>\n",
              "      <td>[12395, 4673, 25, 97]</td>\n",
              "      <td>0.726702</td>\n",
              "      <td>0.795082</td>\n",
              "      <td>0.039657</td>\n",
              "      <td>0.760647</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>svc_clf1</td>\n",
              "      <td>[10750, 6318, 19, 103]</td>\n",
              "      <td>0.631355</td>\n",
              "      <td>0.844262</td>\n",
              "      <td>0.031484</td>\n",
              "      <td>0.737048</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>svc_clf2</td>\n",
              "      <td>[7181, 9887, 38, 84]</td>\n",
              "      <td>0.422629</td>\n",
              "      <td>0.688525</td>\n",
              "      <td>0.016645</td>\n",
              "      <td>0.554627</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>svc_clf3</td>\n",
              "      <td>[14126, 2942, 22, 100]</td>\n",
              "      <td>0.827574</td>\n",
              "      <td>0.819672</td>\n",
              "      <td>0.063211</td>\n",
              "      <td>0.823651</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>svc_clf4</td>\n",
              "      <td>[14240, 2828, 23, 99]</td>\n",
              "      <td>0.834148</td>\n",
              "      <td>0.811475</td>\n",
              "      <td>0.064939</td>\n",
              "      <td>0.822893</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>svc_clf5</td>\n",
              "      <td>[14296, 2772, 24, 98]</td>\n",
              "      <td>0.837347</td>\n",
              "      <td>0.803279</td>\n",
              "      <td>0.065508</td>\n",
              "      <td>0.820435</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>svc_clf6</td>\n",
              "      <td>[14335, 2733, 22, 100]</td>\n",
              "      <td>0.839732</td>\n",
              "      <td>0.819672</td>\n",
              "      <td>0.067682</td>\n",
              "      <td>0.829774</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>bayes_clf0</td>\n",
              "      <td>[8297, 8771, 40, 82]</td>\n",
              "      <td>0.487435</td>\n",
              "      <td>0.672131</td>\n",
              "      <td>0.018273</td>\n",
              "      <td>0.579123</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>bayes_clf1</td>\n",
              "      <td>[9041, 8027, 25, 97]</td>\n",
              "      <td>0.531588</td>\n",
              "      <td>0.795082</td>\n",
              "      <td>0.023527</td>\n",
              "      <td>0.662393</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>bayes_clf2</td>\n",
              "      <td>[10242, 6826, 39, 83]</td>\n",
              "      <td>0.600640</td>\n",
              "      <td>0.680328</td>\n",
              "      <td>0.023610</td>\n",
              "      <td>0.640199</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>bayes_clf3</td>\n",
              "      <td>[10323, 6745, 39, 83]</td>\n",
              "      <td>0.605352</td>\n",
              "      <td>0.680328</td>\n",
              "      <td>0.023885</td>\n",
              "      <td>0.642572</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>bayes_clf4</td>\n",
              "      <td>[10324, 6744, 39, 83]</td>\n",
              "      <td>0.605410</td>\n",
              "      <td>0.680328</td>\n",
              "      <td>0.023888</td>\n",
              "      <td>0.642601</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>bayes_clf5</td>\n",
              "      <td>[10324, 6744, 39, 83]</td>\n",
              "      <td>0.605410</td>\n",
              "      <td>0.680328</td>\n",
              "      <td>0.023888</td>\n",
              "      <td>0.642601</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>bayes_clf6</td>\n",
              "      <td>[10324, 6744, 39, 83]</td>\n",
              "      <td>0.605410</td>\n",
              "      <td>0.680328</td>\n",
              "      <td>0.023888</td>\n",
              "      <td>0.642601</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c8524943-3274-4998-9d6f-5dce78b338b3')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-c8524943-3274-4998-9d6f-5dce78b338b3 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-c8524943-3274-4998-9d6f-5dce78b338b3');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "    model_name        confusion_matrix  accuracy    recall  f1_score  \\\n",
              "0     log_clf0   [10551, 6517, 38, 84]  0.618674  0.688525  0.024989   \n",
              "1     log_clf1   [10551, 6517, 39, 83]  0.618615  0.680328  0.024695   \n",
              "2     svc_clf0   [12395, 4673, 25, 97]  0.726702  0.795082  0.039657   \n",
              "3     svc_clf1  [10750, 6318, 19, 103]  0.631355  0.844262  0.031484   \n",
              "4     svc_clf2    [7181, 9887, 38, 84]  0.422629  0.688525  0.016645   \n",
              "5     svc_clf3  [14126, 2942, 22, 100]  0.827574  0.819672  0.063211   \n",
              "6     svc_clf4   [14240, 2828, 23, 99]  0.834148  0.811475  0.064939   \n",
              "7     svc_clf5   [14296, 2772, 24, 98]  0.837347  0.803279  0.065508   \n",
              "8     svc_clf6  [14335, 2733, 22, 100]  0.839732  0.819672  0.067682   \n",
              "9   bayes_clf0    [8297, 8771, 40, 82]  0.487435  0.672131  0.018273   \n",
              "10  bayes_clf1    [9041, 8027, 25, 97]  0.531588  0.795082  0.023527   \n",
              "11  bayes_clf2   [10242, 6826, 39, 83]  0.600640  0.680328  0.023610   \n",
              "12  bayes_clf3   [10323, 6745, 39, 83]  0.605352  0.680328  0.023885   \n",
              "13  bayes_clf4   [10324, 6744, 39, 83]  0.605410  0.680328  0.023888   \n",
              "14  bayes_clf5   [10324, 6744, 39, 83]  0.605410  0.680328  0.023888   \n",
              "15  bayes_clf6   [10324, 6744, 39, 83]  0.605410  0.680328  0.023888   \n",
              "\n",
              "    roc_auc_score  \n",
              "0        0.653349  \n",
              "1        0.649251  \n",
              "2        0.760647  \n",
              "3        0.737048  \n",
              "4        0.554627  \n",
              "5        0.823651  \n",
              "6        0.822893  \n",
              "7        0.820435  \n",
              "8        0.829774  \n",
              "9        0.579123  \n",
              "10       0.662393  \n",
              "11       0.640199  \n",
              "12       0.642572  \n",
              "13       0.642601  \n",
              "14       0.642601  \n",
              "15       0.642601  "
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "display(models_eval)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xbdXqp_Rq353"
      },
      "source": [
        "Best Parameters: \n",
        "\n",
        "{'var_smoothing': '1e-3'}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M_gEyKKnt00q"
      },
      "source": [
        "## K-Nearest Neighbor\n",
        "\n",
        "- Library: Scikit-learn\n",
        "- Shuffling does not affect the model building. No random_state."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Vw5TiOkaZTHW"
      },
      "outputs": [],
      "source": [
        "# Training\n",
        "\n",
        "name = 'neigh_clf'\n",
        "\n",
        "train = pd.DataFrame(columns = ['n_neighbors', 'algorithm', 'n_jobs'])\n",
        "train = train.append({'n_neighbors': 5, 'algorithm':'auto', 'n_jobs':-1}, ignore_index=True)\n",
        "train = train.append({'n_neighbors': 1, 'algorithm':'auto', 'n_jobs':-1}, ignore_index=True)\n",
        "train = train.append({'n_neighbors': 20, 'algorithm':'kd_tree', 'n_jobs':-1}, ignore_index=True)\n",
        "\n",
        "train = train.reset_index()\n",
        "for index, row in train.iterrows():\n",
        "    model_name = name + str(index)\n",
        "    neigh_clf = KNeighborsClassifier(n_neighbors=int(row['n_neighbors']), algorithm = row['algorithm'], n_jobs = int(row['n_jobs']))\n",
        "    neigh_clf.fit(X_train, y_train)\n",
        "    \n",
        "    y_true = y_val\n",
        "    y_pred = neigh_clf.predict(X_val)\n",
        "    evaluation_results = evaluation_metrics(y_true, y_pred)\n",
        "\n",
        "    models = models.append({'model_name': model_name, \n",
        "                            'model': neigh_clf, \n",
        "                            'parameters': neigh_clf.get_params()}, \n",
        "                            ignore_index=True)\n",
        "    \n",
        "    models_eval = models_eval.append({'model_name': model_name, \n",
        "                                      'confusion_matrix' : evaluation_results[0], \n",
        "                                      'accuracy': evaluation_results[1], \n",
        "                                      'recall' : evaluation_results[2], \n",
        "                                      'f1_score': evaluation_results[3], \n",
        "                                      'roc_auc_score': evaluation_results[4]}, \n",
        "                                      ignore_index=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 645
        },
        "id": "EvI_e6r-exRk",
        "outputId": "75ad3127-c614-461d-fd65-f5e4e6e26f1f"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-364ebc9e-2f37-4d9a-b49e-ced6c48f97e5\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>model_name</th>\n",
              "      <th>confusion_matrix</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>recall</th>\n",
              "      <th>f1_score</th>\n",
              "      <th>roc_auc_score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>log_clf0</td>\n",
              "      <td>[10551, 6517, 38, 84]</td>\n",
              "      <td>0.618674</td>\n",
              "      <td>0.688525</td>\n",
              "      <td>0.024989</td>\n",
              "      <td>0.653349</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>log_clf1</td>\n",
              "      <td>[10551, 6517, 39, 83]</td>\n",
              "      <td>0.618615</td>\n",
              "      <td>0.680328</td>\n",
              "      <td>0.024695</td>\n",
              "      <td>0.649251</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>svc_clf0</td>\n",
              "      <td>[12395, 4673, 25, 97]</td>\n",
              "      <td>0.726702</td>\n",
              "      <td>0.795082</td>\n",
              "      <td>0.039657</td>\n",
              "      <td>0.760647</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>svc_clf1</td>\n",
              "      <td>[10750, 6318, 19, 103]</td>\n",
              "      <td>0.631355</td>\n",
              "      <td>0.844262</td>\n",
              "      <td>0.031484</td>\n",
              "      <td>0.737048</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>svc_clf2</td>\n",
              "      <td>[7181, 9887, 38, 84]</td>\n",
              "      <td>0.422629</td>\n",
              "      <td>0.688525</td>\n",
              "      <td>0.016645</td>\n",
              "      <td>0.554627</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>svc_clf3</td>\n",
              "      <td>[14126, 2942, 22, 100]</td>\n",
              "      <td>0.827574</td>\n",
              "      <td>0.819672</td>\n",
              "      <td>0.063211</td>\n",
              "      <td>0.823651</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>svc_clf4</td>\n",
              "      <td>[14240, 2828, 23, 99]</td>\n",
              "      <td>0.834148</td>\n",
              "      <td>0.811475</td>\n",
              "      <td>0.064939</td>\n",
              "      <td>0.822893</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>svc_clf5</td>\n",
              "      <td>[14296, 2772, 24, 98]</td>\n",
              "      <td>0.837347</td>\n",
              "      <td>0.803279</td>\n",
              "      <td>0.065508</td>\n",
              "      <td>0.820435</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>svc_clf6</td>\n",
              "      <td>[14335, 2733, 22, 100]</td>\n",
              "      <td>0.839732</td>\n",
              "      <td>0.819672</td>\n",
              "      <td>0.067682</td>\n",
              "      <td>0.829774</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>bayes_clf0</td>\n",
              "      <td>[8297, 8771, 40, 82]</td>\n",
              "      <td>0.487435</td>\n",
              "      <td>0.672131</td>\n",
              "      <td>0.018273</td>\n",
              "      <td>0.579123</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>bayes_clf1</td>\n",
              "      <td>[9041, 8027, 25, 97]</td>\n",
              "      <td>0.531588</td>\n",
              "      <td>0.795082</td>\n",
              "      <td>0.023527</td>\n",
              "      <td>0.662393</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>bayes_clf2</td>\n",
              "      <td>[10242, 6826, 39, 83]</td>\n",
              "      <td>0.600640</td>\n",
              "      <td>0.680328</td>\n",
              "      <td>0.023610</td>\n",
              "      <td>0.640199</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>bayes_clf3</td>\n",
              "      <td>[10323, 6745, 39, 83]</td>\n",
              "      <td>0.605352</td>\n",
              "      <td>0.680328</td>\n",
              "      <td>0.023885</td>\n",
              "      <td>0.642572</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>bayes_clf4</td>\n",
              "      <td>[10324, 6744, 39, 83]</td>\n",
              "      <td>0.605410</td>\n",
              "      <td>0.680328</td>\n",
              "      <td>0.023888</td>\n",
              "      <td>0.642601</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>bayes_clf5</td>\n",
              "      <td>[10324, 6744, 39, 83]</td>\n",
              "      <td>0.605410</td>\n",
              "      <td>0.680328</td>\n",
              "      <td>0.023888</td>\n",
              "      <td>0.642601</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>bayes_clf6</td>\n",
              "      <td>[10324, 6744, 39, 83]</td>\n",
              "      <td>0.605410</td>\n",
              "      <td>0.680328</td>\n",
              "      <td>0.023888</td>\n",
              "      <td>0.642601</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>neigh_clf0</td>\n",
              "      <td>[16733, 335, 30, 92]</td>\n",
              "      <td>0.978767</td>\n",
              "      <td>0.754098</td>\n",
              "      <td>0.335155</td>\n",
              "      <td>0.867235</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>neigh_clf1</td>\n",
              "      <td>[16916, 152, 43, 79]</td>\n",
              "      <td>0.988656</td>\n",
              "      <td>0.647541</td>\n",
              "      <td>0.447592</td>\n",
              "      <td>0.819318</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>neigh_clf2</td>\n",
              "      <td>[16334, 734, 22, 100]</td>\n",
              "      <td>0.956021</td>\n",
              "      <td>0.819672</td>\n",
              "      <td>0.209205</td>\n",
              "      <td>0.888334</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-364ebc9e-2f37-4d9a-b49e-ced6c48f97e5')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-364ebc9e-2f37-4d9a-b49e-ced6c48f97e5 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-364ebc9e-2f37-4d9a-b49e-ced6c48f97e5');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "    model_name        confusion_matrix  accuracy    recall  f1_score  \\\n",
              "0     log_clf0   [10551, 6517, 38, 84]  0.618674  0.688525  0.024989   \n",
              "1     log_clf1   [10551, 6517, 39, 83]  0.618615  0.680328  0.024695   \n",
              "2     svc_clf0   [12395, 4673, 25, 97]  0.726702  0.795082  0.039657   \n",
              "3     svc_clf1  [10750, 6318, 19, 103]  0.631355  0.844262  0.031484   \n",
              "4     svc_clf2    [7181, 9887, 38, 84]  0.422629  0.688525  0.016645   \n",
              "5     svc_clf3  [14126, 2942, 22, 100]  0.827574  0.819672  0.063211   \n",
              "6     svc_clf4   [14240, 2828, 23, 99]  0.834148  0.811475  0.064939   \n",
              "7     svc_clf5   [14296, 2772, 24, 98]  0.837347  0.803279  0.065508   \n",
              "8     svc_clf6  [14335, 2733, 22, 100]  0.839732  0.819672  0.067682   \n",
              "9   bayes_clf0    [8297, 8771, 40, 82]  0.487435  0.672131  0.018273   \n",
              "10  bayes_clf1    [9041, 8027, 25, 97]  0.531588  0.795082  0.023527   \n",
              "11  bayes_clf2   [10242, 6826, 39, 83]  0.600640  0.680328  0.023610   \n",
              "12  bayes_clf3   [10323, 6745, 39, 83]  0.605352  0.680328  0.023885   \n",
              "13  bayes_clf4   [10324, 6744, 39, 83]  0.605410  0.680328  0.023888   \n",
              "14  bayes_clf5   [10324, 6744, 39, 83]  0.605410  0.680328  0.023888   \n",
              "15  bayes_clf6   [10324, 6744, 39, 83]  0.605410  0.680328  0.023888   \n",
              "16  neigh_clf0    [16733, 335, 30, 92]  0.978767  0.754098  0.335155   \n",
              "17  neigh_clf1    [16916, 152, 43, 79]  0.988656  0.647541  0.447592   \n",
              "18  neigh_clf2   [16334, 734, 22, 100]  0.956021  0.819672  0.209205   \n",
              "\n",
              "    roc_auc_score  \n",
              "0        0.653349  \n",
              "1        0.649251  \n",
              "2        0.760647  \n",
              "3        0.737048  \n",
              "4        0.554627  \n",
              "5        0.823651  \n",
              "6        0.822893  \n",
              "7        0.820435  \n",
              "8        0.829774  \n",
              "9        0.579123  \n",
              "10       0.662393  \n",
              "11       0.640199  \n",
              "12       0.642572  \n",
              "13       0.642601  \n",
              "14       0.642601  \n",
              "15       0.642601  \n",
              "16       0.867235  \n",
              "17       0.819318  \n",
              "18       0.888334  "
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "display(models_eval)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SlJiuLzfen_x",
        "outputId": "4d500753-4312-4f02-f52c-b8a2198a884a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fitting 3 folds for each of 50 candidates, totalling 150 fits\n",
            "[CV 1/3] END .algorithm=kd_tree, n_neighbors=12;, score=0.997 total time=   9.4s\n",
            "[CV 2/3] END .algorithm=kd_tree, n_neighbors=12;, score=0.996 total time=   9.3s\n",
            "[CV 3/3] END .algorithm=kd_tree, n_neighbors=12;, score=0.997 total time=   9.3s\n",
            "[CV 1/3] END .....algorithm=auto, n_neighbors=4;, score=0.995 total time=   6.6s\n",
            "[CV 2/3] END .....algorithm=auto, n_neighbors=4;, score=0.995 total time=   6.2s\n",
            "[CV 3/3] END .....algorithm=auto, n_neighbors=4;, score=0.995 total time=   8.3s\n",
            "[CV 1/3] END .algorithm=kd_tree, n_neighbors=19;, score=0.997 total time=   9.3s\n",
            "[CV 2/3] END .algorithm=kd_tree, n_neighbors=19;, score=0.996 total time=  10.1s\n",
            "[CV 3/3] END .algorithm=kd_tree, n_neighbors=19;, score=0.997 total time=  11.2s\n",
            "[CV 1/3] END ..algorithm=kd_tree, n_neighbors=8;, score=0.997 total time=   7.2s\n",
            "[CV 2/3] END ..algorithm=kd_tree, n_neighbors=8;, score=0.996 total time=   9.3s\n",
            "[CV 3/3] END ..algorithm=kd_tree, n_neighbors=8;, score=0.996 total time=   6.9s\n",
            "[CV 1/3] END ..algorithm=kd_tree, n_neighbors=2;, score=0.994 total time=   7.6s\n",
            "[CV 2/3] END ..algorithm=kd_tree, n_neighbors=2;, score=0.993 total time=   5.5s\n",
            "[CV 3/3] END ..algorithm=kd_tree, n_neighbors=2;, score=0.993 total time=   5.8s\n",
            "[CV 1/3] END ....algorithm=auto, n_neighbors=18;, score=0.996 total time=  10.5s\n",
            "[CV 2/3] END ....algorithm=auto, n_neighbors=18;, score=0.996 total time=  10.7s\n",
            "[CV 3/3] END ....algorithm=auto, n_neighbors=18;, score=0.996 total time=   8.6s\n",
            "[CV 1/3] END algorithm=ball_tree, n_neighbors=7;, score=0.998 total time=  58.7s\n",
            "[CV 2/3] END algorithm=ball_tree, n_neighbors=7;, score=0.997 total time= 1.3min\n",
            "[CV 3/3] END algorithm=ball_tree, n_neighbors=7;, score=0.997 total time=  58.3s\n",
            "[CV 1/3] END .....algorithm=auto, n_neighbors=3;, score=0.998 total time=   8.3s\n",
            "[CV 2/3] END .....algorithm=auto, n_neighbors=3;, score=0.997 total time=   5.7s\n",
            "[CV 3/3] END .....algorithm=auto, n_neighbors=3;, score=0.997 total time=   7.9s\n",
            "[CV 1/3] END ..algorithm=kd_tree, n_neighbors=4;, score=0.995 total time=   6.4s\n",
            "[CV 2/3] END ..algorithm=kd_tree, n_neighbors=4;, score=0.995 total time=   7.0s\n",
            "[CV 3/3] END ..algorithm=kd_tree, n_neighbors=4;, score=0.995 total time=   8.1s\n",
            "[CV 1/3] END ..algorithm=kd_tree, n_neighbors=7;, score=0.998 total time=   7.5s\n",
            "[CV 2/3] END ..algorithm=kd_tree, n_neighbors=7;, score=0.997 total time=   9.0s\n",
            "[CV 3/3] END ..algorithm=kd_tree, n_neighbors=7;, score=0.997 total time=   7.9s\n",
            "[CV 1/3] END .algorithm=kd_tree, n_neighbors=16;, score=0.996 total time=  10.1s\n",
            "[CV 2/3] END .algorithm=kd_tree, n_neighbors=16;, score=0.996 total time=  10.6s\n",
            "[CV 3/3] END .algorithm=kd_tree, n_neighbors=16;, score=0.996 total time=   8.4s\n",
            "[CV 1/3] END .algorithm=kd_tree, n_neighbors=20;, score=0.996 total time=  11.9s\n",
            "[CV 2/3] END .algorithm=kd_tree, n_neighbors=20;, score=0.996 total time=  10.5s\n",
            "[CV 3/3] END .algorithm=kd_tree, n_neighbors=20;, score=0.996 total time=   9.7s\n",
            "[CV 1/3] END ..algorithm=kd_tree, n_neighbors=1;, score=0.998 total time=   6.8s\n",
            "[CV 2/3] END ..algorithm=kd_tree, n_neighbors=1;, score=0.997 total time=   5.7s\n",
            "[CV 3/3] END ..algorithm=kd_tree, n_neighbors=1;, score=0.997 total time=   5.5s\n",
            "[CV 1/3] END .algorithm=kd_tree, n_neighbors=18;, score=0.996 total time=  10.9s\n",
            "[CV 2/3] END .algorithm=kd_tree, n_neighbors=18;, score=0.996 total time=  10.2s\n",
            "[CV 3/3] END .algorithm=kd_tree, n_neighbors=18;, score=0.996 total time=   9.0s\n",
            "[CV 1/3] END .....algorithm=auto, n_neighbors=8;, score=0.997 total time=   9.2s\n",
            "[CV 2/3] END .....algorithm=auto, n_neighbors=8;, score=0.996 total time=   6.7s\n",
            "[CV 3/3] END .....algorithm=auto, n_neighbors=8;, score=0.996 total time=   9.5s\n",
            "[CV 1/3] END .....algorithm=auto, n_neighbors=7;, score=0.998 total time=   6.5s\n",
            "[CV 2/3] END .....algorithm=auto, n_neighbors=7;, score=0.997 total time=   9.1s\n",
            "[CV 3/3] END .....algorithm=auto, n_neighbors=7;, score=0.997 total time=   6.9s\n",
            "[CV 1/3] END algorithm=ball_tree, n_neighbors=6;, score=0.996 total time=  55.1s\n",
            "[CV 2/3] END algorithm=ball_tree, n_neighbors=6;, score=0.996 total time= 1.2min\n",
            "[CV 3/3] END algorithm=ball_tree, n_neighbors=6;, score=0.996 total time=  59.5s\n",
            "[CV 1/3] END algorithm=ball_tree, n_neighbors=18;, score=0.996 total time= 1.1min\n",
            "[CV 2/3] END algorithm=ball_tree, n_neighbors=18;, score=0.996 total time= 1.4min\n",
            "[CV 3/3] END algorithm=ball_tree, n_neighbors=18;, score=0.996 total time= 1.1min\n",
            "[CV 1/3] END algorithm=ball_tree, n_neighbors=8;, score=0.997 total time=  56.0s\n",
            "[CV 2/3] END algorithm=ball_tree, n_neighbors=8;, score=0.996 total time= 1.3min\n",
            "[CV 3/3] END algorithm=ball_tree, n_neighbors=8;, score=0.996 total time=  57.0s\n",
            "[CV 1/3] END ....algorithm=auto, n_neighbors=11;, score=0.997 total time=  10.3s\n",
            "[CV 2/3] END ....algorithm=auto, n_neighbors=11;, score=0.997 total time=   8.0s\n",
            "[CV 3/3] END ....algorithm=auto, n_neighbors=11;, score=0.997 total time=   9.7s\n",
            "[CV 1/3] END algorithm=ball_tree, n_neighbors=5;, score=0.998 total time=  51.5s\n",
            "[CV 2/3] END algorithm=ball_tree, n_neighbors=5;, score=0.997 total time= 1.2min\n",
            "[CV 3/3] END algorithm=ball_tree, n_neighbors=5;, score=0.998 total time=  53.9s\n",
            "[CV 1/3] END algorithm=ball_tree, n_neighbors=11;, score=0.997 total time=  60.0s\n",
            "[CV 2/3] END algorithm=ball_tree, n_neighbors=11;, score=0.997 total time= 1.3min\n",
            "[CV 3/3] END algorithm=ball_tree, n_neighbors=11;, score=0.997 total time= 1.0min\n",
            "[CV 1/3] END ....algorithm=auto, n_neighbors=19;, score=0.997 total time=   8.4s\n",
            "[CV 2/3] END ....algorithm=auto, n_neighbors=19;, score=0.996 total time=  11.1s\n",
            "[CV 3/3] END ....algorithm=auto, n_neighbors=19;, score=0.997 total time=  11.0s\n",
            "[CV 1/3] END .....algorithm=auto, n_neighbors=5;, score=0.998 total time=   6.2s\n",
            "[CV 2/3] END .....algorithm=auto, n_neighbors=5;, score=0.997 total time=   7.4s\n",
            "[CV 3/3] END .....algorithm=auto, n_neighbors=5;, score=0.998 total time=   7.5s\n",
            "[CV 1/3] END .....algorithm=auto, n_neighbors=2;, score=0.994 total time=   5.4s\n",
            "[CV 2/3] END .....algorithm=auto, n_neighbors=2;, score=0.993 total time=   7.7s\n",
            "[CV 3/3] END .....algorithm=auto, n_neighbors=2;, score=0.993 total time=   5.4s\n",
            "[CV 1/3] END ....algorithm=auto, n_neighbors=13;, score=0.997 total time=  10.1s\n",
            "[CV 2/3] END ....algorithm=auto, n_neighbors=13;, score=0.997 total time=   7.7s\n",
            "[CV 3/3] END ....algorithm=auto, n_neighbors=13;, score=0.997 total time=  10.9s\n",
            "[CV 1/3] END .algorithm=kd_tree, n_neighbors=11;, score=0.997 total time=   8.2s\n",
            "[CV 2/3] END .algorithm=kd_tree, n_neighbors=11;, score=0.997 total time=   9.0s\n",
            "[CV 3/3] END .algorithm=kd_tree, n_neighbors=11;, score=0.997 total time=   9.1s\n",
            "[CV 1/3] END ..algorithm=kd_tree, n_neighbors=3;, score=0.998 total time=   6.5s\n",
            "[CV 2/3] END ..algorithm=kd_tree, n_neighbors=3;, score=0.997 total time=   5.8s\n",
            "[CV 3/3] END ..algorithm=kd_tree, n_neighbors=3;, score=0.997 total time=   8.3s\n",
            "[CV 1/3] END algorithm=ball_tree, n_neighbors=15;, score=0.997 total time=  59.2s\n",
            "[CV 2/3] END algorithm=ball_tree, n_neighbors=15;, score=0.997 total time= 1.3min\n",
            "[CV 3/3] END algorithm=ball_tree, n_neighbors=15;, score=0.997 total time= 1.0min\n",
            "[CV 1/3] END .algorithm=kd_tree, n_neighbors=13;, score=0.997 total time=  10.3s\n",
            "[CV 2/3] END .algorithm=kd_tree, n_neighbors=13;, score=0.997 total time=   8.2s\n",
            "[CV 3/3] END .algorithm=kd_tree, n_neighbors=13;, score=0.997 total time=   9.4s\n",
            "[CV 1/3] END algorithm=ball_tree, n_neighbors=14;, score=0.997 total time=  51.5s\n",
            "[CV 2/3] END algorithm=ball_tree, n_neighbors=14;, score=0.996 total time= 1.1min\n",
            "[CV 3/3] END algorithm=ball_tree, n_neighbors=14;, score=0.996 total time=  57.5s\n",
            "[CV 1/3] END ....algorithm=auto, n_neighbors=20;, score=0.996 total time=  10.7s\n",
            "[CV 2/3] END ....algorithm=auto, n_neighbors=20;, score=0.996 total time=   9.1s\n",
            "[CV 3/3] END ....algorithm=auto, n_neighbors=20;, score=0.996 total time=  11.7s\n",
            "[CV 1/3] END .algorithm=kd_tree, n_neighbors=15;, score=0.997 total time=   9.0s\n",
            "[CV 2/3] END .algorithm=kd_tree, n_neighbors=15;, score=0.997 total time=   9.9s\n",
            "[CV 3/3] END .algorithm=kd_tree, n_neighbors=15;, score=0.997 total time=  10.7s\n",
            "[CV 1/3] END .....algorithm=auto, n_neighbors=6;, score=0.996 total time=   6.6s\n",
            "[CV 2/3] END .....algorithm=auto, n_neighbors=6;, score=0.996 total time=   8.6s\n",
            "[CV 3/3] END .....algorithm=auto, n_neighbors=6;, score=0.996 total time=   6.9s\n",
            "[CV 1/3] END ....algorithm=auto, n_neighbors=14;, score=0.997 total time=  10.2s\n",
            "[CV 2/3] END ....algorithm=auto, n_neighbors=14;, score=0.996 total time=   8.0s\n",
            "[CV 3/3] END ....algorithm=auto, n_neighbors=14;, score=0.996 total time=  11.2s\n",
            "[CV 1/3] END ....algorithm=auto, n_neighbors=15;, score=0.997 total time=   8.8s\n",
            "[CV 2/3] END ....algorithm=auto, n_neighbors=15;, score=0.997 total time=  10.1s\n",
            "[CV 3/3] END ....algorithm=auto, n_neighbors=15;, score=0.997 total time=  11.1s\n",
            "[CV 1/3] END algorithm=ball_tree, n_neighbors=2;, score=0.994 total time=  46.8s\n",
            "[CV 2/3] END algorithm=ball_tree, n_neighbors=2;, score=0.993 total time= 1.1min\n",
            "[CV 3/3] END algorithm=ball_tree, n_neighbors=2;, score=0.993 total time=  47.2s\n",
            "[CV 1/3] END algorithm=ball_tree, n_neighbors=12;, score=0.997 total time=  55.3s\n",
            "[CV 2/3] END algorithm=ball_tree, n_neighbors=12;, score=0.996 total time= 1.2min\n",
            "[CV 3/3] END algorithm=ball_tree, n_neighbors=12;, score=0.997 total time=  58.5s\n",
            "[CV 1/3] END .algorithm=kd_tree, n_neighbors=14;, score=0.997 total time=   9.8s\n",
            "[CV 2/3] END .algorithm=kd_tree, n_neighbors=14;, score=0.996 total time=   9.6s\n",
            "[CV 3/3] END .algorithm=kd_tree, n_neighbors=14;, score=0.996 total time=   8.4s\n",
            "[CV 1/3] END ..algorithm=kd_tree, n_neighbors=5;, score=0.998 total time=   7.9s\n",
            "[CV 2/3] END ..algorithm=kd_tree, n_neighbors=5;, score=0.997 total time=   6.5s\n",
            "[CV 3/3] END ..algorithm=kd_tree, n_neighbors=5;, score=0.998 total time=   7.2s\n",
            "[CV 1/3] END ....algorithm=auto, n_neighbors=12;, score=0.997 total time=   8.9s\n",
            "[CV 2/3] END ....algorithm=auto, n_neighbors=12;, score=0.996 total time=   9.0s\n",
            "[CV 3/3] END ....algorithm=auto, n_neighbors=12;, score=0.997 total time=   8.6s\n",
            "[CV 1/3] END algorithm=ball_tree, n_neighbors=4;, score=0.995 total time=  48.5s\n",
            "[CV 2/3] END algorithm=ball_tree, n_neighbors=4;, score=0.995 total time= 1.1min\n",
            "[CV 3/3] END algorithm=ball_tree, n_neighbors=4;, score=0.995 total time=  49.8s\n",
            "[CV 1/3] END ....algorithm=auto, n_neighbors=17;, score=0.997 total time=  10.4s\n",
            "[CV 2/3] END ....algorithm=auto, n_neighbors=17;, score=0.997 total time=   8.0s\n",
            "[CV 3/3] END ....algorithm=auto, n_neighbors=17;, score=0.997 total time=  11.0s\n",
            "[CV 1/3] END algorithm=ball_tree, n_neighbors=19;, score=0.997 total time=  59.2s\n",
            "[CV 2/3] END algorithm=ball_tree, n_neighbors=19;, score=0.996 total time= 1.3min\n",
            "[CV 3/3] END algorithm=ball_tree, n_neighbors=19;, score=0.997 total time= 1.1min\n",
            "[CV 1/3] END algorithm=ball_tree, n_neighbors=1;, score=0.998 total time=  42.7s\n",
            "[CV 2/3] END algorithm=ball_tree, n_neighbors=1;, score=0.997 total time=  56.6s\n",
            "[CV 3/3] END algorithm=ball_tree, n_neighbors=1;, score=0.997 total time=  44.0s\n",
            "[CV 1/3] END algorithm=ball_tree, n_neighbors=3;, score=0.998 total time=  43.5s\n",
            "[CV 2/3] END algorithm=ball_tree, n_neighbors=3;, score=0.997 total time= 1.0min\n",
            "[CV 3/3] END algorithm=ball_tree, n_neighbors=3;, score=0.997 total time=  47.7s\n",
            "[CV 1/3] END algorithm=ball_tree, n_neighbors=17;, score=0.997 total time=  56.5s\n",
            "[CV 2/3] END algorithm=ball_tree, n_neighbors=17;, score=0.997 total time= 1.2min\n",
            "[CV 3/3] END algorithm=ball_tree, n_neighbors=17;, score=0.997 total time=  58.6s\n",
            "[CV 1/3] END algorithm=ball_tree, n_neighbors=20;, score=0.996 total time=  56.7s\n",
            "[CV 2/3] END algorithm=ball_tree, n_neighbors=20;, score=0.996 total time= 1.4min\n",
            "[CV 3/3] END algorithm=ball_tree, n_neighbors=20;, score=0.996 total time= 1.2min\n",
            "[CV 1/3] END .....algorithm=auto, n_neighbors=9;, score=0.998 total time=   7.4s\n",
            "[CV 2/3] END .....algorithm=auto, n_neighbors=9;, score=0.997 total time=   9.7s\n",
            "[CV 3/3] END .....algorithm=auto, n_neighbors=9;, score=0.998 total time=   7.4s\n",
            "[CV 1/3] END algorithm=ball_tree, n_neighbors=16;, score=0.996 total time= 1.0min\n",
            "[CV 2/3] END algorithm=ball_tree, n_neighbors=16;, score=0.996 total time= 1.3min\n",
            "[CV 3/3] END algorithm=ball_tree, n_neighbors=16;, score=0.996 total time= 1.1min\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "{'n_neighbors': 7, 'algorithm': 'ball_tree'}"
            ]
          },
          "execution_count": 48,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# RandomizedSearchCV\n",
        "\n",
        "random_grid = {\n",
        "                \"n_neighbors\": [int(x) for x in np.linspace(1, 20, num = 20)],\n",
        "                \"algorithm\": ['auto', 'kd_tree','ball_tree']\n",
        "              }\n",
        "\n",
        "neigh_random = RandomizedSearchCV(estimator = neigh_clf, \n",
        "                                  param_distributions = random_grid, \n",
        "                                  n_iter = 50, \n",
        "                                  cv = 3, \n",
        "                                  verbose = 3, \n",
        "                                  scoring = 'recall',\n",
        "                                  random_state = 10)\n",
        "\n",
        "neigh_random.fit(X_train, y_train)\n",
        "neigh_random.best_params_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2G3z6f8vP21Z",
        "outputId": "2844e3cb-8bcc-4577-d8e6-93f85400bd58"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'n_neighbors': 7, 'algorithm': 'ball_tree'}"
            ]
          },
          "execution_count": 49,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "neigh_random.best_params_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kTB3Zxm-PUu4",
        "outputId": "9f56d167-6cdb-4b88-c1e3-b91d30b4b01e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.9975882784640104"
            ]
          },
          "execution_count": 50,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "neigh_random.best_score_"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "brtgIH7pt1jO"
      },
      "source": [
        "## Decision Tree\n",
        "\n",
        "- Library: Scikit-learn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sgwicO4LbXRt"
      },
      "outputs": [],
      "source": [
        "# Training\n",
        "\n",
        "name = 'tree_clf'\n",
        "\n",
        "train = pd.DataFrame(columns = ['criterion', 'splitter', 'min_samples_leaf', 'max_features', 'max_depth', 'n_jobs', 'random_state'])\n",
        "train = train.append({'criterion' : 'gini', 'splitter': 'best', 'min_samples_leaf': 1, 'max_features': 9, 'max_depth': None, 'random_state': 10}, ignore_index=True)\n",
        "train = train.append({'criterion' : 'entropy', 'splitter': 'best', 'min_samples_leaf': 1, 'max_features': 9, 'max_depth': None, 'random_state': 10}, ignore_index=True)\n",
        "train = train.append({'criterion' : 'gini', 'splitter': 'random', 'min_samples_leaf': 1, 'max_features': \"auto\", 'max_depth': None, 'random_state': 10}, ignore_index=True)\n",
        "train = train.append({'criterion' : 'entropy', 'splitter': 'random', 'min_samples_leaf': 1, 'max_features': \"auto\", 'max_depth': None, 'random_state': 10}, ignore_index=True)\n",
        "\n",
        "train = train.reset_index()\n",
        "for index, row in train.iterrows():\n",
        "    model_name = name + str(index)\n",
        "    tree_clf = DecisionTreeClassifier(criterion = row['criterion'], splitter = row['splitter'], max_depth = None, random_state = row['random_state'])\n",
        "    tree_clf.fit(X_train, y_train)\n",
        "    \n",
        "    y_true = y_val\n",
        "    y_pred = tree_clf.predict(X_val)\n",
        "    evaluation_results = evaluation_metrics(y_true, y_pred)\n",
        "\n",
        "    models = models.append({'model_name': model_name, \n",
        "                            'model': tree_clf, \n",
        "                            'parameters': tree_clf.get_params()}, \n",
        "                            ignore_index=True)\n",
        "    \n",
        "    models_eval = models_eval.append({'model_name': model_name, \n",
        "                                      'confusion_matrix' : evaluation_results[0], \n",
        "                                      'accuracy': evaluation_results[1], \n",
        "                                      'recall' : evaluation_results[2], \n",
        "                                      'f1_score': evaluation_results[3], \n",
        "                                      'roc_auc_score': evaluation_results[4]}, \n",
        "                                      ignore_index=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 770
        },
        "id": "YC01I-OZbZQU",
        "outputId": "abfe3fb6-7030-4ba5-fdfc-ba49c771431e"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-6efabce4-365d-4286-9e8c-c9f5191aed82\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>model_name</th>\n",
              "      <th>confusion_matrix</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>recall</th>\n",
              "      <th>f1_score</th>\n",
              "      <th>roc_auc_score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>log_clf0</td>\n",
              "      <td>[10551, 6517, 38, 84]</td>\n",
              "      <td>0.618674</td>\n",
              "      <td>0.688525</td>\n",
              "      <td>0.024989</td>\n",
              "      <td>0.653349</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>log_clf1</td>\n",
              "      <td>[10551, 6517, 39, 83]</td>\n",
              "      <td>0.618615</td>\n",
              "      <td>0.680328</td>\n",
              "      <td>0.024695</td>\n",
              "      <td>0.649251</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>svc_clf0</td>\n",
              "      <td>[12395, 4673, 25, 97]</td>\n",
              "      <td>0.726702</td>\n",
              "      <td>0.795082</td>\n",
              "      <td>0.039657</td>\n",
              "      <td>0.760647</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>svc_clf1</td>\n",
              "      <td>[10750, 6318, 19, 103]</td>\n",
              "      <td>0.631355</td>\n",
              "      <td>0.844262</td>\n",
              "      <td>0.031484</td>\n",
              "      <td>0.737048</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>svc_clf2</td>\n",
              "      <td>[7181, 9887, 38, 84]</td>\n",
              "      <td>0.422629</td>\n",
              "      <td>0.688525</td>\n",
              "      <td>0.016645</td>\n",
              "      <td>0.554627</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>svc_clf3</td>\n",
              "      <td>[14126, 2942, 22, 100]</td>\n",
              "      <td>0.827574</td>\n",
              "      <td>0.819672</td>\n",
              "      <td>0.063211</td>\n",
              "      <td>0.823651</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>svc_clf4</td>\n",
              "      <td>[14240, 2828, 23, 99]</td>\n",
              "      <td>0.834148</td>\n",
              "      <td>0.811475</td>\n",
              "      <td>0.064939</td>\n",
              "      <td>0.822893</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>svc_clf5</td>\n",
              "      <td>[14296, 2772, 24, 98]</td>\n",
              "      <td>0.837347</td>\n",
              "      <td>0.803279</td>\n",
              "      <td>0.065508</td>\n",
              "      <td>0.820435</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>svc_clf6</td>\n",
              "      <td>[14335, 2733, 22, 100]</td>\n",
              "      <td>0.839732</td>\n",
              "      <td>0.819672</td>\n",
              "      <td>0.067682</td>\n",
              "      <td>0.829774</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>bayes_clf0</td>\n",
              "      <td>[8297, 8771, 40, 82]</td>\n",
              "      <td>0.487435</td>\n",
              "      <td>0.672131</td>\n",
              "      <td>0.018273</td>\n",
              "      <td>0.579123</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>bayes_clf1</td>\n",
              "      <td>[9041, 8027, 25, 97]</td>\n",
              "      <td>0.531588</td>\n",
              "      <td>0.795082</td>\n",
              "      <td>0.023527</td>\n",
              "      <td>0.662393</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>bayes_clf2</td>\n",
              "      <td>[10242, 6826, 39, 83]</td>\n",
              "      <td>0.600640</td>\n",
              "      <td>0.680328</td>\n",
              "      <td>0.023610</td>\n",
              "      <td>0.640199</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>bayes_clf3</td>\n",
              "      <td>[10323, 6745, 39, 83]</td>\n",
              "      <td>0.605352</td>\n",
              "      <td>0.680328</td>\n",
              "      <td>0.023885</td>\n",
              "      <td>0.642572</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>bayes_clf4</td>\n",
              "      <td>[10324, 6744, 39, 83]</td>\n",
              "      <td>0.605410</td>\n",
              "      <td>0.680328</td>\n",
              "      <td>0.023888</td>\n",
              "      <td>0.642601</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>bayes_clf5</td>\n",
              "      <td>[10324, 6744, 39, 83]</td>\n",
              "      <td>0.605410</td>\n",
              "      <td>0.680328</td>\n",
              "      <td>0.023888</td>\n",
              "      <td>0.642601</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>bayes_clf6</td>\n",
              "      <td>[10324, 6744, 39, 83]</td>\n",
              "      <td>0.605410</td>\n",
              "      <td>0.680328</td>\n",
              "      <td>0.023888</td>\n",
              "      <td>0.642601</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>neigh_clf0</td>\n",
              "      <td>[16733, 335, 30, 92]</td>\n",
              "      <td>0.978767</td>\n",
              "      <td>0.754098</td>\n",
              "      <td>0.335155</td>\n",
              "      <td>0.867235</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>neigh_clf1</td>\n",
              "      <td>[16916, 152, 43, 79]</td>\n",
              "      <td>0.988656</td>\n",
              "      <td>0.647541</td>\n",
              "      <td>0.447592</td>\n",
              "      <td>0.819318</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>neigh_clf2</td>\n",
              "      <td>[16334, 734, 22, 100]</td>\n",
              "      <td>0.956021</td>\n",
              "      <td>0.819672</td>\n",
              "      <td>0.209205</td>\n",
              "      <td>0.888334</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>tree_clf0</td>\n",
              "      <td>[16936, 132, 23, 99]</td>\n",
              "      <td>0.990983</td>\n",
              "      <td>0.811475</td>\n",
              "      <td>0.560907</td>\n",
              "      <td>0.901871</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>tree_clf1</td>\n",
              "      <td>[16942, 126, 20, 102]</td>\n",
              "      <td>0.991507</td>\n",
              "      <td>0.836066</td>\n",
              "      <td>0.582857</td>\n",
              "      <td>0.914342</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>tree_clf2</td>\n",
              "      <td>[16931, 137, 25, 97]</td>\n",
              "      <td>0.990576</td>\n",
              "      <td>0.795082</td>\n",
              "      <td>0.544944</td>\n",
              "      <td>0.893528</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>tree_clf3</td>\n",
              "      <td>[16884, 184, 25, 97]</td>\n",
              "      <td>0.987842</td>\n",
              "      <td>0.795082</td>\n",
              "      <td>0.481390</td>\n",
              "      <td>0.892151</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-6efabce4-365d-4286-9e8c-c9f5191aed82')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-6efabce4-365d-4286-9e8c-c9f5191aed82 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-6efabce4-365d-4286-9e8c-c9f5191aed82');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "    model_name        confusion_matrix  accuracy    recall  f1_score  \\\n",
              "0     log_clf0   [10551, 6517, 38, 84]  0.618674  0.688525  0.024989   \n",
              "1     log_clf1   [10551, 6517, 39, 83]  0.618615  0.680328  0.024695   \n",
              "2     svc_clf0   [12395, 4673, 25, 97]  0.726702  0.795082  0.039657   \n",
              "3     svc_clf1  [10750, 6318, 19, 103]  0.631355  0.844262  0.031484   \n",
              "4     svc_clf2    [7181, 9887, 38, 84]  0.422629  0.688525  0.016645   \n",
              "5     svc_clf3  [14126, 2942, 22, 100]  0.827574  0.819672  0.063211   \n",
              "6     svc_clf4   [14240, 2828, 23, 99]  0.834148  0.811475  0.064939   \n",
              "7     svc_clf5   [14296, 2772, 24, 98]  0.837347  0.803279  0.065508   \n",
              "8     svc_clf6  [14335, 2733, 22, 100]  0.839732  0.819672  0.067682   \n",
              "9   bayes_clf0    [8297, 8771, 40, 82]  0.487435  0.672131  0.018273   \n",
              "10  bayes_clf1    [9041, 8027, 25, 97]  0.531588  0.795082  0.023527   \n",
              "11  bayes_clf2   [10242, 6826, 39, 83]  0.600640  0.680328  0.023610   \n",
              "12  bayes_clf3   [10323, 6745, 39, 83]  0.605352  0.680328  0.023885   \n",
              "13  bayes_clf4   [10324, 6744, 39, 83]  0.605410  0.680328  0.023888   \n",
              "14  bayes_clf5   [10324, 6744, 39, 83]  0.605410  0.680328  0.023888   \n",
              "15  bayes_clf6   [10324, 6744, 39, 83]  0.605410  0.680328  0.023888   \n",
              "16  neigh_clf0    [16733, 335, 30, 92]  0.978767  0.754098  0.335155   \n",
              "17  neigh_clf1    [16916, 152, 43, 79]  0.988656  0.647541  0.447592   \n",
              "18  neigh_clf2   [16334, 734, 22, 100]  0.956021  0.819672  0.209205   \n",
              "19   tree_clf0    [16936, 132, 23, 99]  0.990983  0.811475  0.560907   \n",
              "20   tree_clf1   [16942, 126, 20, 102]  0.991507  0.836066  0.582857   \n",
              "21   tree_clf2    [16931, 137, 25, 97]  0.990576  0.795082  0.544944   \n",
              "22   tree_clf3    [16884, 184, 25, 97]  0.987842  0.795082  0.481390   \n",
              "\n",
              "    roc_auc_score  \n",
              "0        0.653349  \n",
              "1        0.649251  \n",
              "2        0.760647  \n",
              "3        0.737048  \n",
              "4        0.554627  \n",
              "5        0.823651  \n",
              "6        0.822893  \n",
              "7        0.820435  \n",
              "8        0.829774  \n",
              "9        0.579123  \n",
              "10       0.662393  \n",
              "11       0.640199  \n",
              "12       0.642572  \n",
              "13       0.642601  \n",
              "14       0.642601  \n",
              "15       0.642601  \n",
              "16       0.867235  \n",
              "17       0.819318  \n",
              "18       0.888334  \n",
              "19       0.901871  \n",
              "20       0.914342  \n",
              "21       0.893528  \n",
              "22       0.892151  "
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "display(models_eval)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HuK06hK8bZ_r",
        "outputId": "f4c5e678-00a0-4ba4-ea50-53c85241fa75"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fitting 3 folds for each of 100 candidates, totalling 300 fits\n",
            "[CV 1/3] END criterion=gini, max_depth=10, max_features=5, min_samples_leaf=2, splitter=best;, score=0.915 total time=   1.2s\n",
            "[CV 2/3] END criterion=gini, max_depth=10, max_features=5, min_samples_leaf=2, splitter=best;, score=0.942 total time=   1.2s\n",
            "[CV 3/3] END criterion=gini, max_depth=10, max_features=5, min_samples_leaf=2, splitter=best;, score=0.946 total time=   1.2s\n",
            "[CV 1/3] END criterion=gini, max_depth=5, max_features=1, min_samples_leaf=2, splitter=random;, score=0.752 total time=   0.1s\n",
            "[CV 2/3] END criterion=gini, max_depth=5, max_features=1, min_samples_leaf=2, splitter=random;, score=0.881 total time=   0.1s\n",
            "[CV 3/3] END criterion=gini, max_depth=5, max_features=1, min_samples_leaf=2, splitter=random;, score=0.887 total time=   0.1s\n",
            "[CV 1/3] END criterion=log_loss, max_depth=10, max_features=6, min_samples_leaf=1, splitter=random;, score=0.879 total time=   0.2s\n",
            "[CV 2/3] END criterion=log_loss, max_depth=10, max_features=6, min_samples_leaf=1, splitter=random;, score=0.789 total time=   0.2s\n",
            "[CV 3/3] END criterion=log_loss, max_depth=10, max_features=6, min_samples_leaf=1, splitter=random;, score=0.863 total time=   0.2s\n",
            "[CV 1/3] END criterion=log_loss, max_depth=10, max_features=2, min_samples_leaf=4, splitter=best;, score=0.801 total time=   0.6s\n",
            "[CV 2/3] END criterion=log_loss, max_depth=10, max_features=2, min_samples_leaf=4, splitter=best;, score=0.899 total time=   0.6s\n",
            "[CV 3/3] END criterion=log_loss, max_depth=10, max_features=2, min_samples_leaf=4, splitter=best;, score=0.859 total time=   0.6s\n",
            "[CV 1/3] END criterion=log_loss, max_depth=None, max_features=1, min_samples_leaf=4, splitter=best;, score=0.968 total time=   0.5s\n",
            "[CV 2/3] END criterion=log_loss, max_depth=None, max_features=1, min_samples_leaf=4, splitter=best;, score=0.974 total time=   0.5s\n",
            "[CV 3/3] END criterion=log_loss, max_depth=None, max_features=1, min_samples_leaf=4, splitter=best;, score=0.976 total time=   0.5s\n",
            "[CV 1/3] END criterion=gini, max_depth=5, max_features=1, min_samples_leaf=1, splitter=best;, score=0.777 total time=   0.2s\n",
            "[CV 2/3] END criterion=gini, max_depth=5, max_features=1, min_samples_leaf=1, splitter=best;, score=0.628 total time=   0.2s\n",
            "[CV 3/3] END criterion=gini, max_depth=5, max_features=1, min_samples_leaf=1, splitter=best;, score=0.776 total time=   0.2s\n",
            "[CV 1/3] END criterion=entropy, max_depth=5, max_features=2, min_samples_leaf=4, splitter=random;, score=0.633 total time=   0.1s\n",
            "[CV 2/3] END criterion=entropy, max_depth=5, max_features=2, min_samples_leaf=4, splitter=random;, score=0.724 total time=   0.1s\n",
            "[CV 3/3] END criterion=entropy, max_depth=5, max_features=2, min_samples_leaf=4, splitter=random;, score=0.581 total time=   0.1s\n",
            "[CV 1/3] END criterion=log_loss, max_depth=5, max_features=5, min_samples_leaf=2, splitter=best;, score=0.878 total time=   0.8s\n",
            "[CV 2/3] END criterion=log_loss, max_depth=5, max_features=5, min_samples_leaf=2, splitter=best;, score=0.862 total time=   1.1s\n",
            "[CV 3/3] END criterion=log_loss, max_depth=5, max_features=5, min_samples_leaf=2, splitter=best;, score=0.868 total time=   1.2s\n",
            "[CV 1/3] END criterion=log_loss, max_depth=5, max_features=6, min_samples_leaf=4, splitter=random;, score=0.478 total time=   0.2s\n",
            "[CV 2/3] END criterion=log_loss, max_depth=5, max_features=6, min_samples_leaf=4, splitter=random;, score=0.575 total time=   0.2s\n",
            "[CV 3/3] END criterion=log_loss, max_depth=5, max_features=6, min_samples_leaf=4, splitter=random;, score=0.565 total time=   0.2s\n",
            "[CV 1/3] END criterion=entropy, max_depth=3, max_features=2, min_samples_leaf=2, splitter=best;, score=0.445 total time=   0.4s\n",
            "[CV 2/3] END criterion=entropy, max_depth=3, max_features=2, min_samples_leaf=2, splitter=best;, score=0.446 total time=   0.4s\n",
            "[CV 3/3] END criterion=entropy, max_depth=3, max_features=2, min_samples_leaf=2, splitter=best;, score=0.449 total time=   0.4s\n",
            "[CV 1/3] END criterion=gini, max_depth=1, max_features=6, min_samples_leaf=3, splitter=random;, score=0.930 total time=   0.1s\n",
            "[CV 2/3] END criterion=gini, max_depth=1, max_features=6, min_samples_leaf=3, splitter=random;, score=0.930 total time=   0.1s\n",
            "[CV 3/3] END criterion=gini, max_depth=1, max_features=6, min_samples_leaf=3, splitter=random;, score=0.930 total time=   0.1s\n",
            "[CV 1/3] END criterion=entropy, max_depth=15, max_features=1, min_samples_leaf=4, splitter=random;, score=0.795 total time=   0.1s\n",
            "[CV 2/3] END criterion=entropy, max_depth=15, max_features=1, min_samples_leaf=4, splitter=random;, score=0.943 total time=   0.1s\n",
            "[CV 3/3] END criterion=entropy, max_depth=15, max_features=1, min_samples_leaf=4, splitter=random;, score=0.956 total time=   0.1s\n",
            "[CV 1/3] END criterion=gini, max_depth=5, max_features=1, min_samples_leaf=5, splitter=best;, score=0.777 total time=   0.4s\n",
            "[CV 2/3] END criterion=gini, max_depth=5, max_features=1, min_samples_leaf=5, splitter=best;, score=0.628 total time=   0.4s\n",
            "[CV 3/3] END criterion=gini, max_depth=5, max_features=1, min_samples_leaf=5, splitter=best;, score=0.776 total time=   0.3s\n",
            "[CV 1/3] END criterion=entropy, max_depth=5, max_features=5, min_samples_leaf=4, splitter=best;, score=0.878 total time=   1.0s\n",
            "[CV 2/3] END criterion=entropy, max_depth=5, max_features=5, min_samples_leaf=4, splitter=best;, score=0.862 total time=   0.9s\n",
            "[CV 3/3] END criterion=entropy, max_depth=5, max_features=5, min_samples_leaf=4, splitter=best;, score=0.868 total time=   0.8s\n",
            "[CV 1/3] END criterion=entropy, max_depth=15, max_features=1, min_samples_leaf=2, splitter=best;, score=0.919 total time=   0.5s\n",
            "[CV 2/3] END criterion=entropy, max_depth=15, max_features=1, min_samples_leaf=2, splitter=best;, score=0.929 total time=   0.5s\n",
            "[CV 3/3] END criterion=entropy, max_depth=15, max_features=1, min_samples_leaf=2, splitter=best;, score=0.936 total time=   0.5s\n",
            "[CV 1/3] END criterion=entropy, max_depth=8, max_features=6, min_samples_leaf=3, splitter=random;, score=0.835 total time=   0.2s\n",
            "[CV 2/3] END criterion=entropy, max_depth=8, max_features=6, min_samples_leaf=3, splitter=random;, score=0.850 total time=   0.2s\n",
            "[CV 3/3] END criterion=entropy, max_depth=8, max_features=6, min_samples_leaf=3, splitter=random;, score=0.728 total time=   0.2s\n",
            "[CV 1/3] END criterion=gini, max_depth=3, max_features=2, min_samples_leaf=2, splitter=best;, score=0.692 total time=   0.3s\n",
            "[CV 2/3] END criterion=gini, max_depth=3, max_features=2, min_samples_leaf=2, splitter=best;, score=0.692 total time=   0.3s\n",
            "[CV 3/3] END criterion=gini, max_depth=3, max_features=2, min_samples_leaf=2, splitter=best;, score=0.696 total time=   0.3s\n",
            "[CV 1/3] END criterion=gini, max_depth=10, max_features=3, min_samples_leaf=6, splitter=best;, score=0.914 total time=   0.8s\n",
            "[CV 2/3] END criterion=gini, max_depth=10, max_features=3, min_samples_leaf=6, splitter=best;, score=0.908 total time=   0.8s\n",
            "[CV 3/3] END criterion=gini, max_depth=10, max_features=3, min_samples_leaf=6, splitter=best;, score=0.924 total time=   0.8s\n",
            "[CV 1/3] END criterion=log_loss, max_depth=5, max_features=2, min_samples_leaf=5, splitter=best;, score=0.829 total time=   0.4s\n",
            "[CV 2/3] END criterion=log_loss, max_depth=5, max_features=2, min_samples_leaf=5, splitter=best;, score=0.828 total time=   0.4s\n",
            "[CV 3/3] END criterion=log_loss, max_depth=5, max_features=2, min_samples_leaf=5, splitter=best;, score=0.617 total time=   0.4s\n",
            "[CV 1/3] END criterion=gini, max_depth=1, max_features=3, min_samples_leaf=6, splitter=best;, score=0.578 total time=   0.2s\n",
            "[CV 2/3] END criterion=gini, max_depth=1, max_features=3, min_samples_leaf=6, splitter=best;, score=0.575 total time=   0.2s\n",
            "[CV 3/3] END criterion=gini, max_depth=1, max_features=3, min_samples_leaf=6, splitter=best;, score=0.579 total time=   0.2s\n",
            "[CV 1/3] END criterion=gini, max_depth=3, max_features=5, min_samples_leaf=6, splitter=random;, score=0.571 total time=   0.1s\n",
            "[CV 2/3] END criterion=gini, max_depth=3, max_features=5, min_samples_leaf=6, splitter=random;, score=0.575 total time=   0.1s\n",
            "[CV 3/3] END criterion=gini, max_depth=3, max_features=5, min_samples_leaf=6, splitter=random;, score=0.576 total time=   0.1s\n",
            "[CV 1/3] END criterion=gini, max_depth=1, max_features=3, min_samples_leaf=4, splitter=best;, score=0.578 total time=   0.2s\n",
            "[CV 2/3] END criterion=gini, max_depth=1, max_features=3, min_samples_leaf=4, splitter=best;, score=0.575 total time=   0.2s\n",
            "[CV 3/3] END criterion=gini, max_depth=1, max_features=3, min_samples_leaf=4, splitter=best;, score=0.579 total time=   0.2s\n",
            "[CV 1/3] END criterion=log_loss, max_depth=1, max_features=1, min_samples_leaf=3, splitter=best;, score=0.454 total time=   0.2s\n",
            "[CV 2/3] END criterion=log_loss, max_depth=1, max_features=1, min_samples_leaf=3, splitter=best;, score=0.454 total time=   0.2s\n",
            "[CV 3/3] END criterion=log_loss, max_depth=1, max_features=1, min_samples_leaf=3, splitter=best;, score=0.458 total time=   0.2s\n",
            "[CV 1/3] END criterion=log_loss, max_depth=None, max_features=3, min_samples_leaf=2, splitter=random;, score=0.983 total time=   0.4s\n",
            "[CV 2/3] END criterion=log_loss, max_depth=None, max_features=3, min_samples_leaf=2, splitter=random;, score=0.984 total time=   0.4s\n",
            "[CV 3/3] END criterion=log_loss, max_depth=None, max_features=3, min_samples_leaf=2, splitter=random;, score=0.986 total time=   0.4s\n",
            "[CV 1/3] END criterion=gini, max_depth=None, max_features=4, min_samples_leaf=4, splitter=best;, score=0.982 total time=   1.9s\n",
            "[CV 2/3] END criterion=gini, max_depth=None, max_features=4, min_samples_leaf=4, splitter=best;, score=0.982 total time=   2.0s\n",
            "[CV 3/3] END criterion=gini, max_depth=None, max_features=4, min_samples_leaf=4, splitter=best;, score=0.985 total time=   1.5s\n",
            "[CV 1/3] END criterion=log_loss, max_depth=None, max_features=2, min_samples_leaf=6, splitter=random;, score=0.958 total time=   0.2s\n",
            "[CV 2/3] END criterion=log_loss, max_depth=None, max_features=2, min_samples_leaf=6, splitter=random;, score=0.906 total time=   0.2s\n",
            "[CV 3/3] END criterion=log_loss, max_depth=None, max_features=2, min_samples_leaf=6, splitter=random;, score=0.885 total time=   0.2s\n",
            "[CV 1/3] END criterion=gini, max_depth=15, max_features=6, min_samples_leaf=4, splitter=random;, score=0.908 total time=   0.3s\n",
            "[CV 2/3] END criterion=gini, max_depth=15, max_features=6, min_samples_leaf=4, splitter=random;, score=0.946 total time=   0.2s\n",
            "[CV 3/3] END criterion=gini, max_depth=15, max_features=6, min_samples_leaf=4, splitter=random;, score=0.897 total time=   0.2s\n",
            "[CV 1/3] END criterion=entropy, max_depth=1, max_features=1, min_samples_leaf=2, splitter=best;, score=0.454 total time=   0.1s\n",
            "[CV 2/3] END criterion=entropy, max_depth=1, max_features=1, min_samples_leaf=2, splitter=best;, score=0.454 total time=   0.1s\n",
            "[CV 3/3] END criterion=entropy, max_depth=1, max_features=1, min_samples_leaf=2, splitter=best;, score=0.458 total time=   0.1s\n",
            "[CV 1/3] END criterion=log_loss, max_depth=None, max_features=2, min_samples_leaf=3, splitter=best;, score=0.986 total time=   0.8s\n",
            "[CV 2/3] END criterion=log_loss, max_depth=None, max_features=2, min_samples_leaf=3, splitter=best;, score=0.984 total time=   0.8s\n",
            "[CV 3/3] END criterion=log_loss, max_depth=None, max_features=2, min_samples_leaf=3, splitter=best;, score=0.986 total time=   0.8s\n",
            "[CV 1/3] END criterion=log_loss, max_depth=1, max_features=5, min_samples_leaf=3, splitter=best;, score=0.454 total time=   0.2s\n",
            "[CV 2/3] END criterion=log_loss, max_depth=1, max_features=5, min_samples_leaf=3, splitter=best;, score=0.454 total time=   0.2s\n",
            "[CV 3/3] END criterion=log_loss, max_depth=1, max_features=5, min_samples_leaf=3, splitter=best;, score=0.458 total time=   0.2s\n",
            "[CV 1/3] END criterion=gini, max_depth=1, max_features=3, min_samples_leaf=6, splitter=random;, score=0.930 total time=   0.1s\n",
            "[CV 2/3] END criterion=gini, max_depth=1, max_features=3, min_samples_leaf=6, splitter=random;, score=0.930 total time=   0.1s\n",
            "[CV 3/3] END criterion=gini, max_depth=1, max_features=3, min_samples_leaf=6, splitter=random;, score=0.930 total time=   0.1s\n",
            "[CV 1/3] END criterion=log_loss, max_depth=15, max_features=6, min_samples_leaf=2, splitter=random;, score=0.952 total time=   0.2s\n",
            "[CV 2/3] END criterion=log_loss, max_depth=15, max_features=6, min_samples_leaf=2, splitter=random;, score=0.944 total time=   0.2s\n",
            "[CV 3/3] END criterion=log_loss, max_depth=15, max_features=6, min_samples_leaf=2, splitter=random;, score=0.815 total time=   0.2s\n",
            "[CV 1/3] END criterion=log_loss, max_depth=None, max_features=5, min_samples_leaf=5, splitter=random;, score=0.980 total time=   0.3s\n",
            "[CV 2/3] END criterion=log_loss, max_depth=None, max_features=5, min_samples_leaf=5, splitter=random;, score=0.981 total time=   0.3s\n",
            "[CV 3/3] END criterion=log_loss, max_depth=None, max_features=5, min_samples_leaf=5, splitter=random;, score=0.981 total time=   0.3s\n",
            "[CV 1/3] END criterion=log_loss, max_depth=None, max_features=6, min_samples_leaf=6, splitter=best;, score=0.985 total time=   2.0s\n",
            "[CV 2/3] END criterion=log_loss, max_depth=None, max_features=6, min_samples_leaf=6, splitter=best;, score=0.982 total time=   2.7s\n",
            "[CV 3/3] END criterion=log_loss, max_depth=None, max_features=6, min_samples_leaf=6, splitter=best;, score=0.986 total time=   3.1s\n",
            "[CV 1/3] END criterion=log_loss, max_depth=10, max_features=4, min_samples_leaf=4, splitter=random;, score=0.784 total time=   0.3s\n",
            "[CV 2/3] END criterion=log_loss, max_depth=10, max_features=4, min_samples_leaf=4, splitter=random;, score=0.824 total time=   0.3s\n",
            "[CV 3/3] END criterion=log_loss, max_depth=10, max_features=4, min_samples_leaf=4, splitter=random;, score=0.879 total time=   0.2s\n",
            "[CV 1/3] END criterion=log_loss, max_depth=10, max_features=4, min_samples_leaf=6, splitter=random;, score=0.796 total time=   0.2s\n",
            "[CV 2/3] END criterion=log_loss, max_depth=10, max_features=4, min_samples_leaf=6, splitter=random;, score=0.820 total time=   0.2s\n",
            "[CV 3/3] END criterion=log_loss, max_depth=10, max_features=4, min_samples_leaf=6, splitter=random;, score=0.883 total time=   0.2s\n",
            "[CV 1/3] END criterion=log_loss, max_depth=8, max_features=4, min_samples_leaf=2, splitter=best;, score=0.789 total time=   1.0s\n",
            "[CV 2/3] END criterion=log_loss, max_depth=8, max_features=4, min_samples_leaf=2, splitter=best;, score=0.889 total time=   1.0s\n",
            "[CV 3/3] END criterion=log_loss, max_depth=8, max_features=4, min_samples_leaf=2, splitter=best;, score=0.872 total time=   1.0s\n",
            "[CV 1/3] END criterion=gini, max_depth=15, max_features=1, min_samples_leaf=1, splitter=best;, score=0.944 total time=   0.4s\n",
            "[CV 2/3] END criterion=gini, max_depth=15, max_features=1, min_samples_leaf=1, splitter=best;, score=0.954 total time=   0.4s\n",
            "[CV 3/3] END criterion=gini, max_depth=15, max_features=1, min_samples_leaf=1, splitter=best;, score=0.944 total time=   0.4s\n",
            "[CV 1/3] END criterion=entropy, max_depth=None, max_features=3, min_samples_leaf=2, splitter=best;, score=0.988 total time=   1.1s\n",
            "[CV 2/3] END criterion=entropy, max_depth=None, max_features=3, min_samples_leaf=2, splitter=best;, score=0.985 total time=   1.2s\n",
            "[CV 3/3] END criterion=entropy, max_depth=None, max_features=3, min_samples_leaf=2, splitter=best;, score=0.986 total time=   1.1s\n",
            "[CV 1/3] END criterion=gini, max_depth=15, max_features=4, min_samples_leaf=4, splitter=best;, score=0.974 total time=   1.1s\n",
            "[CV 2/3] END criterion=gini, max_depth=15, max_features=4, min_samples_leaf=4, splitter=best;, score=0.976 total time=   1.5s\n",
            "[CV 3/3] END criterion=gini, max_depth=15, max_features=4, min_samples_leaf=4, splitter=best;, score=0.972 total time=   1.7s\n",
            "[CV 1/3] END criterion=log_loss, max_depth=8, max_features=2, min_samples_leaf=5, splitter=random;, score=0.682 total time=   0.2s\n",
            "[CV 2/3] END criterion=log_loss, max_depth=8, max_features=2, min_samples_leaf=5, splitter=random;, score=0.715 total time=   0.2s\n",
            "[CV 3/3] END criterion=log_loss, max_depth=8, max_features=2, min_samples_leaf=5, splitter=random;, score=0.516 total time=   0.2s\n",
            "[CV 1/3] END criterion=entropy, max_depth=5, max_features=4, min_samples_leaf=6, splitter=best;, score=0.874 total time=   1.0s\n",
            "[CV 2/3] END criterion=entropy, max_depth=5, max_features=4, min_samples_leaf=6, splitter=best;, score=0.867 total time=   1.0s\n",
            "[CV 3/3] END criterion=entropy, max_depth=5, max_features=4, min_samples_leaf=6, splitter=best;, score=0.864 total time=   0.9s\n",
            "[CV 1/3] END criterion=gini, max_depth=1, max_features=5, min_samples_leaf=5, splitter=random;, score=0.930 total time=   0.1s\n",
            "[CV 2/3] END criterion=gini, max_depth=1, max_features=5, min_samples_leaf=5, splitter=random;, score=0.930 total time=   0.1s\n",
            "[CV 3/3] END criterion=gini, max_depth=1, max_features=5, min_samples_leaf=5, splitter=random;, score=0.930 total time=   0.1s\n",
            "[CV 1/3] END criterion=gini, max_depth=5, max_features=6, min_samples_leaf=5, splitter=random;, score=0.585 total time=   0.1s\n",
            "[CV 2/3] END criterion=gini, max_depth=5, max_features=6, min_samples_leaf=5, splitter=random;, score=0.595 total time=   0.1s\n",
            "[CV 3/3] END criterion=gini, max_depth=5, max_features=6, min_samples_leaf=5, splitter=random;, score=0.565 total time=   0.1s\n",
            "[CV 1/3] END criterion=entropy, max_depth=1, max_features=1, min_samples_leaf=4, splitter=random;, score=0.881 total time=   0.1s\n",
            "[CV 2/3] END criterion=entropy, max_depth=1, max_features=1, min_samples_leaf=4, splitter=random;, score=0.881 total time=   0.1s\n",
            "[CV 3/3] END criterion=entropy, max_depth=1, max_features=1, min_samples_leaf=4, splitter=random;, score=0.886 total time=   0.1s\n",
            "[CV 1/3] END criterion=gini, max_depth=None, max_features=2, min_samples_leaf=5, splitter=random;, score=0.950 total time=   0.2s\n",
            "[CV 2/3] END criterion=gini, max_depth=None, max_features=2, min_samples_leaf=5, splitter=random;, score=0.959 total time=   0.2s\n",
            "[CV 3/3] END criterion=gini, max_depth=None, max_features=2, min_samples_leaf=5, splitter=random;, score=0.948 total time=   0.2s\n",
            "[CV 1/3] END criterion=gini, max_depth=8, max_features=1, min_samples_leaf=5, splitter=best;, score=0.837 total time=   0.3s\n",
            "[CV 2/3] END criterion=gini, max_depth=8, max_features=1, min_samples_leaf=5, splitter=best;, score=0.738 total time=   0.3s\n",
            "[CV 3/3] END criterion=gini, max_depth=8, max_features=1, min_samples_leaf=5, splitter=best;, score=0.825 total time=   0.3s\n",
            "[CV 1/3] END criterion=gini, max_depth=3, max_features=5, min_samples_leaf=1, splitter=random;, score=0.571 total time=   0.1s\n",
            "[CV 2/3] END criterion=gini, max_depth=3, max_features=5, min_samples_leaf=1, splitter=random;, score=0.575 total time=   0.1s\n",
            "[CV 3/3] END criterion=gini, max_depth=3, max_features=5, min_samples_leaf=1, splitter=random;, score=0.576 total time=   0.1s\n",
            "[CV 1/3] END criterion=log_loss, max_depth=3, max_features=6, min_samples_leaf=1, splitter=random;, score=0.305 total time=   0.1s\n",
            "[CV 2/3] END criterion=log_loss, max_depth=3, max_features=6, min_samples_leaf=1, splitter=random;, score=0.294 total time=   0.1s\n",
            "[CV 3/3] END criterion=log_loss, max_depth=3, max_features=6, min_samples_leaf=1, splitter=random;, score=0.298 total time=   0.1s\n",
            "[CV 1/3] END criterion=log_loss, max_depth=15, max_features=2, min_samples_leaf=1, splitter=random;, score=0.816 total time=   0.2s\n",
            "[CV 2/3] END criterion=log_loss, max_depth=15, max_features=2, min_samples_leaf=1, splitter=random;, score=0.906 total time=   0.2s\n",
            "[CV 3/3] END criterion=log_loss, max_depth=15, max_features=2, min_samples_leaf=1, splitter=random;, score=0.866 total time=   0.2s\n",
            "[CV 1/3] END criterion=log_loss, max_depth=3, max_features=1, min_samples_leaf=5, splitter=best;, score=0.739 total time=   0.2s\n",
            "[CV 2/3] END criterion=log_loss, max_depth=3, max_features=1, min_samples_leaf=5, splitter=best;, score=0.709 total time=   0.2s\n",
            "[CV 3/3] END criterion=log_loss, max_depth=3, max_features=1, min_samples_leaf=5, splitter=best;, score=0.738 total time=   0.2s\n",
            "[CV 1/3] END criterion=gini, max_depth=None, max_features=6, min_samples_leaf=2, splitter=random;, score=0.985 total time=   0.3s\n",
            "[CV 2/3] END criterion=gini, max_depth=None, max_features=6, min_samples_leaf=2, splitter=random;, score=0.984 total time=   0.3s\n",
            "[CV 3/3] END criterion=gini, max_depth=None, max_features=6, min_samples_leaf=2, splitter=random;, score=0.986 total time=   0.3s\n",
            "[CV 1/3] END criterion=entropy, max_depth=10, max_features=3, min_samples_leaf=4, splitter=random;, score=0.757 total time=   0.1s\n",
            "[CV 2/3] END criterion=entropy, max_depth=10, max_features=3, min_samples_leaf=4, splitter=random;, score=0.855 total time=   0.1s\n",
            "[CV 3/3] END criterion=entropy, max_depth=10, max_features=3, min_samples_leaf=4, splitter=random;, score=0.846 total time=   0.1s\n",
            "[CV 1/3] END criterion=log_loss, max_depth=10, max_features=1, min_samples_leaf=6, splitter=best;, score=0.909 total time=   0.4s\n",
            "[CV 2/3] END criterion=log_loss, max_depth=10, max_features=1, min_samples_leaf=6, splitter=best;, score=0.782 total time=   0.4s\n",
            "[CV 3/3] END criterion=log_loss, max_depth=10, max_features=1, min_samples_leaf=6, splitter=best;, score=0.886 total time=   0.4s\n",
            "[CV 1/3] END criterion=log_loss, max_depth=10, max_features=3, min_samples_leaf=3, splitter=random;, score=0.753 total time=   0.1s\n",
            "[CV 2/3] END criterion=log_loss, max_depth=10, max_features=3, min_samples_leaf=3, splitter=random;, score=0.860 total time=   0.1s\n",
            "[CV 3/3] END criterion=log_loss, max_depth=10, max_features=3, min_samples_leaf=3, splitter=random;, score=0.850 total time=   0.1s\n",
            "[CV 1/3] END criterion=entropy, max_depth=15, max_features=3, min_samples_leaf=6, splitter=best;, score=0.964 total time=   1.0s\n",
            "[CV 2/3] END criterion=entropy, max_depth=15, max_features=3, min_samples_leaf=6, splitter=best;, score=0.963 total time=   1.0s\n",
            "[CV 3/3] END criterion=entropy, max_depth=15, max_features=3, min_samples_leaf=6, splitter=best;, score=0.969 total time=   1.0s\n",
            "[CV 1/3] END criterion=log_loss, max_depth=5, max_features=4, min_samples_leaf=5, splitter=random;, score=0.862 total time=   0.1s\n",
            "[CV 2/3] END criterion=log_loss, max_depth=5, max_features=4, min_samples_leaf=5, splitter=random;, score=0.641 total time=   0.2s\n",
            "[CV 3/3] END criterion=log_loss, max_depth=5, max_features=4, min_samples_leaf=5, splitter=random;, score=0.644 total time=   0.2s\n",
            "[CV 1/3] END criterion=gini, max_depth=8, max_features=1, min_samples_leaf=1, splitter=best;, score=0.843 total time=   0.5s\n",
            "[CV 2/3] END criterion=gini, max_depth=8, max_features=1, min_samples_leaf=1, splitter=best;, score=0.738 total time=   0.4s\n",
            "[CV 3/3] END criterion=gini, max_depth=8, max_features=1, min_samples_leaf=1, splitter=best;, score=0.724 total time=   0.4s\n",
            "[CV 1/3] END criterion=log_loss, max_depth=5, max_features=6, min_samples_leaf=3, splitter=best;, score=0.872 total time=   1.4s\n",
            "[CV 2/3] END criterion=log_loss, max_depth=5, max_features=6, min_samples_leaf=3, splitter=best;, score=0.869 total time=   1.4s\n",
            "[CV 3/3] END criterion=log_loss, max_depth=5, max_features=6, min_samples_leaf=3, splitter=best;, score=0.871 total time=   1.4s\n",
            "[CV 1/3] END criterion=log_loss, max_depth=10, max_features=3, min_samples_leaf=5, splitter=random;, score=0.757 total time=   0.1s\n",
            "[CV 2/3] END criterion=log_loss, max_depth=10, max_features=3, min_samples_leaf=5, splitter=random;, score=0.859 total time=   0.1s\n",
            "[CV 3/3] END criterion=log_loss, max_depth=10, max_features=3, min_samples_leaf=5, splitter=random;, score=0.854 total time=   0.1s\n",
            "[CV 1/3] END criterion=log_loss, max_depth=15, max_features=2, min_samples_leaf=3, splitter=best;, score=0.955 total time=   0.8s\n",
            "[CV 2/3] END criterion=log_loss, max_depth=15, max_features=2, min_samples_leaf=3, splitter=best;, score=0.970 total time=   0.7s\n",
            "[CV 3/3] END criterion=log_loss, max_depth=15, max_features=2, min_samples_leaf=3, splitter=best;, score=0.965 total time=   0.8s\n",
            "[CV 1/3] END criterion=entropy, max_depth=None, max_features=4, min_samples_leaf=4, splitter=best;, score=0.984 total time=   1.4s\n",
            "[CV 2/3] END criterion=entropy, max_depth=None, max_features=4, min_samples_leaf=4, splitter=best;, score=0.983 total time=   1.4s\n",
            "[CV 3/3] END criterion=entropy, max_depth=None, max_features=4, min_samples_leaf=4, splitter=best;, score=0.985 total time=   1.4s\n",
            "[CV 1/3] END criterion=gini, max_depth=3, max_features=6, min_samples_leaf=6, splitter=best;, score=0.646 total time=   0.5s\n",
            "[CV 2/3] END criterion=gini, max_depth=3, max_features=6, min_samples_leaf=6, splitter=best;, score=0.644 total time=   0.5s\n",
            "[CV 3/3] END criterion=gini, max_depth=3, max_features=6, min_samples_leaf=6, splitter=best;, score=0.646 total time=   0.5s\n",
            "[CV 1/3] END criterion=entropy, max_depth=None, max_features=1, min_samples_leaf=2, splitter=best;, score=0.978 total time=   0.5s\n",
            "[CV 2/3] END criterion=entropy, max_depth=None, max_features=1, min_samples_leaf=2, splitter=best;, score=0.978 total time=   0.5s\n",
            "[CV 3/3] END criterion=entropy, max_depth=None, max_features=1, min_samples_leaf=2, splitter=best;, score=0.978 total time=   0.5s\n",
            "[CV 1/3] END criterion=gini, max_depth=3, max_features=5, min_samples_leaf=2, splitter=best;, score=0.646 total time=   0.6s\n",
            "[CV 2/3] END criterion=gini, max_depth=3, max_features=5, min_samples_leaf=2, splitter=best;, score=0.644 total time=   0.7s\n",
            "[CV 3/3] END criterion=gini, max_depth=3, max_features=5, min_samples_leaf=2, splitter=best;, score=0.646 total time=   0.7s\n",
            "[CV 1/3] END criterion=log_loss, max_depth=None, max_features=4, min_samples_leaf=3, splitter=best;, score=0.988 total time=   2.0s\n",
            "[CV 2/3] END criterion=log_loss, max_depth=None, max_features=4, min_samples_leaf=3, splitter=best;, score=0.987 total time=   2.2s\n",
            "[CV 3/3] END criterion=log_loss, max_depth=None, max_features=4, min_samples_leaf=3, splitter=best;, score=0.989 total time=   1.3s\n",
            "[CV 1/3] END criterion=gini, max_depth=3, max_features=3, min_samples_leaf=1, splitter=best;, score=0.694 total time=   0.3s\n",
            "[CV 2/3] END criterion=gini, max_depth=3, max_features=3, min_samples_leaf=1, splitter=best;, score=0.693 total time=   0.3s\n",
            "[CV 3/3] END criterion=gini, max_depth=3, max_features=3, min_samples_leaf=1, splitter=best;, score=0.697 total time=   0.3s\n",
            "[CV 1/3] END criterion=entropy, max_depth=None, max_features=5, min_samples_leaf=2, splitter=random;, score=0.984 total time=   0.3s\n",
            "[CV 2/3] END criterion=entropy, max_depth=None, max_features=5, min_samples_leaf=2, splitter=random;, score=0.986 total time=   0.3s\n",
            "[CV 3/3] END criterion=entropy, max_depth=None, max_features=5, min_samples_leaf=2, splitter=random;, score=0.987 total time=   0.2s\n",
            "[CV 1/3] END criterion=log_loss, max_depth=5, max_features=2, min_samples_leaf=2, splitter=random;, score=0.633 total time=   0.1s\n",
            "[CV 2/3] END criterion=log_loss, max_depth=5, max_features=2, min_samples_leaf=2, splitter=random;, score=0.724 total time=   0.1s\n",
            "[CV 3/3] END criterion=log_loss, max_depth=5, max_features=2, min_samples_leaf=2, splitter=random;, score=0.581 total time=   0.1s\n",
            "[CV 1/3] END criterion=entropy, max_depth=None, max_features=2, min_samples_leaf=4, splitter=random;, score=0.968 total time=   0.2s\n",
            "[CV 2/3] END criterion=entropy, max_depth=None, max_features=2, min_samples_leaf=4, splitter=random;, score=0.925 total time=   0.2s\n",
            "[CV 3/3] END criterion=entropy, max_depth=None, max_features=2, min_samples_leaf=4, splitter=random;, score=0.964 total time=   0.2s\n",
            "[CV 1/3] END criterion=log_loss, max_depth=15, max_features=3, min_samples_leaf=3, splitter=best;, score=0.971 total time=   1.0s\n",
            "[CV 2/3] END criterion=log_loss, max_depth=15, max_features=3, min_samples_leaf=3, splitter=best;, score=0.946 total time=   1.0s\n",
            "[CV 3/3] END criterion=log_loss, max_depth=15, max_features=3, min_samples_leaf=3, splitter=best;, score=0.958 total time=   1.0s\n",
            "[CV 1/3] END criterion=log_loss, max_depth=15, max_features=4, min_samples_leaf=6, splitter=random;, score=0.934 total time=   0.2s\n",
            "[CV 2/3] END criterion=log_loss, max_depth=15, max_features=4, min_samples_leaf=6, splitter=random;, score=0.885 total time=   0.2s\n",
            "[CV 3/3] END criterion=log_loss, max_depth=15, max_features=4, min_samples_leaf=6, splitter=random;, score=0.917 total time=   0.2s\n",
            "[CV 1/3] END criterion=entropy, max_depth=15, max_features=6, min_samples_leaf=1, splitter=random;, score=0.909 total time=   0.2s\n",
            "[CV 2/3] END criterion=entropy, max_depth=15, max_features=6, min_samples_leaf=1, splitter=random;, score=0.946 total time=   0.2s\n",
            "[CV 3/3] END criterion=entropy, max_depth=15, max_features=6, min_samples_leaf=1, splitter=random;, score=0.909 total time=   0.2s\n",
            "[CV 1/3] END criterion=log_loss, max_depth=1, max_features=2, min_samples_leaf=6, splitter=best;, score=0.454 total time=   0.1s\n",
            "[CV 2/3] END criterion=log_loss, max_depth=1, max_features=2, min_samples_leaf=6, splitter=best;, score=0.454 total time=   0.1s\n",
            "[CV 3/3] END criterion=log_loss, max_depth=1, max_features=2, min_samples_leaf=6, splitter=best;, score=0.458 total time=   0.1s\n",
            "[CV 1/3] END criterion=log_loss, max_depth=3, max_features=5, min_samples_leaf=3, splitter=best;, score=0.719 total time=   0.5s\n",
            "[CV 2/3] END criterion=log_loss, max_depth=3, max_features=5, min_samples_leaf=3, splitter=best;, score=0.878 total time=   0.5s\n",
            "[CV 3/3] END criterion=log_loss, max_depth=3, max_features=5, min_samples_leaf=3, splitter=best;, score=0.719 total time=   0.7s\n",
            "[CV 1/3] END criterion=gini, max_depth=8, max_features=5, min_samples_leaf=1, splitter=random;, score=0.818 total time=   0.3s\n",
            "[CV 2/3] END criterion=gini, max_depth=8, max_features=5, min_samples_leaf=1, splitter=random;, score=0.751 total time=   0.3s\n",
            "[CV 3/3] END criterion=gini, max_depth=8, max_features=5, min_samples_leaf=1, splitter=random;, score=0.768 total time=   0.3s\n",
            "[CV 1/3] END criterion=entropy, max_depth=10, max_features=3, min_samples_leaf=6, splitter=best;, score=0.864 total time=   1.3s\n",
            "[CV 2/3] END criterion=entropy, max_depth=10, max_features=3, min_samples_leaf=6, splitter=best;, score=0.890 total time=   1.3s\n",
            "[CV 3/3] END criterion=entropy, max_depth=10, max_features=3, min_samples_leaf=6, splitter=best;, score=0.923 total time=   1.3s\n",
            "[CV 1/3] END criterion=gini, max_depth=3, max_features=5, min_samples_leaf=6, splitter=best;, score=0.646 total time=   0.6s\n",
            "[CV 2/3] END criterion=gini, max_depth=3, max_features=5, min_samples_leaf=6, splitter=best;, score=0.644 total time=   0.4s\n",
            "[CV 3/3] END criterion=gini, max_depth=3, max_features=5, min_samples_leaf=6, splitter=best;, score=0.646 total time=   0.5s\n",
            "[CV 1/3] END criterion=log_loss, max_depth=15, max_features=4, min_samples_leaf=1, splitter=random;, score=0.937 total time=   0.2s\n",
            "[CV 2/3] END criterion=log_loss, max_depth=15, max_features=4, min_samples_leaf=1, splitter=random;, score=0.931 total time=   0.2s\n",
            "[CV 3/3] END criterion=log_loss, max_depth=15, max_features=4, min_samples_leaf=1, splitter=random;, score=0.923 total time=   0.2s\n",
            "[CV 1/3] END criterion=log_loss, max_depth=3, max_features=4, min_samples_leaf=3, splitter=best;, score=0.434 total time=   0.5s\n",
            "[CV 2/3] END criterion=log_loss, max_depth=3, max_features=4, min_samples_leaf=3, splitter=best;, score=0.430 total time=   0.4s\n",
            "[CV 3/3] END criterion=log_loss, max_depth=3, max_features=4, min_samples_leaf=3, splitter=best;, score=0.438 total time=   0.5s\n",
            "[CV 1/3] END criterion=gini, max_depth=3, max_features=5, min_samples_leaf=3, splitter=best;, score=0.646 total time=   0.5s\n",
            "[CV 2/3] END criterion=gini, max_depth=3, max_features=5, min_samples_leaf=3, splitter=best;, score=0.644 total time=   0.5s\n",
            "[CV 3/3] END criterion=gini, max_depth=3, max_features=5, min_samples_leaf=3, splitter=best;, score=0.646 total time=   0.5s\n",
            "[CV 1/3] END criterion=gini, max_depth=15, max_features=2, min_samples_leaf=1, splitter=random;, score=0.882 total time=   0.2s\n",
            "[CV 2/3] END criterion=gini, max_depth=15, max_features=2, min_samples_leaf=1, splitter=random;, score=0.867 total time=   0.2s\n",
            "[CV 3/3] END criterion=gini, max_depth=15, max_features=2, min_samples_leaf=1, splitter=random;, score=0.818 total time=   0.1s\n",
            "[CV 1/3] END criterion=entropy, max_depth=3, max_features=3, min_samples_leaf=1, splitter=best;, score=0.892 total time=   0.4s\n",
            "[CV 2/3] END criterion=entropy, max_depth=3, max_features=3, min_samples_leaf=1, splitter=best;, score=0.889 total time=   0.3s\n",
            "[CV 3/3] END criterion=entropy, max_depth=3, max_features=3, min_samples_leaf=1, splitter=best;, score=0.892 total time=   0.4s\n",
            "[CV 1/3] END criterion=log_loss, max_depth=None, max_features=3, min_samples_leaf=6, splitter=best;, score=0.982 total time=   1.1s\n",
            "[CV 2/3] END criterion=log_loss, max_depth=None, max_features=3, min_samples_leaf=6, splitter=best;, score=0.980 total time=   1.2s\n",
            "[CV 3/3] END criterion=log_loss, max_depth=None, max_features=3, min_samples_leaf=6, splitter=best;, score=0.981 total time=   1.1s\n",
            "[CV 1/3] END criterion=gini, max_depth=3, max_features=1, min_samples_leaf=2, splitter=random;, score=0.831 total time=   0.1s\n",
            "[CV 2/3] END criterion=gini, max_depth=3, max_features=1, min_samples_leaf=2, splitter=random;, score=0.881 total time=   0.1s\n",
            "[CV 3/3] END criterion=gini, max_depth=3, max_features=1, min_samples_leaf=2, splitter=random;, score=0.886 total time=   0.1s\n",
            "[CV 1/3] END criterion=gini, max_depth=5, max_features=4, min_samples_leaf=6, splitter=random;, score=0.585 total time=   0.1s\n",
            "[CV 2/3] END criterion=gini, max_depth=5, max_features=4, min_samples_leaf=6, splitter=random;, score=0.641 total time=   0.1s\n",
            "[CV 3/3] END criterion=gini, max_depth=5, max_features=4, min_samples_leaf=6, splitter=random;, score=0.644 total time=   0.1s\n",
            "[CV 1/3] END criterion=gini, max_depth=10, max_features=4, min_samples_leaf=6, splitter=random;, score=0.772 total time=   0.2s\n",
            "[CV 2/3] END criterion=gini, max_depth=10, max_features=4, min_samples_leaf=6, splitter=random;, score=0.891 total time=   0.2s\n",
            "[CV 3/3] END criterion=gini, max_depth=10, max_features=4, min_samples_leaf=6, splitter=random;, score=0.890 total time=   0.3s\n",
            "[CV 1/3] END criterion=log_loss, max_depth=10, max_features=4, min_samples_leaf=1, splitter=random;, score=0.866 total time=   0.3s\n",
            "[CV 2/3] END criterion=log_loss, max_depth=10, max_features=4, min_samples_leaf=1, splitter=random;, score=0.823 total time=   0.3s\n",
            "[CV 3/3] END criterion=log_loss, max_depth=10, max_features=4, min_samples_leaf=1, splitter=random;, score=0.879 total time=   0.3s\n",
            "[CV 1/3] END criterion=entropy, max_depth=10, max_features=5, min_samples_leaf=1, splitter=random;, score=0.836 total time=   0.3s\n",
            "[CV 2/3] END criterion=entropy, max_depth=10, max_features=5, min_samples_leaf=1, splitter=random;, score=0.876 total time=   0.3s\n",
            "[CV 3/3] END criterion=entropy, max_depth=10, max_features=5, min_samples_leaf=1, splitter=random;, score=0.901 total time=   0.3s\n",
            "[CV 1/3] END criterion=entropy, max_depth=None, max_features=3, min_samples_leaf=4, splitter=random;, score=0.975 total time=   0.4s\n",
            "[CV 2/3] END criterion=entropy, max_depth=None, max_features=3, min_samples_leaf=4, splitter=random;, score=0.980 total time=   0.4s\n",
            "[CV 3/3] END criterion=entropy, max_depth=None, max_features=3, min_samples_leaf=4, splitter=random;, score=0.978 total time=   0.4s\n",
            "[CV 1/3] END criterion=gini, max_depth=10, max_features=5, min_samples_leaf=5, splitter=best;, score=0.922 total time=   1.8s\n",
            "[CV 2/3] END criterion=gini, max_depth=10, max_features=5, min_samples_leaf=5, splitter=best;, score=0.949 total time=   1.5s\n",
            "[CV 3/3] END criterion=gini, max_depth=10, max_features=5, min_samples_leaf=5, splitter=best;, score=0.934 total time=   1.1s\n",
            "[CV 1/3] END criterion=entropy, max_depth=15, max_features=2, min_samples_leaf=4, splitter=best;, score=0.938 total time=   0.8s\n",
            "[CV 2/3] END criterion=entropy, max_depth=15, max_features=2, min_samples_leaf=4, splitter=best;, score=0.936 total time=   0.7s\n",
            "[CV 3/3] END criterion=entropy, max_depth=15, max_features=2, min_samples_leaf=4, splitter=best;, score=0.931 total time=   0.7s\n",
            "[CV 1/3] END criterion=entropy, max_depth=None, max_features=5, min_samples_leaf=4, splitter=random;, score=0.980 total time=   0.3s\n",
            "[CV 2/3] END criterion=entropy, max_depth=None, max_features=5, min_samples_leaf=4, splitter=random;, score=0.979 total time=   0.3s\n",
            "[CV 3/3] END criterion=entropy, max_depth=None, max_features=5, min_samples_leaf=4, splitter=random;, score=0.984 total time=   0.3s\n",
            "[CV 1/3] END criterion=entropy, max_depth=10, max_features=5, min_samples_leaf=2, splitter=random;, score=0.836 total time=   0.2s\n",
            "[CV 2/3] END criterion=entropy, max_depth=10, max_features=5, min_samples_leaf=2, splitter=random;, score=0.880 total time=   0.2s\n",
            "[CV 3/3] END criterion=entropy, max_depth=10, max_features=5, min_samples_leaf=2, splitter=random;, score=0.861 total time=   0.2s\n",
            "[CV 1/3] END criterion=log_loss, max_depth=8, max_features=6, min_samples_leaf=4, splitter=best;, score=0.933 total time=   1.4s\n",
            "[CV 2/3] END criterion=log_loss, max_depth=8, max_features=6, min_samples_leaf=4, splitter=best;, score=0.930 total time=   1.3s\n",
            "[CV 3/3] END criterion=log_loss, max_depth=8, max_features=6, min_samples_leaf=4, splitter=best;, score=0.940 total time=   1.3s\n",
            "[CV 1/3] END criterion=entropy, max_depth=1, max_features=3, min_samples_leaf=3, splitter=best;, score=0.454 total time=   0.2s\n",
            "[CV 2/3] END criterion=entropy, max_depth=1, max_features=3, min_samples_leaf=3, splitter=best;, score=0.454 total time=   0.2s\n",
            "[CV 3/3] END criterion=entropy, max_depth=1, max_features=3, min_samples_leaf=3, splitter=best;, score=0.458 total time=   0.2s\n",
            "[CV 1/3] END criterion=entropy, max_depth=8, max_features=5, min_samples_leaf=4, splitter=best;, score=0.926 total time=   1.6s\n",
            "[CV 2/3] END criterion=entropy, max_depth=8, max_features=5, min_samples_leaf=4, splitter=best;, score=0.919 total time=   1.7s\n",
            "[CV 3/3] END criterion=entropy, max_depth=8, max_features=5, min_samples_leaf=4, splitter=best;, score=0.874 total time=   1.7s\n",
            "[CV 1/3] END criterion=entropy, max_depth=None, max_features=4, min_samples_leaf=5, splitter=random;, score=0.982 total time=   0.4s\n",
            "[CV 2/3] END criterion=entropy, max_depth=None, max_features=4, min_samples_leaf=5, splitter=random;, score=0.977 total time=   0.4s\n",
            "[CV 3/3] END criterion=entropy, max_depth=None, max_features=4, min_samples_leaf=5, splitter=random;, score=0.977 total time=   0.3s\n",
            "[CV 1/3] END criterion=gini, max_depth=8, max_features=5, min_samples_leaf=2, splitter=best;, score=0.885 total time=   1.0s\n",
            "[CV 2/3] END criterion=gini, max_depth=8, max_features=5, min_samples_leaf=2, splitter=best;, score=0.909 total time=   1.0s\n",
            "[CV 3/3] END criterion=gini, max_depth=8, max_features=5, min_samples_leaf=2, splitter=best;, score=0.922 total time=   1.0s\n",
            "[CV 1/3] END criterion=gini, max_depth=8, max_features=3, min_samples_leaf=3, splitter=best;, score=0.835 total time=   0.6s\n",
            "[CV 2/3] END criterion=gini, max_depth=8, max_features=3, min_samples_leaf=3, splitter=best;, score=0.853 total time=   0.6s\n",
            "[CV 3/3] END criterion=gini, max_depth=8, max_features=3, min_samples_leaf=3, splitter=best;, score=0.872 total time=   0.6s\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "{'splitter': 'best',\n",
              " 'min_samples_leaf': 3,\n",
              " 'max_features': 4,\n",
              " 'max_depth': None,\n",
              " 'criterion': 'log_loss'}"
            ]
          },
          "execution_count": 53,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# RandomizedSearchCV\n",
        "\n",
        "max_depth = [1, 3, 5, 8, 10, 15]\n",
        "max_depth.append(None)\n",
        "\n",
        "random_grid = {\n",
        "              \"max_depth\": max_depth,\n",
        "              \"max_features\": [int(x) for x in np.linspace(1, len(X_train.columns), num = len(X_train.columns))],\n",
        "              \"min_samples_leaf\": [int(x) for x in np.linspace(1, len(X_train.columns), num = len(X_train.columns))],\n",
        "              \"criterion\": [\"gini\", \"entropy\", \"log_loss\"],\n",
        "              \"splitter\": [\"random\", \"best\"]\n",
        "              }\n",
        "\n",
        "tree_random = RandomizedSearchCV(estimator = tree_clf, \n",
        "                                 param_distributions = random_grid, \n",
        "                                 n_iter = 100, \n",
        "                                 cv = 3, \n",
        "                                 verbose = 3, \n",
        "                                 scoring = 'recall',\n",
        "                                 random_state = 10)\n",
        "\n",
        "tree_random.fit(X_train, y_train)\n",
        "tree_random.best_params_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2vMPck5n8EAi",
        "outputId": "124043eb-9467-4084-d6ad-877cf7aa34fe"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'splitter': 'best',\n",
              " 'min_samples_leaf': 3,\n",
              " 'max_features': 4,\n",
              " 'max_depth': None,\n",
              " 'criterion': 'log_loss'}"
            ]
          },
          "execution_count": 54,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tree_random.best_params_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7XhQr9Cc8EuF",
        "outputId": "c96fd504-3a2a-4a6e-c80e-99fe7a98a579"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.988102664047578"
            ]
          },
          "execution_count": 55,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tree_random.best_score_"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e5dbRikwt1ov"
      },
      "source": [
        "## Random Forest Classifier\n",
        "\n",
        "- Library: Scikit-learn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GuRwiYIX8Giw"
      },
      "outputs": [],
      "source": [
        "# Training\n",
        "\n",
        "name = 'rnd_clf'\n",
        "\n",
        "train = pd.DataFrame(columns = ['n_estimators', 'min_samples_split', 'min_samples_leaf', 'max_features','max_depth', 'n_jobs', 'random_state'])\n",
        "train = train.append({'n_estimators' : 100, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'auto', 'max_depth' : None, 'n_jobs': -1, 'random_state': 10}, ignore_index=True)\n",
        "train = train.append({'n_estimators' : 300, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_features': 'auto', 'max_depth' : 31, 'n_jobs': -1, 'random_state': 10}, ignore_index=True)\n",
        "train = train.append({'n_estimators' : 300, 'min_samples_split': 3, 'min_samples_leaf': 1, 'max_features': 'auto', 'max_depth' : None, 'n_jobs': -1, 'random_state': 10}, ignore_index=True)\n",
        "\n",
        "train = train.reset_index()\n",
        "for index, row in train.iterrows():\n",
        "    model_name = name + str(index)\n",
        "    rnd_clf = RandomForestClassifier(n_estimators = int(row['n_estimators']), max_depth = None, \n",
        "                                    n_jobs = int(row['n_jobs']), random_state = int(row['random_state']))\n",
        "    rnd_clf.fit(X_train, y_train)\n",
        "    \n",
        "    y_true = y_val\n",
        "    y_pred = rnd_clf.predict(X_val)\n",
        "    evaluation_results = evaluation_metrics(y_true, y_pred)\n",
        "\n",
        "    models = models.append({'model_name': model_name, \n",
        "                            'model': rnd_clf, \n",
        "                            'parameters': rnd_clf.get_params()}, \n",
        "                            ignore_index=True)\n",
        "    \n",
        "    models_eval = models_eval.append({'model_name': model_name, \n",
        "                                      'confusion_matrix' : evaluation_results[0], \n",
        "                                      'accuracy': evaluation_results[1], \n",
        "                                      'recall' : evaluation_results[2], \n",
        "                                      'f1_score': evaluation_results[3], \n",
        "                                      'roc_auc_score': evaluation_results[4]}, \n",
        "                                      ignore_index=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 864
        },
        "id": "8-QVWDIU8Hhy",
        "outputId": "d28c674a-6680-4ab0-c083-10d6397a1dc2"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-31e1449c-f5ef-498d-91d8-a470f36cecf3\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>model_name</th>\n",
              "      <th>confusion_matrix</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>recall</th>\n",
              "      <th>f1_score</th>\n",
              "      <th>roc_auc_score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>log_clf0</td>\n",
              "      <td>[10551, 6517, 38, 84]</td>\n",
              "      <td>0.618674</td>\n",
              "      <td>0.688525</td>\n",
              "      <td>0.024989</td>\n",
              "      <td>0.653349</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>log_clf1</td>\n",
              "      <td>[10551, 6517, 39, 83]</td>\n",
              "      <td>0.618615</td>\n",
              "      <td>0.680328</td>\n",
              "      <td>0.024695</td>\n",
              "      <td>0.649251</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>svc_clf0</td>\n",
              "      <td>[12395, 4673, 25, 97]</td>\n",
              "      <td>0.726702</td>\n",
              "      <td>0.795082</td>\n",
              "      <td>0.039657</td>\n",
              "      <td>0.760647</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>svc_clf1</td>\n",
              "      <td>[10750, 6318, 19, 103]</td>\n",
              "      <td>0.631355</td>\n",
              "      <td>0.844262</td>\n",
              "      <td>0.031484</td>\n",
              "      <td>0.737048</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>svc_clf2</td>\n",
              "      <td>[7181, 9887, 38, 84]</td>\n",
              "      <td>0.422629</td>\n",
              "      <td>0.688525</td>\n",
              "      <td>0.016645</td>\n",
              "      <td>0.554627</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>svc_clf3</td>\n",
              "      <td>[14126, 2942, 22, 100]</td>\n",
              "      <td>0.827574</td>\n",
              "      <td>0.819672</td>\n",
              "      <td>0.063211</td>\n",
              "      <td>0.823651</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>svc_clf4</td>\n",
              "      <td>[14240, 2828, 23, 99]</td>\n",
              "      <td>0.834148</td>\n",
              "      <td>0.811475</td>\n",
              "      <td>0.064939</td>\n",
              "      <td>0.822893</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>svc_clf5</td>\n",
              "      <td>[14296, 2772, 24, 98]</td>\n",
              "      <td>0.837347</td>\n",
              "      <td>0.803279</td>\n",
              "      <td>0.065508</td>\n",
              "      <td>0.820435</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>svc_clf6</td>\n",
              "      <td>[14335, 2733, 22, 100]</td>\n",
              "      <td>0.839732</td>\n",
              "      <td>0.819672</td>\n",
              "      <td>0.067682</td>\n",
              "      <td>0.829774</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>bayes_clf0</td>\n",
              "      <td>[8297, 8771, 40, 82]</td>\n",
              "      <td>0.487435</td>\n",
              "      <td>0.672131</td>\n",
              "      <td>0.018273</td>\n",
              "      <td>0.579123</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>bayes_clf1</td>\n",
              "      <td>[9041, 8027, 25, 97]</td>\n",
              "      <td>0.531588</td>\n",
              "      <td>0.795082</td>\n",
              "      <td>0.023527</td>\n",
              "      <td>0.662393</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>bayes_clf2</td>\n",
              "      <td>[10242, 6826, 39, 83]</td>\n",
              "      <td>0.600640</td>\n",
              "      <td>0.680328</td>\n",
              "      <td>0.023610</td>\n",
              "      <td>0.640199</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>bayes_clf3</td>\n",
              "      <td>[10323, 6745, 39, 83]</td>\n",
              "      <td>0.605352</td>\n",
              "      <td>0.680328</td>\n",
              "      <td>0.023885</td>\n",
              "      <td>0.642572</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>bayes_clf4</td>\n",
              "      <td>[10324, 6744, 39, 83]</td>\n",
              "      <td>0.605410</td>\n",
              "      <td>0.680328</td>\n",
              "      <td>0.023888</td>\n",
              "      <td>0.642601</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>bayes_clf5</td>\n",
              "      <td>[10324, 6744, 39, 83]</td>\n",
              "      <td>0.605410</td>\n",
              "      <td>0.680328</td>\n",
              "      <td>0.023888</td>\n",
              "      <td>0.642601</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>bayes_clf6</td>\n",
              "      <td>[10324, 6744, 39, 83]</td>\n",
              "      <td>0.605410</td>\n",
              "      <td>0.680328</td>\n",
              "      <td>0.023888</td>\n",
              "      <td>0.642601</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>neigh_clf0</td>\n",
              "      <td>[16733, 335, 30, 92]</td>\n",
              "      <td>0.978767</td>\n",
              "      <td>0.754098</td>\n",
              "      <td>0.335155</td>\n",
              "      <td>0.867235</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>neigh_clf1</td>\n",
              "      <td>[16916, 152, 43, 79]</td>\n",
              "      <td>0.988656</td>\n",
              "      <td>0.647541</td>\n",
              "      <td>0.447592</td>\n",
              "      <td>0.819318</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>neigh_clf2</td>\n",
              "      <td>[16334, 734, 22, 100]</td>\n",
              "      <td>0.956021</td>\n",
              "      <td>0.819672</td>\n",
              "      <td>0.209205</td>\n",
              "      <td>0.888334</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>tree_clf0</td>\n",
              "      <td>[16936, 132, 23, 99]</td>\n",
              "      <td>0.990983</td>\n",
              "      <td>0.811475</td>\n",
              "      <td>0.560907</td>\n",
              "      <td>0.901871</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>tree_clf1</td>\n",
              "      <td>[16942, 126, 20, 102]</td>\n",
              "      <td>0.991507</td>\n",
              "      <td>0.836066</td>\n",
              "      <td>0.582857</td>\n",
              "      <td>0.914342</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>tree_clf2</td>\n",
              "      <td>[16931, 137, 25, 97]</td>\n",
              "      <td>0.990576</td>\n",
              "      <td>0.795082</td>\n",
              "      <td>0.544944</td>\n",
              "      <td>0.893528</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>tree_clf3</td>\n",
              "      <td>[16884, 184, 25, 97]</td>\n",
              "      <td>0.987842</td>\n",
              "      <td>0.795082</td>\n",
              "      <td>0.481390</td>\n",
              "      <td>0.892151</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>rnd_clf0</td>\n",
              "      <td>[17015, 53, 22, 100]</td>\n",
              "      <td>0.995637</td>\n",
              "      <td>0.819672</td>\n",
              "      <td>0.727273</td>\n",
              "      <td>0.908283</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>rnd_clf1</td>\n",
              "      <td>[17014, 54, 23, 99]</td>\n",
              "      <td>0.995521</td>\n",
              "      <td>0.811475</td>\n",
              "      <td>0.720000</td>\n",
              "      <td>0.904156</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>rnd_clf2</td>\n",
              "      <td>[17014, 54, 23, 99]</td>\n",
              "      <td>0.995521</td>\n",
              "      <td>0.811475</td>\n",
              "      <td>0.720000</td>\n",
              "      <td>0.904156</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-31e1449c-f5ef-498d-91d8-a470f36cecf3')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-31e1449c-f5ef-498d-91d8-a470f36cecf3 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-31e1449c-f5ef-498d-91d8-a470f36cecf3');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "    model_name        confusion_matrix  accuracy    recall  f1_score  \\\n",
              "0     log_clf0   [10551, 6517, 38, 84]  0.618674  0.688525  0.024989   \n",
              "1     log_clf1   [10551, 6517, 39, 83]  0.618615  0.680328  0.024695   \n",
              "2     svc_clf0   [12395, 4673, 25, 97]  0.726702  0.795082  0.039657   \n",
              "3     svc_clf1  [10750, 6318, 19, 103]  0.631355  0.844262  0.031484   \n",
              "4     svc_clf2    [7181, 9887, 38, 84]  0.422629  0.688525  0.016645   \n",
              "5     svc_clf3  [14126, 2942, 22, 100]  0.827574  0.819672  0.063211   \n",
              "6     svc_clf4   [14240, 2828, 23, 99]  0.834148  0.811475  0.064939   \n",
              "7     svc_clf5   [14296, 2772, 24, 98]  0.837347  0.803279  0.065508   \n",
              "8     svc_clf6  [14335, 2733, 22, 100]  0.839732  0.819672  0.067682   \n",
              "9   bayes_clf0    [8297, 8771, 40, 82]  0.487435  0.672131  0.018273   \n",
              "10  bayes_clf1    [9041, 8027, 25, 97]  0.531588  0.795082  0.023527   \n",
              "11  bayes_clf2   [10242, 6826, 39, 83]  0.600640  0.680328  0.023610   \n",
              "12  bayes_clf3   [10323, 6745, 39, 83]  0.605352  0.680328  0.023885   \n",
              "13  bayes_clf4   [10324, 6744, 39, 83]  0.605410  0.680328  0.023888   \n",
              "14  bayes_clf5   [10324, 6744, 39, 83]  0.605410  0.680328  0.023888   \n",
              "15  bayes_clf6   [10324, 6744, 39, 83]  0.605410  0.680328  0.023888   \n",
              "16  neigh_clf0    [16733, 335, 30, 92]  0.978767  0.754098  0.335155   \n",
              "17  neigh_clf1    [16916, 152, 43, 79]  0.988656  0.647541  0.447592   \n",
              "18  neigh_clf2   [16334, 734, 22, 100]  0.956021  0.819672  0.209205   \n",
              "19   tree_clf0    [16936, 132, 23, 99]  0.990983  0.811475  0.560907   \n",
              "20   tree_clf1   [16942, 126, 20, 102]  0.991507  0.836066  0.582857   \n",
              "21   tree_clf2    [16931, 137, 25, 97]  0.990576  0.795082  0.544944   \n",
              "22   tree_clf3    [16884, 184, 25, 97]  0.987842  0.795082  0.481390   \n",
              "23    rnd_clf0    [17015, 53, 22, 100]  0.995637  0.819672  0.727273   \n",
              "24    rnd_clf1     [17014, 54, 23, 99]  0.995521  0.811475  0.720000   \n",
              "25    rnd_clf2     [17014, 54, 23, 99]  0.995521  0.811475  0.720000   \n",
              "\n",
              "    roc_auc_score  \n",
              "0        0.653349  \n",
              "1        0.649251  \n",
              "2        0.760647  \n",
              "3        0.737048  \n",
              "4        0.554627  \n",
              "5        0.823651  \n",
              "6        0.822893  \n",
              "7        0.820435  \n",
              "8        0.829774  \n",
              "9        0.579123  \n",
              "10       0.662393  \n",
              "11       0.640199  \n",
              "12       0.642572  \n",
              "13       0.642601  \n",
              "14       0.642601  \n",
              "15       0.642601  \n",
              "16       0.867235  \n",
              "17       0.819318  \n",
              "18       0.888334  \n",
              "19       0.901871  \n",
              "20       0.914342  \n",
              "21       0.893528  \n",
              "22       0.892151  \n",
              "23       0.908283  \n",
              "24       0.904156  \n",
              "25       0.904156  "
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "display(models_eval)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IhoNEKJN8JSz",
        "outputId": "bfb8d139-995e-4a0c-9170-048cd2182578"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fitting 3 folds for each of 50 candidates, totalling 150 fits\n",
            "[CV 1/3] END max_depth=8, max_features=1, min_samples_leaf=1, min_samples_split=6, n_estimators=500;, score=0.856 total time= 1.6min\n",
            "[CV 2/3] END max_depth=8, max_features=1, min_samples_leaf=1, min_samples_split=6, n_estimators=500;, score=0.851 total time= 1.6min\n",
            "[CV 3/3] END max_depth=8, max_features=1, min_samples_leaf=1, min_samples_split=6, n_estimators=500;, score=0.864 total time= 1.6min\n",
            "[CV 1/3] END max_depth=10, max_features=2, min_samples_leaf=1, min_samples_split=3, n_estimators=300;, score=0.929 total time= 1.7min\n",
            "[CV 2/3] END max_depth=10, max_features=2, min_samples_leaf=1, min_samples_split=3, n_estimators=300;, score=0.925 total time= 1.7min\n",
            "[CV 3/3] END max_depth=10, max_features=2, min_samples_leaf=1, min_samples_split=3, n_estimators=300;, score=0.926 total time= 1.8min\n",
            "[CV 1/3] END max_depth=15, max_features=3, min_samples_leaf=1, min_samples_split=10, n_estimators=300;, score=0.989 total time= 3.1min\n",
            "[CV 2/3] END max_depth=15, max_features=3, min_samples_leaf=1, min_samples_split=10, n_estimators=300;, score=0.988 total time= 3.0min\n",
            "[CV 3/3] END max_depth=15, max_features=3, min_samples_leaf=1, min_samples_split=10, n_estimators=300;, score=0.990 total time= 3.0min\n",
            "[CV 1/3] END max_depth=5, max_features=4, min_samples_leaf=1, min_samples_split=2, n_estimators=200;, score=0.807 total time= 1.2min\n",
            "[CV 2/3] END max_depth=5, max_features=4, min_samples_leaf=1, min_samples_split=2, n_estimators=200;, score=0.798 total time= 1.3min\n",
            "[CV 3/3] END max_depth=5, max_features=4, min_samples_leaf=1, min_samples_split=2, n_estimators=200;, score=0.804 total time= 1.2min\n",
            "[CV 1/3] END max_depth=8, max_features=6, min_samples_leaf=2, min_samples_split=6, n_estimators=300;, score=0.906 total time= 3.8min\n",
            "[CV 2/3] END max_depth=8, max_features=6, min_samples_leaf=2, min_samples_split=6, n_estimators=300;, score=0.923 total time= 3.9min\n",
            "[CV 3/3] END max_depth=8, max_features=6, min_samples_leaf=2, min_samples_split=6, n_estimators=300;, score=0.917 total time= 4.0min\n",
            "[CV 1/3] END max_depth=3, max_features=5, min_samples_leaf=1, min_samples_split=5, n_estimators=500;, score=0.670 total time= 2.4min\n",
            "[CV 2/3] END max_depth=3, max_features=5, min_samples_leaf=1, min_samples_split=5, n_estimators=500;, score=0.666 total time= 2.4min\n",
            "[CV 3/3] END max_depth=3, max_features=5, min_samples_leaf=1, min_samples_split=5, n_estimators=500;, score=0.672 total time= 2.4min\n",
            "[CV 1/3] END max_depth=1, max_features=5, min_samples_leaf=4, min_samples_split=10, n_estimators=300;, score=0.578 total time=  33.7s\n",
            "[CV 2/3] END max_depth=1, max_features=5, min_samples_leaf=4, min_samples_split=10, n_estimators=300;, score=0.575 total time=  33.8s\n",
            "[CV 3/3] END max_depth=1, max_features=5, min_samples_leaf=4, min_samples_split=10, n_estimators=300;, score=0.579 total time=  34.0s\n",
            "[CV 1/3] END max_depth=8, max_features=2, min_samples_leaf=2, min_samples_split=3, n_estimators=100;, score=0.883 total time=  29.8s\n",
            "[CV 2/3] END max_depth=8, max_features=2, min_samples_leaf=2, min_samples_split=3, n_estimators=100;, score=0.882 total time=  30.0s\n",
            "[CV 3/3] END max_depth=8, max_features=2, min_samples_leaf=2, min_samples_split=3, n_estimators=100;, score=0.884 total time=  28.9s\n",
            "[CV 1/3] END max_depth=1, max_features=1, min_samples_leaf=2, min_samples_split=2, n_estimators=100;, score=0.610 total time=   5.6s\n",
            "[CV 2/3] END max_depth=1, max_features=1, min_samples_leaf=2, min_samples_split=2, n_estimators=100;, score=0.605 total time=   4.3s\n",
            "[CV 3/3] END max_depth=1, max_features=1, min_samples_leaf=2, min_samples_split=2, n_estimators=100;, score=0.610 total time=   5.4s\n",
            "[CV 1/3] END max_depth=1, max_features=6, min_samples_leaf=2, min_samples_split=2, n_estimators=500;, score=0.578 total time= 1.1min\n",
            "[CV 2/3] END max_depth=1, max_features=6, min_samples_leaf=2, min_samples_split=2, n_estimators=500;, score=0.575 total time= 1.1min\n",
            "[CV 3/3] END max_depth=1, max_features=6, min_samples_leaf=2, min_samples_split=2, n_estimators=500;, score=0.579 total time= 1.1min\n",
            "[CV 1/3] END max_depth=5, max_features=6, min_samples_leaf=1, min_samples_split=5, n_estimators=200;, score=0.762 total time= 1.7min\n",
            "[CV 2/3] END max_depth=5, max_features=6, min_samples_leaf=1, min_samples_split=5, n_estimators=200;, score=0.774 total time= 1.7min\n",
            "[CV 3/3] END max_depth=5, max_features=6, min_samples_leaf=1, min_samples_split=5, n_estimators=200;, score=0.758 total time= 1.8min\n",
            "[CV 1/3] END max_depth=1, max_features=1, min_samples_leaf=4, min_samples_split=3, n_estimators=200;, score=0.610 total time=  10.5s\n",
            "[CV 2/3] END max_depth=1, max_features=1, min_samples_leaf=4, min_samples_split=3, n_estimators=200;, score=0.604 total time=  11.7s\n",
            "[CV 3/3] END max_depth=1, max_features=1, min_samples_leaf=4, min_samples_split=3, n_estimators=200;, score=0.610 total time=   9.0s\n",
            "[CV 1/3] END max_depth=8, max_features=5, min_samples_leaf=2, min_samples_split=3, n_estimators=400;, score=0.900 total time= 4.6min\n",
            "[CV 2/3] END max_depth=8, max_features=5, min_samples_leaf=2, min_samples_split=3, n_estimators=400;, score=0.912 total time= 4.3min\n",
            "[CV 3/3] END max_depth=8, max_features=5, min_samples_leaf=2, min_samples_split=3, n_estimators=400;, score=0.910 total time= 4.3min\n",
            "[CV 1/3] END max_depth=8, max_features=2, min_samples_leaf=4, min_samples_split=2, n_estimators=200;, score=0.885 total time= 1.0min\n",
            "[CV 2/3] END max_depth=8, max_features=2, min_samples_leaf=4, min_samples_split=2, n_estimators=200;, score=0.883 total time= 1.1min\n",
            "[CV 3/3] END max_depth=8, max_features=2, min_samples_leaf=4, min_samples_split=2, n_estimators=200;, score=0.884 total time= 1.1min\n",
            "[CV 1/3] END max_depth=10, max_features=5, min_samples_leaf=1, min_samples_split=3, n_estimators=400;, score=0.953 total time= 5.2min\n",
            "[CV 2/3] END max_depth=10, max_features=5, min_samples_leaf=1, min_samples_split=3, n_estimators=400;, score=0.957 total time= 5.2min\n",
            "[CV 3/3] END max_depth=10, max_features=5, min_samples_leaf=1, min_samples_split=3, n_estimators=400;, score=0.955 total time= 5.1min\n",
            "[CV 1/3] END max_depth=15, max_features=1, min_samples_leaf=1, min_samples_split=2, n_estimators=200;, score=0.980 total time=  52.6s\n",
            "[CV 2/3] END max_depth=15, max_features=1, min_samples_leaf=1, min_samples_split=2, n_estimators=200;, score=0.977 total time=  56.8s\n",
            "[CV 3/3] END max_depth=15, max_features=1, min_samples_leaf=1, min_samples_split=2, n_estimators=200;, score=0.981 total time=  54.1s\n",
            "[CV 1/3] END max_depth=15, max_features=6, min_samples_leaf=2, min_samples_split=10, n_estimators=200;, score=0.987 total time= 3.7min\n",
            "[CV 2/3] END max_depth=15, max_features=6, min_samples_leaf=2, min_samples_split=10, n_estimators=200;, score=0.983 total time= 3.6min\n",
            "[CV 3/3] END max_depth=15, max_features=6, min_samples_leaf=2, min_samples_split=10, n_estimators=200;, score=0.986 total time= 3.4min\n",
            "[CV 1/3] END max_depth=None, max_features=5, min_samples_leaf=2, min_samples_split=10, n_estimators=500;, score=0.995 total time= 7.7min\n",
            "[CV 2/3] END max_depth=None, max_features=5, min_samples_leaf=2, min_samples_split=10, n_estimators=500;, score=0.995 total time= 7.7min\n",
            "[CV 3/3] END max_depth=None, max_features=5, min_samples_leaf=2, min_samples_split=10, n_estimators=500;, score=0.995 total time= 7.9min\n",
            "[CV 1/3] END max_depth=None, max_features=5, min_samples_leaf=1, min_samples_split=5, n_estimators=300;, score=0.996 total time= 4.7min\n",
            "[CV 2/3] END max_depth=None, max_features=5, min_samples_leaf=1, min_samples_split=5, n_estimators=300;, score=0.995 total time= 4.7min\n",
            "[CV 3/3] END max_depth=None, max_features=5, min_samples_leaf=1, min_samples_split=5, n_estimators=300;, score=0.996 total time= 4.7min\n",
            "[CV 1/3] END max_depth=8, max_features=6, min_samples_leaf=1, min_samples_split=6, n_estimators=200;, score=0.907 total time= 2.2min\n",
            "[CV 2/3] END max_depth=8, max_features=6, min_samples_leaf=1, min_samples_split=6, n_estimators=200;, score=0.924 total time= 2.2min\n",
            "[CV 3/3] END max_depth=8, max_features=6, min_samples_leaf=1, min_samples_split=6, n_estimators=200;, score=0.917 total time= 2.2min\n",
            "[CV 1/3] END max_depth=5, max_features=1, min_samples_leaf=4, min_samples_split=10, n_estimators=100;, score=0.766 total time=  12.4s\n",
            "[CV 2/3] END max_depth=5, max_features=1, min_samples_leaf=4, min_samples_split=10, n_estimators=100;, score=0.760 total time=  11.0s\n",
            "[CV 3/3] END max_depth=5, max_features=1, min_samples_leaf=4, min_samples_split=10, n_estimators=100;, score=0.770 total time=  13.2s\n",
            "[CV 1/3] END max_depth=3, max_features=2, min_samples_leaf=4, min_samples_split=2, n_estimators=500;, score=0.684 total time= 1.1min\n",
            "[CV 2/3] END max_depth=3, max_features=2, min_samples_leaf=4, min_samples_split=2, n_estimators=500;, score=0.684 total time= 1.1min\n",
            "[CV 3/3] END max_depth=3, max_features=2, min_samples_leaf=4, min_samples_split=2, n_estimators=500;, score=0.685 total time= 1.1min\n",
            "[CV 1/3] END max_depth=10, max_features=4, min_samples_leaf=1, min_samples_split=5, n_estimators=100;, score=0.952 total time=  53.1s\n",
            "[CV 2/3] END max_depth=10, max_features=4, min_samples_leaf=1, min_samples_split=5, n_estimators=100;, score=0.956 total time=  54.0s\n",
            "[CV 3/3] END max_depth=10, max_features=4, min_samples_leaf=1, min_samples_split=5, n_estimators=100;, score=0.954 total time=  55.1s\n",
            "[CV 1/3] END max_depth=15, max_features=2, min_samples_leaf=2, min_samples_split=10, n_estimators=500;, score=0.986 total time= 3.1min\n",
            "[CV 2/3] END max_depth=15, max_features=2, min_samples_leaf=2, min_samples_split=10, n_estimators=500;, score=0.985 total time= 3.2min\n",
            "[CV 3/3] END max_depth=15, max_features=2, min_samples_leaf=2, min_samples_split=10, n_estimators=500;, score=0.988 total time= 3.2min\n",
            "[CV 1/3] END max_depth=None, max_features=2, min_samples_leaf=1, min_samples_split=6, n_estimators=300;, score=0.997 total time= 2.2min\n",
            "[CV 2/3] END max_depth=None, max_features=2, min_samples_leaf=1, min_samples_split=6, n_estimators=300;, score=0.996 total time= 2.2min\n",
            "[CV 3/3] END max_depth=None, max_features=2, min_samples_leaf=1, min_samples_split=6, n_estimators=300;, score=0.997 total time= 2.1min\n",
            "[CV 1/3] END max_depth=1, max_features=5, min_samples_leaf=1, min_samples_split=10, n_estimators=300;, score=0.578 total time=  33.1s\n",
            "[CV 2/3] END max_depth=1, max_features=5, min_samples_leaf=1, min_samples_split=10, n_estimators=300;, score=0.575 total time=  33.1s\n",
            "[CV 3/3] END max_depth=1, max_features=5, min_samples_leaf=1, min_samples_split=10, n_estimators=300;, score=0.579 total time=  33.2s\n",
            "[CV 1/3] END max_depth=5, max_features=1, min_samples_leaf=4, min_samples_split=5, n_estimators=500;, score=0.786 total time= 1.1min\n",
            "[CV 2/3] END max_depth=5, max_features=1, min_samples_leaf=4, min_samples_split=5, n_estimators=500;, score=0.783 total time= 1.1min\n",
            "[CV 3/3] END max_depth=5, max_features=1, min_samples_leaf=4, min_samples_split=5, n_estimators=500;, score=0.790 total time= 1.1min\n",
            "[CV 1/3] END max_depth=5, max_features=6, min_samples_leaf=2, min_samples_split=10, n_estimators=100;, score=0.762 total time=  48.0s\n",
            "[CV 2/3] END max_depth=5, max_features=6, min_samples_leaf=2, min_samples_split=10, n_estimators=100;, score=0.772 total time=  47.7s\n",
            "[CV 3/3] END max_depth=5, max_features=6, min_samples_leaf=2, min_samples_split=10, n_estimators=100;, score=0.757 total time=  47.4s\n",
            "[CV 1/3] END max_depth=8, max_features=4, min_samples_leaf=2, min_samples_split=2, n_estimators=300;, score=0.900 total time= 2.4min\n",
            "[CV 2/3] END max_depth=8, max_features=4, min_samples_leaf=2, min_samples_split=2, n_estimators=300;, score=0.904 total time= 2.4min\n",
            "[CV 3/3] END max_depth=8, max_features=4, min_samples_leaf=2, min_samples_split=2, n_estimators=300;, score=0.907 total time= 2.4min\n",
            "[CV 1/3] END max_depth=None, max_features=2, min_samples_leaf=4, min_samples_split=5, n_estimators=300;, score=0.996 total time= 2.5min\n",
            "[CV 2/3] END max_depth=None, max_features=2, min_samples_leaf=4, min_samples_split=5, n_estimators=300;, score=0.995 total time= 2.1min\n",
            "[CV 3/3] END max_depth=None, max_features=2, min_samples_leaf=4, min_samples_split=5, n_estimators=300;, score=0.996 total time= 2.2min\n",
            "[CV 1/3] END max_depth=None, max_features=5, min_samples_leaf=2, min_samples_split=3, n_estimators=200;, score=0.996 total time= 3.2min\n",
            "[CV 2/3] END max_depth=None, max_features=5, min_samples_leaf=2, min_samples_split=3, n_estimators=200;, score=0.995 total time= 3.2min\n",
            "[CV 3/3] END max_depth=None, max_features=5, min_samples_leaf=2, min_samples_split=3, n_estimators=200;, score=0.996 total time= 3.2min\n",
            "[CV 1/3] END max_depth=8, max_features=5, min_samples_leaf=2, min_samples_split=10, n_estimators=100;, score=0.902 total time= 1.0min\n",
            "[CV 2/3] END max_depth=8, max_features=5, min_samples_leaf=2, min_samples_split=10, n_estimators=100;, score=0.911 total time=  59.0s\n",
            "[CV 3/3] END max_depth=8, max_features=5, min_samples_leaf=2, min_samples_split=10, n_estimators=100;, score=0.910 total time=  58.9s\n",
            "[CV 1/3] END max_depth=1, max_features=1, min_samples_leaf=1, min_samples_split=6, n_estimators=300;, score=0.636 total time=  15.0s\n",
            "[CV 2/3] END max_depth=1, max_features=1, min_samples_leaf=1, min_samples_split=6, n_estimators=300;, score=0.631 total time=  14.6s\n",
            "[CV 3/3] END max_depth=1, max_features=1, min_samples_leaf=1, min_samples_split=6, n_estimators=300;, score=0.635 total time=  14.5s\n",
            "[CV 1/3] END max_depth=5, max_features=6, min_samples_leaf=2, min_samples_split=10, n_estimators=400;, score=0.762 total time= 3.1min\n",
            "[CV 2/3] END max_depth=5, max_features=6, min_samples_leaf=2, min_samples_split=10, n_estimators=400;, score=0.775 total time= 3.1min\n",
            "[CV 3/3] END max_depth=5, max_features=6, min_samples_leaf=2, min_samples_split=10, n_estimators=400;, score=0.758 total time= 3.1min\n",
            "[CV 1/3] END max_depth=1, max_features=5, min_samples_leaf=2, min_samples_split=3, n_estimators=100;, score=0.578 total time=  12.1s\n",
            "[CV 2/3] END max_depth=1, max_features=5, min_samples_leaf=2, min_samples_split=3, n_estimators=100;, score=0.575 total time=   9.1s\n",
            "[CV 3/3] END max_depth=1, max_features=5, min_samples_leaf=2, min_samples_split=3, n_estimators=100;, score=0.579 total time=  12.6s\n",
            "[CV 1/3] END max_depth=5, max_features=4, min_samples_leaf=2, min_samples_split=3, n_estimators=200;, score=0.807 total time= 1.1min\n",
            "[CV 2/3] END max_depth=5, max_features=4, min_samples_leaf=2, min_samples_split=3, n_estimators=200;, score=0.798 total time= 1.2min\n",
            "[CV 3/3] END max_depth=5, max_features=4, min_samples_leaf=2, min_samples_split=3, n_estimators=200;, score=0.804 total time= 1.2min\n",
            "[CV 1/3] END max_depth=8, max_features=6, min_samples_leaf=4, min_samples_split=6, n_estimators=100;, score=0.909 total time= 1.2min\n",
            "[CV 2/3] END max_depth=8, max_features=6, min_samples_leaf=4, min_samples_split=6, n_estimators=100;, score=0.924 total time= 1.2min\n",
            "[CV 3/3] END max_depth=8, max_features=6, min_samples_leaf=4, min_samples_split=6, n_estimators=100;, score=0.917 total time= 1.2min\n",
            "[CV 1/3] END max_depth=15, max_features=3, min_samples_leaf=2, min_samples_split=2, n_estimators=200;, score=0.989 total time= 1.8min\n",
            "[CV 2/3] END max_depth=15, max_features=3, min_samples_leaf=2, min_samples_split=2, n_estimators=200;, score=0.988 total time= 1.7min\n",
            "[CV 3/3] END max_depth=15, max_features=3, min_samples_leaf=2, min_samples_split=2, n_estimators=200;, score=0.991 total time= 1.8min\n",
            "[CV 1/3] END max_depth=10, max_features=4, min_samples_leaf=4, min_samples_split=2, n_estimators=100;, score=0.949 total time=  55.0s\n",
            "[CV 2/3] END max_depth=10, max_features=4, min_samples_leaf=4, min_samples_split=2, n_estimators=100;, score=0.953 total time=  54.0s\n",
            "[CV 3/3] END max_depth=10, max_features=4, min_samples_leaf=4, min_samples_split=2, n_estimators=100;, score=0.956 total time=  57.2s\n",
            "[CV 1/3] END max_depth=10, max_features=6, min_samples_leaf=1, min_samples_split=10, n_estimators=100;, score=0.947 total time= 1.4min\n",
            "[CV 2/3] END max_depth=10, max_features=6, min_samples_leaf=1, min_samples_split=10, n_estimators=100;, score=0.946 total time= 1.5min\n",
            "[CV 3/3] END max_depth=10, max_features=6, min_samples_leaf=1, min_samples_split=10, n_estimators=100;, score=0.948 total time= 1.4min\n",
            "[CV 1/3] END max_depth=15, max_features=4, min_samples_leaf=1, min_samples_split=3, n_estimators=300;, score=0.990 total time= 3.6min\n",
            "[CV 2/3] END max_depth=15, max_features=4, min_samples_leaf=1, min_samples_split=3, n_estimators=300;, score=0.988 total time= 3.5min\n",
            "[CV 3/3] END max_depth=15, max_features=4, min_samples_leaf=1, min_samples_split=3, n_estimators=300;, score=0.991 total time= 3.5min\n",
            "[CV 1/3] END max_depth=10, max_features=5, min_samples_leaf=4, min_samples_split=10, n_estimators=300;, score=0.952 total time= 3.6min\n",
            "[CV 2/3] END max_depth=10, max_features=5, min_samples_leaf=4, min_samples_split=10, n_estimators=300;, score=0.956 total time= 3.4min\n",
            "[CV 3/3] END max_depth=10, max_features=5, min_samples_leaf=4, min_samples_split=10, n_estimators=300;, score=0.955 total time= 3.4min\n",
            "[CV 1/3] END max_depth=8, max_features=4, min_samples_leaf=2, min_samples_split=5, n_estimators=100;, score=0.901 total time=  48.6s\n",
            "[CV 2/3] END max_depth=8, max_features=4, min_samples_leaf=2, min_samples_split=5, n_estimators=100;, score=0.903 total time=  47.2s\n",
            "[CV 3/3] END max_depth=8, max_features=4, min_samples_leaf=2, min_samples_split=5, n_estimators=100;, score=0.907 total time=  47.2s\n",
            "[CV 1/3] END max_depth=5, max_features=5, min_samples_leaf=2, min_samples_split=5, n_estimators=100;, score=0.785 total time=  38.0s\n",
            "[CV 2/3] END max_depth=5, max_features=5, min_samples_leaf=2, min_samples_split=5, n_estimators=100;, score=0.770 total time=  39.6s\n",
            "[CV 3/3] END max_depth=5, max_features=5, min_samples_leaf=2, min_samples_split=5, n_estimators=100;, score=0.775 total time=  39.3s\n",
            "[CV 1/3] END max_depth=3, max_features=1, min_samples_leaf=2, min_samples_split=10, n_estimators=300;, score=0.733 total time=  25.7s\n",
            "[CV 2/3] END max_depth=3, max_features=1, min_samples_leaf=2, min_samples_split=10, n_estimators=300;, score=0.729 total time=  25.2s\n",
            "[CV 3/3] END max_depth=3, max_features=1, min_samples_leaf=2, min_samples_split=10, n_estimators=300;, score=0.738 total time=  26.5s\n",
            "[CV 1/3] END max_depth=5, max_features=2, min_samples_leaf=2, min_samples_split=5, n_estimators=100;, score=0.795 total time=  18.5s\n",
            "[CV 2/3] END max_depth=5, max_features=2, min_samples_leaf=2, min_samples_split=5, n_estimators=100;, score=0.793 total time=  18.5s\n",
            "[CV 3/3] END max_depth=5, max_features=2, min_samples_leaf=2, min_samples_split=5, n_estimators=100;, score=0.798 total time=  18.6s\n",
            "[CV 1/3] END max_depth=1, max_features=2, min_samples_leaf=2, min_samples_split=2, n_estimators=200;, score=0.572 total time=  13.2s\n",
            "[CV 2/3] END max_depth=1, max_features=2, min_samples_leaf=2, min_samples_split=2, n_estimators=200;, score=0.569 total time=  13.2s\n",
            "[CV 3/3] END max_depth=1, max_features=2, min_samples_leaf=2, min_samples_split=2, n_estimators=200;, score=0.573 total time=  11.5s\n",
            "[CV 1/3] END max_depth=15, max_features=6, min_samples_leaf=4, min_samples_split=5, n_estimators=300;, score=0.987 total time= 4.9min\n",
            "[CV 2/3] END max_depth=15, max_features=6, min_samples_leaf=4, min_samples_split=5, n_estimators=300;, score=0.983 total time= 4.9min\n",
            "[CV 3/3] END max_depth=15, max_features=6, min_samples_leaf=4, min_samples_split=5, n_estimators=300;, score=0.986 total time= 4.9min\n",
            "[CV 1/3] END max_depth=10, max_features=6, min_samples_leaf=1, min_samples_split=10, n_estimators=500;, score=0.946 total time= 6.5min\n",
            "[CV 2/3] END max_depth=10, max_features=6, min_samples_leaf=1, min_samples_split=10, n_estimators=500;, score=0.948 total time= 6.9min\n",
            "[CV 3/3] END max_depth=10, max_features=6, min_samples_leaf=1, min_samples_split=10, n_estimators=500;, score=0.949 total time= 6.7min\n",
            "[CV 1/3] END max_depth=15, max_features=2, min_samples_leaf=2, min_samples_split=5, n_estimators=400;, score=0.987 total time= 2.5min\n",
            "[CV 2/3] END max_depth=15, max_features=2, min_samples_leaf=2, min_samples_split=5, n_estimators=400;, score=0.986 total time= 2.5min\n",
            "[CV 3/3] END max_depth=15, max_features=2, min_samples_leaf=2, min_samples_split=5, n_estimators=400;, score=0.989 total time= 2.5min\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "{'n_estimators': 300,\n",
              " 'min_samples_split': 6,\n",
              " 'min_samples_leaf': 1,\n",
              " 'max_features': 2,\n",
              " 'max_depth': None}"
            ]
          },
          "execution_count": 58,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# RandomizedSearchCV\n",
        "\n",
        "# Number of trees in random forest\n",
        "n_estimators = [100, 200, 300, 400, 500]\n",
        "# Number of features to consider at every split\n",
        "max_features = [int(x) for x in np.linspace(1, len(X_train.columns), num = len(X_train.columns))]\n",
        "# Maximum number of levels in tree\n",
        "max_depth = [1, 3, 5, 8, 10, 15]\n",
        "max_depth.append(None)\n",
        "# Minimum number of samples required to split a node\n",
        "min_samples_split = [2, 3, 5, 6, 10]\n",
        "# Minimum number of samples required at each leaf node\n",
        "min_samples_leaf = [1, 2, 4]\n",
        "\n",
        "# Create the random grid\n",
        "random_grid = {\n",
        "               'n_estimators': n_estimators,\n",
        "               'max_features': max_features,\n",
        "               'max_depth': max_depth,\n",
        "               'min_samples_split': min_samples_split,\n",
        "               'min_samples_leaf': min_samples_leaf,\n",
        "              }\n",
        "\n",
        "rnd_random = RandomizedSearchCV(estimator = rnd_clf, \n",
        "                                param_distributions = random_grid, \n",
        "                                n_iter = 50, \n",
        "                                cv = 3, \n",
        "                                verbose = 3, \n",
        "                                scoring = 'recall',\n",
        "                                random_state = 10)\n",
        "\n",
        "rnd_random.fit(X_train, y_train)\n",
        "rnd_random.best_params_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9JdZxZ03KdPs",
        "outputId": "60e79d59-bc7c-46e0-998e-2ec8a536b1fa"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'n_estimators': 300,\n",
              " 'min_samples_split': 6,\n",
              " 'min_samples_leaf': 1,\n",
              " 'max_features': 2,\n",
              " 'max_depth': None}"
            ]
          },
          "execution_count": 59,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "rnd_random.best_params_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZAW2m9t_KeN3",
        "outputId": "a06a5bad-8e8a-45fd-aca6-4a9d68556b6c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.9967379463882539"
            ]
          },
          "execution_count": 60,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "rnd_random.best_score_"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-0VzXIIcuTah"
      },
      "source": [
        "## Gradient Boosting Classifier\n",
        "\n",
        "- Library: Scikit-learn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LLnnnelYKl_I"
      },
      "outputs": [],
      "source": [
        "# Training\n",
        "\n",
        "name = 'gboost_clf'\n",
        "\n",
        "train = pd.DataFrame(columns = ['n_estimators', 'learning_rate', 'max_depth', 'random_state'])\n",
        "train = train.append({'n_estimators': 100, 'learning_rate':0.1, 'max_depth':3, 'random_state':10}, ignore_index=True)\n",
        "train = train.append({'n_estimators': 500, 'learning_rate':0.5, 'max_depth':1, 'random_state':10}, ignore_index=True)\n",
        "train = train.append({'n_estimators': 50, 'learning_rate':0.01, 'max_depth':10, 'random_state':10}, ignore_index=True)\n",
        "\n",
        "train = train.reset_index()\n",
        "for index, row in train.iterrows():\n",
        "    model_name = name + str(index)\n",
        "    gboost_clf = GradientBoostingClassifier(n_estimators=int(row['n_estimators']), learning_rate=row['learning_rate'],\n",
        "                                            max_depth=int(row['max_depth']), random_state=int(row['random_state']))\n",
        "    gboost_clf.fit(X_train, y_train)\n",
        "   \n",
        "    y_true = y_val\n",
        "    y_pred = gboost_clf.predict(X_val)\n",
        "    evaluation_results = evaluation_metrics(y_true, y_pred)\n",
        "\n",
        "    models = models.append({'model_name': model_name, \n",
        "                            'model': gboost_clf, \n",
        "                            'parameters': gboost_clf.get_params()}, \n",
        "                            ignore_index=True)\n",
        "   \n",
        "    models_eval = models_eval.append({'model_name': model_name, \n",
        "                                      'confusion_matrix' : evaluation_results[0], \n",
        "                                      'accuracy': evaluation_results[1], \n",
        "                                      'recall' : evaluation_results[2], \n",
        "                                      'f1_score': evaluation_results[3], \n",
        "                                      'roc_auc_score': evaluation_results[4]}, \n",
        "                                      ignore_index=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 958
        },
        "id": "FdHGO8xUKm_P",
        "outputId": "d881afb5-6f62-4af5-a5dc-c88f963ac5e3"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-1af48fc9-fa5c-4d33-9fd5-995cde98b329\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>model_name</th>\n",
              "      <th>confusion_matrix</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>recall</th>\n",
              "      <th>f1_score</th>\n",
              "      <th>roc_auc_score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>log_clf0</td>\n",
              "      <td>[10551, 6517, 38, 84]</td>\n",
              "      <td>0.618674</td>\n",
              "      <td>0.688525</td>\n",
              "      <td>0.024989</td>\n",
              "      <td>0.653349</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>log_clf1</td>\n",
              "      <td>[10551, 6517, 39, 83]</td>\n",
              "      <td>0.618615</td>\n",
              "      <td>0.680328</td>\n",
              "      <td>0.024695</td>\n",
              "      <td>0.649251</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>svc_clf0</td>\n",
              "      <td>[12395, 4673, 25, 97]</td>\n",
              "      <td>0.726702</td>\n",
              "      <td>0.795082</td>\n",
              "      <td>0.039657</td>\n",
              "      <td>0.760647</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>svc_clf1</td>\n",
              "      <td>[10750, 6318, 19, 103]</td>\n",
              "      <td>0.631355</td>\n",
              "      <td>0.844262</td>\n",
              "      <td>0.031484</td>\n",
              "      <td>0.737048</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>svc_clf2</td>\n",
              "      <td>[7181, 9887, 38, 84]</td>\n",
              "      <td>0.422629</td>\n",
              "      <td>0.688525</td>\n",
              "      <td>0.016645</td>\n",
              "      <td>0.554627</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>svc_clf3</td>\n",
              "      <td>[14126, 2942, 22, 100]</td>\n",
              "      <td>0.827574</td>\n",
              "      <td>0.819672</td>\n",
              "      <td>0.063211</td>\n",
              "      <td>0.823651</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>svc_clf4</td>\n",
              "      <td>[14240, 2828, 23, 99]</td>\n",
              "      <td>0.834148</td>\n",
              "      <td>0.811475</td>\n",
              "      <td>0.064939</td>\n",
              "      <td>0.822893</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>svc_clf5</td>\n",
              "      <td>[14296, 2772, 24, 98]</td>\n",
              "      <td>0.837347</td>\n",
              "      <td>0.803279</td>\n",
              "      <td>0.065508</td>\n",
              "      <td>0.820435</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>svc_clf6</td>\n",
              "      <td>[14335, 2733, 22, 100]</td>\n",
              "      <td>0.839732</td>\n",
              "      <td>0.819672</td>\n",
              "      <td>0.067682</td>\n",
              "      <td>0.829774</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>bayes_clf0</td>\n",
              "      <td>[8297, 8771, 40, 82]</td>\n",
              "      <td>0.487435</td>\n",
              "      <td>0.672131</td>\n",
              "      <td>0.018273</td>\n",
              "      <td>0.579123</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>bayes_clf1</td>\n",
              "      <td>[9041, 8027, 25, 97]</td>\n",
              "      <td>0.531588</td>\n",
              "      <td>0.795082</td>\n",
              "      <td>0.023527</td>\n",
              "      <td>0.662393</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>bayes_clf2</td>\n",
              "      <td>[10242, 6826, 39, 83]</td>\n",
              "      <td>0.600640</td>\n",
              "      <td>0.680328</td>\n",
              "      <td>0.023610</td>\n",
              "      <td>0.640199</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>bayes_clf3</td>\n",
              "      <td>[10323, 6745, 39, 83]</td>\n",
              "      <td>0.605352</td>\n",
              "      <td>0.680328</td>\n",
              "      <td>0.023885</td>\n",
              "      <td>0.642572</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>bayes_clf4</td>\n",
              "      <td>[10324, 6744, 39, 83]</td>\n",
              "      <td>0.605410</td>\n",
              "      <td>0.680328</td>\n",
              "      <td>0.023888</td>\n",
              "      <td>0.642601</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>bayes_clf5</td>\n",
              "      <td>[10324, 6744, 39, 83]</td>\n",
              "      <td>0.605410</td>\n",
              "      <td>0.680328</td>\n",
              "      <td>0.023888</td>\n",
              "      <td>0.642601</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>bayes_clf6</td>\n",
              "      <td>[10324, 6744, 39, 83]</td>\n",
              "      <td>0.605410</td>\n",
              "      <td>0.680328</td>\n",
              "      <td>0.023888</td>\n",
              "      <td>0.642601</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>neigh_clf0</td>\n",
              "      <td>[16733, 335, 30, 92]</td>\n",
              "      <td>0.978767</td>\n",
              "      <td>0.754098</td>\n",
              "      <td>0.335155</td>\n",
              "      <td>0.867235</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>neigh_clf1</td>\n",
              "      <td>[16916, 152, 43, 79]</td>\n",
              "      <td>0.988656</td>\n",
              "      <td>0.647541</td>\n",
              "      <td>0.447592</td>\n",
              "      <td>0.819318</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>neigh_clf2</td>\n",
              "      <td>[16334, 734, 22, 100]</td>\n",
              "      <td>0.956021</td>\n",
              "      <td>0.819672</td>\n",
              "      <td>0.209205</td>\n",
              "      <td>0.888334</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>tree_clf0</td>\n",
              "      <td>[16936, 132, 23, 99]</td>\n",
              "      <td>0.990983</td>\n",
              "      <td>0.811475</td>\n",
              "      <td>0.560907</td>\n",
              "      <td>0.901871</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>tree_clf1</td>\n",
              "      <td>[16942, 126, 20, 102]</td>\n",
              "      <td>0.991507</td>\n",
              "      <td>0.836066</td>\n",
              "      <td>0.582857</td>\n",
              "      <td>0.914342</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>tree_clf2</td>\n",
              "      <td>[16931, 137, 25, 97]</td>\n",
              "      <td>0.990576</td>\n",
              "      <td>0.795082</td>\n",
              "      <td>0.544944</td>\n",
              "      <td>0.893528</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>tree_clf3</td>\n",
              "      <td>[16884, 184, 25, 97]</td>\n",
              "      <td>0.987842</td>\n",
              "      <td>0.795082</td>\n",
              "      <td>0.481390</td>\n",
              "      <td>0.892151</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>rnd_clf0</td>\n",
              "      <td>[17015, 53, 22, 100]</td>\n",
              "      <td>0.995637</td>\n",
              "      <td>0.819672</td>\n",
              "      <td>0.727273</td>\n",
              "      <td>0.908283</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>rnd_clf1</td>\n",
              "      <td>[17014, 54, 23, 99]</td>\n",
              "      <td>0.995521</td>\n",
              "      <td>0.811475</td>\n",
              "      <td>0.720000</td>\n",
              "      <td>0.904156</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>rnd_clf2</td>\n",
              "      <td>[17014, 54, 23, 99]</td>\n",
              "      <td>0.995521</td>\n",
              "      <td>0.811475</td>\n",
              "      <td>0.720000</td>\n",
              "      <td>0.904156</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>gboost_clf0</td>\n",
              "      <td>[15446, 1622, 20, 102]</td>\n",
              "      <td>0.904479</td>\n",
              "      <td>0.836066</td>\n",
              "      <td>0.110509</td>\n",
              "      <td>0.870517</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>gboost_clf1</td>\n",
              "      <td>[14823, 2245, 22, 100]</td>\n",
              "      <td>0.868121</td>\n",
              "      <td>0.819672</td>\n",
              "      <td>0.081070</td>\n",
              "      <td>0.844070</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>gboost_clf2</td>\n",
              "      <td>[15990, 1078, 17, 105]</td>\n",
              "      <td>0.936300</td>\n",
              "      <td>0.860656</td>\n",
              "      <td>0.160920</td>\n",
              "      <td>0.898748</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-1af48fc9-fa5c-4d33-9fd5-995cde98b329')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-1af48fc9-fa5c-4d33-9fd5-995cde98b329 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-1af48fc9-fa5c-4d33-9fd5-995cde98b329');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "     model_name        confusion_matrix  accuracy    recall  f1_score  \\\n",
              "0      log_clf0   [10551, 6517, 38, 84]  0.618674  0.688525  0.024989   \n",
              "1      log_clf1   [10551, 6517, 39, 83]  0.618615  0.680328  0.024695   \n",
              "2      svc_clf0   [12395, 4673, 25, 97]  0.726702  0.795082  0.039657   \n",
              "3      svc_clf1  [10750, 6318, 19, 103]  0.631355  0.844262  0.031484   \n",
              "4      svc_clf2    [7181, 9887, 38, 84]  0.422629  0.688525  0.016645   \n",
              "5      svc_clf3  [14126, 2942, 22, 100]  0.827574  0.819672  0.063211   \n",
              "6      svc_clf4   [14240, 2828, 23, 99]  0.834148  0.811475  0.064939   \n",
              "7      svc_clf5   [14296, 2772, 24, 98]  0.837347  0.803279  0.065508   \n",
              "8      svc_clf6  [14335, 2733, 22, 100]  0.839732  0.819672  0.067682   \n",
              "9    bayes_clf0    [8297, 8771, 40, 82]  0.487435  0.672131  0.018273   \n",
              "10   bayes_clf1    [9041, 8027, 25, 97]  0.531588  0.795082  0.023527   \n",
              "11   bayes_clf2   [10242, 6826, 39, 83]  0.600640  0.680328  0.023610   \n",
              "12   bayes_clf3   [10323, 6745, 39, 83]  0.605352  0.680328  0.023885   \n",
              "13   bayes_clf4   [10324, 6744, 39, 83]  0.605410  0.680328  0.023888   \n",
              "14   bayes_clf5   [10324, 6744, 39, 83]  0.605410  0.680328  0.023888   \n",
              "15   bayes_clf6   [10324, 6744, 39, 83]  0.605410  0.680328  0.023888   \n",
              "16   neigh_clf0    [16733, 335, 30, 92]  0.978767  0.754098  0.335155   \n",
              "17   neigh_clf1    [16916, 152, 43, 79]  0.988656  0.647541  0.447592   \n",
              "18   neigh_clf2   [16334, 734, 22, 100]  0.956021  0.819672  0.209205   \n",
              "19    tree_clf0    [16936, 132, 23, 99]  0.990983  0.811475  0.560907   \n",
              "20    tree_clf1   [16942, 126, 20, 102]  0.991507  0.836066  0.582857   \n",
              "21    tree_clf2    [16931, 137, 25, 97]  0.990576  0.795082  0.544944   \n",
              "22    tree_clf3    [16884, 184, 25, 97]  0.987842  0.795082  0.481390   \n",
              "23     rnd_clf0    [17015, 53, 22, 100]  0.995637  0.819672  0.727273   \n",
              "24     rnd_clf1     [17014, 54, 23, 99]  0.995521  0.811475  0.720000   \n",
              "25     rnd_clf2     [17014, 54, 23, 99]  0.995521  0.811475  0.720000   \n",
              "26  gboost_clf0  [15446, 1622, 20, 102]  0.904479  0.836066  0.110509   \n",
              "27  gboost_clf1  [14823, 2245, 22, 100]  0.868121  0.819672  0.081070   \n",
              "28  gboost_clf2  [15990, 1078, 17, 105]  0.936300  0.860656  0.160920   \n",
              "\n",
              "    roc_auc_score  \n",
              "0        0.653349  \n",
              "1        0.649251  \n",
              "2        0.760647  \n",
              "3        0.737048  \n",
              "4        0.554627  \n",
              "5        0.823651  \n",
              "6        0.822893  \n",
              "7        0.820435  \n",
              "8        0.829774  \n",
              "9        0.579123  \n",
              "10       0.662393  \n",
              "11       0.640199  \n",
              "12       0.642572  \n",
              "13       0.642601  \n",
              "14       0.642601  \n",
              "15       0.642601  \n",
              "16       0.867235  \n",
              "17       0.819318  \n",
              "18       0.888334  \n",
              "19       0.901871  \n",
              "20       0.914342  \n",
              "21       0.893528  \n",
              "22       0.892151  \n",
              "23       0.908283  \n",
              "24       0.904156  \n",
              "25       0.904156  \n",
              "26       0.870517  \n",
              "27       0.844070  \n",
              "28       0.898748  "
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "display(models_eval)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Esowp65835v8",
        "outputId": "071dc450-078d-4d06-e947-156069e9c267"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 3 folds for each of 25 candidates, totalling 75 fits\n",
            "[CV 1/3] END learning_rate=0.15, max_depth=15, n_estimators=1000;, score=0.998 total time=27.0min\n",
            "[CV 2/3] END learning_rate=0.15, max_depth=15, n_estimators=1000;, score=0.997 total time=25.6min\n",
            "[CV 3/3] END learning_rate=0.15, max_depth=15, n_estimators=1000;, score=0.997 total time=26.7min\n",
            "[CV 1/3] END learning_rate=0.01, max_depth=5, n_estimators=750;, score=0.919 total time=10.8min\n",
            "[CV 2/3] END learning_rate=0.01, max_depth=5, n_estimators=750;, score=0.917 total time=11.0min\n",
            "[CV 3/3] END learning_rate=0.01, max_depth=5, n_estimators=750;, score=0.917 total time=10.9min\n",
            "[CV 1/3] END learning_rate=0.01, max_depth=3, n_estimators=500;, score=0.841 total time= 4.6min\n",
            "[CV 2/3] END learning_rate=0.01, max_depth=3, n_estimators=500;, score=0.840 total time= 4.5min\n",
            "[CV 3/3] END learning_rate=0.01, max_depth=3, n_estimators=500;, score=0.845 total time= 4.7min\n",
            "[CV 1/3] END learning_rate=0.1, max_depth=5, n_estimators=1000;, score=0.984 total time=14.6min\n",
            "[CV 2/3] END learning_rate=0.1, max_depth=5, n_estimators=1000;, score=0.984 total time=14.9min\n",
            "[CV 3/3] END learning_rate=0.1, max_depth=5, n_estimators=1000;, score=0.985 total time=14.5min\n",
            "[CV 1/3] END learning_rate=0.2, max_depth=15, n_estimators=100;, score=0.996 total time= 4.5min\n",
            "[CV 2/3] END learning_rate=0.2, max_depth=15, n_estimators=100;, score=0.996 total time= 4.4min\n",
            "[CV 3/3] END learning_rate=0.2, max_depth=15, n_estimators=100;, score=0.996 total time= 4.4min\n",
            "[CV 1/3] END learning_rate=0.01, max_depth=10, n_estimators=1000;, score=0.993 total time=27.6min\n",
            "[CV 2/3] END learning_rate=0.01, max_depth=10, n_estimators=1000;, score=0.992 total time=27.5min\n",
            "[CV 3/3] END learning_rate=0.01, max_depth=10, n_estimators=1000;, score=0.993 total time=27.0min\n",
            "[CV 1/3] END learning_rate=0.15, max_depth=10, n_estimators=750;, score=0.997 total time=20.1min\n",
            "[CV 2/3] END learning_rate=0.15, max_depth=10, n_estimators=750;, score=0.997 total time=20.4min\n",
            "[CV 3/3] END learning_rate=0.15, max_depth=10, n_estimators=750;, score=0.998 total time=19.9min\n",
            "[CV 1/3] END learning_rate=0.05, max_depth=15, n_estimators=1000;, score=0.997 total time=45.2min\n",
            "[CV 2/3] END learning_rate=0.05, max_depth=15, n_estimators=1000;, score=0.997 total time=48.3min\n",
            "[CV 3/3] END learning_rate=0.05, max_depth=15, n_estimators=1000;, score=0.997 total time=50.7min\n",
            "[CV 1/3] END learning_rate=0.01, max_depth=1, n_estimators=750;, score=0.759 total time= 2.5min\n",
            "[CV 2/3] END learning_rate=0.01, max_depth=1, n_estimators=750;, score=0.758 total time= 2.5min\n",
            "[CV 3/3] END learning_rate=0.01, max_depth=1, n_estimators=750;, score=0.762 total time= 2.5min\n",
            "[CV 1/3] END learning_rate=0.3, max_depth=1, n_estimators=500;, score=0.866 total time= 1.7min\n",
            "[CV 2/3] END learning_rate=0.3, max_depth=1, n_estimators=500;, score=0.865 total time= 1.6min\n",
            "[CV 3/3] END learning_rate=0.3, max_depth=1, n_estimators=500;, score=0.868 total time= 1.6min\n",
            "[CV 1/3] END learning_rate=0.3, max_depth=5, n_estimators=1000;, score=0.992 total time=15.7min\n",
            "[CV 2/3] END learning_rate=0.3, max_depth=5, n_estimators=1000;, score=0.992 total time=14.8min\n",
            "[CV 3/3] END learning_rate=0.3, max_depth=5, n_estimators=1000;, score=0.993 total time=14.6min\n",
            "[CV 1/3] END learning_rate=0.05, max_depth=5, n_estimators=1000;, score=0.973 total time=14.6min\n",
            "[CV 2/3] END learning_rate=0.05, max_depth=5, n_estimators=1000;, score=0.972 total time=14.4min\n",
            "[CV 3/3] END learning_rate=0.05, max_depth=5, n_estimators=1000;, score=0.974 total time=14.4min\n",
            "[CV 1/3] END learning_rate=0.2, max_depth=15, n_estimators=1000;, score=0.998 total time=19.5min\n",
            "[CV 2/3] END learning_rate=0.2, max_depth=15, n_estimators=1000;, score=0.997 total time=19.4min\n",
            "[CV 3/3] END learning_rate=0.2, max_depth=15, n_estimators=1000;, score=0.997 total time=20.0min\n",
            "[CV 1/3] END learning_rate=0.25, max_depth=1, n_estimators=100;, score=0.818 total time=  19.5s\n",
            "[CV 2/3] END learning_rate=0.25, max_depth=1, n_estimators=100;, score=0.817 total time=  19.0s\n",
            "[CV 3/3] END learning_rate=0.25, max_depth=1, n_estimators=100;, score=0.812 total time=  19.6s\n",
            "[CV 1/3] END learning_rate=0.5, max_depth=1, n_estimators=750;, score=0.873 total time= 2.4min\n",
            "[CV 2/3] END learning_rate=0.5, max_depth=1, n_estimators=750;, score=0.872 total time= 2.4min\n",
            "[CV 3/3] END learning_rate=0.5, max_depth=1, n_estimators=750;, score=0.874 total time= 2.4min\n",
            "[CV 1/3] END learning_rate=0.1, max_depth=5, n_estimators=100;, score=0.928 total time= 1.4min\n",
            "[CV 2/3] END learning_rate=0.1, max_depth=5, n_estimators=100;, score=0.928 total time= 1.4min\n",
            "[CV 3/3] END learning_rate=0.1, max_depth=5, n_estimators=100;, score=0.928 total time= 1.4min\n",
            "[CV 1/3] END learning_rate=0.01, max_depth=15, n_estimators=100;, score=0.986 total time= 3.9min\n",
            "[CV 2/3] END learning_rate=0.01, max_depth=15, n_estimators=100;, score=0.986 total time= 3.8min\n",
            "[CV 3/3] END learning_rate=0.01, max_depth=15, n_estimators=100;, score=0.986 total time= 3.7min\n",
            "[CV 1/3] END learning_rate=0.3, max_depth=3, n_estimators=500;, score=0.961 total time= 4.3min\n",
            "[CV 2/3] END learning_rate=0.3, max_depth=3, n_estimators=500;, score=0.958 total time= 4.4min\n",
            "[CV 3/3] END learning_rate=0.3, max_depth=3, n_estimators=500;, score=0.961 total time= 4.3min\n",
            "[CV 1/3] END learning_rate=0.2, max_depth=1, n_estimators=750;, score=0.866 total time= 2.4min\n",
            "[CV 2/3] END learning_rate=0.2, max_depth=1, n_estimators=750;, score=0.866 total time= 2.4min\n",
            "[CV 3/3] END learning_rate=0.2, max_depth=1, n_estimators=750;, score=0.868 total time= 2.4min\n",
            "[CV 1/3] END learning_rate=0.5, max_depth=15, n_estimators=750;, score=0.998 total time= 7.6min\n",
            "[CV 2/3] END learning_rate=0.5, max_depth=15, n_estimators=750;, score=0.997 total time= 7.7min\n",
            "[CV 3/3] END learning_rate=0.5, max_depth=15, n_estimators=750;, score=0.997 total time= 7.5min\n",
            "[CV 1/3] END learning_rate=0.05, max_depth=8, n_estimators=1000;, score=0.995 total time=21.9min\n",
            "[CV 2/3] END learning_rate=0.05, max_depth=8, n_estimators=1000;, score=0.994 total time=21.9min\n",
            "[CV 3/3] END learning_rate=0.05, max_depth=8, n_estimators=1000;, score=0.995 total time=21.7min\n",
            "[CV 1/3] END learning_rate=0.1, max_depth=3, n_estimators=100;, score=0.874 total time=  51.5s\n",
            "[CV 2/3] END learning_rate=0.1, max_depth=3, n_estimators=100;, score=0.871 total time=  50.9s\n",
            "[CV 3/3] END learning_rate=0.1, max_depth=3, n_estimators=100;, score=0.877 total time=  50.5s\n",
            "[CV 1/3] END learning_rate=0.1, max_depth=15, n_estimators=750;, score=0.997 total time=32.2min\n",
            "[CV 2/3] END learning_rate=0.1, max_depth=15, n_estimators=750;, score=0.997 total time=31.8min\n",
            "[CV 3/3] END learning_rate=0.1, max_depth=15, n_estimators=750;, score=0.997 total time=32.1min\n",
            "[CV 1/3] END learning_rate=0.3, max_depth=1, n_estimators=1000;, score=0.871 total time= 3.1min\n",
            "[CV 2/3] END learning_rate=0.3, max_depth=1, n_estimators=1000;, score=0.867 total time= 3.1min\n",
            "[CV 3/3] END learning_rate=0.3, max_depth=1, n_estimators=1000;, score=0.871 total time= 3.2min\n",
            "[CV 1/3] END learning_rate=0.25, max_depth=8, n_estimators=100;, score=0.991 total time= 2.1min\n",
            "[CV 2/3] END learning_rate=0.25, max_depth=8, n_estimators=100;, score=0.989 total time= 2.1min\n",
            "[CV 3/3] END learning_rate=0.25, max_depth=8, n_estimators=100;, score=0.992 total time= 2.1min\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'n_estimators': 1000, 'max_depth': 15, 'learning_rate': 0.2}"
            ]
          },
          "metadata": {},
          "execution_count": 63
        }
      ],
      "source": [
        "# RandomizedSearchCV\n",
        "\n",
        "random_grid = {\n",
        "              \"n_estimators\": [100, 500, 750, 1000],\n",
        "              \"learning_rate\": [0.01, 0.05, 0.10, 0.15, 0.20, 0.25, 0.30, 0.50],\n",
        "              \"max_depth\": [1, 3, 5, 8, 10, 15]\n",
        "              }\n",
        "\n",
        "gboost_random = RandomizedSearchCV(estimator = gboost_clf, \n",
        "                                 param_distributions = random_grid, \n",
        "                                 n_iter = 25, \n",
        "                                 cv = 3, \n",
        "                                 verbose = 3, \n",
        "                                 scoring = 'recall',\n",
        "                                 random_state = 10)\n",
        "\n",
        "gboost_random.fit(X_train, y_train)\n",
        "gboost_random.best_params_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f6-C1PnUKo9b",
        "outputId": "a60ae20e-2831-40f7-a16e-d195c5cc6d19"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'n_estimators': 1000, 'max_depth': 15, 'learning_rate': 0.2}"
            ]
          },
          "execution_count": 64,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "gboost_random.best_params_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8MoALn6aKpy4",
        "outputId": "f506f719-f0ad-4a01-daf5-e399b5f7a7b0"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9973683640400243"
            ]
          },
          "metadata": {},
          "execution_count": 65
        }
      ],
      "source": [
        "gboost_random.best_score_"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J3M3ob9buTHm"
      },
      "source": [
        "## XGBoost\n",
        "\n",
        "- Library: xgboost"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Training\n",
        "\n",
        "name = 'xgboost_clf'\n",
        "\n",
        "train = pd.DataFrame(columns = ['n_estimators', 'learning_rate', 'max_depth', 'random_state'])\n",
        "train = train.append({'n_estimators': 1000, 'learning_rate':0.1, 'max_depth':8, 'random_state':10}, ignore_index=True)\n",
        "train = train.append({'n_estimators': 500, 'learning_rate':0.5, 'max_depth':1, 'random_state':10}, ignore_index=True)\n",
        "train = train.append({'n_estimators': 750, 'learning_rate':0.01, 'max_depth':10, 'random_state':10}, ignore_index=True)\n",
        "\n",
        "train = train.reset_index()\n",
        "for index, row in train.iterrows():\n",
        "    model_name = name + str(index)\n",
        "    xgboost_clf = XGBClassifier(n_estimators=int(row['n_estimators']), learning_rate=row['learning_rate'],\n",
        "                                max_depth=int(row['max_depth']), random_state=int(row['random_state']))\n",
        "    xgboost_clf.fit(X_train, y_train)\n",
        "    \n",
        "    y_true = y_val\n",
        "    y_pred = xgboost_clf.predict(X_val)\n",
        "    evaluation_results = evaluation_metrics(y_true, y_pred)\n",
        "\n",
        "    models = models.append({'model_name': model_name, \n",
        "                            'model': xgboost_clf, \n",
        "                            'parameters': xgboost_clf.get_params()}, \n",
        "                            ignore_index=True)\n",
        "    \n",
        "    models_eval = models_eval.append({'model_name': model_name, \n",
        "                                      'confusion_matrix' : evaluation_results[0], \n",
        "                                      'accuracy': evaluation_results[1], \n",
        "                                      'recall' : evaluation_results[2], \n",
        "                                      'f1_score': evaluation_results[3], \n",
        "                                      'roc_auc_score': evaluation_results[4]}, \n",
        "                                      ignore_index=True)"
      ],
      "metadata": {
        "id": "gsrIlNccx2Ve"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "display(models_eval)"
      ],
      "metadata": {
        "id": "blvSjmCQx4Jn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# RandomizedSearchCV\n",
        "\n",
        "random_grid = {\n",
        "              \"n_estimators\": [100, 500, 750, 1000],\n",
        "              \"learning_rate\": [0.01, 0.05, 0.10, 0.15, 0.20, 0.25, 0.30, 0.50],\n",
        "              \"max_depth\": [1, 3, 5, 8, 10, 15],\n",
        "              \"min_child_weight\" : [1, 3, 5, 7]\n",
        "              }\n",
        "\n",
        "xgboost_random = RandomizedSearchCV(estimator = xgboost_clf, \n",
        "                                 param_distributions = random_grid, \n",
        "                                 n_iter = 50, \n",
        "                                 cv = 3, \n",
        "                                 verbose = 3, \n",
        "                                 scoring = 'recall',\n",
        "                                 random_state = 10)\n",
        "\n",
        "xgboost_random.fit(X_train, y_train)\n",
        "xgboost_random.best_params_"
      ],
      "metadata": {
        "id": "Gsxz-zlSx4rX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "xgboost_random.best_params_"
      ],
      "metadata": {
        "id": "iyoU-_v-x7yk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "xgboost_random.best_score_"
      ],
      "metadata": {
        "id": "XVWwrCr-x7BR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p3iAdzksueOk"
      },
      "source": [
        "## LightGBM\n",
        "\n",
        "- Library: lightbgm"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Training\n",
        "\n",
        "name = 'lightgbm_clf'\n",
        "\n",
        "train = pd.DataFrame(columns = ['n_estimators', 'learning_rate', 'max_depth', 'random_state'])\n",
        "train = train.append({'n_estimators': 1000, 'learning_rate':0.1, 'max_depth':3, 'random_state':10}, ignore_index=True)\n",
        "train = train.append({'n_estimators': 500, 'learning_rate':0.5, 'max_depth':1, 'random_state':10}, ignore_index=True)\n",
        "train = train.append({'n_estimators': 750, 'learning_rate':0.01, 'max_depth':10, 'random_state':10}, ignore_index=True)\n",
        "\n",
        "train = train.reset_index()\n",
        "for index, row in train.iterrows():\n",
        "    model_name = name + str(index)\n",
        "    lightgbm_clf = LGBMClassifier(n_estimators=int(row['n_estimators']), learning_rate=row['learning_rate'],\n",
        "                                max_depth=int(row['max_depth']), random_state=int(row['random_state']))\n",
        "    lightgbm_clf.fit(X_train, y_train)\n",
        "    \n",
        "    y_true = y_val\n",
        "    y_pred = lightgbm_clf.predict(X_val)\n",
        "    evaluation_results = evaluation_metrics(y_true, y_pred)   \n",
        "\n",
        "    models = models.append({'model_name': model_name, \n",
        "                            'model': lightgbm_clf, \n",
        "                            'parameters': lightgbm_clf.get_params()}, \n",
        "                            ignore_index=True)\n",
        "    \n",
        "    models_eval = models_eval.append({'model_name': model_name, \n",
        "                                      'confusion_matrix' : evaluation_results[0], \n",
        "                                      'accuracy': evaluation_results[1], \n",
        "                                      'recall' : evaluation_results[2], \n",
        "                                      'f1_score': evaluation_results[3], \n",
        "                                      'roc_auc_score': evaluation_results[4]}, \n",
        "                                      ignore_index=True)"
      ],
      "metadata": {
        "id": "Uos6QrfPx-Sx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "display(models_eval)"
      ],
      "metadata": {
        "id": "pb9U9uW9x_Hr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# RandomizedSearchCV\n",
        "\n",
        "random_grid = {\n",
        "              \"n_estimators\": [100, 500, 750, 1000],\n",
        "              \"learning_rate\": [0.01, 0.05, 0.10, 0.15, 0.20, 0.25, 0.30, 0.50],\n",
        "              \"max_depth\": [1, 3, 5, 8, 10, 15, 20],\n",
        "              \"num_leaves\": [10, 31, 50, 100, 200, 500],\n",
        "              \"min_data_in_leaf\": [10, 20, 25, 50, 100]\n",
        "              }\n",
        "\n",
        "lightgbm_random = RandomizedSearchCV(estimator = lightgbm_clf, \n",
        "                                 param_distributions = random_grid, \n",
        "                                 n_iter = 50, \n",
        "                                 cv = 5, \n",
        "                                 verbose = 3, \n",
        "                                 scoring = 'recall',\n",
        "                                 random_state = 10)\n",
        "\n",
        "lightgbm_random.fit(X_train, y_train)\n",
        "lightgbm_random.best_params_"
      ],
      "metadata": {
        "id": "eQMX7UAuyAGt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lightgbm_random.best_params_"
      ],
      "metadata": {
        "id": "pN10sCa7yBLN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lightgbm_random.best_score_"
      ],
      "metadata": {
        "id": "Nl0bjtkGyB4v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QpthCMRHuhWe"
      },
      "source": [
        "## Artificial Neural Network\n",
        "\n",
        "- Library: Keras, Tensorflow"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "fJ6kS48GZVH3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3868595b-8371-43fe-9fb1-b950f73cbca2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.11.0\n",
            "2.11.0\n"
          ]
        }
      ],
      "source": [
        "tf.random.set_seed(10)\n",
        "\n",
        "print(tf.__version__)\n",
        "print(keras.__version__)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vivojhGnfeEz"
      },
      "source": [
        "#### Experiment 1: Base Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "XO7_fl_pfaEP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "05ec6d25-b836-4081-aac9-92cf00805366"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Int64Index: 272834 entries, 32349 to 236669\n",
            "Data columns (total 6 columns):\n",
            " #   Column      Non-Null Count   Dtype  \n",
            "---  ------      --------------   -----  \n",
            " 0   LATITUDE    272834 non-null  float64\n",
            " 1   LONGITUDE   272834 non-null  float64\n",
            " 2   CO_MOL/M2   272834 non-null  float64\n",
            " 3   SO2_MOL/M2  272834 non-null  float64\n",
            " 4   NO2_MOL/M2  272834 non-null  float64\n",
            " 5   O3_MOL/M2   272834 non-null  float64\n",
            "dtypes: float64(6)\n",
            "memory usage: 14.6 MB\n"
          ]
        }
      ],
      "source": [
        "X_train.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "OVpParvzfhtl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c5f72ee8-805f-4aa3-e475-801889d56cc9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_3 (Dense)             (None, 15)                105       \n",
            "                                                                 \n",
            " dense_4 (Dense)             (None, 10)                160       \n",
            "                                                                 \n",
            " dense_5 (Dense)             (None, 1)                 11        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 276\n",
            "Trainable params: 276\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "ann_clf = keras.models.Sequential([\n",
        "    keras.layers.Dense(15, input_shape=(X_train.shape[1],), activation='relu'), # No bias term\n",
        "    # keras.layers.Dense(10, activation='relu'), \n",
        "    keras.layers.Dense(10, activation='relu'), \n",
        "    keras.layers.Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "ann_clf.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "zfmrnfPOhhPr",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "outputId": "1609f72f-08ed-45fa-a741-23232b2c59c8"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "0    136417\n",
              "1    136417\n",
              "Name: FIRE_OCCURRED, dtype: int64"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "display(y_train.value_counts())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "ZN18brcTbRwx",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "outputId": "f0fb5017-5729-4c42-f45b-4d1916dca8f8"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "0    17068\n",
              "1      122\n",
              "Name: FIRE_OCCURRED, dtype: int64"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "display(y_val.value_counts())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "bK1SXteMfln5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ce574400-6ccb-45e1-fdb2-a4852feb4db6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "27284/27284 [==============================] - 123s 4ms/step - loss: 0.5026 - accuracy: 0.7534 - val_loss: 0.4742 - val_accuracy: 0.7434\n",
            "Epoch 2/50\n",
            "27284/27284 [==============================] - 83s 3ms/step - loss: 0.4420 - accuracy: 0.7886 - val_loss: 0.3624 - val_accuracy: 0.8160\n",
            "Epoch 3/50\n",
            "27284/27284 [==============================] - 88s 3ms/step - loss: 0.4193 - accuracy: 0.7986 - val_loss: 0.4366 - val_accuracy: 0.7666\n",
            "Epoch 4/50\n",
            "27284/27284 [==============================] - 86s 3ms/step - loss: 0.3991 - accuracy: 0.8121 - val_loss: 0.4489 - val_accuracy: 0.7510\n",
            "Epoch 5/50\n",
            "27284/27284 [==============================] - 83s 3ms/step - loss: 0.3882 - accuracy: 0.8213 - val_loss: 0.3748 - val_accuracy: 0.8284\n",
            "Epoch 6/50\n",
            "27284/27284 [==============================] - 82s 3ms/step - loss: 0.3801 - accuracy: 0.8271 - val_loss: 0.2327 - val_accuracy: 0.9081\n",
            "Epoch 7/50\n",
            "27284/27284 [==============================] - 81s 3ms/step - loss: 0.3748 - accuracy: 0.8306 - val_loss: 0.3514 - val_accuracy: 0.8454\n",
            "Epoch 8/50\n",
            "27284/27284 [==============================] - 82s 3ms/step - loss: 0.3707 - accuracy: 0.8333 - val_loss: 0.3255 - val_accuracy: 0.8649\n",
            "Epoch 9/50\n",
            "27284/27284 [==============================] - 83s 3ms/step - loss: 0.3662 - accuracy: 0.8368 - val_loss: 0.4253 - val_accuracy: 0.8045\n",
            "Epoch 10/50\n",
            "27284/27284 [==============================] - 84s 3ms/step - loss: 0.3627 - accuracy: 0.8395 - val_loss: 0.3707 - val_accuracy: 0.8432\n",
            "Epoch 11/50\n",
            "27284/27284 [==============================] - 82s 3ms/step - loss: 0.3591 - accuracy: 0.8414 - val_loss: 0.2934 - val_accuracy: 0.8693\n",
            "Epoch 12/50\n",
            "27284/27284 [==============================] - 81s 3ms/step - loss: 0.3550 - accuracy: 0.8436 - val_loss: 0.3778 - val_accuracy: 0.8376\n",
            "Epoch 13/50\n",
            "27284/27284 [==============================] - 83s 3ms/step - loss: 0.3523 - accuracy: 0.8461 - val_loss: 0.3505 - val_accuracy: 0.8538\n",
            "Epoch 14/50\n",
            "27284/27284 [==============================] - 83s 3ms/step - loss: 0.3496 - accuracy: 0.8474 - val_loss: 0.3433 - val_accuracy: 0.8599\n",
            "Epoch 15/50\n",
            "27284/27284 [==============================] - 80s 3ms/step - loss: 0.3480 - accuracy: 0.8490 - val_loss: 0.3705 - val_accuracy: 0.8428\n",
            "Epoch 16/50\n",
            "27284/27284 [==============================] - 80s 3ms/step - loss: 0.3467 - accuracy: 0.8492 - val_loss: 0.3312 - val_accuracy: 0.8673\n",
            "Epoch 17/50\n",
            "27284/27284 [==============================] - 82s 3ms/step - loss: 0.3448 - accuracy: 0.8497 - val_loss: 0.2920 - val_accuracy: 0.8828\n",
            "Epoch 18/50\n",
            "27284/27284 [==============================] - 82s 3ms/step - loss: 0.3439 - accuracy: 0.8508 - val_loss: 0.3360 - val_accuracy: 0.8539\n",
            "Epoch 19/50\n",
            "27284/27284 [==============================] - 81s 3ms/step - loss: 0.3426 - accuracy: 0.8517 - val_loss: 0.3580 - val_accuracy: 0.8501\n",
            "Epoch 20/50\n",
            "27284/27284 [==============================] - 81s 3ms/step - loss: 0.3419 - accuracy: 0.8526 - val_loss: 0.3043 - val_accuracy: 0.8768\n",
            "Epoch 21/50\n",
            "27284/27284 [==============================] - 80s 3ms/step - loss: 0.3412 - accuracy: 0.8530 - val_loss: 0.3301 - val_accuracy: 0.8614\n",
            "Epoch 22/50\n",
            "27284/27284 [==============================] - 80s 3ms/step - loss: 0.3404 - accuracy: 0.8532 - val_loss: 0.4550 - val_accuracy: 0.7943\n",
            "Epoch 23/50\n",
            "27284/27284 [==============================] - 83s 3ms/step - loss: 0.3390 - accuracy: 0.8537 - val_loss: 0.3409 - val_accuracy: 0.8505\n",
            "Epoch 24/50\n",
            "27284/27284 [==============================] - 81s 3ms/step - loss: 0.3378 - accuracy: 0.8544 - val_loss: 0.4233 - val_accuracy: 0.8166\n",
            "Epoch 25/50\n",
            "27284/27284 [==============================] - 83s 3ms/step - loss: 0.3369 - accuracy: 0.8550 - val_loss: 0.3403 - val_accuracy: 0.8563\n",
            "Epoch 26/50\n",
            "27284/27284 [==============================] - 84s 3ms/step - loss: 0.3365 - accuracy: 0.8550 - val_loss: 0.4077 - val_accuracy: 0.8179\n",
            "Epoch 27/50\n",
            "27284/27284 [==============================] - 84s 3ms/step - loss: 0.3358 - accuracy: 0.8549 - val_loss: 0.2655 - val_accuracy: 0.8927\n",
            "Epoch 28/50\n",
            "27284/27284 [==============================] - 83s 3ms/step - loss: 0.3350 - accuracy: 0.8554 - val_loss: 0.4484 - val_accuracy: 0.8004\n",
            "Epoch 29/50\n",
            "27284/27284 [==============================] - 83s 3ms/step - loss: 0.3346 - accuracy: 0.8556 - val_loss: 0.3429 - val_accuracy: 0.8554\n",
            "Epoch 30/50\n",
            "27284/27284 [==============================] - 82s 3ms/step - loss: 0.3344 - accuracy: 0.8559 - val_loss: 0.2614 - val_accuracy: 0.9007\n",
            "Epoch 31/50\n",
            "27284/27284 [==============================] - 85s 3ms/step - loss: 0.3335 - accuracy: 0.8561 - val_loss: 0.2513 - val_accuracy: 0.8998\n",
            "Epoch 32/50\n",
            "27284/27284 [==============================] - 82s 3ms/step - loss: 0.3334 - accuracy: 0.8564 - val_loss: 0.3179 - val_accuracy: 0.8736\n",
            "Epoch 33/50\n",
            "27284/27284 [==============================] - 82s 3ms/step - loss: 0.3334 - accuracy: 0.8560 - val_loss: 0.3732 - val_accuracy: 0.8398\n",
            "Epoch 34/50\n",
            "27284/27284 [==============================] - 82s 3ms/step - loss: 0.3326 - accuracy: 0.8562 - val_loss: 0.3405 - val_accuracy: 0.8508\n",
            "Epoch 35/50\n",
            "27284/27284 [==============================] - 82s 3ms/step - loss: 0.3325 - accuracy: 0.8568 - val_loss: 0.3351 - val_accuracy: 0.8543\n",
            "Epoch 36/50\n",
            "27284/27284 [==============================] - 82s 3ms/step - loss: 0.3318 - accuracy: 0.8569 - val_loss: 0.3387 - val_accuracy: 0.8568\n",
            "Epoch 37/50\n",
            "27284/27284 [==============================] - 85s 3ms/step - loss: 0.3313 - accuracy: 0.8580 - val_loss: 0.2970 - val_accuracy: 0.8741\n",
            "Epoch 38/50\n",
            "27284/27284 [==============================] - 83s 3ms/step - loss: 0.3312 - accuracy: 0.8574 - val_loss: 0.3193 - val_accuracy: 0.8609\n",
            "Epoch 39/50\n",
            "27284/27284 [==============================] - 83s 3ms/step - loss: 0.3308 - accuracy: 0.8574 - val_loss: 0.3649 - val_accuracy: 0.8388\n",
            "Epoch 40/50\n",
            "27284/27284 [==============================] - 83s 3ms/step - loss: 0.3310 - accuracy: 0.8579 - val_loss: 0.3713 - val_accuracy: 0.8261\n",
            "Epoch 41/50\n",
            "27284/27284 [==============================] - 85s 3ms/step - loss: 0.3301 - accuracy: 0.8578 - val_loss: 0.2447 - val_accuracy: 0.9090\n",
            "Epoch 42/50\n",
            "27284/27284 [==============================] - 84s 3ms/step - loss: 0.3301 - accuracy: 0.8581 - val_loss: 0.2632 - val_accuracy: 0.8899\n",
            "Epoch 43/50\n",
            "27284/27284 [==============================] - 86s 3ms/step - loss: 0.3298 - accuracy: 0.8578 - val_loss: 0.2914 - val_accuracy: 0.8911\n",
            "Epoch 44/50\n",
            "27284/27284 [==============================] - 86s 3ms/step - loss: 0.3299 - accuracy: 0.8586 - val_loss: 0.3550 - val_accuracy: 0.8405\n",
            "Epoch 45/50\n",
            "27284/27284 [==============================] - 85s 3ms/step - loss: 0.3290 - accuracy: 0.8589 - val_loss: 0.3052 - val_accuracy: 0.8757\n",
            "Epoch 46/50\n",
            "27284/27284 [==============================] - 84s 3ms/step - loss: 0.3292 - accuracy: 0.8583 - val_loss: 0.3149 - val_accuracy: 0.8676\n",
            "Epoch 47/50\n",
            "27284/27284 [==============================] - 83s 3ms/step - loss: 0.3294 - accuracy: 0.8588 - val_loss: 0.3507 - val_accuracy: 0.8513\n",
            "Epoch 48/50\n",
            "27284/27284 [==============================] - 85s 3ms/step - loss: 0.3292 - accuracy: 0.8585 - val_loss: 0.3246 - val_accuracy: 0.8627\n",
            "Epoch 49/50\n",
            "27284/27284 [==============================] - 86s 3ms/step - loss: 0.3292 - accuracy: 0.8591 - val_loss: 0.3427 - val_accuracy: 0.8624\n",
            "Epoch 50/50\n",
            "27284/27284 [==============================] - 86s 3ms/step - loss: 0.3286 - accuracy: 0.8589 - val_loss: 0.3210 - val_accuracy: 0.8676\n"
          ]
        }
      ],
      "source": [
        "ann_clf.compile(optimizer = 'adam',\n",
        "                metrics=['accuracy'],\n",
        "                loss = 'binary_crossentropy')\n",
        "\n",
        "# ann_clf.compile(optimizer = 'adam', \n",
        "#                 loss ='binary_crossentropy',\n",
        "#                 metrics=[tf.keras.metrics.Accuracy(), tf.keras.metrics.Recall()])\n",
        "\n",
        "record = ann_clf.fit(\n",
        "            X_train, \n",
        "            y_train, \n",
        "            validation_data = (X_val, y_val), \n",
        "            batch_size = 10, \n",
        "            epochs = 50)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "ChuhGr3Ufmgq",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        },
        "outputId": "0f41c803-9640-4c0c-9399-598e0334b32a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ],
      "source": [
        "keras.utils.plot_model(ann_clf, show_shapes=True, rankdir=\"LR\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "rsSZTcIlfnQa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a6668eda-396a-4933-a486-27fbe8e4614a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train: 0.860, Validation: 0.868, Test: 0.865\n"
          ]
        }
      ],
      "source": [
        "_, train_acc = ann_clf.evaluate(X_train, y_train, verbose=0)\n",
        "_, val_acc = ann_clf.evaluate(X_val, y_val, verbose=0)\n",
        "_, test_acc = ann_clf.evaluate(X_test, y_test, verbose=0)\n",
        "print('Train: %.3f, Validation: %.3f, Test: %.3f' % (train_acc, val_acc, test_acc))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "Jvmnf03BfoDj",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 302
        },
        "outputId": "e7dadba7-8164-489f-cee7-704cd23bd358"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "plt.plot(record.history['accuracy'], label='Training')\n",
        "plt.plot(record.history['val_accuracy'], label='Validation')\n",
        "plt.legend()\n",
        "plt.xlabel('Epochs', fontsize=16)\n",
        "plt.ylabel('Accuracy', fontsize=16)\n",
        "plt.title('Accuracy Curves', fontsize=16)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "Bk9KBNCCfpw5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 301
        },
        "outputId": "96dacb5e-65af-43d3-cbf4-80d3590a5f12"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "# plot training history\n",
        "plt.plot(record.history['loss'], label='Training')\n",
        "plt.plot(record.history['val_loss'], label='Validation')\n",
        "plt.legend()\n",
        "plt.xlabel('Epochs', fontsize=14)\n",
        "plt.ylabel('Loss', fontsize=14)\n",
        "plt.title('Loss Curves', fontsize=16)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hy1WHdJSfrl1"
      },
      "source": [
        "#### Experiment 2: Different Batch Sizes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "EbpRvs_nfsV4"
      },
      "outputs": [],
      "source": [
        "# Fit a Model and Plot Learning Curve\n",
        "\n",
        "def fit_model_1(X_train, y_train, X_val, y_val, n_batch):\n",
        "  \n",
        "  # Define Model\n",
        "  ann_clf = keras.models.Sequential([\n",
        "      keras.layers.Dense(15, input_shape=(X_train.shape[1],), activation='relu'), # No bias term\n",
        "      # keras.layers.Dense(10, activation='relu'), \n",
        "      keras.layers.Dense(10, activation='relu'), \n",
        "      keras.layers.Dense(1, activation='sigmoid')\n",
        "  ])\n",
        "\n",
        "  # Compile Model\n",
        "  ann_clf.compile(optimizer = 'adam',\n",
        "                  metrics=['accuracy'],\n",
        "                  loss = 'binary_crossentropy')\n",
        "\n",
        "  \n",
        "  # Fit Model\n",
        "  history = ann_clf.fit(X_train,\n",
        "                      y_train,\n",
        "                      validation_data=(X_val, y_val),\n",
        "                      epochs=100,\n",
        "                      verbose=0,\n",
        "                      batch_size=n_batch)\n",
        "\n",
        "  # Plot Learning Curves\n",
        "  plt.plot(history.history['accuracy'], label='train') \n",
        "  plt.plot(history.history['val_accuracy'], label='test') \n",
        "  plt.title('batch='+str(n_batch)) \n",
        "  plt.legend()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "govzlyT3fwI0"
      },
      "outputs": [],
      "source": [
        "# Create Learning Curves for Different Batch Sizes\n",
        "\n",
        "# batch_sizes = [4, 6, 10, 16, 32, 64, 128, 260]\n",
        "batch_sizes = [5, 10, 15, 20, 25, 30]\n",
        "\n",
        "plt.figure(figsize=(10,15))\n",
        "for i in range(len(batch_sizes)):\n",
        "\n",
        "  # Determine the Plot Number\n",
        "  plot_no = 420 + (i+1)\n",
        "  plt.subplot(plot_no)\n",
        "\n",
        "  # Fit Model and Plot Learning Curves for a Batch Size\n",
        "  fit_model_1(X_train, y_train, X_val, y_val, batch_sizes[i])\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ijreZVeVs9OP"
      },
      "source": [
        "Based on the accuracy graph above, the model that is good enough to show stability is the model with batch size 15"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jDdPwZjcfxsF"
      },
      "source": [
        "#### Experiment 3: Different EPOCHs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gjSGc9u6fxTv"
      },
      "outputs": [],
      "source": [
        "# Fit a Model and Plot Learning Curve\n",
        "\n",
        "def fit_model_2(X_train, y_train, X_val, y_val, n_epoch):\n",
        "\n",
        "  # Define Model\n",
        "  ann_clf = keras.models.Sequential([\n",
        "      keras.layers.Dense(15, input_shape=(X_train.shape[1],), activation='relu'), # No bias term\n",
        "      # keras.layers.Dense(10, activation='relu'), \n",
        "      keras.layers.Dense(10, activation='relu'), \n",
        "      keras.layers.Dense(1, activation='sigmoid')\n",
        "  ])\n",
        "\n",
        "  # Compile Model\n",
        "  ann_clf.compile(optimizer = 'adam',\n",
        "                  metrics=['accuracy'],\n",
        "                  loss = 'binary_crossentropy')\n",
        "\n",
        "    \n",
        "  # Fit Model\n",
        "  history = ann_clf.fit(X_train,\n",
        "                      y_train,\n",
        "                      validation_data=(X_val, y_val),\n",
        "                      epochs=n_epoch,\n",
        "                      verbose=0,\n",
        "                      batch_size=15)\n",
        "    \n",
        "  # Plot Learning Curves\n",
        "  plt.plot(history.history['accuracy'], label='train')\n",
        "  plt.plot(history.history['val_accuracy'], label='test')\n",
        "  plt.title('epoch='+str(n_epoch))\n",
        "  plt.legend()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "SP2zm_ySfznt"
      },
      "outputs": [],
      "source": [
        "# Create Learning Curves for Different EPOCHs\n",
        "\n",
        "epochs = [20, 50, 80, 100]\n",
        "\n",
        "plt.figure(figsize=(10,15))\n",
        "for i in range(len(epochs)):\n",
        "\n",
        "  # Determine the Plot Number\n",
        "  plot_no = 420 + (i+1)\n",
        "  plt.subplot(plot_no)\n",
        "\n",
        "  # Fit Model and Plot Learning Curves for an EPOCH\n",
        "  fit_model_2(X_train, y_train, X_val, y_val, epochs[i])\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FgOswfIGtCEp"
      },
      "source": [
        "Based on the accuracy graph above, the model that is good enough to show stability is the model with EPCOH 50"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3_QvFWOmf0JZ"
      },
      "source": [
        "#### Experiment 4: Early Stopping"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "3AUOp_Qwf2_U"
      },
      "outputs": [],
      "source": [
        "from keras.callbacks import EarlyStopping\n",
        "from keras.callbacks import ModelCheckpoint"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-dBPUNAngRj7"
      },
      "outputs": [],
      "source": [
        "def fit_model_3():\n",
        "\n",
        "  # Define Model\n",
        "  ann_clf = keras.models.Sequential([\n",
        "      keras.layers.Dense(15, input_shape=(X_train.shape[1],), activation='relu'), # No bias term\n",
        "      # keras.layers.Dense(10, activation='relu'), \n",
        "      keras.layers.Dense(10, activation='relu'), \n",
        "      keras.layers.Dropout(0.2),\n",
        "      keras.layers.Dense(1, activation='sigmoid')\n",
        "  ])\n",
        "\n",
        "  # Compile Model\n",
        "  ann_clf.compile(optimizer = 'adam',\n",
        "                  metrics=['accuracy'],\n",
        "                  loss = 'binary_crossentropy')\n",
        "\n",
        "  return ann_clf\n",
        "\n",
        "ann_clf = fit_model_3()\n",
        "\n",
        "es = EarlyStopping(monitor='val_loss',\n",
        "                   mode='min',\n",
        "                   verbose=1,\n",
        "                   patience=150)\n",
        "\n",
        "mc = ModelCheckpoint('best_model.h5',\n",
        "                     monitor='val_accuracy',\n",
        "                     mode='max',\n",
        "                     verbose=1,\n",
        "                     save_best_only=True)\n",
        "\n",
        "history = ann_clf.fit(X_train,\n",
        "                    y_train,\n",
        "                    validation_data=(X_val, y_val),\n",
        "                    epochs=50,\n",
        "                    verbose=0,\n",
        "                    batch_size=15,\n",
        "                    callbacks=[es, mc])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C5BRoQZKs2xD"
      },
      "outputs": [],
      "source": [
        "# plot training history\n",
        "plt.plot(history.history['loss'], label='Training')\n",
        "plt.plot(history.history['val_loss'], label='Validation')\n",
        "plt.legend()\n",
        "plt.xlabel('Epochs', fontsize=14)\n",
        "plt.ylabel('Loss', fontsize=14)\n",
        "plt.title('Loss Curves', fontsize=16)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ctyV4qGXs32m"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=[8,5])\n",
        "plt.plot(history.history['accuracy'], label='Training')\n",
        "plt.plot(history.history['val_accuracy'], label='Validation')\n",
        "plt.legend()\n",
        "plt.xlabel('Epochs', fontsize=16)\n",
        "plt.ylabel('Accuracy', fontsize=16)\n",
        "plt.title('Accuracy Curves', fontsize=16)\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U2gkZNesMiMV"
      },
      "outputs": [],
      "source": [
        "_, train_acc = ann_clf.evaluate(X_train, y_train, verbose=0)\n",
        "_, val_acc = ann_clf.evaluate(X_val, y_val, verbose=0)\n",
        "_, test_acc = ann_clf.evaluate(X_test, y_test, verbose=0)\n",
        "print('Train: %.3f, Validation: %.3f, Test: %.3f' % (train_acc, val_acc, test_acc))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ScrqamwvMuWL"
      },
      "source": [
        "Accuracy result for no early stopping  - Train: 0.964, Validation: 0.946, Test: 0.945\n",
        "\n",
        "Accuracy result for early stopping - Train: 0.961, Validation: 0.935, Test: 0.931\n",
        "\n",
        "Early stopping is not beneficial"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4rBdGe3Gukv6"
      },
      "source": [
        "## Voting Classifier\n",
        "\n",
        "- Library: Scikit-learn, Keras, Tensorflow\n",
        "- Shuffling does not affect the model building. No random_state.\n",
        "- No need for RandomizedSearchCV since there is only 1 important hyperparameter: voting"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Re-train top 3 models using their best hyperparameters\n",
        "\n",
        "model_1 = LGBMClassifier(n_estimators=1000, learning_rate=0.1, max_depth=3, random_state=10)\n",
        "model_2 = GradientBoostingClassifier(n_estimators=500, learning_rate=0.5, max_depth=1, random_state=10)\n",
        "model_3 = RandomForestClassifier(n_estimators=1000, max_depth = None, n_jobs =-1, random_state=10)\n",
        "\n",
        "name = 'ensem_clf'\n",
        "\n",
        "train = pd.DataFrame(columns = ['voting', 'n_jobs'])\n",
        "train = train.append({'voting': 'hard', 'n_jobs': -1}, ignore_index=True)\n",
        "train = train.append({'voting': 'soft', 'n_jobs': -1}, ignore_index=True)\n",
        "train = train.reset_index()\n",
        "\n",
        "for index, row in train.iterrows():\n",
        "    model_name = name + str(index)\n",
        "    ens_clf = VotingClassifier(estimators=[('m1', model_1), ('m2', model_2), ('m3', model_3)],\n",
        "                               voting = row['voting'],\n",
        "                               n_jobs = int(row['n_jobs']))\n",
        "    ens_clf.fit(X_train, y_train)\n",
        "    y_true = y_val\n",
        "    y_pred = ens_clf.predict(X_val)\n",
        "    evaluation_results = evaluation_metrics(y_true, y_pred)\n",
        "\n",
        "    models = models.append({'model_name': model_name, \n",
        "                            'model': ens_clf, \n",
        "                            'parameters': ens_clf.get_params()}, \n",
        "                            ignore_index=True)\n",
        "    \n",
        "    models_eval = models_eval.append({'model_name': model_name, \n",
        "                                      'confusion_matrix' : evaluation_results[0], \n",
        "                                      'accuracy': evaluation_results[1], \n",
        "                                      'recall' : evaluation_results[2], \n",
        "                                      'f1_score': evaluation_results[3], \n",
        "                                      'roc_auc_score': evaluation_results[4]}, \n",
        "                                      ignore_index=True)"
      ],
      "metadata": {
        "id": "g96PV4i57y_2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aH_ZSwaoefvB"
      },
      "source": [
        "Best Parameters: \n",
        "\n",
        "{'voting': 'hard'}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VSpOrrm2gNXL"
      },
      "source": [
        "# Model Training & Validation Results"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VznMSI5Zv4zN"
      },
      "source": [
        "## Best hyperparameters for each model:\n",
        "\n",
        "**log_clf:**\n",
        "\n",
        "{'warm_start': True,\n",
        " 'solver': 'lbfgs',\n",
        " 'penalty': 'none',\n",
        " 'max_iter': 331,\n",
        " 'dual': False,\n",
        " 'C': 0}\n",
        "\n",
        "**svm_clf:**\n",
        "\n",
        "{'kernel': 'rbf','C' : '8','class_weight'='balanced'}\n",
        "\n",
        "**bayes_clf:**\n",
        "\n",
        "{'var_smoothing': '1e-3'}\n",
        "\n",
        "**knn_clf:**\n",
        "\n",
        "{'n_neighbors': 19, 'algorithm': 'kd_tree'}\n",
        "\n",
        "**tree_clf:**\n",
        "\n",
        "{'splitter': 'random',\n",
        " 'min_samples_leaf': 2,\n",
        " 'max_features': 11,\n",
        " 'max_depth': None,\n",
        " 'criterion': 'entropy'}\n",
        "\n",
        "**rnd_clf:**\n",
        "\n",
        "{'n_estimators': 415,\n",
        " 'min_samples_split': 6,\n",
        " 'min_samples_leaf': 1,\n",
        " 'max_features': 4,\n",
        " 'max_depth': 18}\n",
        "\n",
        "**gboost_clf:**\n",
        "\n",
        "{'n_estimators': 1000, 'max_depth': 8, 'learning_rate': 0.1}\n",
        "\n",
        "**xgboost_clf:**\n",
        "\n",
        "{'n_estimators': 1000,\n",
        " 'min_child_weight': 7,\n",
        " 'max_depth': 8,\n",
        " 'learning_rate': 0.1}\n",
        "\n",
        "**lightgbm_clf:**\n",
        "\n",
        "{'num_leaves': 50,\n",
        " 'n_estimators': 1000,\n",
        " 'min_data_in_leaf': 10,\n",
        " 'max_depth': 8,\n",
        " 'learning_rate': 0.05}\n",
        "\n",
        "**ann_clf:**\n",
        "- Batch size 15\n",
        "- EPOCH 50\n",
        "\n",
        "**ens_clf:**\n",
        "\n",
        "{'voting':'hard'}\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "toc_visible": true,
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}