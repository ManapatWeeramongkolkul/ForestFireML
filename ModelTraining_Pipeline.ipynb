{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyN+02rI0OsK0IlC5Wh5iJ/W"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Model Training Pipeline\n"
      ],
      "metadata": {
        "id": "COF7WWOtCQRP"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qK_KRJw0rpA9"
      },
      "outputs": [],
      "source": [
        "# Basic Libraries\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sb\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Data Source\n",
        "\n",
        "df = pd.read_csv(\"/content/drive/MyDrive/Senior Project/Datasets/test_gee.csv\")\n",
        "# df = pd.read_csv(\"/content/drive/MyDrive/Senior Project/Datasets/test.csv\")\n",
        "\n",
        "df = df.drop('Unnamed: 0', axis=1)\n",
        "df.head()"
      ],
      "metadata": {
        "id": "BTKpuPDqvTli"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df1['FireOccurred'].value_counts()\n",
        "print(\"Column numbers: \", len(df1.columns))"
      ],
      "metadata": {
        "id": "2z3siI-MvbQs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Encoder & Scaler\n",
        "\n",
        "X = df1.drop('FireOccurred', axis=1)\n",
        "y = df1['FireOccurred']\n",
        "\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "encoder = LabelEncoder()\n",
        "for i in range(len(df1.columns)-1):\n",
        "  X.iloc[:,i] = encoder.fit_transform(X.iloc[:,i])\n",
        "\n",
        "scaler = StandardScaler().fit(X)\n",
        "test = scaler.transform(X)\n",
        "\n",
        "display(X)"
      ],
      "metadata": {
        "id": "_Y_7l5u9vfb4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Training, Validation, Testing Split\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# 80:10:10\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.10, random_state=1, shuffle=True)\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=1/9, random_state=1, shuffle=True)\n",
        "\n",
        "Original = [X_train, X_val, X_test, y_train, y_val, y_test] # For reference"
      ],
      "metadata": {
        "id": "96m0rNH7vhDg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if len(X_train)==len(y_train) and len(X_test) == len(y_test) and len(X_val) == len(y_val):\n",
        "  print(\"X and y data length matching\")\n",
        "else:\n",
        "  print(\"Error in data preparation pipeline\")\n",
        "print()\n",
        "print(\"No. of training data = %d\" % len(X_train))\n",
        "print(\"No. of validation data = %d\" % len(X_val))\n",
        "print(\"No. of testing data = %d\" % len(X_test))"
      ],
      "metadata": {
        "id": "oihO76nhvifX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "display(y_test.value_counts())"
      ],
      "metadata": {
        "id": "1ZcyP7nRvlYp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# SMOTE\n",
        "\n",
        "from collections import Counter\n",
        "from imblearn.over_sampling import SMOTE \n",
        "\n",
        "print('Original dataset shape %s' % Counter(y_train))\n",
        "sm = SMOTE(random_state=42)\n",
        "X_train, y_train = sm.fit_resample(X_train, y_train)\n",
        "print('Resampled dataset shape %s' % Counter(y_train))"
      ],
      "metadata": {
        "id": "T8MI03z-vmdA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Store Model Parameters and Eval\n",
        "\n",
        "models = pd.DataFrame(columns = ['model_name', 'model', 'parameters'])\n",
        "models_eval = pd.DataFrame(columns = ['model_name', 'confusion_matrix', 'accuracy', 'recall', 'f1_score', 'roc_auc_score'])"
      ],
      "metadata": {
        "id": "2m4kHhLmvnxj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluation Metrics\n",
        "\n",
        "from sklearn.metrics import confusion_matrix, recall_score, f1_score, roc_auc_score, accuracy_score\n",
        "\n",
        "def evaluation_metrics(y_true, y_pred):\n",
        "  cfm = confusion_matrix(y_true, y_pred).ravel()\n",
        "  acc = accuracy_score(y_true, y_pred)\n",
        "  recs = recall_score(y_true, y_pred, average='binary')\n",
        "  f1s = f1_score(y_true, y_pred, average='binary')\n",
        "  rocs = roc_auc_score(y_true, y_pred, average='macro')\n",
        "  return [cfm, acc, recs, f1s, rocs]"
      ],
      "metadata": {
        "id": "5pMqZtYUvo3T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Confusion matrix format : [ tn , fp , fn , tp ]"
      ],
      "metadata": {
        "id": "bDAw6kBSvqrd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import ML Algorithms\n",
        "\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "import xgboost\n",
        "from xgboost import XGBClassifier\n",
        "import lightgbm\n",
        "from lightgbm import LGBMClassifier\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from sklearn.ensemble import VotingClassifier"
      ],
      "metadata": {
        "id": "fFvGo3IYwC3h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Logistic Regression\n",
        "\n",
        "Library: Scikit-learn"
      ],
      "metadata": {
        "id": "ez3z3utYt1Y4"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "fiXiFiYsZSB6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Support Vector Machine (SVM)\n",
        "\n",
        "Library: Scikit-learn"
      ],
      "metadata": {
        "id": "oBBQ_iust1eb"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "tsq0c55qZSVE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Naive Bayes\n",
        "\n",
        "Library: Scikit-learn"
      ],
      "metadata": {
        "id": "Tzx0wl2ht1R1"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "tAmU3wsqZSwf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## K-Nearest Neighbor\n",
        "\n",
        "Library: Scikit-learn"
      ],
      "metadata": {
        "id": "M_gEyKKnt00q"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Vw5TiOkaZTHW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Random Forest Classifier\n",
        "\n",
        "Library: Scikit-learn"
      ],
      "metadata": {
        "id": "e5dbRikwt1ov"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "_n_M-g9kZTyK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Decision Tree\n",
        "\n",
        "Library: Scikit-learn"
      ],
      "metadata": {
        "id": "brtgIH7pt1jO"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "le5Xgsd8ZUHB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Gradient Boosting Classifier\n",
        "\n",
        "Library: Scikit-learn"
      ],
      "metadata": {
        "id": "-0VzXIIcuTah"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "xRoZe1r0ZUd-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## XGBoost\n",
        "\n",
        "Library: xgboost"
      ],
      "metadata": {
        "id": "J3M3ob9buTHm"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "evYZbB-MZVmF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## LightGBM\n",
        "\n",
        "Library: lightbgm"
      ],
      "metadata": {
        "id": "p3iAdzksueOk"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "sh_I5t-TZVaP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Artificial Neural Network\n",
        "\n",
        "Library: Keras, Tensorflow"
      ],
      "metadata": {
        "id": "QpthCMRHuhWe"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "fJ6kS48GZVH3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Ensemble Learning\n",
        "\n",
        "Library: Scikit-learn, Keras, Tensorflow"
      ],
      "metadata": {
        "id": "4rBdGe3Gukv6"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "YCHV8rR-ZU5c"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}