{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyP7tB7RR+QsD3xtb31YmdzM"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Data Preparation Pipeline\n",
        "* Data Exploration\n",
        "* Feature Engineering\n",
        "* Data Cleaning\n",
        "* Encoding & Scaling\n",
        "* SMOTE\n",
        "* Saving Data"
      ],
      "metadata": {
        "id": "eRbQd8qMpiwO"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OcaiG9b7jiId"
      },
      "outputs": [],
      "source": [
        "# Basic Libraries\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sb\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Data Source\n",
        "\n",
        "df = pd.read_csv(\"/content/drive/MyDrive/Senior Project/Datasets/test_gee.csv\")\n",
        "# df = pd.read_csv(\"/content/drive/MyDrive/Senior Project/Datasets/test.csv\")\n",
        "\n",
        "df = df.drop(columns = ['Unnamed: 0', 'lat_min', 'lat_max', 'long_min', 'long_max','DAYNIGHT'], axis=1)\n",
        "df.head()"
      ],
      "metadata": {
        "id": "aaGDE5G8s5vD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataplot = sb.heatmap(df.corr())\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "m32WLw2ps62-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.describe()"
      ],
      "metadata": {
        "id": "quCnEtj0s806"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.dtypes"
      ],
      "metadata": {
        "id": "VbcNpCH3s-fL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "display(df['FireOccurred'].value_counts())\n",
        "print(\"Column numbers: \", len(df.columns))"
      ],
      "metadata": {
        "id": "ObCcSHUQs_Yv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "display(df['ACQ_DATE'].value_counts())"
      ],
      "metadata": {
        "id": "qMf34M4_tAoS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "display(df['ACQ_TIME'].value_counts())"
      ],
      "metadata": {
        "id": "ZhEte8EDtAj1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = df.drop('FireOccurred', axis=1)\n",
        "y = df['FireOccurred']"
      ],
      "metadata": {
        "id": "XmTDXbJktCx6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Encoder\n",
        "\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.preprocessing import OrdinalEncoder\n",
        "\n",
        "labelEncoder = LabelEncoder()\n",
        "ordinalEncoder = OrdinalEncoder()\n",
        "\n",
        "X[['ACQ_TIME','ACQ_DATE']] = ordinalEncoder.fit_transform(X[['ACQ_TIME','ACQ_DATE']])\n",
        "X.head()\n",
        "\n",
        "# for i in range(len(df.columns)-1):\n",
        "#   X.iloc[:,i] = labelEncoder.fit_transform(X.iloc[:,i])"
      ],
      "metadata": {
        "id": "4ofZBjeEtDnc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Scaler\n",
        "\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "standardScaler = StandardScaler()\n",
        "X = pd.DataFrame(standardScaler.fit_transform(X),columns = X.columns)\n",
        "\n",
        "display(X)"
      ],
      "metadata": {
        "id": "eLXEkzq3tEmj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Training, Validation, Testing Split\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# 80:10:10\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.10, random_state=10, shuffle=True)\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=1/9, random_state=10, shuffle=True)\n",
        "\n",
        "Original = [X_train, X_val, X_test, y_train, y_val, y_test] # For reference"
      ],
      "metadata": {
        "id": "ATwp_pK7tFpT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if len(X_train)==len(y_train) and len(X_test) == len(y_test) and len(X_val) == len(y_val):\n",
        "  print(\"X and y data length matching\")\n",
        "else:\n",
        "  print(\"Error in data preparation pipeline\")\n",
        "print()\n",
        "print(\"No. of training data = %d\" % len(X_train))\n",
        "print(\"No. of validation data = %d\" % len(X_val))\n",
        "print(\"No. of testing data = %d\" % len(X_test))"
      ],
      "metadata": {
        "id": "Fow_aMKbtGdi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "display(y_test.value_counts())"
      ],
      "metadata": {
        "id": "20oSAMddtHaw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# SMOTE\n",
        "\n",
        "from collections import Counter\n",
        "from imblearn.over_sampling import SMOTE \n",
        "\n",
        "print('Original dataset shape %s' % Counter(y_train))\n",
        "sm = SMOTE(random_state=10)\n",
        "X_train, y_train = sm.fit_resample(X_train, y_train)\n",
        "print('Resampled dataset shape %s' % Counter(y_train))"
      ],
      "metadata": {
        "id": "GMRPKOGOtIY5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluation Metrics\n",
        "\n",
        "from sklearn.metrics import confusion_matrix, recall_score, f1_score, roc_auc_score, accuracy_score\n",
        "\n",
        "def evaluation_metrics(y_true, y_pred):\n",
        "  cfm = confusion_matrix(y_true, y_pred).ravel()\n",
        "  acc = accuracy_score(y_true, y_pred)\n",
        "  recs = recall_score(y_true, y_pred, average='binary')\n",
        "  f1s = f1_score(y_true, y_pred, average='binary')\n",
        "  rocs = roc_auc_score(y_true, y_pred, average='macro')\n",
        "  return [cfm, acc, recs, f1s, rocs]"
      ],
      "metadata": {
        "id": "IG_gBLkrtJeF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Confusion matrix format : [ tn , fp , fn , tp ]"
      ],
      "metadata": {
        "id": "7yxGRtintLaB"
      }
    }
  ]
}