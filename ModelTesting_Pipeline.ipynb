{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Model Testing Pipeline"
      ],
      "metadata": {
        "id": "X0gcT8nXCSrj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Identifying the best model (considered with best parameters of each respectively)\n",
        "1.   Re-train models using both training and validation data\n",
        "2.   Evaluate models using testing data"
      ],
      "metadata": {
        "id": "offcn2_6XQuz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Basic Libraries\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sb\n",
        "import matplotlib.pyplot as plt\n",
        "from datetime import datetime\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "MHtSfJxdWlq0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9bfdf8fb-e7df-427c-dbb6-3d5c4b325964"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Data Source\n",
        "\n",
        "df = pd.read_csv(\"/content/drive/MyDrive/Senior Project/Datasets/cleaned_gee_data.csv\")\n",
        "df = df.drop(columns = ['Unnamed: 0'], axis=1)\n",
        "df.head()"
      ],
      "metadata": {
        "id": "0GxSoEprWoLW",
        "outputId": "0b7cdf3a-93e7-42f2-c909-fda6b57527ae",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 270
        }
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   LATITUDE  LONGITUDE  ACQ_DATE  ACQ_TIME  OPEN_TIME  CLOSE_TIME  BRIGHTNESS  \\\n",
              "0 -5.466232  -0.176027 -1.866392  0.634294   0.506405    0.526945   -2.231078   \n",
              "1 -5.466232  -0.176027 -1.866392  0.634294   0.506405    0.526945   -2.231078   \n",
              "2 -5.466232  -0.176027 -1.866392  0.634294   0.506405    0.526945   -2.231078   \n",
              "3 -5.466232  -0.176027 -1.866392  0.634294   0.506405    0.526945   -2.231078   \n",
              "4 -5.433352  -0.197441 -1.723773  0.634294   2.286080    1.793843   -1.141613   \n",
              "\n",
              "   FIRE_OCCURRED  CO_MOL/M2  SO2_MOL/M2  NO2_MOL/M2  O3_MOL/M2  LOCATION  \\\n",
              "0              0  -0.024223   -0.474440   -1.152277  -0.511001 -1.159086   \n",
              "1              0   0.113599   -0.474440   -1.152277  -0.511001 -1.159086   \n",
              "2              0  -0.024223   -0.474440   -1.361255  -0.511001 -1.159086   \n",
              "3              0   0.113599   -0.474440   -1.361255  -0.511001 -1.159086   \n",
              "4              0  -0.967684    0.339667   -1.251770   0.426114 -1.159086   \n",
              "\n",
              "   INSTRUMENT  DRY_SEASON  \n",
              "0           0           1  \n",
              "1           0           1  \n",
              "2           0           1  \n",
              "3           0           1  \n",
              "4           0           1  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-fc031ea6-e21c-4345-ba9c-4f44e034d732\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>LATITUDE</th>\n",
              "      <th>LONGITUDE</th>\n",
              "      <th>ACQ_DATE</th>\n",
              "      <th>ACQ_TIME</th>\n",
              "      <th>OPEN_TIME</th>\n",
              "      <th>CLOSE_TIME</th>\n",
              "      <th>BRIGHTNESS</th>\n",
              "      <th>FIRE_OCCURRED</th>\n",
              "      <th>CO_MOL/M2</th>\n",
              "      <th>SO2_MOL/M2</th>\n",
              "      <th>NO2_MOL/M2</th>\n",
              "      <th>O3_MOL/M2</th>\n",
              "      <th>LOCATION</th>\n",
              "      <th>INSTRUMENT</th>\n",
              "      <th>DRY_SEASON</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>-5.466232</td>\n",
              "      <td>-0.176027</td>\n",
              "      <td>-1.866392</td>\n",
              "      <td>0.634294</td>\n",
              "      <td>0.506405</td>\n",
              "      <td>0.526945</td>\n",
              "      <td>-2.231078</td>\n",
              "      <td>0</td>\n",
              "      <td>-0.024223</td>\n",
              "      <td>-0.474440</td>\n",
              "      <td>-1.152277</td>\n",
              "      <td>-0.511001</td>\n",
              "      <td>-1.159086</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>-5.466232</td>\n",
              "      <td>-0.176027</td>\n",
              "      <td>-1.866392</td>\n",
              "      <td>0.634294</td>\n",
              "      <td>0.506405</td>\n",
              "      <td>0.526945</td>\n",
              "      <td>-2.231078</td>\n",
              "      <td>0</td>\n",
              "      <td>0.113599</td>\n",
              "      <td>-0.474440</td>\n",
              "      <td>-1.152277</td>\n",
              "      <td>-0.511001</td>\n",
              "      <td>-1.159086</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>-5.466232</td>\n",
              "      <td>-0.176027</td>\n",
              "      <td>-1.866392</td>\n",
              "      <td>0.634294</td>\n",
              "      <td>0.506405</td>\n",
              "      <td>0.526945</td>\n",
              "      <td>-2.231078</td>\n",
              "      <td>0</td>\n",
              "      <td>-0.024223</td>\n",
              "      <td>-0.474440</td>\n",
              "      <td>-1.361255</td>\n",
              "      <td>-0.511001</td>\n",
              "      <td>-1.159086</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>-5.466232</td>\n",
              "      <td>-0.176027</td>\n",
              "      <td>-1.866392</td>\n",
              "      <td>0.634294</td>\n",
              "      <td>0.506405</td>\n",
              "      <td>0.526945</td>\n",
              "      <td>-2.231078</td>\n",
              "      <td>0</td>\n",
              "      <td>0.113599</td>\n",
              "      <td>-0.474440</td>\n",
              "      <td>-1.361255</td>\n",
              "      <td>-0.511001</td>\n",
              "      <td>-1.159086</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>-5.433352</td>\n",
              "      <td>-0.197441</td>\n",
              "      <td>-1.723773</td>\n",
              "      <td>0.634294</td>\n",
              "      <td>2.286080</td>\n",
              "      <td>1.793843</td>\n",
              "      <td>-1.141613</td>\n",
              "      <td>0</td>\n",
              "      <td>-0.967684</td>\n",
              "      <td>0.339667</td>\n",
              "      <td>-1.251770</td>\n",
              "      <td>0.426114</td>\n",
              "      <td>-1.159086</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-fc031ea6-e21c-4345-ba9c-4f44e034d732')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-fc031ea6-e21c-4345-ba9c-4f44e034d732 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-fc031ea6-e21c-4345-ba9c-4f44e034d732');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.info()"
      ],
      "metadata": {
        "id": "_YD_aLsrWoFf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "40b2b595-71ab-41c6-e296-4e17ca5b3dd8"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 171893 entries, 0 to 171892\n",
            "Data columns (total 15 columns):\n",
            " #   Column         Non-Null Count   Dtype  \n",
            "---  ------         --------------   -----  \n",
            " 0   LATITUDE       171893 non-null  float64\n",
            " 1   LONGITUDE      171893 non-null  float64\n",
            " 2   ACQ_DATE       171893 non-null  float64\n",
            " 3   ACQ_TIME       171893 non-null  float64\n",
            " 4   OPEN_TIME      171893 non-null  float64\n",
            " 5   CLOSE_TIME     171893 non-null  float64\n",
            " 6   BRIGHTNESS     171893 non-null  float64\n",
            " 7   FIRE_OCCURRED  171893 non-null  int64  \n",
            " 8   CO_MOL/M2      171893 non-null  float64\n",
            " 9   SO2_MOL/M2     171893 non-null  float64\n",
            " 10  NO2_MOL/M2     171893 non-null  float64\n",
            " 11  O3_MOL/M2      171893 non-null  float64\n",
            " 12  LOCATION       171893 non-null  float64\n",
            " 13  INSTRUMENT     171893 non-null  int64  \n",
            " 14  DRY_SEASON     171893 non-null  int64  \n",
            "dtypes: float64(12), int64(3)\n",
            "memory usage: 19.7 MB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "display(df['FIRE_OCCURRED'].value_counts())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "id": "jXbXzzezgiT4",
        "outputId": "41ff3b39-2708-423d-ea12-bf8ebac7000d"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "0    170544\n",
              "1      1349\n",
              "Name: FIRE_OCCURRED, dtype: int64"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X = df.drop('FIRE_OCCURRED', axis=1)\n",
        "y = df['FIRE_OCCURRED']"
      ],
      "metadata": {
        "id": "lRQpZTs5hQ7x"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Training, Testing Split\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# 90:10\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.10, random_state=10, shuffle=True)\n",
        "\n",
        "Original = [X_train, X_test, y_train, y_test] # For reference"
      ],
      "metadata": {
        "id": "LF5R0TqqWqAQ"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if len(X_train)==len(y_train) and len(X_test) == len(y_test):\n",
        "  print(\"X and y data length matching\")\n",
        "else:\n",
        "  print(\"Error in data preparation pipeline\")\n",
        "print()\n",
        "print(\"No. of training data = %d\" % len(X_train))\n",
        "print(\"No. of testing data = %d\" % len(X_test))"
      ],
      "metadata": {
        "id": "Q1mt3NsQWgVN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "517045bb-5353-4ba3-f035-cc4ab7c90380"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X and y data length matching\n",
            "\n",
            "No. of training data = 154703\n",
            "No. of testing data = 17190\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "display(y_test.value_counts())"
      ],
      "metadata": {
        "id": "pIhtWUGDmlHn",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "outputId": "8226ae84-1315-48dd-869c-5ebd4cadeefc"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "0    17059\n",
              "1      131\n",
              "Name: FIRE_OCCURRED, dtype: int64"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# SMOTE\n",
        "\n",
        "from collections import Counter\n",
        "from imblearn.over_sampling import SMOTE \n",
        "\n",
        "print('Original dataset shape %s' % Counter(y_train))\n",
        "sm = SMOTE(random_state=10)\n",
        "X_train, y_train = sm.fit_resample(X_train, y_train)\n",
        "print('Resampled dataset shape %s' % Counter(y_train))"
      ],
      "metadata": {
        "id": "GhX5M0pSnDq7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c6583ad2-2f79-4819-8e1d-9462586737b9"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original dataset shape Counter({0: 153485, 1: 1218})\n",
            "Resampled dataset shape Counter({0: 153485, 1: 153485})\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluation Metrics\n",
        "\n",
        "from sklearn.metrics import confusion_matrix, recall_score, f1_score, roc_auc_score, accuracy_score\n",
        "\n",
        "def evaluation_metrics(y_true, y_pred):\n",
        "  cfm = confusion_matrix(y_true, y_pred).ravel()\n",
        "  acc = accuracy_score(y_true, y_pred)\n",
        "  recs = recall_score(y_true, y_pred, average='binary')\n",
        "  f1s = f1_score(y_true, y_pred, average='binary')\n",
        "  rocs = roc_auc_score(y_true, y_pred, average='macro')\n",
        "  return [cfm, acc, recs, f1s, rocs]"
      ],
      "metadata": {
        "id": "AsnI9sv5nNyu"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Confusion matrix format : [ tn , fp , fn , tp ]"
      ],
      "metadata": {
        "id": "bPS8aE8bpEa4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Store Model Parameters and Eval\n",
        "\n",
        "models_final = pd.DataFrame(columns = ['model_name', 'model', 'parameters'])\n",
        "models_test = pd.DataFrame(columns = ['model_name', 'confusion_matrix', 'accuracy', 'recall', 'f1_score', 'roc_auc_score'])"
      ],
      "metadata": {
        "id": "beEJSW87njvC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jZr8lVAHyw_I"
      },
      "outputs": [],
      "source": [
        "# Import ML Algorithms\n",
        "\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "import xgboost\n",
        "from xgboost import XGBClassifier\n",
        "import lightgbm\n",
        "from lightgbm import LGBMClassifier\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from sklearn.ensemble import VotingClassifier\n",
        "\n",
        "# Save Model\n",
        "\n",
        "import pickle"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Logistic Regression\n",
        "\n",
        "- Library: Scikit-learn\n",
        "- 39 seconds to train\n",
        "\n",
        "**Best Parameters:**\n",
        "\n",
        "{'warm_start': False,\n",
        " 'solver': 'newton-cg',\n",
        " 'penalty': 'none',\n",
        " 'max_iter': 247,\n",
        " 'dual': False,\n",
        " 'C': 0}"
      ],
      "metadata": {
        "id": "Xcwy2Vgsuu56"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "name = 'log_clf'\n",
        "\n",
        "log_clf = LogisticRegression(penalty = 'none', \n",
        "                             warm_start = False,\n",
        "                             solver = 'newton-cg',\n",
        "                             max_iter = 247,\n",
        "                             dual = False,\n",
        "                             C = 0,\n",
        "                             n_jobs = -1, \n",
        "                             random_state = 10\n",
        "                             ).fit(X_train,y_train)\n",
        "\n",
        "y_true = y_test\n",
        "y_pred = log_clf.predict(X_test)\n",
        "evaluation_results = evaluation_metrics(y_true, y_pred)\n",
        "\n",
        "models_final = models_final.append({'model_name': name, \n",
        "                        'model': log_clf, \n",
        "                        'parameters': log_clf.get_params()}, \n",
        "                       ignore_index=True)\n",
        "\n",
        "models_test = models_test.append({'model_name': name, \n",
        "                                  'confusion_matrix' : evaluation_results[0], \n",
        "                                  'accuracy': evaluation_results[1], \n",
        "                                  'recall' : evaluation_results[2], \n",
        "                                  'f1_score': evaluation_results[3],\n",
        "                                  'roc_auc_score': evaluation_results[4]}, \n",
        "                                 ignore_index=True)"
      ],
      "metadata": {
        "id": "GTz0ABHmZXIA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2a8d878e-32bf-4f44-cc26-f05d9997121d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Save Model\n",
        "pickle.dump(log_clf, open('log_clf.sav', 'wb')) \n",
        "\n",
        "# Load Model\n",
        "# log_clf = pickle.load(open('log_clf.sav', 'rb'))"
      ],
      "metadata": {
        "id": "awohG7WaP4AL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Support Vector Machine (SVM)\n",
        "\n",
        "- Library: Scikit-learn\n",
        "\n",
        "- Deprecated. Poor performance no matter what.\n",
        "\n",
        "**Best Parameters:**"
      ],
      "metadata": {
        "id": "1LPWXBKHuu3j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_SVM = Original[0]\n",
        "X_test_SVM = Original[1]\n",
        "y_train_SVM = Original[2]\n",
        "y_test_SVM = Original[3]"
      ],
      "metadata": {
        "id": "HpYzEFK-ZXez"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_train_SVM.value_counts()"
      ],
      "metadata": {
        "id": "r_PiEhleyUgO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Undersampling\n",
        "\n",
        "from imblearn.under_sampling import RandomUnderSampler\n",
        "\n",
        "rus = RandomUnderSampler(random_state=10)\n",
        "X_train_SVM, y_train_SVM = rus.fit_resample(X_train_SVM, y_train_SVM)"
      ],
      "metadata": {
        "id": "xm5dMsbQyYti"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "display(y_train_SVM.value_counts())"
      ],
      "metadata": {
        "id": "NIAB45oCyhzw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "name = 'svc_clf'\n",
        "\n",
        "svc_clf = SVC(kernel = 'rbf', \n",
        "              random_state = 10\n",
        "              ).fit(X_train_SVM,y_train_SVM)\n",
        "\n",
        "y_true = y_test_SVM\n",
        "y_pred = svc_clf.predict(X_test_SVM)\n",
        "evaluation_results = evaluation_metrics(y_true, y_pred)\n",
        "\n",
        "models_final = models_final.append({'model_name': name, \n",
        "                        'model': svc_clf, \n",
        "                        'parameters': svc_clf.get_params()}, \n",
        "                       ignore_index=True)\n",
        "\n",
        "models_test = models_test.append({'model_name': name, \n",
        "                                  'confusion_matrix' : evaluation_results[0], \n",
        "                                  'accuracy': evaluation_results[1], \n",
        "                                  'recall' : evaluation_results[2], \n",
        "                                  'f1_score': evaluation_results[3],\n",
        "                                  'roc_auc_score': evaluation_results[4]}, \n",
        "                                 ignore_index=True)"
      ],
      "metadata": {
        "id": "vio-Fo6Nyl9S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Save Model\n",
        "pickle.dump(svc_clf, open('svc_clf.sav', 'wb')) \n",
        "\n",
        "# Load Model\n",
        "# svc_clf = pickle.load(open('svc_clf.sav', 'rb'))"
      ],
      "metadata": {
        "id": "JxxyWrHYUM94"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Naive Bayes\n",
        "\n",
        "- Library: Scikit-learn\n",
        "- 1 minute to train\n",
        "\n",
        "**Best Parameters:**\n",
        "\n",
        "{'var_smoothing': 1e-20}"
      ],
      "metadata": {
        "id": "jFKJ-rs3uu1O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "name = 'bayes_clf'\n",
        "\n",
        "bayes_clf = GaussianNB(var_smoothing = 1e-20\n",
        "                       ).fit(X_train,y_train)\n",
        "\n",
        "y_true = y_test\n",
        "y_pred = bayes_clf.predict(X_test)\n",
        "evaluation_results = evaluation_metrics(y_true, y_pred)\n",
        "\n",
        "models_final = models_final.append({'model_name': name, \n",
        "                        'model': bayes_clf, \n",
        "                        'parameters': bayes_clf.get_params()}, \n",
        "                       ignore_index=True)\n",
        "\n",
        "models_test = models_test.append({'model_name': name, \n",
        "                                  'confusion_matrix' : evaluation_results[0], \n",
        "                                  'accuracy': evaluation_results[1], \n",
        "                                  'recall' : evaluation_results[2], \n",
        "                                  'f1_score': evaluation_results[3],\n",
        "                                  'roc_auc_score': evaluation_results[4]}, \n",
        "                                 ignore_index=True)"
      ],
      "metadata": {
        "id": "xX1Uk1TcZX4R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Save Model\n",
        "pickle.dump(bayes_clf, open('bayes_clf.sav', 'wb')) \n",
        "\n",
        "# Load Model\n",
        "# bayes_clf = pickle.load(open('bayes_clf.sav', 'rb'))"
      ],
      "metadata": {
        "id": "TNFSyBguUQs7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## K-Nearest Neighbor\n",
        "\n",
        "- Library: Scikit-learn\n",
        "- 1 mins 10 seconds to train\n",
        "\n",
        "**Best Parameters:**\n",
        "\n",
        "{'n_neighbors': 5, 'algorithm':'auto', 'leaf_size':30 }"
      ],
      "metadata": {
        "id": "tLaZu_G9uuzC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "name = 'neigh_clf'\n",
        "\n",
        "neigh_clf = KNeighborsClassifier(n_neighbors = 5, \n",
        "                                 algorithm = 'auto',\n",
        "                                 leaf_size = 30,\n",
        "                                 p = 2,\n",
        "                                 metric = 'minkowski',\n",
        "                                 n_jobs = -1, \n",
        "                                 ).fit(X_train,y_train)\n",
        "\n",
        "y_true = y_test\n",
        "y_pred = neigh_clf.predict(X_test)\n",
        "evaluation_results = evaluation_metrics(y_true, y_pred)\n",
        "\n",
        "models_final = models_final.append({'model_name': name, \n",
        "                        'model': neigh_clf, \n",
        "                        'parameters': neigh_clf.get_params()}, \n",
        "                       ignore_index=True)\n",
        "\n",
        "models_test = models_test.append({'model_name': name, \n",
        "                                  'confusion_matrix' : evaluation_results[0], \n",
        "                                  'accuracy': evaluation_results[1], \n",
        "                                  'recall' : evaluation_results[2], \n",
        "                                  'f1_score': evaluation_results[3],\n",
        "                                  'roc_auc_score': evaluation_results[4]}, \n",
        "                                 ignore_index=True)"
      ],
      "metadata": {
        "id": "DDM4MrNrZYTH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Save Model\n",
        "pickle.dump(neigh_clf, open('neigh_clf.sav', 'wb')) \n",
        "\n",
        "# Load Model\n",
        "# neigh_clf = pickle.load(open('neigh_clf.sav', 'rb'))"
      ],
      "metadata": {
        "id": "QFlPN08YUVCk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Decision Tree\n",
        "\n",
        "- Library: Scikit-learn\n",
        "- Very quick to train. Almost immediately trained.\n",
        "\n",
        "**Best Parameters:**\n",
        "\n",
        "{'splitter': 'best',\n",
        " 'min_samples_leaf': 1,\n",
        " 'max_features': 9,\n",
        " 'max_depth': None,\n",
        " 'criterion': 'gini'}\n"
      ],
      "metadata": {
        "id": "h4rV9G4OuurU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "name = 'tree_clf'\n",
        "\n",
        "tree_clf = DecisionTreeClassifier(criterion = 'gini', \n",
        "                                  splitter = 'best', \n",
        "                                  min_samples_leaf = 1,\n",
        "                                  max_features = 9,\n",
        "                                  max_depth = None,\n",
        "                                  random_state = 10\n",
        "                                  ).fit(X_train,y_train)\n",
        "\n",
        "y_true = y_test\n",
        "y_pred = tree_clf.predict(X_test)\n",
        "evaluation_results = evaluation_metrics(y_true, y_pred)\n",
        "\n",
        "models_final = models_final.append({'model_name': name, \n",
        "                        'model': tree_clf, \n",
        "                        'parameters': tree_clf.get_params()}, \n",
        "                       ignore_index=True)\n",
        "\n",
        "models_test = models_test.append({'model_name': name, \n",
        "                                  'confusion_matrix' : evaluation_results[0], \n",
        "                                  'accuracy': evaluation_results[1], \n",
        "                                  'recall' : evaluation_results[2], \n",
        "                                  'f1_score': evaluation_results[3],\n",
        "                                  'roc_auc_score': evaluation_results[4]}, \n",
        "                                 ignore_index=True)"
      ],
      "metadata": {
        "id": "-2V9TCX1ZY-y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Save Model\n",
        "pickle.dump(tree_clf, open('tree_clf.sav', 'wb')) \n",
        "\n",
        "# Load Model\n",
        "# tree_clf = pickle.load(open('tree_clf.sav', 'rb'))"
      ],
      "metadata": {
        "id": "NpSlVQAqUXdP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Random Forest Classifier\n",
        "\n",
        "- Library: Scikit-learn\n",
        "- Very quick to train. Only 6 seconds needed.\n",
        "\n",
        "**Best Parameters:**\n",
        "\n",
        "{'n_estimators': 300,\n",
        " 'min_samples_split': 2,\n",
        " 'min_samples_leaf': 1,\n",
        " 'max_features': 'auto',\n",
        " 'max_depth': 31}"
      ],
      "metadata": {
        "id": "qAaISg5Kuuwi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "name = 'rnd_clf'\n",
        "\n",
        "rnd_clf = RandomForestClassifier(n_estimators = 300, \n",
        "                                  min_samples_split = 2,\n",
        "                                  min_samples_leaf = 1,\n",
        "                                  max_features = 'auto',\n",
        "                                  max_depth = 31, \n",
        "                                  n_jobs = -1, \n",
        "                                  random_state = 10\n",
        "                                  ).fit(X_train,y_train)\n",
        "\n",
        "y_true = y_test\n",
        "y_pred = rnd_clf.predict(X_test)\n",
        "evaluation_results = evaluation_metrics(y_true, y_pred)\n",
        "\n",
        "models_final = models_final.append({'model_name': name, \n",
        "                        'model': rnd_clf, \n",
        "                        'parameters': rnd_clf.get_params()}, \n",
        "                       ignore_index=True)\n",
        "\n",
        "models_test = models_test.append({'model_name': name, \n",
        "                                  'confusion_matrix' : evaluation_results[0], \n",
        "                                  'accuracy': evaluation_results[1], \n",
        "                                  'recall' : evaluation_results[2], \n",
        "                                  'f1_score': evaluation_results[3],\n",
        "                                  'roc_auc_score': evaluation_results[4]}, \n",
        "                                 ignore_index=True)"
      ],
      "metadata": {
        "id": "1ZdpWxd0ZYo3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Save Model\n",
        "pickle.dump(rnd_clf, open('rnd_clf.sav', 'wb')) \n",
        "\n",
        "# Load Model\n",
        "# rnd_clf = pickle.load(open('rnd_clf.sav', 'rb'))"
      ],
      "metadata": {
        "id": "y1I0R1PlUa-y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Gradient Boosting Classifier\n",
        "\n",
        "- Library: Scikit-learn\n",
        "- 1 mins 25 seconds to train\n",
        "\n",
        "**Best Parameters:**\n",
        "\n",
        "{'n_estimators': 500, 'learning_rate':0.5, 'max_depth':1, 'random_state':10}"
      ],
      "metadata": {
        "id": "7Vvojs9tuuoh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "name = 'gboost_clf'\n",
        "\n",
        "gboost_clf = GradientBoostingClassifier(n_estimators = 500, \n",
        "                                        learning_rate = 0.5, \n",
        "                                        max_depth = 1,\n",
        "                                        criterion = 'friedman_mse',\n",
        "                                        random_state = 10\n",
        "                                        ).fit(X_train,y_train)\n",
        "\n",
        "y_true = y_test\n",
        "y_pred = gboost_clf.predict(X_test)\n",
        "evaluation_results = evaluation_metrics(y_true, y_pred)\n",
        "\n",
        "models_final = models_final.append({'model_name': name, \n",
        "                        'model': gboost_clf, \n",
        "                        'parameters': gboost_clf.get_params()}, \n",
        "                       ignore_index=True)\n",
        "\n",
        "models_test = models_test.append({'model_name': name, \n",
        "                                  'confusion_matrix' : evaluation_results[0], \n",
        "                                  'accuracy': evaluation_results[1], \n",
        "                                  'recall' : evaluation_results[2], \n",
        "                                  'f1_score': evaluation_results[3],\n",
        "                                  'roc_auc_score': evaluation_results[4]}, \n",
        "                                 ignore_index=True)"
      ],
      "metadata": {
        "id": "cXDZXJXyZZVj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Save Model\n",
        "pickle.dump(gboost_clf, open('gboost_clf.sav', 'wb')) \n",
        "\n",
        "# Load Model\n",
        "# gboost_clf = pickle.load(open('gboost_clf.sav', 'rb'))"
      ],
      "metadata": {
        "id": "zce_1i0JUdSO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## XGBoost\n",
        "\n",
        "- Library: xgboost\n",
        "- ~6 minutes to train\n",
        "\n",
        "**Best Parameters:**\n",
        "\n",
        "{'n_estimators': 750, 'learning_rate':0.01, 'max_depth':10}"
      ],
      "metadata": {
        "id": "NfVD2dOouulp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "name = 'xgboost_clf'\n",
        "\n",
        "xgboost_clf = XGBClassifier(booster = 'gbtree',\n",
        "                            verbosity = 1,\n",
        "                            n_estimators = 750, \n",
        "                            learning_rate = 0.01,\n",
        "                            max_depth = 10, \n",
        "                            min_child_weight = 1,\n",
        "                            sampling_method = 'uniform',\n",
        "                            gamma = 0,\n",
        "                            random_state = 10\n",
        "                            ).fit(X_train,y_train)\n",
        "\n",
        "y_true = y_test\n",
        "y_pred = xgboost_clf.predict(X_test)\n",
        "evaluation_results = evaluation_metrics(y_true, y_pred)\n",
        "\n",
        "models_final = models_final.append({'model_name': name, \n",
        "                        'model': xgboost_clf, \n",
        "                        'parameters': xgboost_clf.get_params()}, \n",
        "                       ignore_index=True)\n",
        "\n",
        "models_test = models_test.append({'model_name': name, \n",
        "                                  'confusion_matrix' : evaluation_results[0], \n",
        "                                  'accuracy': evaluation_results[1], \n",
        "                                  'recall' : evaluation_results[2], \n",
        "                                  'f1_score': evaluation_results[3],\n",
        "                                  'roc_auc_score': evaluation_results[4]}, \n",
        "                                 ignore_index=True)"
      ],
      "metadata": {
        "id": "6QYj-9csZZvE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Save Model\n",
        "pickle.dump(xgboost_clf, open('xgboost_clf.sav', 'wb')) \n",
        "\n",
        "# Load Model\n",
        "# xgboost_clf = pickle.load(open('xgboost_clf.sav', 'rb'))"
      ],
      "metadata": {
        "id": "zaiGv1r7UgrB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## LightGBM\n",
        "\n",
        "- Library: lightbgm\n",
        "- 3 seconds to train\n",
        "\n",
        "**Best Parameters:**\n",
        "\n",
        "{'n_estimators': 1000, 'learning_rate':0.1, 'max_depth':3, 'random_state':10}"
      ],
      "metadata": {
        "id": "X23LZaWruugg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "name = 'lightgbm_clf'\n",
        "\n",
        "lightgbm_clf = LGBMClassifier(booster = 'gbdt',\n",
        "                              n_estimators = 1000, \n",
        "                              num_iterations = 100,\n",
        "                              learning_rate = 0.1, \n",
        "                              max_depth = 3,\n",
        "                              num_leaves = 31,\n",
        "                              tree_learner = 'serial',\n",
        "                              random_state = 10\n",
        "                              ).fit(X_train,y_train)\n",
        "\n",
        "y_true = y_test\n",
        "y_pred = lightgbm_clf.predict(X_test)\n",
        "evaluation_results = evaluation_metrics(y_true, y_pred)\n",
        "\n",
        "models_final = models_final.append({'model_name': name, \n",
        "                        'model': lightgbm_clf, \n",
        "                        'parameters': lightgbm_clf.get_params()}, \n",
        "                       ignore_index=True)\n",
        "\n",
        "models_test = models_test.append({'model_name': name, \n",
        "                                  'confusion_matrix' : evaluation_results[0], \n",
        "                                  'accuracy': evaluation_results[1], \n",
        "                                  'recall' : evaluation_results[2], \n",
        "                                  'f1_score': evaluation_results[3],\n",
        "                                  'roc_auc_score': evaluation_results[4]}, \n",
        "                                 ignore_index=True)"
      ],
      "metadata": {
        "id": "B0wkCOloZaJc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Save Model\n",
        "pickle.dump(lightgbm_clf, open('lightgbm_clf.sav', 'wb')) \n",
        "\n",
        "# Load Model\n",
        "# lightgbm_clf = pickle.load(open('lightgbm_clf.sav', 'rb'))"
      ],
      "metadata": {
        "id": "hKuZKlbHUjKl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Artificial Neural Network\n",
        "\n",
        "- Library: Keras, Tensorflow\n",
        "- Approximately 30+ minutes to train\n",
        "\n",
        "**Best Parameters:**"
      ],
      "metadata": {
        "id": "9ZkjCtnBuuZq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "name = 'ann_clf'\n",
        "\n",
        "ann_clf = keras.models.Sequential([\n",
        "    keras.layers.Dense(17, input_shape=(X_train.shape[1],), activation='relu'), # 16 columns. 1 bias term to accelerate activation of a node.\n",
        "    keras.layers.Dense(8, activation='relu'), # One hidden layer is sufficient for the large majority of problems. \n",
        "    # Set the number of neurons in the hidden layer as the mean of the neurons in the input and output layers.\n",
        "    keras.layers.Dense(1, activation='sigmoid'), # Only 1 acceptable unless softmax activation function is used\n",
        "])\n",
        "\n",
        "ann_clf.summary()"
      ],
      "metadata": {
        "id": "6arjXn0ZZafL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Shuffle Data since SMOTE appends many 1s at the end\n",
        "\n",
        "from sklearn.utils import shuffle\n",
        "\n",
        "X_train_ANN, y_train_ANN = shuffle(X_train, y_train, random_state = 10)"
      ],
      "metadata": {
        "id": "vj52PJMuOEEt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "display(y_train_ANN.value_counts())"
      ],
      "metadata": {
        "id": "s2hCVFYFOGKG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "display(y_test.value_counts())"
      ],
      "metadata": {
        "id": "qkyja7zKOJhE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ann_clf.compile(optimizer = 'adam', \n",
        "                metrics=['accuracy'], \n",
        "                loss ='binary_crossentropy')\n",
        "\n",
        "record = ann_clf.fit(\n",
        "            X_train_ANN, \n",
        "            y_train_ANN, \n",
        "            validation_data = (X_test, y_test), \n",
        "            batch_size = 10, \n",
        "            epochs = 50)"
      ],
      "metadata": {
        "id": "fSMBrn5lOPjl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_true = y_test\n",
        "prediction = ann_clf.predict(X_test)\n",
        "prediction = pd.Series(prediction[:, 0])\n",
        "y_pred = []\n",
        "\n",
        "for i in range(len(prediction)):\n",
        "  if prediction[i] >= 0.5:\n",
        "    y_pred.append(1)\n",
        "  else:\n",
        "    y_pred.append(0)\n",
        "\n",
        "evaluation_results = evaluation_metrics(y_true, y_pred)\n",
        "\n",
        "models_final = models_final.append({'model_name': name, \n",
        "                        'model': ann_clf, \n",
        "                        'parameters': ann_clf.layers}, \n",
        "                       ignore_index=True)\n",
        "\n",
        "models_test = models_test.append({'model_name': name, \n",
        "                                  'confusion_matrix' : evaluation_results[0], \n",
        "                                  'accuracy': evaluation_results[1], \n",
        "                                  'recall' : evaluation_results[2], \n",
        "                                  'f1_score': evaluation_results[3],\n",
        "                                  'roc_auc_score': evaluation_results[4]}, \n",
        "                                 ignore_index=True)"
      ],
      "metadata": {
        "id": "LBW9ybn_ORDF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Save Model\n",
        "ann_clf.save('ann_clf.h5') \n",
        "\n",
        "# Load Model\n",
        "# ann_clf = tf.keras.models.load_model('ann_clf.h5')"
      ],
      "metadata": {
        "id": "zpqGEd-mUu_c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Ensemble Learning\n",
        "\n",
        "- Library: Scikit-learn, Keras, Tensorflow\n",
        "- 7 minutes to train\n",
        "\n",
        "**Best Parameters:**\n",
        "\n",
        "{'voting': 'hard', 'n_jobs': -1}"
      ],
      "metadata": {
        "id": "2splAOL5vKme"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "display(models_test)"
      ],
      "metadata": {
        "id": "J0W9wksKZa5w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Confusion matrix format : [ tn , fp , fn , tp ]"
      ],
      "metadata": {
        "id": "vOXxERQZOgc8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print('Best Model By Accuracy')\n",
        "print(models_test.loc[models_test['accuracy'] == max(models_test['accuracy'])].model_name.to_string(index=False))\n",
        "print('-----------------------')\n",
        "print('Best Model By Recall')\n",
        "print(models_test.loc[models_test['recall'] == max(models_test['recall'])].model_name.to_string(index=False))\n",
        "print('-----------------------')\n",
        "print('Best Model By F1')\n",
        "print(models_test.loc[models_test['f1_score'] == max(models_test['f1_score'])].model_name.to_string(index=False))\n",
        "print('-----------------------')\n",
        "print('Best Model By ROC')\n",
        "print(models_test.loc[models_test['roc_auc_score'] == max(models_test['roc_auc_score'])].model_name.to_string(index=False))\n",
        "print('-----------------------')"
      ],
      "metadata": {
        "id": "WtqTQizSOfOI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "name = 'ensem_clf'\n",
        "\n",
        "ensem_clf = VotingClassifier(estimators=[('m1', xgboost_clf), ('m2', tree_clf), ('m3', rnd_clf)],\n",
        "                             voting = 'hard',\n",
        "                             n_jobs = -1, \n",
        "                             ).fit(X_train,y_train)\n",
        "\n",
        "y_true = y_test\n",
        "y_pred = ensem_clf.predict(X_test)\n",
        "evaluation_results = evaluation_metrics(y_true, y_pred)\n",
        "\n",
        "models_final = models_final.append({'model_name': name, \n",
        "                        'model': ensem_clf, \n",
        "                        'parameters': ensem_clf.get_params()}, \n",
        "                       ignore_index=True)\n",
        "\n",
        "models_test = models_test.append({'model_name': name, \n",
        "                                  'confusion_matrix' : evaluation_results[0], \n",
        "                                  'accuracy': evaluation_results[1], \n",
        "                                  'recall' : evaluation_results[2], \n",
        "                                  'f1_score': evaluation_results[3],\n",
        "                                  'roc_auc_score': evaluation_results[4]}, \n",
        "                                 ignore_index=True)"
      ],
      "metadata": {
        "id": "lx135hAGOn3Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Save Model\n",
        "pickle.dump(ensem_clf, open('ensem_clf.sav', 'wb')) \n",
        "\n",
        "# Load Model\n",
        "# ensem_clf = pickle.load(open('ensem_clf.sav', 'rb'))"
      ],
      "metadata": {
        "id": "VzdBh8CJUnQi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Discussion"
      ],
      "metadata": {
        "id": "X5HHciHoO1we"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "display(models_final)"
      ],
      "metadata": {
        "id": "RNhaMzBeO39g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "display(models_test)"
      ],
      "metadata": {
        "id": "w7582rF8O1ll"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('Best Model By Accuracy')\n",
        "print(models_test.loc[models_test['accuracy'] == max(models_test['accuracy'])].model_name.to_string(index=False))\n",
        "print('-----------------------')\n",
        "print('Best Model By Recall')\n",
        "print(models_test.loc[models_test['recall'] == max(models_test['recall'])].model_name.to_string(index=False))\n",
        "print('-----------------------')\n",
        "print('Best Model By F1')\n",
        "print(models_test.loc[models_test['f1_score'] == max(models_test['f1_score'])].model_name.to_string(index=False))\n",
        "print('-----------------------')\n",
        "print('Best Model By ROC')\n",
        "print(models_test.loc[models_test['roc_auc_score'] == max(models_test['roc_auc_score'])].model_name.to_string(index=False))\n",
        "print('-----------------------')"
      ],
      "metadata": {
        "id": "UIIwktbiO-KH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "After model testing, the best model identified is xgboost_clf with the following parameters\n",
        "\n",
        "* booster = 'gbtree',\n",
        "* verbosity = 1,\n",
        "* n_estimators = 750, \n",
        "* learning_rate = 0.01,\n",
        "* max_depth = 10, \n",
        "* min_child_weight = 1,\n",
        "* sampling_method = 'uniform',\n",
        "* gamma = 0,\n",
        "* random_state = 10\n",
        "\n",
        "Full version:\n",
        "{'base_score': 0.5, 'booster': 'gbtree', 'colsample_bylevel': 1, 'colsample_bynode': 1, 'colsample_bytree': 1, 'gamma': 0, 'learning_rate': 0.01, 'max_delta_step': 0, 'max_depth': 10, 'min_child_weight': 1, 'missing': None, 'n_estimators': 750, 'n_jobs': 1, 'nthread': None, 'objective': 'binary:logistic', 'random_state': 10, 'reg_alpha': 0, 'reg_lambda': 1, 'scale_pos_weight': 1, 'seed': None, 'silent': None, 'subsample': 1, 'verbosity': 1, 'sampling_method': 'uniform'}\n",
        "\n",
        "### **Key Findings**\n",
        "**General**\n",
        "* All models have a fairly good accuracy and recall score\n",
        "* F1 score, on the other hand, is quite poor for some\n",
        "  * This is due to the underfitting on an unbalanced dataset. Although SMOTE technique has been applied, some model algorithms are unable to capture the relationship between the input and output variables accurately even with the synthetic data\n",
        "* ROC score is the least important evaluation metrics here since it averages over all possible evaluation thresholds. It is just used for reference.\n",
        "\n",
        "**Random Forest Classifier**\n",
        "* Very quickly trained but performs slightly worse than xgboost_clf in all categories\n",
        "* Slightly worse than tree_clf in recall and roc\n",
        "\n",
        "**Decision Tree**\n",
        "* Very quickly trained but performs slightly worse than xgboost_clf in all categories\n",
        "* Slightly worse than rnd_clf in accuracy and f1\n",
        "\n",
        "**Support Vector Machine**\n",
        "* The SVM was deprecated early on in the development due to its many requirements and poor performance\n",
        "* It requires less training data, thus requiring undersampling technique to be applied\n",
        "* Despite this, it is still unable to gain an accuracy of over 80% and take notoriously long to train\n",
        "* Even the best parameters for it were not identified as it would take too long for possibly the worst result of all models\n",
        "\n",
        "**Logistic Regression**\n",
        "* Not that computationally expensive but poor performance generally in relative to other models, especially in f1_score\n",
        "\n",
        "**Naive Bayes**\n",
        "* Not that computationally expensive but poor performance generally in relative to other models, especially in f1_score\n",
        "\n",
        "**K-Nearest Neighbor**\n",
        "* A slightly worse version of gboost_clf\n",
        "\n",
        "**Gradient Boosting Classifier**\n",
        "* Although the best recall score is obtained by the gboost_clf and ann_clf, it performs massively worse in f1_score and is thus disqualified. \n",
        "\n",
        "**XGBoost**\n",
        "* xgboost_clf is the best performer in all metrics used except for recall, where it comes in 2nd\n",
        " * Upon further inspection, it is revealed that it is only be a different of 1 misclassification of 1 false negative case. \n",
        " * Thus, this can be overlooked\n",
        "* However, one massive downside to xgboost_clf is that it takes significantly longer to train when compared to other models that perform slightly worse (rnd_clf and tree_clf)\n",
        "\n",
        "**LightGBM**\n",
        "* Similar to gboost_clf and ann_clf with its poor performance in f1_score, but also worse than the other 2 in recall score\n",
        "\n",
        "**Artificial Neural Network**\n",
        "* Although the best recall score is obtained by the gboost_clf and ann_clf, it performs massively worse in f1_score and is thus disqualified. \n",
        "* Not much experiment has been conducted on ann_clf yet but this is due to the massive computational resources required. Note that this ann_clf is already nearly optimized in many of its parameters.\n",
        "\n",
        "**Ensemble Learning**\n",
        "* The application of ensemble learning did not improve the result of xgboost_clf especially in the recall score and took a long time to train. "
      ],
      "metadata": {
        "id": "WEqs8FYJO_2G"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Conclusion:**\n",
        "* Thus, xgboost_clf is the best performing model.\n",
        "* Personally, I would rate xgboost_clf > tree_clf = rnd_clf > ensem_clf > ann_clf = gboost_clf > lightgbm_clf >>> rest\n",
        "* If we need to retrain a model quickly, either tree_clf and rnd_clf would be more applicable."
      ],
      "metadata": {
        "id": "vsf9xFNJPCDb"
      }
    }
  ]
}